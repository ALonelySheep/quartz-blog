{"/":{"title":"Cyan's Blog","content":"Welcome!ğŸ‰ I'm Cyan Fu, a master student at Carnegie Mellon University studying Artificial Intelligence. \n\nI write about anything and everything here, and my main interest lies at the intersection of AI and 3D vision. I hope you find something interesting here!\n\nCheck out the network at the bottom of the page!\n\n\u003e [!info] Site under construction\n\u003e \n\u003e I'm trying to build a new site with better LaTeX support and automatic Chinese \u003c-\u003e English translation with GPT4. \n\u003e \n\u003e Sorry if some link is broken!\n\n## How about reading something about ...\n### Math\n- ä¸€ä¸ªæŠ½è±¡è€Œæœ‰è¶£çš„å¼•ç†ï¼š [Johnson Lindenstrauss Lemma](notes/2021/2021.12/Johnson%20Lindenstrauss%20Lemma%20-%20Publish%20Version.md)\n- [ä»äºŒé¡¹åˆ†å¸ƒåˆ°æ³Šæ¾åˆ†å¸ƒå†åˆ°æŒ‡æ•°åˆ†å¸ƒ-From Binomial Distribution to Poisson Distribution to Exponential Distribution](notes/2022/2022.5/ä»äºŒé¡¹åˆ†å¸ƒåˆ°æ³Šæ¾åˆ†å¸ƒå†åˆ°æŒ‡æ•°åˆ†å¸ƒ-From%20Binomial%20Distribution%20to%20Poisson%20Distribution%20to%20Exponential%20Distribution.md)\n- [ä¸ºä»€ä¹ˆæ–¹å·®çš„åˆ†æ¯å¸¸å¸¸æ˜¯n-1](notes/2021/2021.10/ä¸ºä»€ä¹ˆæ–¹å·®çš„åˆ†æ¯å¸¸å¸¸æ˜¯n-1.md)\n- [é…‰çŸ©é˜µä¸ºä»€ä¹ˆå«é…‰çŸ©é˜µ](notes/2021/2021.11/é…‰çŸ©é˜µä¸ºä»€ä¹ˆå«é…‰çŸ©é˜µ.md)\n- å¦‚ä½•å¯¹çŸ©é˜µæ±‚å¯¼ï¼Ÿ\n\t- [çŸ©é˜µçš„æ±‚å¯¼](notes/2021/2021.8/çŸ©é˜µçš„æ±‚å¯¼.md)\n\t- [D2L-4-çŸ©é˜µæ±‚å¯¼](notes/2022/2022.1/D2L-4-çŸ©é˜µæ±‚å¯¼.md)\n- [Diffie-Hellmané—®é¢˜](notes/2021/2021.6/Diffie-Hellmané—®é¢˜.md)\n- [KL_Divergence-KLæ•£åº¦](notes/2022/2022.2/KL_Divergence-KLæ•£åº¦.md)\n- [Gilbert Strang æ·±å…¥æµ…å‡ºæœºå™¨å­¦ä¹ çš„çŸ©é˜µçŸ¥è¯†](notes/2022/2022.10/Gilbert%20Strang%20æ·±å…¥æµ…å‡ºæœºå™¨å­¦ä¹ çš„çŸ©é˜µçŸ¥è¯†.md)\n- [Understanding Bayes' Theorem](notes/2021/2021.12/Understanding%20Bayes'%20Theorem.Md)\n### Machine Learning\n- [What on earth is Logit](notes/2022/2022.2/Logit.md)\n- [ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE](notes/2022/2022.2/ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE.md)\n- [Kernel Regression](notes/2022/2022.4/D2L-64-Kernel%20Regression.md)\n- [Norm in Regularization - Intuition](notes/2022/2022.2/Norm%20in%20Regularization%20-%20Intuition.md)\n- [Fisher Linear Discriminant(Pattern_Classification-Chapter_4)](notes/2021/2021.10/Part.29_Fisher_Linear_Discriminant(Pattern_Classification-Chapter_4).Md)\n- [Cross_Entropy-äº¤å‰ç†µ](notes/2022/2022.2/Cross_Entropy-äº¤å‰ç†µ.md)\n\n### Deep Learning\n- [Convolution-å·ç§¯ï¼Œæ•°å­¦ä¸MLå«ä¹‰](notes/2022/2022.2/D2L-32-Convolution-å·ç§¯.md)\n- [1x1å·ç§¯å±‚æœ‰ä»€ä¹ˆç”¨](notes/2022/2022.2/D2L-36-1x1å·ç§¯å±‚.md)\n- æ™ºèƒ½ç‰ˆåŠ æƒå¹³å‡ï¼šAttention\n\t- [Kernel Regression and Attention](notes/2022/2022.4/D2L-66-Kernel%20Regression%20and%20Attention.md)\n\t- [Attention Scoring Function](notes/2022/2022.4/D2L-67-Attention%20Scoring%20Function.md)\n\t- [å›¾è§£Additive Attention](notes/2022/2022.4/D2L-68-Additive%20Attention.md)\n\t- [Scaled Dot-Product Attention](notes/2022/2022.4/D2L-69-Scaled%20Dot-Product%20Attention.md)\n\t- [Seq2Seq with Attention - Bahdanau Attention](notes/2022/2022.4/D2L-70-Seq2Seq%20with%20Attention%20-%20Bahdanau%20Attention.md)\n\t- [å›¾è§£Multi-Head_Attention](notes/2022/2022.4/D2L-71-Multi-Head_Attention.md)\n\t- [å›¾è§£Self-Attention](notes/2022/2022.4/D2L-72-Self-Attention.md)\n- [æ™ºèƒ½ç‰ˆåŠ æƒå¹³å‡ is All You Need: å›¾è§£Transformer](notes/2022/2022.4/D2L-74-Transformer.md)\n- [ç«¯åˆ°ç«¯å­¦ä¹ -End_to_End_Learning-E2E](notes/2022/2022.5/ç«¯åˆ°ç«¯å­¦ä¹ -End_to_End_Learning-E2E.md)\n- [å¥½çš„é¢„æµ‹æ¨¡å‹çš„ç‰¹è´¨](notes/2022/2022.2/å¥½çš„é¢„æµ‹æ¨¡å‹çš„ç‰¹è´¨.md)\n- [What is a tensor](notes/2022/2022.1/D2L-1-What_is_a_tensor.md)\n- [è‡ªåŠ¨æ±‚å¯¼](notes/2022/2022.1/D2L-7-è‡ªåŠ¨æ±‚å¯¼.md)\n\t- [ä¸ºä»€ä¹ˆåå‘ä¼ æ’­æ¯”å‰å‘ä¼ æ’­æ›´é«˜æ•ˆ](notes/2022/2022.1/ä¸ºä»€ä¹ˆåå‘ä¼ æ’­æ¯”å‰å‘ä¼ æ’­æ›´é«˜æ•ˆ.md)\n- [MLP-å¤šå±‚æ„ŸçŸ¥æœº](notes/2022/2022.2/D2L-17-MLP-å¤šå±‚æ„ŸçŸ¥æœº.md)\n- [æƒé‡è¡°å‡](notes/2022/2022.2/D2L-22-æƒé‡è¡°å‡.md)\n- [æ•°å€¼ç¨³å®šæ€§](notes/2022/2022.2/D2L-24-æ•°å€¼ç¨³å®šæ€§.md)\n\t- [D2L-25-è®©è®­ç»ƒæ›´åŠ ç¨³å®š-Xavieråˆå§‹åŒ–](notes/2022/2022.2/D2L-25-è®©è®­ç»ƒæ›´åŠ ç¨³å®š-Xavieråˆå§‹åŒ–.md)\n- [ç»å…¸æ¨¡å‹](notes/2022/2022.10/ç»å…¸æ¨¡å‹.md)\n### English\n[æœ‰æ•ˆåœ°èƒŒè¯µGREå•è¯](notes/2022/2022.7/æœ‰æ•ˆåœ°èƒŒè¯µGREå•è¯.md)\n\n### Paul Graham\n[å¦‚ä½•åŠªåŠ›å·¥ä½œ_Paul_Graham](notes/2021/2021.8/å¦‚ä½•åŠªåŠ›å·¥ä½œ_Paul_Graham.md)\n\n## Blog as Network\n- Feel free to explore the graph below!","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%96%B9%E5%B7%AE%E7%9A%84%E5%88%86%E6%AF%8D%E5%B8%B8%E5%B8%B8%E6%98%AFn-1":{"title":"ä¸ºä»€ä¹ˆæ–¹å·®çš„åˆ†æ¯å¸¸å¸¸æ˜¯n-1","content":"# ä¸ºä»€ä¹ˆæ–¹å·®çš„åˆ†æ¯å¸¸å¸¸æ˜¯$n-1$?\n\n\u003cdiv align=\"right\"\u003e 2021-10-29\u003c/div\u003e\n\nTags: #Math/Statistics #Variance\n\n- æŒ‰ç…§å®šä¹‰, æ–¹å·®çš„åˆ†æ¯çš„ç¡®åº”è¯¥æ˜¯$n$\n\n- ä½†æ˜¯å› ä¸ºæˆ‘ä»¬ç”¨æ ·æœ¬çš„å‡å€¼$\\overline X$ä»£æ›¿äº†æ•°å­¦æœŸæœ›$\\mu$, è€Œè¿™ä¸ª$\\overline X$æ˜¯æœ‰è¯¯å·®çš„, $\\frac 1 n \\rightarrow \\frac 1 {(n-1)}$æ˜¯ä¸ºäº†æ¶ˆé™¤è¿™ä¸ªè¯¯å·®.\n\n## è¯¦ç»†è§£é‡Š\n\u003e å‰æï¼š $X_i$ ç›¸äº’ç‹¬ç«‹\n\næŒ‰ç…§å®šä¹‰, æ–¹å·®çš„å…¬å¼æ˜¯:\n$$\\sigma^{2}=\\mathbb E\\left(\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu \\right)^{2}\\right)$$\nå…¶ä¸­, $\\mu$æ˜¯éšæœºå˜é‡çš„æ•°å­¦æœŸæœ›.\n\n- $$\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu \\right)^{2}$$æ˜¯æ–¹å·®çš„æ— åä¼°è®¡\n\nä½†æ˜¯, å®é™…å·¥ä½œä¸­, æ ·æœ¬çš„æ•°å­¦æœŸæœ›å¸¸å¸¸éš¾ä»¥å¾—åˆ° ,æ‰€ä»¥æˆ‘ä»¬ç”¨æ ·æœ¬çš„å‡å€¼æ¥ä»£æ›¿æ•°å­¦æœŸæœ›:\n$$\\mu \\rightarrow \\overline X = \\frac{1}{n} \\sum_{i=1}^{n} X_{i}$$\n\nè¿™ä¼šä¸ä¼šå¸¦æ¥è¯¯å·®å‘¢? å½“ç„¶ä¼š!\n\n- **å¦‚æœç›´æ¥é‡‡ç”¨$\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}$  ä½œä¸ºä¼°è®¡ï¼Œé‚£ä¹ˆä½ ä¼šå€¾å‘äºä½ä¼°æ–¹å·®!** (å˜æˆåä½çš„æœ‰åä¼°è®¡)\n\nè¿™æ˜¯å› ä¸º:\n$$\\begin{aligned}\n\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2} \u0026=\\frac{1}{n} \\sum_{i=1}^{n}\\left[\\left(X_{i}-\\mu\\right)+(\\mu-\\bar{X})\\right]^{2} \\\\\n\u0026=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}+\\frac{2}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)(\\mu-\\bar{X})+\\frac{1}{n} \\sum_{i=1}^{n}(\\mu-\\bar{X})^{2} \\\\\n\u0026=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}+2(\\bar{X}-\\mu)(\\mu-\\bar{X})+(\\mu-\\bar{X})^{2} \\\\\n\u0026=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}-(\\mu-\\bar{X})^{2}\n\\end{aligned}$$\n\næ¢è¨€ä¹‹ï¼Œé™¤éæ­£å¥½ $X=\\mu$, å¦åˆ™æˆ‘ä»¬ä¸€å®šæœ‰\n$$\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}\u003c\\sigma^2$$\n\nè€Œ ï¼ˆè¯æ˜è§[Prove that $E (\\overline{X} - \\mu)^2 = \\frac{1}{n}\\sigma^2$](https://math.stackexchange.com/questions/1363505/prove-that-e-overlinex-mu2-frac1n-sigma2)ï¼‰ï¼š\n$$\\mathrm{E}\\left[(\\bar{X}-\\mu)^{2}\\right]=\\frac{1}{n} \\sigma^{2}$$\n\næ‰€ä»¥:\n\n$$E\\left[\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}\\right]=\\sigma^{2}-\\frac{1}{n} \\sigma^{2}=\\frac{n-1}{n} \\sigma^{2}$$\n\nä¸ºäº†è°ƒæ•´, æˆ‘ä»¬ä¹˜ä¸Š$\\frac n {n-1}$\n\nå…¬å¼ä¹Ÿéšä¹‹å˜ä¸º:\n$$\n\\frac n {n-1} \\times \\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2} = \\frac{1}{n-1} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2} \n$$\n\n\n\n%%\nä¸‹é¢è¿™ä¸ªè¯´æ³•å¥½åƒæœ‰ç‚¹é—®é¢˜, é—®é¢˜çš„å…³é”®æ˜¯ç›´æ¥ä»£æ¢ä¼šä½¿æ–¹å·®çš„ä¼°è®¡å˜æˆæœ‰åä¼°è®¡\n\næˆ‘ä»¬çœ‹ä»¥ä¸‹ä¾‹å­:\n![](notes/2021/2021.10/assets/img_2022-10-15.gif)\nå›¾ä¸­, ç»¿è‰²æ•£ç‚¹æ˜¯æ ·æœ¬. å¯¹äºå¯èƒ½çš„çœŸå®åˆ†å¸ƒ, æˆ‘ä»¬å–ä¸åŒçš„$\\mu$, å¯ä»¥çœ‹åˆ°, $\\mu$ä¸$\\overline X$çš„è·ç¦»è¶Šå¤§, æ–¹å·®çš„è¯¯å·®ä¹Ÿè¶Šå¤§%%\n\n\n\n\n\n## Source\n- https://www.zhihu.com/question/20099757\n- https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE/3108412\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.10/%E4%BD%8F%E6%88%BF%E8%87%AA%E6%9C%89%E7%8E%87-House_Ownership_Rate":{"title":"ä½æˆ¿è‡ªæœ‰ç‡-House_Ownership_Rate","content":"# ä½æˆ¿è‡ªæœ‰ç‡ - House Ownership Rate\n\n\u003cdiv align=\"right\"\u003e 2021-11-06\u003c/div\u003e\n\nTags: #HousingMarket #Index\n\n- å³æ‹¥æœ‰ä½æˆ¿çš„äººå£å æ€»äººå£çš„æ¯”ç‡\n- ä¸åŒå›½å®¶çš„ç»Ÿè®¡æ–¹å¼ä¸åŒ\n\n[List of countries by home ownership rate](https://en.wikipedia.org/wiki/List_of_countries_by_home_ownership_rate#cite_note-4)\n\n- ä¸­å›½çš„ä½æˆ¿è‡ªæœ‰ç‡ä¸º89%(2018)\n- è€ç‰Œå‘è¾¾ç»æµä½“å¦‚ç¾å›½ã€è‹±å›½ï¼Œä½æˆ¿è‡ªæœ‰ç‡ç¨³å®šåœ¨60%å·¦å³ã€‚å¾·å›½ã€é¦™æ¸¯æ›´ä½ï¼Œä¸åˆ°50%ã€‚\n\n![](notes/2021/2021.10/assets/img_2022-10-15.png)\n![](notes/2021/2021.10/assets/img_2022-10-15-1.png)\n[^3]\n- æˆ‘å›½çš„ä½æˆ¿è‡ªæœ‰ç‡æ¥è¿‘90%ï¼Œ**ä¸»è¦æ˜¯è®¡ç®—å£å¾„ä¸åŒå¯¼è‡´çš„è™šé«˜**ã€‚å›½é™…ä¸Šï¼Œä½æˆ¿è‡ªæœ‰ç‡è®¡ç®—æ–¹æ³•æ˜¯å±…ä½åœ¨è‡ªæœ‰äº§æƒçš„å®¶åº­æˆ·æ•°/å…¨éƒ¨å®¶åº­æˆ·æ•°ï¼Œè€Œæˆ‘å›½åˆ™æ˜¯æŒ‰ç…§è‡ªæœ‰ï¼ˆç§æœ‰ï¼‰ä½å®…å»ºç­‘é¢ç§¯/å®æœ‰ä½å®…å»ºç­‘é¢ç§¯è®¡ç®—ï¼Œå®ä¸ºä½æˆ¿ç§æœ‰ç‡ã€‚ä¸¤è€…æœ‰ä¸¤ä¸ªåŒºåˆ«ï¼Œä¸€æ˜¯å›½å¤–æ˜¯æŒ‰ç…§æˆ·æ•°ï¼Œè€Œæˆ‘å›½æ˜¯æ ¹æ®å»ºç­‘é¢ç§¯ï¼ŒäºŒæ˜¯åè€…å°†æœ¬åœ°æ— æˆ¿ã€ä½†åœ¨å¤–åœ°æœ‰æˆ¿çš„ä¹Ÿçº³å…¥è®¡ç®—ã€‚è€ƒè™‘åˆ°è¿™ä¸¤ä¸ªå› ç´ ï¼Œæˆ‘å›½çš„ä½æˆ¿è‡ªæœ‰ç‡åº”è¯¥å¤„äºè¾ƒåˆç†çš„æ°´å¹³ã€‚[^2]\n\n## About Housing Market\n#### Why is the housing market important to the economy?[^1]\nThe housing market is closely linked to consumer spending. When house prices go up, homeowners become better off and feel more confident. Some people will borrow more against the value of their home, either to spend on goods and services, renovate their house, supplement their pension, or pay off other debt.\n\nWhen house prices go down, homeowners risk that their house will be worth less than their outstanding mortgage.Â  People are therefore more likely to cut down on spending and hold off from making personal investments.\n\n\n\n[^1]: https://www.bankofengland.co.uk/knowledgebank/how-does-the-housing-market-affect-the-economy\n[^2]: http://finance.sina.cn/zl/2019-04-25/zl-ihvhiewr8156465.d.html?from=wap\n[^3]: ä½æˆ¿è‡ªæœ‰ç‡ä¸ç»æµå‘å±•æ°´å¹³â€”â€”åŸºäºä¸­å›½31 ä¸ªçœå’Œåœ°åŒºçš„ç»éªŒåˆ†æä½™ç§‹æ¢…1ï¼Œ2ï¼Œå­™ä¼Ÿå¢3ï¼Œ4ï¼Œéƒ‘æ€é½3ï¼Œ4","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.10/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5_Covariance_Matrix":{"title":"åæ–¹å·®çŸ©é˜µ_Covariance_Matrix","content":"# Covariance Matrix\n\n\u003cdiv align=\"right\"\u003e 2021-10-29\u003c/div\u003e\n\nTags: #Matrix #Math/Statistics \n\n\nhttps://janakiev.com/blog/covariance-matrix/\n\n\n## Variance, Covariance \n\n- **Variance** measures the variation of a single random variable (like height of a person in a population)\n\t$$\\sigma_{x}^{2}=\\mathbb E \\left(\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}\\right)$$\n\tLink: [ä¸ºä»€ä¹ˆæ–¹å·®çš„åˆ†æ¯å¸¸å¸¸æ˜¯n-1](notes/2021/2021.10/ä¸ºä»€ä¹ˆæ–¹å·®çš„åˆ†æ¯å¸¸å¸¸æ˜¯n-1.md)\n\t\n- Whereas **[covariance](notes/2021/2021.12/Covariance-åæ–¹å·®.md)** is a measure of **how much two random variables vary together** (like the height of a person and the weight of a person in a population)\n\t$$\\sigma(x, y)=\\mathbb E\\left(\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)\\right)$$\n\næ‰€ä»¥æ–¹å·®ä¹Ÿå¯ä»¥çœ‹ä½œä¸€ä¸ªéšæœºå˜é‡è‡ªå·±ä¸è‡ªå·±çš„åæ–¹å·®:\n$$\\sigma_{x}^{2} = \\frac{1}{n-1} \\sum_{i=1}^{n}(x_{i}-\\bar{x})(x_{i}-\\bar{x}) = \\sigma(x, x)$$\n\n## åæ–¹å·®çŸ©é˜µ\n[Wikipedia](https://zh.wikipedia.org/zh-hans/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5):\n\nå‡è®¾$X$æ˜¯ä»¥$n$ä¸ªéšæœºå˜é‡ç»„æˆçš„åˆ—å‘é‡ï¼Œ\n\n$\\mathbf{X} = \\begin{bmatrix} X_1 \\\\ X_2 \\\\ \\vdots \\\\ X_n \\end{bmatrix}$\n\nå¹¶ä¸”$\\mu_i$æ˜¯$X_i$çš„æœŸæœ›å€¼ï¼Œå³, $\\mu_i = \\mathrm{E}(X_i)$ã€‚åæ–¹å·®çŸ©é˜µçš„ç¬¬$(i,j)$é …ï¼ˆç¬¬$(i,j)$é …æ˜¯ä¸€ä¸ªåæ–¹å·®ï¼‰è¢«å®šä¹‰ä¸ºå¦‚ä¸‹å½¢å¼ï¼š\n\n$$\\Sigma_{ij}\n= \\mathrm{cov}(X_i, X_j) = \\mathrm{E}\\begin{bmatrix}\n(X_i - \\mu_i) (X_j - \\mu_j)\n\\end{bmatrix}$$\n\nè€Œåæ–¹å·®çŸ©é˜µä¸ºï¼š\n\n$$\\Sigma=\\mathrm{E}\n\\left[\n \\left(\n \\mathbf{X} - \\mathrm{E}[\\mathbf{X}]\n \\right)\n \\left(\n \\mathbf{X} - \\mathrm{E}[\\mathbf{X}]\n \\right)^{\\rm T}\n\\right]$$\n\n\n$$=\n\\begin{bmatrix}\n \\mathrm{E}[(X_1 - \\mu_1)(X_1 - \\mu_1)] \u0026 \\mathrm{E}[(X_1 - \\mu_1)(X_2 - \\mu_2)] \u0026 \\cdots \u0026 \\mathrm{E}[(X_1 - \\mu_1)(X_n - \\mu_n)] \\\\ \\\\\n \\mathrm{E}[(X_2 - \\mu_2)(X_1 - \\mu_1)] \u0026 \\mathrm{E}[(X_2 - \\mu_2)(X_2 - \\mu_2)] \u0026 \\cdots \u0026 \\mathrm{E}[(X_2 - \\mu_2)(X_n - \\mu_n)] \\\\ \\\\\n \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ \\\\\n \\mathrm{E}[(X_n - \\mu_n)(X_1 - \\mu_1)] \u0026 \\mathrm{E}[(X_n - \\mu_n)(X_2 - \\mu_2)] \u0026 \\cdots \u0026 \\mathrm{E}[(X_n - \\mu_n)(X_n - \\mu_n)]\n\\end{bmatrix}$$\n\nçŸ©é˜µä¸­çš„ç¬¬$(i,j)$ä¸ªå…ƒç´ æ˜¯$X_i$ä¸$X_j$çš„åæ–¹å·®\n\n## è¿›ä¸€æ­¥\n\nçŸ©é˜µçš„å¥‡å¼‚å€¼åˆ†è§£å¯ä»¥å°†æ•°æ®è¿˜åŸä¸ºæ™®é€šçš„å½¢å¼, è¿™åœ¨LDAç­‰è®¸å¤šç®—æ³•ä¸­éƒ½æœ‰åº”ç”¨\nè¿›ä¸€æ­¥å¯ä»¥é˜…è¯»ä»¥ä¸‹æ–‡ç« :\nhttps://janakiev.com/blog/covariance-matrix/","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.10/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0-Lagrange_Multiplier":{"title":"æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°-Lagrange_Multiplier","content":"# æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°\n\n\u003cdiv align=\"right\"\u003e 2021-10-29\u003c/div\u003e\n\nTags: #Math #Optimization \n\n\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Lagrange_multiplier.png/300px-Lagrange_multiplier.png)\n\n## Intuition\n$$\\mathcal{L}(x, y, \\lambda)=f(x, y)-\\lambda g(x, y)$$\nåœ¨ä¸€ä¸ªä¸‰ç»´æ›²é¢($f(x,y)$)ä¸Šé¢ç”»äº†ä¸€æ¡æ›²çº¿($g(x,y)$), æ±‚è¿™æ¡æ›²çº¿ä¸Šé¢çš„æœ€ä½ç‚¹.\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/LagrangeMultipliers2D.svg/300px-LagrangeMultipliers2D.svg.png)\n\n## Explanation\n\nä¸­è‹±æ–‡çš„ç»´åŸºç™¾ç§‘å·²ç»è§£é‡Šçš„ååˆ†ç›´è§‚ä¸æ¸…æ™°äº†:\n\n\n- [Chinese](https://zh.wikipedia.org/zh-hans/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0)\n- [English](https://en.wikipedia.org/wiki/Lagrange_multiplier)\n\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.10/%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%96%B9%E5%90%91%E6%98%AF%E5%93%AA%E4%B8%AA%E6%96%B9%E5%90%91-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%A2%AF%E5%BA%A6%E6%98%AF%E5%87%BD%E6%95%B0%E5%A2%9E%E9%95%BF%E6%9C%80%E5%BF%AB%E7%9A%84%E6%96%B9%E5%90%91":{"title":"æ¢¯åº¦çš„æ–¹å‘æ˜¯å“ªä¸ªæ–¹å‘-ä¸ºä»€ä¹ˆæ¢¯åº¦æ˜¯å‡½æ•°å¢é•¿æœ€å¿«çš„æ–¹å‘","content":"# ä¸ºä»€ä¹ˆæ¢¯åº¦æ˜¯å‡½æ•°å¢é•¿æœ€å¿«çš„æ–¹å‘\n\n\u003cdiv align=\"right\"\u003e 2021-10-14\u003c/div\u003e\n\nTags: #Math \n\nçœ‹è¿™ç¯‡æ–‡ç« å¯å¿«é€Ÿå›é¡¾é«˜æ•°:\nhttps://zhuanlan.zhihu.com/p/38525412\n\n## Key Idea\n- å¯¹äºä»»æ„æ–¹å‘ä¸€ä¸ªå¢é‡ $\\Delta z=f\\left(x_{0}+t \\cos \\alpha, y_{0}+t \\sin \\alpha\\right)-f\\left(x_{0}, y_{0}\\right)$ \n- å‡½æ•°æ²¿æ­¤æ–¹å‘çš„å˜åŒ–ç‡ä¸º:\n$$\n\\lim _{t \\rightarrow 0^{+}} \\frac{f\\left(x_{0}+t \\cos \\alpha, y_{0}+t \\sin \\alpha\\right)-f\\left(x_{0}, y_{0}\\right)}{t}=f_{x}\\left(x_{0}, y_{0}\\right) \\cos \\alpha+f_{y}\\left(x_{0}, y_{0}\\right) \\sin \\alpha\n$$\n\n- ç”±äºä¸Šå¼å¯ä»¥çœ‹æˆä¸¤ä¸ªå‘é‡çš„å†…ç§¯, å³ä»¥ä¸‹ä¸¤ä¸ªå‘é‡:\n $\\mathbf{g}=\\left(f_{x}\\left(x_{0}, y_{0}\\right), f_{y}\\left(x_{0}, y_{0}\\right)\\right)$ \n $\\mathbf{e}_{l}=(\\cos \\alpha, \\sin \\alpha)$\nåˆ™:\n$f_{x}\\left(x_{0}, y_{0}\\right) \\cos \\alpha+f_{y}\\left(x_{0}, y_{0}\\right) \\sin \\alpha=\\mathbf{g} \\cdot \\mathbf{e}_{l}=\\left|\\mathbf{g} \\| \\mathbf{e}_{l}\\right| \\cos \\theta=\\textcolor[RGB]{203,77,73}{|\\mathbf{g}| \\cos \\theta}$\n\nå…¶ä¸­ï¼Œ $\\theta$ ä¸º $\\mathbf{g}$ å’Œ $\\mathbf{e}_{l}$ çš„å¤¹è§’ã€‚æ‰€ä»¥æ ¹æ®å¤¹è§’:\n- å½“ $\\theta=0$ æ—¶, å³ $\\mathbf{e}_{l}$ å’Œ $\\mathbf{g}$ æ–¹å‘ç›¸åŒæ—¶ï¼Œå‡½æ•°å˜åŒ–ç‡æœ€å¤§ï¼Œä¸”åœ¨ç‚¹ $\\left(x_{0}, y_{0}\\right)$ å¤„å‘ˆä¸Šå‡è¶‹åŠ¿;\n- å½“ $\\theta=\\pi$ æ—¶ï¼Œå³ $\\mathbf{e}_{l}$ å’Œ $\\mathrm{g}$ æ–¹å‘ç›¸åæ—¶ï¼Œå‡½æ•°å˜åŒ–ç‡æœ€å¤§ï¼Œä¸”åœ¨ç‚¹ $\\left(x_{0}, y_{0}\\right)$ å¤„å‘ˆä¸‹é™è¶‹åŠ¿;\n\nè€Œæ¢¯åº¦çš„å®šä¹‰æ˜¯:\n\nè®¾äºŒå…ƒå‡½æ•° $z=f(x, y)$ åœ¨å¹³é¢åŒºåŸŸDä¸Šå…·æœ‰ä¸€é˜¶è¿ç»­åå¯¼æ•°ï¼Œåˆ™å¯¹äºæ¯ä¸€ä¸ªç‚¹P $(x, y)$ éƒ½å¯å®šå‡ºä¸€ä¸ªå‘é‡ $\\left\\{\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}\\right\\}=f_{x}(x, y) \\bar{i}+f_{y}(x, y) \\bar{j}$,è¯¥å‡½æ•°å°±ç§°ä¸ºå‡½æ•° $z=f(x, y)$ åœ¨ç‚¹ $P(x, y)$ çš„æ¢¯åº¦, è®°ä½œ$grad\\space f (x, y)$ æˆ– $\\nabla f(x, y)$,å³æœ‰:\n$$grad\\space f (x, y)=\\nabla f(x, y)=\\left\\{\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}\\right\\}=f_{x}(x, y) \\vec{i}+f_{y}(x, y) \\vec{j}$$\nå…¶ä¸­ $\\nabla=\\frac{\\partial}{\\partial x} \\vec{i}+\\frac{\\partial}{\\partial y} \\vec{j}$ ç§°ä¸ºäºŒç»´çš„) å‘é‡å¾®ç®—å­æˆ–$Nabla$ç®—å­, $\\nabla f=\\frac{\\partial f}{\\partial x} \\vec{i}+\\frac{\\partial f}{\\partial y} \\vec{j}$ ã€‚\n\næ‰€ä»¥æ¢¯åº¦çš„æ–¹å‘å°±æ˜¯å‘é‡$\\mathbf{g}$çš„æ–¹å‘, æ–¹å‘å¯¼æ•°åœ¨æ¢¯åº¦æ–¹å‘å–å¾—æœ€å¤§å€¼, è¯¥æœ€å¤§å€¼ä¸ºæ¢¯åº¦çš„æ¨¡:\n$$|\\operatorname{grad} f(x, y)|=\\sqrt{\\left(\\frac{\\partial f}{\\partial x}\\right)^{2}+\\left(\\frac{\\partial f}{\\partial y}\\right)^{2}}$$","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.10/CMU15-445_3_Lecture_Note":{"title":"CMU15-445_3_Lecture_Note","content":"# 03 - Database Storage I\n\n\u003cdiv align=\"right\"\u003e 2021-10-20\u003c/div\u003e\n\nTags: #Database\n\n## Outline\nDifferent Layers of the whole system, One layer at a time, from bottom to top.\n![](notes/2021/2021.10/assets/img_2022-10-15-2.png)\n\n## Disk-Oriented Architecture\n- Not in Memory\n- Move data between non-volatile to volatile storage\n\t![](notes/2021/2021.10/assets/img_2022-10-15-3.png)\n\t- æ³¨æ„å¯»å€æ–¹å¼ä¹Ÿåœ¨å˜, ä¸‹é¢çš„æ˜¯ Block-Addressable, ä¸Šé¢çš„æ˜¯Byte-Addressable\n\t- ä¸‹é¢çš„æ˜¯Sequentialçš„ ä¸Šé¢çš„æ˜¯Non-Sequentialçš„\n\t- æˆ‘ä»¬å…³å¿ƒä¸‹é¢çš„ä¸‰å±‚å’Œä¸Šé¢çš„ç¬¬ä¸€å±‚(è¿™é—¨è¯¾), å› ä¸ºä¸‹é¢çš„å®åœ¨æ˜¯å¤ªæ…¢äº†, å…ˆè€ƒè™‘ä¸‹é¢çš„\n\t\t![](notes/2021/2021.10/assets/img_2022-10-15-4.png)\n\t- First hand material: Non-volatile Memory\n\t- ç›´è§‚çš„ç†è§£ä¸åŒå±‚é¢çš„è¯»å–é€Ÿåº¦:\n\t\t![](notes/2021/2021.10/assets/img_2022-10-15-5.png)\n\t- **Goal:** Allow the DBMS to manage databases that exceed the amount of memory available. (Create an illusion that all the data is stored in memory )\n\nHow it works:\n![](notes/2021/2021.10/assets/img_2022-10-15-6.png)\nSyllabus: \n![](notes/2021/2021.10/assets/img_2022-10-15-7.png)\n\n## Why not use the OS?\n### Virtual Memory?\nThe OS only sees a bunch of reads and writes, the DBMS (almost) always wants to control things itself and can do a better job at it.\n\n**mmap**: the way virtual memory works:\n![](notes/2021/2021.10/assets/img_2022-10-15-8.png)\n\n**Problem #1:  How the DBMS represents the database in files on disk:**\n\n(Later) Problem #2: How the DBMS manages its memory and move data back-and-forth from disk. \n\n## Problem #1\n### File Storage\nThe DBMS stores a database as one or more files on disk, In the meanwhile,  The OS doesn't know anything about the contents of these files.\n\n#### Who do the work?\n**The storage manager**\nâ†’ responsible for maintaining a database's files.\nâ†’ Some do their own scheduling for reads and writes to improve spatial and temporal locality of pages.\n\n#### How?\nIt organizes the files as **a collection of pages**.\n\nA page is **a fixed-size block of data.**\nâ†’ Most systems do NOT mix page types.\nâ†’ Some systems require a page to be **self-contained.**\n\nEach page is given **a unique identifier.**\nâ†’ The DBMS uses **an indirection layer** to map page ids to physical locations.\n\nThere are three different notions of \"pages\" in a DBMS:\nâ†’ Hardware Page (usually 4KB)\nâ†’ OS Page (usually 4KB)\nâ†’ Database Page (512B-16KB)\n\n- ç¡¬ä»¶å±‚ä¿è¯äº†4KBçš„åŸå­æ€§, (æ¯”å¦‚æœ‰ä¸€æ¬¡å†™å…¥æ“ä½œå¤±è´¥äº†, é‚£ä¹ˆå¤±è´¥çš„èŒƒå›´ä¸€å®šæ˜¯4KBæœ€å°å•ä½çš„)\n\n#### Page Storage Architecture\n- Different DBMSs manage pages in files on disk in different ways.\n\t**â†’ Heap File Organization** \n\tâ†’ Sequential / Sorted File Organization\n\tâ†’ Hashing File Organization\n\n- At this point in the hierarchy we don't need to know anything about what is inside of the pages.\n\n##### Heap File Organization\n- an **unordered** collection of pages where tuples that are stored in **random order**.\n- Need **meta-data** to keep track of what pages exist and which ones have free space.\n- Two ways to represent a heap file:\n\tâ†’ Linked List\n\tâ†’ Page Directory\n\n###### Linked List\n![](notes/2021/2021.10/assets/img_2022-10-15-9.png)\n\n###### Page Directory\n![](notes/2021/2021.10/assets/img_2022-10-15-10.png) \n\n### Page Layout\n ![](notes/2021/2021.10/assets/img_2022-10-15-11.png)\n- We have a page header to store meta-data.\n#### How to organize the data stored inside of the page?\nAssume we only store tuples;\n\n**Two approaches:**\n\tâ†’ Tuple-oriented\n\tâ†’ Log-structured\n\t\n##### Tuple-oriented\n- It's a bad idea to store all the tuples linearly:\n![](notes/2021/2021.10/assets/img_2022-10-15-12.png)\n\n###### Slotted Pages\n- Instead, the most common layout scheme is called **slotted pages**.\n\t![](notes/2021/2021.10/assets/img_2022-10-15-13.png)\n- The slot array maps \"slots\" to the tuples' starting position offsets.\n- å¢é•¿æ–¹å‘:\n![](notes/2021/2021.10/assets/img_2022-10-15-14.png)\n\n- If you delete a slot in the middle, some DBMS clean the empty gap while others don't.\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/1D81vXw2T_w?start=3609\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n![](notes/2021/2021.10/assets/img_2022-10-15-15.png)\n\n##### Log Structured File Organization\n- Instead of storing tuples in pages, the DBMS only stores **log records**.\n\tE.g. Insertion Deletion Updates etc.\n\t![](notes/2021/2021.10/assets/img_2022-10-15-16.png)\n\n- To read a record, the DBMS scans the log backwards and \"recreates\" the tuple to find what it needs. \t\n\t![](notes/2021/2021.10/assets/img_2022-10-15-17.png)\n\n- Build indexes to allow it to jump to locations in the log.\n\t![](notes/2021/2021.10/assets/img_2022-10-15-18.png)\n\n- Periodically (å‘¨æœŸæ€§åœ°) compact the log.\n\t![](notes/2021/2021.10/assets/img_2022-10-15-19.png)\t\n\n\n\n\n### Tuple Layout\n- A tuple is essentially **a sequence of bytes**.\n\t- It's the job of the DBMS to interpret those bytes into attribute types and values.\n#### Tuple header\n![](notes/2021/2021.10/assets/img_2022-10-15-20.png)\n\tâ†’ Visibility info (concurrency control)\n\tâ†’ Bit Map for NULL values.\n- We do not need to store meta-data about the schema.\n\n#### Tuple Data\n![](notes/2021/2021.10/assets/img_2022-10-15-21.png)\n- Stored in the order that you specify them when you create the table.\n- This is done for software engineering reasons.\n\n#### Denormalized Tuple Dataq\n![](notes/2021/2021.10/assets/img_2022-10-15-22.png)\n\n![](notes/2021/2021.10/assets/img_2022-10-15-23.png)\n\n![](notes/2021/2021.10/assets/img_2022-10-15-24.png)\n\n#### Record IDs\nIn order to keep track of individual tuples, each tuple is assigned **a unique record identifier**.\n\tâ†’ Most common: `page_id + offset/slot`\n\tâ†’ Can also contain file location info.\n\nAn application cannot rely on these ids to mean anything.\n\u003e It changes!\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Call_StackStack_Frame%E7%9A%84%E6%9E%84%E6%88%90":{"title":"Call_Stack(Stack_Frame)çš„æ„æˆ","content":"# Call Stack\n\n\u003cdiv align=\"right\"\u003e 2021-10-07\u003c/div\u003e\n\nTags: #Stack #OperatingSystem #Assembly\n\nä¸¤ä¸ªéå¸¸å¥½çš„è§†é¢‘:\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jyRQpRHSYNY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Gfmq2vGhWbw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-2_Bottom-Up_Parsing-%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E5%88%86%E6%9E%90":{"title":"Compiler-2_Bottom-Up_Parsing-è‡ªåº•å‘ä¸Šåˆ†æ","content":"# Bottom-Up Parsing\n\n\u003cdiv align=\"right\"\u003e 2021-10-30\u003c/div\u003e\n\nTags: #Compiler #Course \n\n- è‡ªåº•å‘ä¸Šåˆ†ææ˜¯ä¸€ç§è¯­æ³•åˆ†ææ–¹æ³•, å®ƒä»è¯­æ³•æ ‘çš„ä¸‹è¾¹ç¼˜(å³ä¸€å †ç»ˆç»“ç¬¦)å¼€å§‹, é€æ­¥å‘ä¸Šæ„å»ºè¿™ä¸ªå¥å­çš„æ¨å¯¼è¿‡ç¨‹\n\n- ä¸€èˆ¬æ¥è¯´, è‡ªåº•å‘ä¸Šåˆ†ææ¯”è‡ªä¸Šè€Œä¸‹åˆ†æè¦æ›´å¼ºå¤§, åŒæ—¶ä¹Ÿæ›´å¤æ‚.\n\n## Shift-reduce parsing[^1]\n- ç§»ä½-è§„çº¦åˆ†æ(Shift-Reduce Parsing)æ˜¯è‡ªåº•å‘ä¸Šåˆ†æçš„ä¸»æµæ–¹æ³•\n![](https://upload.wikimedia.org/wikipedia/en/thumb/0/0e/Shift-Reduce_Parse_Steps_Numbered.svg/265px-Shift-Reduce_Parse_Steps_Numbered.svg.png)\n\n- æœ‰è®¸å¤šä¸åŒçš„ç§»ä½è§„çº¦åˆ†ææ–¹æ³•: æ¯”å¦‚: [\"ç®—ç¬¦ä¼˜å…ˆåˆ†æ\"](notes/2021/2021.10/Compiler-3_ç®—ç¬¦ä¼˜å…ˆåˆ†æ.md)å’Œ\"LRåˆ†æ\"éƒ½å±äºç§»ä½è§„çº¦åˆ†æ.\n- This is a good illustration\n![](notes/2021/2021.10/assets/img_2022-10-15-25.png)[^2]\n\n- Operator Precedence grammar could be either ambiguous or unambiguous.[^2]\n### è¯¾å ‚æ¦‚å¿µ: çŸ­è¯­ ç›´æ¥çŸ­è¯­ å¥æŸ„ è§„èŒƒè§„çº¦\n![](notes/2021/2021.10/assets/img_2022-10-15-26.png)\nè§„èŒƒè§„çº¦: æ¯æ­¥éƒ½æ›¿æ¢å¥æŸ„çš„è§„çº¦\n![](notes/2021/2021.10/assets/img_2022-10-15-27.png)\nå¥æŸ„å°±æ˜¯ **\"é‚£ä¸ªå¯ä»¥ç›´æ¥è§„çº¦çš„ä¸œè¥¿\"**\n\n### stack-based shift-reduce parsing\n\n- åƒtable-driven predictive parserä¸€æ ·(æ¯”å¦‚LL(1)åˆ†æé‡Œé¢çš„é‚£ä¸ªè¡¨), æœ‰çš„è‡ªåº•å‘ä¸Šåˆ†æå™¨ä½¿ç”¨æ ˆæ¥è·Ÿè¸ªåˆ†æçš„ä½ç½®, ä½¿ç”¨åˆ†æè¡¨æ¥å†³å®šæ¥ä¸‹æ¥åšä»€ä¹ˆ.\n\n\n\n\n\n\n\n\n[^1]: https://en.wikipedia.org/wiki/Shift-reduce_parser\n[^2]: https://www.geeksforgeeks.org/role-of-operator-precedence-parser/","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-3_%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E5%88%86%E6%9E%90":{"title":"Compiler-3_ç®—ç¬¦ä¼˜å…ˆåˆ†æ","content":"# Operator-precedence grammar\n\n\u003cdiv align=\"right\"\u003e 2021-10-30\u003c/div\u003e\n\nTags: #Compiler #Course #FormalLanguage \n\n## ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•\n- ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•(OPG)æ˜¯ä¸€ç§**æœ‰ç‰¹æ®Šæ€§è´¨çš„ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•**(CFG)\n- å®ƒçš„ç‰¹æ®Šæ€§è´¨è¡¨ç°ä¸º:\n\t- äº§ç”Ÿå¼å³éƒ¨ä¸èƒ½ä¸ºç©º (å³æ²¡æœ‰ $P\\rightarrow \\varepsilon$)\n\t- äº§ç”Ÿå¼å³è¾¹ä¸èƒ½æœ‰ä¸¤ä¸ªè¿ç»­çš„éç»ˆç»“ç¬¦ (å³æ²¡æœ‰ $P\\rightarrow \\cdots AB\\cdots$)\n- ä¸Šè¿°è§„åˆ™ä½¿å¾—æˆ‘ä»¬å¯ä»¥å®šä¹‰ç»ˆç»“ç¬¦ä¹‹é—´çš„\"ä¼˜å…ˆçº§\"(Precedence), ([ä¸ºä»€ä¹ˆ?](#ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•çš„æ ¸å¿ƒç‰¹å¾))\n\n- ç®—ç¬¦ä¼˜å…ˆåˆ†æä¸æ˜¯è§„èŒƒè§„çº¦, å®ƒçš„æ¯ä¸€æ­¥ä¸ä¸€å®šæ›¿æ¢å¥æŸ„\n\n- åœ¨ä¹¦é‡Œé¢çš„å®šä¹‰ä¸­, **ç®—ç¬¦æ–‡æ³•**æ˜¯ä¸å«ä¸¤ä¸ªè¿ç»­éç»ˆç»“ç¬¦çš„æ–‡æ³•, **ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•**åˆ™æ˜¯ç»ˆç»“ç¬¦ä¹‹é—´æœ€å¤šåªæœ‰ä¸€ç§ä¼˜å…ˆå…³ç³»çš„**ç®—ç¬¦æ–‡æ³•**\n\n\u003e ## Main differences with respect to LR parsers\n\u003e  - There is **no explicit state** associated to the parser (and thus no state  pushed on the stack)\n\u003e  - The decision of whether to shift or reduce is taken **based solely on the symbol on the top of the stack and the next input symbol** (and stored in a shift-reduce table)\n\u003e  - In case of reduction, the handle is the longest sequence at the top of stack matching the RHS of a rule\n\n### ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•çš„æ ¸å¿ƒç‰¹å¾\næœ‰å‡ ä¸ªæ¦‚å¿µæˆ‘æ„Ÿåˆ°å¾ˆéš¾ç†è§£:\n- ä¸ºä»€ä¹ˆç®—ç¬¦ä¼˜å…ˆæ–‡æ³•è¦å«\"ç®—ç¬¦ä¼˜å…ˆ\"æ–‡æ³•? å¦‚æœæ˜¯å› ä¸ºå®ƒå®šä¹‰äº†è¿ç®—ç¬¦ä¹‹é—´çš„ä¼˜å…ˆçº§, é‚£ä¹ˆ:\n- è¿ç®—ç¬¦çš„ä¼˜å…ˆçº§æ€æ ·å¸®åŠ©æˆ‘ä»¬è¿›è¡Œè¯­æ³•åˆ†æ?\n- ä¸ºä»€ä¹ˆ\"äº§ç”Ÿå¼æ²¡æœ‰ä¸¤ä¸ªè¿ç»­çš„ç»ˆç»“ç¬¦\"ä¾¿å¯ä»¥å®šä¹‰è¿ç®—ç¬¦ä¹‹é—´çš„ä¼˜å…ˆçº§? å¦‚æœæœ‰äº†ä¸¤ä¸ªè¿ç»­çš„ç»ˆç»“ç¬¦åˆä¼šæ€æ ·å¹²æ‰°ç®—ç¬¦ä¼˜å…ˆåˆ†æçš„æ­£ç¡®è¿›è¡Œ?\n\n\u003e - ç®—ç¬¦ä¼˜å…ˆåˆ†ææ³•æ˜¯**ä»¿æ•ˆå››åˆ™è¿ç®—çš„è®¡ç®—è¿‡ç¨‹è€Œæ„é€ çš„ä¸€ç§è¯­æ³•åˆ†ææ–¹æ³•**ã€‚ç®—ç¬¦ä¼˜å…ˆåˆ†ææ³•çš„å…³é”®æ˜¯æ¯”è¾ƒä¸¤ä¸ªç›¸ç»§å‡ºç°çš„ç»ˆç»“ç¬¦çš„ä¼˜å…ˆçº§è€Œå†³å®šåº”é‡‡å–çš„åŠ¨ä½œã€‚[^2]\n\u003e - \"ä»¿æ•ˆå››åˆ™è¿ç®—çš„è®¡ç®—è¿‡ç¨‹\" - ä½•ä»¥è§å¾—?\n- æ€»ä¹‹, ç®—ç¬¦ä¼˜å…ˆåˆ†æçš„æ ¸å¿ƒæ¦‚å¿µè¿˜æ˜¯åƒä¸€å›¢éš¾ä»¥æ‰æ‘¸çš„é›¾\n\n- ä»¿ç…§å››åˆ™è¿ç®—å¯å¦è¿™æ ·ç†è§£:\n![](notes/2021/2021.10/assets/img_2022-10-15-28.png)\n\n- Oberlin Universityçš„PPT[^5]ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯:\n\næˆ‘ä»¬é¦–å…ˆå®šä¹‰\"æ‹¬å·æ–‡æ³•(parenthesis grammar)\":  \n- a) The right hand side of every rule is enclosed in parentheses.\n- b) Parentheses occur nowhere else.\n- c) No two rules have the same right hand side.\n![](notes/2021/2021.10/assets/img_2022-10-15-29.png)\n- **The parentheses make the prime phrases disjoint**. The handle is always the leftmost prime phrase.\n\né‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è¿™æ ·ç†è§£ä¼˜å…ˆçº§æ–‡æ³•: \n- Def. A simple **precedence grammar** is one **in which we can insert symbols \"\u003c\", \"=\", and \"\u003e\" to produce a language** (treating \"\u003c\" and \"\u003e\" as parentheses) that can be parsed like a parenthesized grammar.\n\nä¸€ä¸ª\"ä¼˜å…ˆçº§æ–‡æ³•\"äº§ç”Ÿçš„å¥å­æ˜¯ä¸€ä¸²åµŒå¥—çš„æ‹¬å·.\nä¸€ä¸ªç´ çŸ­è¯­ä¾¿æ˜¯ä¸€å¯¹æ‹¬å·, æˆ‘ä»¬ä¸æ–­æ¶ˆé™¤æœ€å·¦è¾¹çš„ç´ çŸ­è¯­, æš´éœ²ä¸‹é¢çš„(æ ˆé‡Œé¢çš„)ç´ çŸ­è¯­\nåµŒå¥—çš„\"è¶Šæ·±\"çš„æ‹¬å·\"å †çš„è¶Šé«˜\", æˆ‘ä»¬parseçš„è¿‡ç¨‹ä¾¿æ˜¯ä¸æ–­è®©è¿™ä¸ªå±±å˜çŸ®çš„è¿‡ç¨‹.\n![](notes/2021/2021.10/assets/img_2022-10-15-30.png)\n- ç†è§£\"å¥å­æ‹¬å·\":\nWe always start with \"\u003c\" and the first token on the stack, and at EOF push \"\u003e\". We should end with the Start symbol on the stack.\n\n- ç†è§£ç®—ç¬¦æ–‡æ³•: \nå…³äºä¸ºä»€ä¹ˆæ²¡æœ‰ä¸¤ä¸ªè¿ç»­éç»ˆç»“ç¬¦, ä¾¿å¯ä»¥ç§°ä¹‹ä¸º\"ç®—ç¬¦æ–‡æ³•\",æˆ‘å®åœ¨æ‰¾ä¸åˆ°æ›´è¯¦ç»†çš„èµ„æ–™äº†, ä¸‹é¢é‚£ç¯‡è®ºæ–‡é‡Œé¢çš„è¿™æ®µè¯ä¼¼ä¹æ˜¯å…¶æœ€åˆçš„å®šä¹‰:\n![](notes/2021/2021.10/assets/img_2022-10-15-31.png)\næ³¨æ„è¿™ä¸ªæ€§è´¨; å¦‚æœäº§ç”Ÿå¼é‡Œé¢æ²¡æœ‰ä¸¤ä¸ªè¿ç»­çš„éç»ˆç»“ç¬¦, é‚£ä¹ˆä»»æ„å¥å‹é‡Œé¢ä¹Ÿä¸å¯èƒ½æœ‰ä¸¤ä¸ªè¿ç»­çš„éç»ˆç»“ç¬¦:\n- è¯æ˜:![](notes/2021/2021.10/assets/img_2022-10-15-32.png)\næˆ‘çŒœæµ‹å› ä¸ºå› ä¸ºç®—æœ¯è¡¨è¾¾å¼é‡Œé¢éƒ½æ˜¯ç®—å­å’Œç®—ç¬¦äº¤æ›¿å‡ºç°, æ‰€ä»¥ä¼šæœ‰\"ç®—ç¬¦æ–‡æ³•\"è¿™ä¸ªåå­—.\n\nç»¼ä¸Š, ç»“åˆ\"ç®—ç¬¦\"æ–‡æ³•å’Œ\"ä¼˜å…ˆçº§\"æ–‡æ³•, ä¾¿æœ‰äº†\"ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•\"\n\n### History\nRobert W. Floyd. 1963. Syntactic Analysis and Operator Precedence. _J. ACM_ 10, 3 (July 1963), 316â€“333. DOI:https://doi.org/10.1145/321172.321179\n\næ²¡æœ‰ç»†è‡´çš„è€ƒè¯è¿‡å‡ºå¤„, åªæ˜¯è°·æ­Œæœç´¢åˆ°çš„, ä½†æ˜¯æ ¹æ®æ–‡ç« å†…å®¹çŒœæµ‹åº”å½“æ˜¯å‡ºå¤„.\n\nåœ¨æ–‡ç« é‡Œé¢, æˆ‘ç†è§£åˆ°äº†ä»¥ä¸‹æ¦‚å¿µ:\n- ç†è§£\"**ç´ çŸ­è¯­**\":\n\t- A prime phrase is a phrase which contains at least one terminal character, but no prime phrase other than itself.\n\t- ç´ çŸ­è¯­é‡Œé¢çš„\"ç´ \", æŒ‡ä»£çš„æ˜¯Prime, ä¹Ÿå°±æ˜¯ç´ æ•°çš„\"ç´ \", åº”å½“ç†è§£ä¸º\"æœ€åŸºæœ¬çš„, æœ€åŸåˆçš„\", å› ä¸ºç´ æ•°æ˜¯\"æœ€å°ä¸å¯åˆ†çš„æ•°\"(ç®—æœ¯åŸºæœ¬å®šç†[^3])\n- ç†è§£è¯¾æœ¬é‡Œé¢çš„\"å¥å­æ‹¬å·: #\"[^4]\n\t- å¯¹äº $BxC$, å…¶ä¸­B, Cä¸ºç»ˆç»“ç¬¦\n\t\t![](notes/2021/2021.10/assets/img_2022-10-15-33.png)\n\t- åƒä¸Šé¢è¿™æ ·è®°å¿†å…¶å®æ¯”\"æŠŠ#å½“ä½œä¸€ä¸ªç»ˆç»“ç¬¦\"ç®€å•\n\n## ç®—ç¬¦ä¼˜å…ˆçº§\n**a â‹– b** This means a â€œyields precedence toâ€ b.  \n**a â‹— b** This means a â€œtakes precedence overâ€ b.  \n**a â‰ b** This means a â€œhas same precedence asâ€ b.\n\n### æ€ä¹ˆç¡®å®šä¼˜å…ˆçº§\n\n- **aç­‰äºb** \n\tå½“ä¸”ä»…å½“ æ–‡æ³•Gä¸­å«æœ‰å½¢å¦‚$Pâ†’ \\cdots ab\\cdots$ æˆ– $Pâ†’\\cdots aQb\\cdots$çš„äº§ç”Ÿå¼ï¼›\n- **aå°äºb** \n\tå½“ä¸”ä»…å½“ Gä¸­å«æœ‰å½¢å¦‚$Pâ†’\\cdots aR\\cdots$ çš„äº§ç”Ÿå¼ï¼Œè€Œ$R  \\overset{+}{\\Rightarrow}b\\cdots$ æˆ–$R\\overset{+}{\\Rightarrow}Qb\\cdots$ \n\tå³è¯­æ³•æ ‘ä¸­, aåœ¨bçš„å·¦ä¸Šé¢\n- **aå¤§äºb** \n\tå½“ä¸”ä»…å½“ Gä¸­å«æœ‰å½¢å¦‚$Pâ†’\\cdots Rb\\cdots$ çš„äº§ç”Ÿå¼ï¼Œè€Œ$R\\overset{+}{\\Rightarrow}\\cdots a$æˆ–$R\\overset{+}{\\Rightarrow}\\cdots aQ$\n\tå³è¯­æ³•æ ‘ä¸­, aåœ¨bçš„å·¦ä¸‹é¢\n\t\n\tåœ¨ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•é‡Œé¢, ä»»æ„ä¸¤ä¸ªç»ˆç»“ç¬¦ **è‡³å¤šæ»¡è¶³ä¸€ç§å…³ç³»**\n\n## åˆ†ææ­¥éª¤\n![](notes/2021/2021.10/assets/img_2022-10-15-34.png)\nå‰ä¸‰æ­¥éƒ½æ˜¯åœ¨è¿›è¡Œå‡†å¤‡å·¥ä½œ, å³æ„é€ åé¢è¦ç”¨åˆ°çš„ç®—ç¬¦ä¼˜å…ˆè¡¨, \nåŒæ—¶, ç¡®å®šä¼˜å…ˆçº§çš„è¿‡ç¨‹ä¹Ÿæ˜¯éªŒè¯è¿™ä¸ªæ–‡æ³•æ˜¯ä¸æ˜¯ç®—ç¬¦ä¼˜å…ˆæ–‡æ³•çš„è¿‡ç¨‹\n\n### æ£€æŸ¥æ˜¯å¦æœ‰Îµ-äº§ç”Ÿå¼\n\n### FIRSTVT(NT), LASTVT(NT)\n- æ„é€ å¯¹è±¡: æ‰€æœ‰éç»ˆç»“ç¬¦\n- å®šä¹‰:\n$$\\begin{aligned}\n\u0026\\operatorname{FIRSTVT}(\\mathrm{P})=\\left\\{\\mathrm{a} \\mid \\mathrm{P} \\stackrel{+}{\\Rightarrow} \\mathrm{a} \\cdots \\text { æˆ– }{\\mathrm{P}} \\stackrel{+}{\\Rightarrow} \\mathrm{Qa}\\cdots , \\mathrm{a} \\in \\mathrm{V}_{\\mathrm{T}} \\text { è€Œ } \\mathrm{Q} \\in \\mathrm{V}_{\\mathrm{N}}\\right\\} \\\\\n\u0026\\mathrm{LASTVT}(\\mathrm{P})=\\left\\{\\mathrm{a} \\mid \\mathrm{P} \\stackrel{+}{\\Rightarrow} \\cdots \\mathrm{a} \\text { æˆ– } \\mathrm{P} \\stackrel{+}{\\Rightarrow} \\cdots \\mathrm{aQ}, \\mathrm{a} \\in \\mathrm{V}_{\\mathrm{T}} \\text { è€Œ } \\mathrm{Q} \\in \\mathrm{V}_{\\mathrm{N}}\\right\\}\n\\end{aligned}$$\n- FIRSTVT: éç»ˆç»“ç¬¦çš„æ‰€æœ‰ç¬¬ä¸€ä¸ª(FIRST)ç»ˆç»“ç¬¦(VT)\n- LASTVT: éç»ˆç»“ç¬¦çš„æ‰€æœ‰æœ€åä¸€ä¸ª(LAST)ç»ˆç»“ç¬¦(VT)\n\n#### å¦‚ä½•æ„é€  FIRSTVT(NT), LASTVT(NT)\n- é€’å½’æ„é€ \n\n##### FIRSTVT(B)\n- é¦–å…ˆæ‰€æœ‰äº§ç”Ÿå¼$Bâ†’a\\cdots$,  æˆ–è€…  $Bâ†’Ca\\cdots$, æœ‰ $a\\in FIRSTVT(B)$\n- ç„¶åå¯¹äºæ‰€æœ‰çš„$Bâ†’Ca\\cdots$,  æœ‰$FIRSTVT(B) = FIRSTVT(C)\\cup FIRSTVT(B)$\n\nè¿™æ ·çš„è¯å¯èƒ½ä¼šå¥—å¾ˆå¤šå±‚, ä¹¦ä¸Šé‡‡ç”¨çš„æ–¹æ³•æ˜¯ç”¨ä¸€ä¸ªæ ˆ:\n![](notes/2021/2021.10/assets/img_2022-10-15-35.png)\n\n- é¦–å…ˆ, å°†ç›´æ¥èƒ½å¤Ÿçœ‹å‡ºæ¥çš„å…ƒç´ åœ¨è¡¨ä¸­æ ‡è®°, å¹¶ä¸”å…¥æ ˆ.\n![](notes/2021/2021.10/assets/img_2022-10-15-36.png)\n- ç„¶å, å°†æ ˆé¡¶å…ƒç´ $(C, d)$å‡ºæ ˆ, å¦‚æœCæ˜¯æŸä¸€ä¸ªäº§ç”Ÿå¼çš„ç¬¬ä¸€ä¸ªéç»ˆç»“ç¬¦(æ¯”å¦‚$Bâ†’Ca\\cdots$), é‚£ä¹ˆå°†$d$åŠ å…¥åˆ°$FIRSTVT(B)$é‡Œé¢.\n- æ ‡è®°$(B, d)$, åŒæ—¶$(B, d)$å…¥æ ˆ\n- é‡å¤, ç›´åˆ°æ ˆç©º\n\nç†è§£FIRSTVT(B)\n![500](notes/2021/2021.10/assets/img_2022-10-15-37.png)\nç†è§£è¿™ç§\"æ ˆä¸­å…ƒç´ å¯¹\"çš„æ›´æ–°æ–¹å¼\n![500](notes/2021/2021.10/assets/img_2022-10-15-38.png)\n\n###### LASTVT(B)\nç±»ä¼¼çš„\n- é¦–å…ˆæ‰€æœ‰äº§ç”Ÿå¼$Bâ†’\\cdots a$,  æˆ–è€…  $Bâ†’\\cdots aC$, æœ‰ $a\\in LASTVT(B)$\n- ç„¶åå¯¹äºæ‰€æœ‰çš„$Bâ†’\\cdots aC$,  æœ‰$LASTVT(B) = LASTVT(C)\\cup LASTVT(B)$\n\n### æ„é€ ä¼˜å…ˆçº§è¡¨\n\u003e æ³¨æ„åŒºåˆ†: è¿™ä¸ªè¡¨æ˜¯æ„é€ FIRSTVT å’Œ LASTVT çš„, ä¸æ˜¯ä¼˜å…ˆçº§è¡¨\n\u003e ![300](notes/2021/2021.10/assets/img_2022-10-15-39.png)\n\nç„¶åæˆ‘ä»¬æ ¹æ®FIRSTVT å’Œ LASTVT æ¥æ„é€ ä¼˜å…ˆçº§è¡¨\n![500](notes/2021/2021.10/assets/img_2022-10-15-40.png)\n![600](notes/2021/2021.10/assets/img_2022-10-15-41.png)\næ„é€ å‡ºæ¥é•¿è¿™æ ·\n![](notes/2021/2021.10/assets/img_2022-10-15-42.png)\n\n#### ç‰¹åˆ«æ³¨æ„!\nç®—ç¬¦ä¼˜å…ˆçº§ä¸æ»¡è¶³äº¤æ¢å¾‹, æ‰€ä»¥$a\\lessdot b\\nRightarrow b\\gtrdot a$   \n**æ‰€ä»¥è¿™ä¸ªè¡¨æ ¼å¹¶ä¸æ˜¯åå¯¹ç§°çŸ©é˜µ!!**\nè¦åˆ†æ¸…æ¨ªçºµè½´, åœ¨è¯¾æœ¬å’Œè¯¾ä»¶é‡Œé¢, éƒ½æ˜¯\n![300](notes/2021/2021.10/assets/img_2022-10-15-43.png)\n\n\u003e è¯¾æœ¬é‡Œæˆ‘ä»¬å¼•å…¥#ç¬¦å·è¡¨ç¤ºå¥å­çš„æ‹¬å·\n\u003e å³ä¸€å¼€å§‹ åœ¨æ–‡æ³•ä¸­æ·»åŠ Eâ†’#E# , Eä¸ºå¼€å§‹ç¬¦å·, \n\u003e å®¹æ˜“æ¨å‡º: \n\u003e - \\# â‹– FIRSTVT(E)\n\u003e - LASTVT(E) â‹— \\# \n\u003e - \\# â‰ \\# \n%%\u003e ![400](notes/2021/2021.10/assets/img_2022-10-15-44.png)%%\n\u003e ![](notes/2021/2021.10/assets/img_2022-10-15-45.png)\n\u003e è¯¾ä»¶é‡Œé¢æ²¡æœ‰å†™,  ä½†æ˜¯åœ¨åˆ†æå…·ä½“çš„å¥å‹çš„æ—¶å€™éœ€è¦è®°ä½\n\n\n### æœ€å·¦ç´ çŸ­è¯­â€”ç®—ç¬¦ä¼˜å…ˆåˆ†æä¸­çš„å¯å½’çº¦ä¸²\n- ç´ çŸ­è¯­\nè‡³å°‘å«æœ‰ä¸€ä¸ªç»ˆç»“ç¬¦ä¸”é™¤å®ƒè‡ªèº«ä¹‹å¤–ä¸å«æœ‰ä»»ä½•æ›´å°çš„ç´ çŸ­è¯­ã€‚\n(è¯­æ³•åˆ†ææ ‘é‡Œé¢è‡³å°‘å«æœ‰ä¸€ä¸ªç»ˆç»“ç¬¦çš„æœ€å°å­æ ‘)\n- æœ€å·¦ç´ çŸ­è¯­\nå¤„äºå¥å‹æœ€å·¦è¾¹çš„é‚£ä¸ªç´ çŸ­è¯­ã€‚\n![600](notes/2021/2021.10/assets/img_2022-10-15-46.png)\nåœ¨ç®—ç¬¦ä¼˜å…ˆå¥å‹é‡Œé¢, å¥å‹ä¸€å®šæ˜¯ä»¥ä¸‹æ ¼å¼:\n$\\#N_1\\space a_1\\space N_2\\space a_2\\space \\cdots N_n\\space a_n\\space N_{n+1} \\#$ \nå…¶ä¸­: ${a}_{{i}} \\in {V}_{{T}}, {N}_{{i}} \\in {V}_{{N}}$ (éç»ˆç»“ç¬¦å¯æœ‰å¯æ— , ä½†æ˜¯ä¸€å®šä¸ä¼šæŒ¨ç€)\n\nå¥å‹æ˜¯è¿™ç§å½¢å¼æ˜¯ç®—ç¬¦æ–‡æ³•çš„å®šä¹‰é€ æˆçš„, ç®—ç¬¦æ–‡æ³•ä¸å…è®¸å‡ºç°ä¸¤ä¸ªè¿ç»­çš„éç»ˆç»“ç¬¦.\n\nä¸€ä¸ªä¾‹å­:\n![500](notes/2021/2021.10/assets/img_2022-10-15-47.png)\nç›´è§‚ä¸Šè¿™æ ·ç†è§£:\n![500](notes/2021/2021.10/assets/img_2022-10-15-48.png)\n### Start Parsing!\n[ç®—ç¬¦ä¼˜å…ˆç®—æ³• è§£æ](notes/2021/2021.10/assets/img_2022-10-15-49.png)\nä¸€ä¸ªå…·ä½“çš„ä¾‹å­:\n[Operator_Precedence_Parse](notes/2021/2021.10/assets/Operator_Precedence_Parse.pdf)\n\n\néœ€è¦æ³¨æ„çš„æ˜¯:\n- ç®—ç¬¦ä¼˜å…ˆåˆ†æåœ¨è§„çº¦è¿™ä¸€æ­¥ä¸Šé¢, å¾—åˆ°çš„æ˜¯\"æŸä¸ªéç»ˆç»“ç¬¦N\", è¿™ä¸ªéç»ˆç»“ç¬¦æ˜¯ä¸é‡è¦çš„, è¿™åœ¨ä¸‹å›¾ä¸­å¯ä»¥æ¸…æ™°çš„çœ‹å‡º:\n- ![](notes/2021/2021.10/assets/Pasted%20image%2020211030172247.png)\n- ä¸Šå›¾åŒæ—¶è¯´æ˜äº† ç®—ç¬¦ä¼˜å…ˆåˆ†æä¸ç­‰ä»·äºè§„èŒƒå½’çº¦ï¼Œæœªå¿…æ˜¯ä¸¥æ ¼çš„æœ€å·¦å½’çº¦(ä»æ ‘é‡Œé¢å¯ä»¥çœ‹å‡ºçœç•¥äº†ä¸€äº›æ­¥éª¤, å³è·³è¿‡äº†æ‰€æœ‰å•éäº§ç”Ÿå¼æ‰€å¯¹åº”çš„å½’çº¦æ­¥éª¤), æ‰€ä»¥å½’çº¦é€Ÿåº¦å¿«ï¼Œä½†å®¹æ˜“è¯¯åˆ¤(å› ä¸ºå¿½ç•¥éç»ˆç»“ç¬¦åœ¨å½’çº¦è¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œå­˜åœ¨æŸç§å±é™©æ€§ï¼Œå¯èƒ½å¯¼è‡´æŠŠæœ¬æ¥ä¸æ˜¯å¥å­çš„è¾“å…¥ä¸²è¯¯è®¤ä¸ºæ˜¯å¥å­)\n- è¿™ä¹ŸåŒæ—¶è¯´æ˜äº†ç®—ç¬¦ä¼˜å…ˆåˆ†ææ²¡æœ‰\"çŠ¶æ€(State)\"ä¸€è¯´, å³æ²¡æœ‰çŠ¶æ€å…¥æ ˆ, æ¨å¯¼è¿‡ç¨‹å®Œå…¨å‡­å€Ÿæ ˆé¡¶ç»ˆç»“ç¬¦ä¸ä¸‹ä¸€ä¸ªç»ˆç»“ç¬¦\n\næ˜“é”™:\n- ä¼˜å…ˆçº§å…³ç³»æ˜¯æ¯ä¸€æ­¥éƒ½æœ‰çš„\n![400](notes/2021/2021.10/assets/Pasted%20image%2020211030211829.png)\n- æˆ‘çš„:\n- ![400](notes/2021/2021.10/assets/Pasted%20image%2020211030211857.png)\n\n### ä¼˜å…ˆå‡½æ•°\nå®é™…åº”ç”¨ä¸­, è€ƒè™‘åˆ°å­˜å‚¨ä¼˜å…ˆè¡¨çš„å¼€é”€å¤ªå¤§, æˆ‘ä»¬å¸¸å¸¸ç”¨ä¼˜å…ˆå‡½æ•°ä»£æ›¿ä¼˜å…ˆè¡¨:\n![](notes/2021/2021.10/assets/Pasted%20image%2020211030193845.png)\n\nå‡½æ•°f ç§°ä¸ºå…¥æ ˆä¼˜å…ˆå‡½æ•°ï¼Œ g ç§°ä¸ºæ¯”è¾ƒä¼˜å…ˆå‡½æ•°\n\n- è‹¥ $\\theta_{1}â‹–\\theta_{2}\\quad$ åˆ™ $\\quad f(\\theta_1)\u003cg(\\theta_2)$\n- è‹¥ $\\theta_{1}â‰\\theta_{2}\\quad$ åˆ™ $\\quad f(\\theta_{1})=g(\\theta_2)$\n- è‹¥ $\\theta_{1}â‹—\\theta_{2}\\quad$ åˆ™ $\\quad f(\\theta_{1})\u003eg(\\theta_{2})$\n\næ³¨æ„: \n- ä¸æ˜¯æ¯ä¸€ä¸ªä¼˜å…ˆè¡¨éƒ½æœ‰å¯¹åº”çš„ä¼˜å…ˆå‡½æ•°\n- åŸæ¥ä¼˜å…ˆè¡¨ä¸ºç©ºçš„é¡¹(ä¸å­˜åœ¨ä¼˜å…ˆå…³ç³»çš„ç»ˆç»“ç¬¦å¯¹),  è½¬åŒ–ä¸ºä¼˜å…ˆå‡½æ•°ä»¥å, ä¸è‡ªç„¶æ•°ç›¸å¯¹åº”ï¼Œå˜æˆå¯ä»¥æ¯”è¾ƒçš„ã€‚æ‰€ä»¥è¦è¿›è¡Œä¸€äº›ç‰¹æ®Šçš„åˆ¤æ–­\n- ä¼˜å…ˆå‡½æ•°ä¸å”¯ä¸€ï¼Œåªè¦å­˜åœ¨ä¸€å¯¹ï¼Œå¿…å­˜åœ¨æ— ç©·å¯¹ä¼˜å…ˆå‡½æ•°ã€‚\n\n![400](notes/2021/2021.10/assets/Pasted%20image%2020211030194053.png)\n\n#### æ€ä¹ˆç”»\n\n- å¦‚æœa çš„ä¼˜å…ˆçº§é«˜äºæˆ–ç­‰äºbï¼Œåˆ™ä» $f_a$ è‡³ $g_b$ ç”»ä¸€æ¡æœ‰å‘è¾¹\n- å¦‚æœa çš„ä¼˜å…ˆçº§ä½äºæˆ–ç­‰äºbï¼Œåˆ™ä» $g_b$ è‡³ $f_a$ ç”»ä¸€æ¡æœ‰å‘è¾¹\n- æ³¨æ„ç›¸ç­‰çš„è¯è¦ç”»æ¥å›ä¸¤æ¡è¾¹\n- æ¯ä¸ªç»“ç‚¹èµ‹äºˆä¸€ä¸ªæ•°, è¯¥æ•°ç­‰äºä»è¯¥ç»“ç‚¹å‡ºå‘å¯è¾¾ç»“ç‚¹ï¼ˆåŒ…æ‹¬å‡ºå‘ç»“ç‚¹æœ¬èº«åœ¨å†…ï¼‰çš„ä¸ªæ•°.\n- å› ä¸ºå¯èƒ½æœ‰çš„è¡¨æ²¡æœ‰ä¼˜å…ˆå‡½æ•°, æ‰€ä»¥è¿˜è¦æ£€æŸ¥æ˜¯å¦æœ‰çŸ›ç›¾: æ˜¯å¦æœ‰çŸ›ç›¾çš„ä¼˜å…ˆçº§, å³: æ˜¯å¦æœ‰ç¯?\n- An Illustration:\n- ![](notes/2021/2021.10/assets/Pasted%20image%2020211105185333.png)[^1]\n\nå¯ä»¥è¯æ˜ï¼š\nè‹¥$aâ‰b$, åˆ™$f(a)=g(b)$; è‹¥$aâ‹– b$, åˆ™$f(a)\u003cg(b)$; è‹¥$aâ‹—b$, åˆ™$f(a)\u003eg(b)$\n\n\n\n\n---\nè¯¾ä»¶ä¸Šå®Œå…¨æ²¡æœ‰è®²å‡ºé”™å¤„ç†\n\n\n[^1]: https://www.geeksforgeeks.org/role-of-operator-precedence-parser/\n[^2]: https://moyangsensei.github.io/2019/05/20/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%EF%BC%9A%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E5%88%86%E6%9E%90/\n[^3]: ä¸è¦æ··æ·†äº†\"ç®—æœ¯åŸºæœ¬å®šç†\"ä¸\"ä»£æ•°åŸºæœ¬å®šç†\"å“¦\n[^4]: æˆ‘è§‰å¾—, è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥‡æ€ªçš„ç§°å‘¼, å®Œå…¨æ²¡æœ‰å¿…è¦åˆé€ ä¸€ä¸ªä¸“æœ‰åè¯å‡ºæ¥\n[^5]: https://www.cs.oberlin.edu/~bob/cs331/Class%20Notes/February/February%2017/Precedence%20Grammars.pdf","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-4-1_%E4%BB%80%E4%B9%88%E6%98%AF-LR-%E5%88%86%E6%9E%90":{"title":"Compiler-4-1_ä»€ä¹ˆæ˜¯ LR åˆ†æ","content":"## ä»€ä¹ˆæ˜¯ LR åˆ†æ\n\n- LR åˆ†ææ–¹æ³•æ˜¯ä¸€ç§è‡ªåº•å‘ä¸Šçš„åˆ†ææ–¹æ³•: å®ƒä»ç»ˆç»“ç¬¦å¼€å§‹, ä»å·¦åˆ°å³, é€æ­¥å¯»æ‰¾å¥æŸ„è¿›è¡Œå½’çº¦. ä»è¿™ä¸ªè§’åº¦çœ‹, LR åˆ†æç›¸å½“äºä¸€ç§é«˜æ•ˆçš„å¥æŸ„æŸ¥æ‰¾æ–¹æ³•.\n\n- LR åˆ†ææ¯” LL åˆ†ææ›´å¼ºå¤§.\n\n\u003e LL (k) åˆ†ææŠ€æœ¯çš„ä¸€ä¸ªå¼±ç‚¹æ˜¯ï¼Œå®ƒåœ¨ä»…ä»…çœ‹åˆ°å³éƒ¨çš„å‰ k ä¸ªå•è¯æ—¶å°±å¿…é¡»é¢„æµ‹è¦ä½¿ç”¨çš„æ˜¯å“ªä¸€ä¸ªäº§ç”Ÿå¼ã€‚å¦ä¸€ç§æ›´æœ‰æ•ˆçš„åˆ†ææ–¹æ³•æ˜¯ LR (k) åˆ†æï¼Œå®ƒå¯ä»¥å°†è¿™ç§åˆ¤æ–­æ¨è¿Ÿè‡³å·±çœ‹åˆ°ä¸æ­£åœ¨è€ƒè™‘çš„è¿™ä¸ªäº§ç”Ÿå¼çš„æ•´ä¸ªå³éƒ¨å¯¹åº”çš„è¾“å…¥å•è¯ä»¥åï¼ˆå¤šäº K ä¸ªå•è¯ï¼‰ ã€‚[^1]\n\n- å­—é¢ä¸Šæ¥è¯´, LR (k) åˆ†æä»£è¡¨: Left-to-right parse, (Reversed) Right-most derivation, k-token look ahead\n\n- LR åˆ†ææ˜¯ä¸€ç§è¡¨é©±åŠ¨çš„ç§»è¿›å½’çº¦åˆ†ææ–¹æ³• (Table-driven \u0026 shift-reduce), æ‰€ä»¥åœ¨è¿›è¡Œåˆ†æçš„æ—¶å€™æˆ‘ä»¬å°†è¯­æ³•è§„åˆ™ç¼–ç åˆ°ä¸€ä¸ªè¡¨é‡Œé¢, æ ¹æ®è¡¨æ¥é€‰æ‹©ä¸åŒçš„ç§»è¿›å½’çº¦æ“ä½œ.\n  - åˆ†æè¡¨ç¤ºæ„å›¾:\n  ![](notes/2021/2021.10/assets/img_2022-10-15-50.png)\n  ä¸Šé¢è¿™ä¸ªè¡¨å®é™…ä¸Šæ˜¯ä¸€ä¸ª DFA çš„ç¼–ç è¡¨:\n  ![](notes/2021/2021.10/assets/img_2022-10-15-51.png)\n  LR åˆ†æå™¨å°†\"æ ˆé¡¶å¥æŸ„çŠ¶æ€\"è½¬åŒ–ä¸º (æŠ½è±¡ä¸º) å¯¹åº”çš„\"DFA çŠ¶æ€\". åœ¨åˆ†ææ—¶, æœ‰æ—¶è¯»å…¥ç»ˆç»“ç¬¦, æ‰§è¡Œ\"Shift\"æ“ä½œ; æœ‰æ—¶è¯»å…¥éç»ˆç»“ç¬¦, æ‰§è¡Œ\"Goto\"æ“ä½œ; æœ‰æ—¶ä»æ ˆé‡Œé¢å¼¹å‡ºå¥æŸ„, æ‰§è¡Œ\"Reduce\"æ“ä½œ. LR åˆ†æå°†æ ˆä¸ DFA ç»“åˆ, ä¸€èµ·è¿›è¡Œåˆ†æ.\n    - **Shift**: Push Terminal to the stack, shift to the next state in DFA\n    - **Goto**: Push Non-terminal to the stack, go to that corresponding state in DFA\n    - **Reduce**: Pop the handle out of stack, also pop the corresponding states out of stack. Intuitively, this means \"retreat\" to the state before the handle. (This may pass through multiple states)\n  - è¦æ³¨æ„æˆ‘ä»¬åˆ†æçš„ LR è¯­è¨€æ˜¯ CFG è¯­è¨€çš„å­ç±», DFA ç­‰ä»·äºæ­£åˆ™è¯­è¨€, æ˜¯ LR è¯­è¨€çš„ä¸€ä¸ªå­ç±». æ‰€ä»¥æˆ‘ä»¬éœ€è¦ç»“åˆæ ˆæ¥å¢å¼º DFA çš„è¡¨ç°åŠ›.\n \n  - åˆ†ææ“ä½œç¤ºæ„å›¾:\n  ![400](notes/2021/2021.10/assets/img_2022-10-15-52.png)\n\nä¸‹é¢æˆ‘ä»¬å°†ä»æŒ‰ç…§ $LR(0) \\rightarrow SLR \\rightarrow LR(1) \\rightarrow LALR(1)$ çš„é¡ºåºæ¥æ¢³ç† LR æ–‡æ³•çš„æ€æƒ³.[^2]\n\n### è¯­æ³•åˆ†æ: æ–‡æ³•å±‚æ¬¡ç»“æ„\n\n![500](notes/2021/2021.10/assets/img_2022-10-15-53.png)[^1]\n\n[^1]: è™ä¹¦ç¬¬ä¸‰ç« \n[^2]: è¿™ä¹Ÿæ˜¯è™ä¹¦çš„é¡ºåº, æˆ‘æ„Ÿè§‰è™ä¹¦é€‚åˆç¬¬äºŒéçœ‹, å› ä¸ºå®ƒå†™çš„ååˆ†ç²¾ç‚¼, åœ¨ç¬¬ä¸€éå­¦ä¹ æŒæ¡äº†å¤§æ¦‚æ–¹æ³•ä»¥å, ç¬¬äºŒéçœ‹è™ä¹¦å¯ä»¥å¿«é€ŸæŠ“ä½æ ¸å¿ƒæ€æƒ³. (æŠŠä¹¦å†™è¿™ä¹ˆç²¾ç‚¼åˆæ¸…æ™°çœŸçš„å¥½å‰å®³äº†)\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-4-2_LR0_Parse":{"title":"Compiler-4-2_LR(0)_Parse","content":"## LR (0)  Parse\n\n- åœ¨åˆ†æ LR (0) è¯­æ³•æ—¶, æˆ‘ä»¬åªéœ€è¦è§‚å¯Ÿæ ˆé¡¶çš„å…ƒç´ , æ ¹æ®æ ˆé¡¶å…ƒç´ æ¥å†³å®šå¦‚ä½•ç§»è¿›/å½’çº¦. è¿™ä¹Ÿæ˜¯ LR (0) é‡Œé¢\"0\"çš„å«ä¹‰ - 0 look ahead.\n\n### LR (0) é¡¹ç›® - LR (0) Item\n\n- LR åˆ†æè¡¨çš„æ„é€ ä»¥\"LR Item\"ä¸ºåŸºç¡€, \"LR Item\"å¯ä»¥ç†è§£ä¸º\"åœ¨å¯»æ‰¾å¥æŸ„çš„è¿‡ç¨‹ä¸­çš„ä¸€ç§æ¨æ–­\".\n- ä¸€ä¸ª LR (0) é¡¹ç›®ç”±ä¸¤éƒ¨åˆ†ç»„æˆ: ä¸€ä¸ªäº§ç”Ÿå¼å’Œä¸€ä¸ªæŒ‡ç¤ºæ ˆé¡¶ä½ç½®çš„å¥ç‚¹:\n $$E\\rightarrow \\alpha\\cdot \\beta$$\n  - æ¯”å¦‚: $E\\rightarrow \\alpha\\cdot \\beta$ ä»£è¡¨: æˆ‘ä»¬å·²ç»è¯†åˆ«åˆ°äº† $\\alpha$ ($\\alpha$ å·²ç»åœ¨æ ˆé‡Œé¢äº†), å¦‚æœåé¢æ¥ä¸‹æ¥çš„éƒ¨åˆ†æ˜¯ $\\beta$, é‚£ä¹ˆå°±å¯ä»¥ç¡®å®šæ˜¯å¥æŸ„ $E\\rightarrow \\alpha\\beta$ äº†\n  - å³, æ¯ä¸€ä¸ªé¡¹éƒ½ä»£è¡¨ç€\"å¥æŸ„çš„ä¸€ç§å¯èƒ½æ€§\"\n\n- é€šå¸¸, åœ¨ä¸€ä¸ªé¡¹ç›®é›†åˆé‡Œé¢æœ‰å¾ˆå¤šä¸åŒçš„é¡¹ç›®:\n  - æ¯”å¦‚: ä¸‹å›¾é«˜äº®éƒ¨åˆ†æ˜¯ä¸€ä¸ªé¡¹ç›®é›†åˆ\n  ![](notes/2021/2021.10/assets/img_2022-10-15-54.png)\n    - åŒä¸€ä¸ªé›†åˆé‡Œçš„é¡¹ç›®çœ‹èµ·æ¥å¾ˆä¸åŒ, ä½†æ˜¯ä»–ä»¬\"æŠ½è±¡çš„å…±åŒç‚¹\"è®©æˆ‘ä»¬å°†å…¶èšåˆä¸º DFA é‡Œé¢çš„ä¸€ä¸ªç­‰ä»·ç±», åé¢æˆ‘ä»¬å°†å™è¿°æ€æ ·å¯»æ‰¾è¿™ç§\"å…±åŒç‚¹\".\n    - Intuitively, ä¸€ä¸ªçŠ¶æ€é‡Œé¢æœ‰è®¸å¤šä¸åŒçš„é¡¹çš„æ„æ€æ˜¯: åŸºäºç°åœ¨æ ˆé‡Œé¢çš„æƒ…å†µ, è¿™äº›å¥æŸ„æ˜¯å¯èƒ½å‡ºç°çš„.\n\n### æ„å»ºè½¬åŒ–è§„åˆ™: DFA\n\nè¿™æ¶‰åŠåˆ°ä¸¤ä¸ªæ“ä½œ\n\n- $\\mathrm{Closure(ä¸€ä¸ªé¡¹ç›®é›†åˆ)}\\space \\Rightarrow$ æ±‚é—­åŒ…, å³æ±‚å‡ºä¸€ä¸ªå°é—­çš„ LR é¡¹ç›®é›†åˆ, ååˆ†ç±»ä¼¼äºå°† NFA è½¬åŒ–ä¸º DFA é‡Œé¢çš„ $\\varepsilon-$ é—­åŒ…\n- $\\mathrm{Goto(ä¸€ä¸ªé¡¹ç›®é›†åˆ, æŸä¸ªç¬¦å·)}\\space \\Rightarrow$ çœ‹çœ‹å½“å‰çŠ¶æ€è¾“å…¥ (åƒæ‰) æŸä¸ªç¬¦å·å, ä¼šè½¬ç§»åˆ°å“ªä¸ªçŠ¶æ€\n\n\u003e è¿™é‡Œå¯ä»¥è”ç³»å½¢å¼è¯­è¨€ä¸è‡ªåŠ¨æœºçš„çŸ¥è¯†: æ„æˆ DFA æœ‰ä¸¤ç§ä¸åŒçš„æ€è·¯: æˆ‘ä»¬å¯ä»¥å…ˆæ ¹æ®äº§ç”Ÿå¼æ„é€ ä¸€ä¸ª LR é¡¹çš„ NFA, ç„¶åå†è½¬åŒ–ä¸º DFA[^3]; æˆ–è€…æˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥æ„é€  DFA.\n\u003e ä¸è¿‡ LR åˆ†æçš„æ—¶å€™æˆ‘ä»¬é€šå¸¸éƒ½é‡‡ç”¨åä¸€ç§æ–¹æ³•: å³ä»åˆå§‹çŠ¶æ€å‡ºå‘, ä¸æ–­åœ°æ ¹æ®æ‰€æœ‰å¯èƒ½çš„è¾“å…¥æ±‚é—­åŒ…, ç”Ÿæˆæ–°çš„çŠ¶æ€é›†, ç›´åˆ°çŠ¶æ€æ•°ä¸å˜.\n\nä¸‹é¢æˆ‘ä»¬è¯¦ç»†è§£é‡Šè¿™ä¸¤ç§æ“ä½œ:\n\n#### Closure (a set of items)\n\nè¿™æ˜¯ç®—æ³•:\n![400](notes/2021/2021.10/assets/img_2022-10-15-55.png)\n\nç›´è§‚çš„æ¥è¯´, è¿™é€šå¸¸ä¼šè®©è¿™ä¸ªé¡¹\n$$\\mathrm{S} \\rightarrow . \\mathrm{L} \\alpha$$\nå˜æˆè¿™ä¸ªé›†åˆ:\n$$\\begin{aligned}\n\u0026\\mathrm{S} \\rightarrow . \\mathrm{L} \\alpha \\\\\n\u0026\\mathrm{L} \\rightarrow .(\\mathrm{L}) \\\\\n\u0026\\mathrm{L} \\rightarrow . \\mathrm{\\beta}\n\\end{aligned}$$\nå¯æ˜¯, ä¸ºä»€ä¹ˆä¸‹é¢è¿™ä¸¤ä¸ªæ–°åŠ è¿›æ¥çš„é¡¹ä¼šå’Œä¸Šé¢çš„é¡¹æ‹¥æœ‰ç›¸åŒçš„åœ°ä½å‘¢?\n\næˆ‘ä»¬ä»é—­åŒ…çš„è§’åº¦æ¥è€ƒè™‘è¿™ä¸ªé—®é¢˜:[^4]\n\n- å¯¹äºè¿™æ ·ä¸€ä¸ªè½¬æ¢, å¯èƒ½æœ‰ä¸¤ç§æƒ…å†µ:\n ![](notes/2021/2021.10/assets/img_2022-10-15-56.png)\n  - å¦‚æœ X æ˜¯ä¸€ä¸ªç»ˆç»“ç¬¦, é‚£ä¹ˆè¿™ä¸ªè½¬ç§»è¡¨ç¤ºå°†è¿™ä¸ªç»ˆç»“ç¬¦å‹å…¥æ ˆé¡¶, å¥ç‚¹å‰ç§».\n  - å¦‚æœ X æ˜¯ä¸€ä¸ªéç»ˆç»“ç¬¦, æƒ…å†µåˆ™å˜å¾—å¤æ‚èµ·æ¥, å› ä¸ºæˆ‘ä»¬åˆ†æçš„å¥å­è‚¯å®šæ˜¯ä¸€ä¸ªç»ˆç»“ç¬¦ä¸², ä¸ä¼šå‡ºç°éç»ˆç»“ç¬¦.\n  è¿›ä¸€æ­¥è€ƒè™‘, å¦‚æœå‡ºç°äº†éç»ˆç»“ç¬¦ X å…¥æ ˆ, é‚£ä¹ˆä»£è¡¨ç€å‰é¢ä¸€å®šå‡ºç°äº†å¯¹äºäº§ç”Ÿå¼ $X\\rightarrow \\beta$ çš„å½’çº¦, è¿™ä¸ªå½’çº¦å°†ç»ˆç»“ç¬¦ä¸² $\\beta$ æ¢æˆäº†éç»ˆç»“ç¬¦ $X$. è¦å‡ºç°è¿™æ ·çš„å½’çº¦, éœ€è¦é¦–å…ˆè¯†åˆ«å‡ºå¯ä»¥äº§ç”Ÿ X çš„å¥æŸ„ $\\beta$. æˆ‘ä»¬å°†è¿™ç§æ€æƒ³è¡¨ç¤ºä¸ºä¸‹å›¾:\n  ![](notes/2021/2021.10/assets/img_2022-10-15-57.png)\n  æ±‚ $\\mathrm{\\varepsilon-CLOSURE}$ çš„æ—¶å€™å°±å°†ä¸¤ä¸ªé¡¹åˆå¹¶åˆ°åŒä¸€ä¸ªçŠ¶æ€é‡Œé¢å»äº†\n\næ‰€ä»¥æˆ‘ä»¬ä¸Šé¢çš„ä¾‹å­å¯ä»¥è¿™æ ·ç†è§£:\n![CLOSURE](notes/2021/2021.10/assets/CLOSURE.svg)\n\n#### Goto (a set, a character)\n\nè¿™æ˜¯ç®—æ³•:\n![300](notes/2021/2021.10/assets/Pasted%20image%2020211106165501.png)\nå³å¯¹äºæ¯ä¸€ä¸ª LR é¡¹ç›®, å°è¯•å‘åç§»åŠ¨ä¸€ä¸ªç¬¦å· (åŒ…æ‹¬ç»ˆç»“ç¬¦å’Œéç»ˆç»“ç¬¦), ç„¶åå†å–è¿™ä¸ªè½¬ç§»çš„é—­åŒ….\n\n#### æ„å»º DFA\n\nè¯´æ˜äº†ä¸¤ä¸ªåŸºæœ¬æ“ä½œ, æ¥ä¸‹æ¥ä¾¿æ˜¯ä»åˆå§‹çŠ¶æ€å‡ºå‘, ä¸æ–­\"è½¬ç§», å–é—­åŒ…, è½¬ç§», å–é—­åŒ…......\"ç›´åˆ°æ•´ä¸ª DFA æ²¡æœ‰å˜åŒ–. è¿™å’Œ NFA è½¬ DFA æ—¶å€™çš„æ€æƒ³å¾ˆç›¸ä¼¼.\n\n![590](notes/2021/2021.10/assets/Pasted%20image%2020211106165953.png)\n\n- è¿™æ—¶, æˆ‘ä»¬é€šå¸¸ä¼šå¾—åˆ°ä¸€ä¸ªç±»ä¼¼äºä¸‹å›¾çš„ DFA:\n ![](notes/2021/2021.10/assets/Pasted%20image%2020211106170041.png)\n  - é‡Œé¢åŒ…å«äº† Shift å’Œ Goto çš„æ‰€æœ‰ä¿¡æ¯, ä½†æ˜¯è¿˜æ²¡æœ‰è¯´æ˜éœ€è¦ Reduce çš„æ—¶å€™è¯¥æ€ä¹ˆåŠ (æ„é€ è½¬ç§»è¡¨çš„æ—¶å€™ä¼šè§£å†³è¿™ä¸ªé—®é¢˜).\n\n- åœ¨åˆ†æçš„æ—¶å€™, ä½¿ç”¨ DFA æ¯”ä½¿ç”¨è½¬ç§»è¡¨ç›´è§‚å¤šäº†.\n \n### æ„å»ºè½¬ç§»è¡¨ DFA â†’ ACTION \u0026 GOTO tables\n\n- å¯¹äº DFA é‡Œé¢çš„æ¯ä¸€æ¡è¾¹:\n  - å¦‚æœè¿™ä¸ªè½¬ç§»æ˜¯ç»ˆç»“ç¬¦, é‚£ä¹ˆåœ¨ ACTION è¡¨é‡Œé¢å¡«ä¸Š **\"Shift \u003cç›®æ ‡çŠ¶æ€\u003e\"**\n  - å¦‚æœè¿™ä¸ªè½¬ç§»æ˜¯éç»ˆç»“ç¬¦, é‚£ä¹ˆåœ¨ GOTO è¡¨é‡Œé¢å¡«ä¸Š **\"Goto \u003cç›®æ ‡çŠ¶æ€\u003e\"**\n- å¯¹äºåŒ…å«å½¢å¦‚ $A \\rightarrow \\gamma\\space  \\textbf.$ çš„çŠ¶æ€ (å³è¿™ä¸ªçŠ¶æ€åŒ…å«ä¸€ä¸ª LR é¡¹, è¿™ä¸ª LR é¡¹æˆåŠŸè¯†åˆ«äº†ä¸€ä¸ªå¥æŸ„), åœ¨ ACTION è¡¨å¯¹åº”ä½ç½®å†™ä¸Š **\"Reduce \u003cäº§ç”Ÿå¼åºå·\u003e\"**\n- å¯¹äºåŒ…å« Sâ€² â†’ S.$ é¡¹çš„çŠ¶æ€, æˆ‘ä»¬åœ¨ ACTION è¡¨å¡«å…¥ **\"Accept\"**, è¡¨ç¤ºåˆ†ææˆåŠŸ. (æˆåŠŸè¯†åˆ«äº†ç¬¬ä¸€ä¸ªäº§ç”Ÿå¼, å³äº§ç”Ÿåˆå§‹ç¬¦å·çš„äº§ç”Ÿå¼: Sâ€² â†’ S.$ )\n\n![500](notes/2021/2021.10/assets/Pasted%20image%2020211106171144.png)\n\n### Start Parsing\n\n- æˆ‘ä»¬å…ˆå‘ç¬¦å·æ ˆé‡Œé¢æ¨å…¥ç¬¦å·$, è¡¨ç¤ºå¥å­çš„æœ«å°¾, å‘çŠ¶æ€æ ˆé‡Œé¢æ¨å…¥çŠ¶æ€ 0, è¡¨ç¤ºåˆå§‹çŠ¶æ€.\n- ç„¶åæˆ‘ä»¬å¼€å§‹é€ä¸ªè¯»å…¥ç¬¦å·, æ ¹æ®è¡¨ (DFA) æ¥è¿›è¡Œ**Shift**\n- å¯¹äº**Reduce**, æˆ‘ä»¬éœ€è¦ pop ç¬¦å·æ ˆé‡Œé¢çš„å¥æŸ„å’ŒçŠ¶æ€æ ˆé‡Œé¢å¯¹åº”çš„çŠ¶æ€, (åœ¨ DFA é‡Œé¢å›é€€åˆ°å¥æŸ„ä¹‹å‰çš„çŠ¶æ€), ç„¶åå†å‹å…¥äº§ç”Ÿå¼å³ä¾§çš„éç»ˆç»“ç¬¦, è¿›è¡Œ**Goto**æ“ä½œ.\n- ä¸€ç›´åœ¨çŠ¶æ€ä¹‹é—´è½¬ç§», ç›´åˆ°\n  - é‡åˆ° Accept â†’ åˆ†ææˆåŠŸ,\n  - æˆ–è€…, é‡åˆ°è¡¨ä¸­ä¸ºç©ºçš„é¡¹ (DFA é‡Œé¢ä¸å­˜åœ¨çš„è¾¹) â†’ å­˜åœ¨è¯­æ³•é”™è¯¯\n\n\u003e ç›¸æ¯”ç»´æŠ¤ç¬¦å·æ ˆå’ŒçŠ¶æ€æ ˆä¸¤ä¸ªæ ˆ, æˆ‘ä»¬ä¹Ÿå¯ä»¥åªç»´æŠ¤ä¸€ä¸ªæ ˆ, å°†çŠ¶æ€å’Œå¯¹åº”çš„ç¬¦å·éƒ½å‹åˆ°è¿™ä¸ªæ ˆé‡Œé¢, åªæ˜¯éœ€è¦æ³¨æ„è¿™æ · reduce çš„æ—¶å€™éœ€è¦ pop ä¸¤å€äº RHS (äº§ç”Ÿå¼å³ä¾§) é•¿åº¦çš„å…ƒç´ .\n\n- ä»¥ä¸Šä¾¿æ˜¯ LR (0) æ–‡æ³•çš„åˆ†æè¿‡ç¨‹.\n\n### LR (0) æ–‡æ³•çš„ä¸è¶³\n\n- ä¸æ­¤åŒæ—¶, LR (0) æ–‡æ³•ä¹Ÿæœ‰ä¸€äº›ä¸è¶³ä¹‹å¤„:\n\n- LR (0) æ–‡æ³•çš„è¡¨ç°èƒ½åŠ›ç›¸å¯¹è¾ƒå¼±, å‡ ä¹æ‰€æœ‰â€œçœŸæ­£çš„â€æ–‡æ³•éƒ½ä¸æ˜¯ LR ( 0 ) çš„.[^5]\n- æ‰€ä»¥, å¾ˆå¤šæ–‡æ³•é‡Œé¢, LR (0) çš„åˆ†æè¡¨é‡Œé¢ä¼šå‡ºç°ç§»è¿›-å½’çº¦å†²çª (Shift Reduce Conflict) æˆ–è€…å½’çº¦-å½’çº¦å†²çª (Reduce-Reduce Conflict)\n\n#### ç§»è¿›-å½’çº¦å†²çª\n\n- LR (0) åˆ†æè¡¨çš„æ¯ä¸€è¡Œè¦ä¹ˆä¸º Shift æˆ–ç©º, è¦ä¹ˆå…¨éƒ¨ä¸ºæŸä¸€ä¸ªå½’çº¦, ä¹Ÿå°±æ˜¯: DFA çš„æ¯ä¸€ä¸ªçŠ¶æ€è¦æ˜¯æœ‰å®Œå…¨è¯†åˆ«å¥æŸ„çš„é¡¹(Reduce)å°±ä¸èƒ½æœ‰ç»ˆç»“ç¬¦æŒ‡å‡ºå» (ä¸èƒ½ Shift å‡ºå»)\n![](notes/2021/2021.10/assets/LR(0)ç§»è¿›è§„çº¦å†²çª.svg)\nè¦æ˜¯æœ‰ä¸€ä¸ªåœ°æ–¹åˆæœ‰ Reduce åˆæœ‰ Shift, å°±æ˜¯ä¸€ä¸ªç§»è¿›å½’çº¦å†²çª.\n\n#### å½’çº¦-å½’çº¦å†²çª\n\nåŒç†, è¦æ˜¯æœ‰ä¸ªçŠ¶æ€é‡Œé¢æœ‰ä¸¤ä¸ªä¸åŒçš„å®Œå…¨è¯†åˆ«çš„å¥æŸ„: $P\\rightarrow\\alpha\\space \\cdot$ ä¸ $Q\\rightarrow\\beta\\space \\cdot$ é‚£ä¹ˆå°±å‡ºç°äº†å½’çº¦-å½’çº¦å†²çª.\n\n- æ³¨æ„åªå¯èƒ½å‡ºç° Shift-Reduce Conflict, ä¸å¯èƒ½å‡ºç° Goto-Reduce Conflict.\n  - è¿™æ˜¯å› ä¸º:\n  1. å‡è®¾ç°åœ¨æ˜¯çŠ¶æ€ a, å¦‚æœä¸‹ä¸€ä¸ªè¯»å…¥çš„æ˜¯éç»ˆç»“ç¬¦ N, é‚£ä¹ˆä¹‹å‰ä¸€å®šæœ‰ä¸€ä¸ªå½’çº¦ $N\\rightarrow \\alpha$ ä½¿å¾— DFA å›é€€åˆ°äº†çŠ¶æ€ a.\n  2. å‡è®¾ç°åœ¨çŠ¶æ€ a æœ‰ä¸€ä¸ª Goto-Reduce Conflict, é‚£ä¹ˆæ„å‘³ç€ç°åœ¨æ ˆé¡¶ä¸€å®šåˆæœ‰ä¸€ä¸ªå®Œå…¨è¯†åˆ«çš„å¥æŸ„ $\\beta$, æ„æˆä¸€ä¸ªå½’çº¦ $P\\rightarrow\\beta$.\n  3. è¿™æ„å‘³ç€åœ¨å½’çº¦ $N\\rightarrow \\alpha$ ä¹‹å‰, æ ˆé‡Œé¢çš„çŠ¶æ€æ˜¯:  $\\space \\cdots\\beta \\alphaæ ˆé¡¶$.\n  4. ä½†æ˜¯è¿™æ˜¯ä¸å¯èƒ½çš„, æˆ‘ä»¬æ„é€  DFA çš„æ–¹å¼å†³å®šäº† $\\beta$ ä¸€å®šä¸€å‡ºç°å°±ä¼šè¢«å½’çº¦æ‰, ä¸å¯èƒ½è¢«å®Œæ•´çš„æ”¾åˆ°æ ˆé‡Œé¢å».\n\n[^3]: è§CCP\u0026P Page155\n[^4]: è§CCP\u0026P 5.2.2èŠ‚\n[^5]: è§ CCP\u0026P 5.2.3 èŠ‚\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-4-3_SLR_parse":{"title":"Compiler-4-3_SLR_parse","content":"## SLR parse\n\n- åœ¨ LR (0) é‡Œé¢, Reduce å®Œå…¨å æ®äº†ä¸€ä¸ªçŠ¶æ€, è¿™é€ æˆäº†æå¤§çš„æµªè´¹:\n  - å›å¿† LL åˆ†æé‡Œé¢çš„ FOLLOW é›†åˆ: FOLLOW (A) = {å¯ä»¥ç«‹å³è·Ÿåœ¨ A åé¢çš„æ‰€æœ‰ç»ˆç»“ç¬¦}\n  - ä¸€ä¸ªçŠ¶æ€éœ€è¦ Reduce ä»£è¡¨ç€å‡ºç°äº†ä¸€ä¸ªå®Œå…¨è¯†åˆ«å¥æŸ„çš„é¡¹: $P\\rightarrow\\alpha\\space \\cdot$, ä½†æ˜¯ä»”ç»†æƒ³æƒ³: æˆ‘ä»¬å®Œå…¨å¯ä»¥å†å‘åå¤šçœ‹ä¸€ä¸ªç¬¦å·, åªæœ‰åœ¨ä¸‹ä¸€ä¸ªç¬¦å·å±äº FOLLOW (P) çš„æ—¶å€™, æˆ‘ä»¬æ‰åº”è¯¥è§„çº¦,\n  ![påé¢è¦æœ‰Follow(p)](notes/2021/2021.10/assets/img_2022-10-15-58.png)\n    - å¦‚ä¸Šå›¾æ‰€ç¤º, è¦æ˜¯ b ä¸åœ¨ FOLLOW (P) é‡Œé¢çš„è¯, Î±å°±ä¸åº”è¯¥æ˜¯ $P\\rightarrow\\alpha$ çš„å¥æŸ„äº†, åº”è¯¥ç»§ç»­ shift, è¯»è¿› b, å¯»æ‰¾å¥æŸ„ $Q\\rightarrow\\alpha\\space b\\cdots$\n\nSLR (1) åˆ†ææ³•å°±æ˜¯åˆ©ç”¨ Look ahead, çœ‹çœ‹ä¸‹ä¸€ä¸ªç¬¦å·å’Œè§„çº¦äº§ç”Ÿå¼çš„éç»ˆç»“ç¬¦æ˜¯ä¸æ˜¯ä¸€è‡´çš„, åªæœ‰åœ¨ä¸€è‡´çš„æ—¶å€™æ‰è¿›è¡Œè§„çº¦, æ¶ˆé™¤äº†éƒ¨åˆ†çš„å†²çª.\n\n### DFA çš„æ„é€ \n\nSLR (k) åˆ†æåœ¨ DFA çš„æ„é€ ä¸Šå’Œ LR (0) åˆ†ææ³•å®Œå…¨ä¸€è‡´.\n\n### åˆ†æè¡¨çš„æ„é€ \n\nSLR (1) åœ¨æ„é€ åˆ†æè¡¨çš„æ—¶å€™ä¸ LR (0) çš„å”¯ä¸€ä¸åŒå°±æ˜¯ Reduce çš„å¡«å…¥æ–¹å¼:\n\n- LR (0) è§‚å¯Ÿæ¯ä¸€ä¸ª set é‡Œé¢çš„é¡¹, åªè¦å‡ºç°å®Œå…¨è¯†åˆ«å¥æŸ„çš„é¡¹ $P\\rightarrow\\alpha\\space \\cdot$ , å°±å°†è¿™ä¸ªçŠ¶æ€å…¨éƒ¨æ ‡æˆ Reduce $P\\rightarrow\\alpha$\n- SLR (1) è¿˜è¦è§‚å¯Ÿ Follow (P), åªåœ¨å±äº Follow (P) çš„ç»ˆç»“ç¬¦ä¸‹é¢å¡«å…¥ Reduce\n\nå¯¹æ¯”:\n\n- æ–‡æ³•:\n ![400](notes/2021/2021.10/assets/img_2022-10-15-59.png)\n- SLR (1) åˆ†æè¡¨:\n ![300](notes/2021/2021.10/assets/img_2022-10-15-60.png)\n- LR (0) åˆ†æè¡¨:\n ![400](notes/2021/2021.10/assets/img_2022-10-15-61.png)\n\n### SLR (k) - k\u003e1\n\nSLR (k) é¡¾åæ€ä¹‰å°±æ˜¯åœ¨å¡«è¡¨çš„æ—¶å€™å‘åè§‚å¯Ÿ k ä¸ªç¬¦å·, æ€æ ·è§‚å¯Ÿå‘¢?\n\n- é™¤äº†åœ¨ Reduce çš„æ—¶å€™è§‚å¯Ÿ, è¿˜éœ€è¦åœ¨ Shift ä¹‹å‰è§‚å¯Ÿ\n\n\u003e #### First Follow é›†åˆçš„æ¨å¹¿\n\n\u003e $First(A)$ æ˜¯ A æ¨å‡ºçš„æ‰€æœ‰ç»ˆç»“ç¬¦ä¸²é‡Œé¢çš„ç¬¬ä¸€ä¸ªç»ˆç»“ç¬¦\n\u003e $First_k(A)$ å³ A æ¨å‡ºçš„æ‰€æœ‰ç»ˆç»“ç¬¦ä¸²é‡Œé¢çš„å‰ k ä¸ªç»ˆç»“ç¬¦ (æ‰€æœ‰é•¿åº¦ä¸º k çš„å‰ç¼€)\n\u003e\n\u003e åŒç†, $Follow_k(A)$ å³ A æ¨å‡ºçš„æ‰€æœ‰ç»ˆç»“ç¬¦ä¸²é‡Œé¢çš„å k ä¸ªç»ˆç»“ç¬¦ (æ‰€æœ‰é•¿åº¦ä¸º k çš„åç¼€)\n\n- **Shift:**\n å¯¹äº $Aâ†’Î±.XÎ²$ (å…¶ä¸­ X æ˜¯ä¸€ä¸ªç¬¦å·, $Î²$ æ˜¯äº§ç”Ÿå¼å‰©ä¸‹çš„éƒ¨åˆ†)\n ç°åœ¨è¾“å…¥ä¸²æ˜¯ $Xw\\cdots$, å…¶ä¸­ $|Xw|=k$.\n å¦‚æœ $Xw\\in First_k(XÎ²)$ é‚£ä¹ˆå°±å°† $X$ è¯»å…¥, å°†ç›¸åº”çš„ Shift é¡¹å¡«å…¥è¡¨ä¸­.\n æ¢å¥è¯è¯´, å¦‚æœ $Xw\\in First_k(XÎ²)$, è¯´æ˜ç°åœ¨è¾“å…¥çš„å‰ k ä¸ªéƒ½å¯èƒ½è¢«è¿™ä¸ªäº§ç”Ÿå¼æ¨å‡º, æ‰€ä»¥æˆ‘ä»¬è¯»å…¥ $X$.\n- **Reduce:**\n å¯¹äº $Pâ†’Î±.$\n ç°åœ¨è¾“å…¥ä¸²æ˜¯ $w\\cdots$, å…¶ä¸­ $w$ æ˜¯å‰ k ä¸ªç»ˆç»“ç¬¦.\n å¦‚æœ $w\\in Follow_k(P)$, å³è¾“å…¥ä¸²æ¥ä¸‹æ¥çš„å‰ k ä¸ªå­—ç¬¦å¯ä»¥ç«‹å³è·Ÿåœ¨ P åé¢, é‚£ä¹ˆå°† Reduce $Pâ†’Î±$ å¡«å…¥è¡¨ä¸­ç›¸åº”ä½ç½®\n\nSLR (k) æ¯” SLR (1) æ›´å¼ºå¤§, ä½†æ˜¯ä¹Ÿæ¯” SLR (1) å¤æ‚å¾—å¤š. åœ¨å®é™…åº”ç”¨ä¸­, æˆ‘ä»¬é€šå¸¸é‡‡ç”¨åé¢ä»‹ç»çš„ LALR åˆ†ææ–¹æ³•.\n\n### SLR åˆ†ææ–¹æ³•çš„ä¸è¶³\n\n- SLR çš„ä¸è¶³åœ¨äº: å®ƒåœ¨åˆ†æçš„æ—¶å€™åˆ©ç”¨äº† Look ahead, ä½†æ˜¯åœ¨æ„å»º DFA çš„æ—¶å€™å´æ²¡æœ‰è€ƒè™‘åˆ° Look Head.\n- è€ƒè™‘ä¸‹é¢è¿™ä¸ª SLR (1) çš„ä¾‹å­:\n  $$\\begin{aligned}\n \u0026S \\rightarrow \\mathbf{i} \\boldsymbol{d} \\mid V:=E \\\\\n \u0026V \\rightarrow \\mathbf{i} \\boldsymbol{d} \\\\\n \u0026E \\rightarrow V \\mid \\boldsymbol{n}\n \\end{aligned}$$\n  - å…¶ä¸­ S ä»£è¡¨èµ‹å€¼è¯­å¥ (Assign-Statement), V ä»£è¡¨å˜é‡ (Variable), E ä»£è¡¨è¡¨è¾¾å¼ (Expression)\n  - 1. æ„é€ çŠ¶æ€ 0:\n  $$\\begin{aligned}\n \u0026S^{\\prime} \\rightarrow . S \\\\\n \u0026S \\rightarrow . id \\\\\n \u0026S \\rightarrow . V:=E \\\\\n \u0026V \\rightarrow . id\n \\end{aligned}$$\n  2. çŠ¶æ€ 0 è¾“å…¥ç»ˆç»“ç¬¦ $id$,  shift å¾—åˆ°çŠ¶æ€ 1:\n   $$\\begin{aligned}\n  \u0026S \\rightarrow id . \\\\\n  \u0026V \\rightarrow id .\n  \\end{aligned}$$\n  3. $Follow (S)=\\{\\$\\}, Follow (V)=\\{\\$, :=\\}$, æ‰€ä»¥è¿™ä¸¤ä¸ªé¡¹éƒ½ä¼šåœ¨ $ç¬¦å·å¤„äº§ç”Ÿä¸€ä¸ªè§„çº¦, è¿™æ˜¯ä¸€ä¸ª Reduce-Reduce å†²çª.\n  - ä½†æ˜¯è¿™ä¸ªå†²çªå®é™…ä¸Šæ˜¯ä¸å­˜åœ¨çš„, **åœ¨è¯»å…¥ $:=$ ä¹‹å‰**, $V \\rightarrow id .$ ä¸åº”è¯¥åœ¨å‰ç»ç¬¦å·ä¸º $ çš„æ—¶å€™è¿›è¡Œè§„çº¦:\n  - ![200](notes/2021/2021.10/assets/img_2022-10-15-62.png)\n\nLR (1) åˆ†æå°†å‰ç»ç¬¦å·çš„åˆ¤æ–­æ•´åˆåˆ° DFA çš„æ„é€ è¿‡ç¨‹ä¸­å», è§£å†³äº†è¿™ä¸ªé—®é¢˜.\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-4-4_LR1_%E5%88%86%E6%9E%90":{"title":"Compiler-4-4_LR(1)_åˆ†æ","content":"## LR (1) åˆ†æ\n\nLR (1) åˆ†æåœ¨ä¸€å¼€å§‹æ„å»º DFA çš„æ—¶å€™ä¾¿è€ƒè™‘åˆ°äº†å‰ç»ç¬¦å·, ä½¿å¾—å…¶åœ¨ç»“æ„ä¸Šæ›´ä¸ºå¼ºå¤§.\n\n### LR (1) é¡¹\n\nåœ¨ LR (0) é¡¹çš„åŸºç¡€ä¸Š, LR (1) é¡¹æ·»åŠ äº†å‰ç»ç¬¦å·:\n$$A\\rightarrow \\alpha\\cdot \\beta, a $$\n\n- å…¶ä¸­ $a$ æ˜¯å‰ç»ç¬¦å·\n\n### LR(1)åˆ†æ: æ„é€ DFA\n\n- æ„é€ DFAçš„ç›®æ ‡å’Œä¹‹å‰ä¸€æ ·: å¯»æ‰¾LR(1)é¡¹çš„è§„èŒƒé›†, å¹¶ä¸”æ„é€ è¿™äº›é›†åˆä¹‹é—´çš„è½¬æ¢å…³ç³».\n\n- å°½ç®¡æˆ‘ä»¬åœ¨å®é™…æ„é€ çš„æ—¶å€™å¾€å¾€ç›´æ¥æ„é€ DFA, ä½†æ˜¯ä»NFAçš„è§’åº¦æ¥è§‚å¯Ÿæ„é€ è¿‡ç¨‹æœ‰åŠ©äºæˆ‘ä»¬ç†è§£LR(1)çš„æœ¬è´¨ç‰¹å¾:\n\n- å¯¹äºLR(1), çŠ¶æ€è½¬æ¢åœ¨æ„é€ æ—¶æœ€å¤§çš„ä¸åŒæ˜¯: $\\varepsilon$-è½¬ç§»éœ€è¦è€ƒè™‘**å‰ç»ç¬¦å·çš„å˜åŒ–**.\n\n#### LR(1): NFAçš„çŠ¶æ€è½¬ç§»\n\n- æˆ‘ä»¬å…ˆè€ƒè™‘éç©ºçš„è½¬ç§»:\n $$[A\\rightarrow \\alpha\\cdot X\\beta,\\space a]\\overset{shift(X)}\\longrightarrow[A\\rightarrow \\alpha X\\cdot\\beta,\\space a]$$ (Xæ˜¯ç»ˆç»“ç¬¦æˆ–éç»ˆç»“ç¬¦)\n  - åœ¨ä¸Šé¢, é¡¹$[A\\rightarrow \\alpha\\cdot X\\beta,\\space a]$è¯»å…¥äº†ç¬¦å·$X$(å°†$X$å‹å…¥ç¬¦å·æ ˆé¡¶), è½¬ç§»åˆ°äº†æ–°çŠ¶æ€$[A\\rightarrow \\alpha X\\cdot\\beta,\\space a]$, **å‰ç»ç¬¦å·ä¸å˜**.\n\næ³¨æ„åˆ°é™¤äº†ä¸å˜çš„å‰ç»ç¬¦å·a, è¿™å’ŒLR(0)é‡Œé¢å‡ ä¹ç›¸åŒ.\n\n- æ¥ä¸‹æ¥è€ƒè™‘$\\varepsilon$-è½¬ç§», å³æ„é€ ç­‰ä»·é›†CLosure(A)çš„æ—¶å€™æ¶‰åŠåˆ°çš„è½¬ç§»:\n $$[A\\rightarrow \\alpha\\cdot B\\gamma,\\space a]\\overset{\\varepsilon}\n \\longrightarrow\n [B\\rightarrow \\cdot\\beta,\\space b_i\\space ]$$  \n å…¶ä¸­, $b_i\\in First(\\gamma a)$, æ‰€ä»¥è¿™å…¶å®æ˜¯å¤šä¸ª$\\varepsilon$-è½¬ç§»:\n ![LR(1) Transition Closure](notes/2021/2021.10/assets/LR(1)%20Transition%20Closure.svg)\n%%$$\\begin{align}[A\\rightarrow \\alpha\\cdot B\\gamma,\\space a]\u0026\\overset{\\varepsilon}\\longrightarrow [B\\rightarrow \\cdot\\beta,\\space b_1\\space ]\\\\[A\\rightarrow \\alpha\\cdot B\\gamma,\\space a]\u0026\\overset{\\varepsilon}\\longrightarrow [B\\rightarrow \\cdot\\beta,\\space b_2\\space ]\\\\\u0026\\quad\\vdots\\\\[A\\rightarrow \\alpha\\cdot B\\gamma,\\space a]\u0026\\overset{\\varepsilon}\\longrightarrow [B\\rightarrow \\cdot\\beta,\\space b_n\\space ]\\end{align}$$%%\n- ä¸LR(0)ä¸åŒ, æˆ‘ä»¬åœ¨æ„é€ ç©ºè½¬ç§»çš„æ—¶å€™è¿˜éœ€è¦è€ƒè™‘å‰ç»ç¬¦å·çš„å˜åŒ–, å³$b_i$å¯ä»¥æ˜¯ä»€ä¹ˆç¬¦å·:\n  - é¦–å…ˆ, å› ä¸ºæœ‰äº§ç”Ÿå¼$A\\rightarrow \\alpha B\\gamma$, æ‰€ä»¥$b_i\\in First(\\gamma)$, åˆå¦‚æœ$\\gamma$æ˜¯å¯ä¸ºç©ºçš„, é‚£ä¹ˆ$b_i$å¯èƒ½æ˜¯$a$. ç»¼ä¸Š, $b_i\\in First(\\gamma a)$\n\n- ä¸SLR(1)ä¸åŒ, æˆ‘ä»¬åœ¨è€ƒè™‘å‰ç»ç¬¦å·çš„æ—¶å€™è¿˜è€ƒè™‘äº†å‰ä¸€ä¸ªLR(1)é¡¹ (é‡Œé¢çš„ $\\gamma$ å’Œ $a$ ), è€Œä¸æ˜¯å°†æ•´ä¸ª$Follow(B)$å†™ä¸Šå».\n  - æˆ‘ä»¬è€ƒè™‘$First(\\gamma a)$ ä¸$Follow(B)$ çš„å…³ç³»:\n  é¦–å…ˆ$A\\rightarrow \\alpha B\\gamma$ , æ‰€ä»¥$First(\\gamma)\\subset Follow(B)$. å¦‚æœ$\\gamma$æ˜¯å¯ä¸ºç©ºçš„, é‚£ä¹ˆæœ‰$Follow(A)\\subset Follow(B)$ , åˆ $a\\in Follow(A)$. æ‰€ä»¥$First(\\gamma a)\\subseteq Follow(B)$.\n- æ³¨æ„: å› ä¸º$B$è¿˜å¯èƒ½å‡ºç°åœ¨å…¶ä»–äº§ç”Ÿå¼é‡Œé¢, æ‰€ä»¥$First(\\gamma a)$å¾ˆæœ‰å¯èƒ½æ˜¯$Follow(B)$çš„çœŸå­é›†, è¿™æ­£æ˜¯LR(1)æ–‡æ³•çš„å¼ºå¤§ä¹‹å¤„.\n  *(The power of the general LR(1) method lies in the fact that the set $First(\\gamma a)$ may be a proper subset of $Follow(B)$. [^6])*\n\n##### å†è®ºSLR(1)\n\nSLR(1)åˆ†ææ³•è™½ç„¶åœ¨æ„é€ DFAçš„æ—¶å€™æ²¡æœ‰è€ƒè™‘å‰ç»ç¬¦å·, ä½†æ˜¯æˆ‘ä»¬å¯ä»¥è¿™æ ·ç±»æ¯”LR(1):\n\n- ä»¤$Follow(B)=\\{b_j, c_i\\mid b_j\\in First(\\gamma a), c_i\\notin First(\\gamma a)\\}$, åˆ™æˆ‘ä»¬æ„é€ çš„é¡¹ç›®é›†æ—¢åŒ…æ‹¬$[B\\rightarrow \\cdot\\beta,\\space b_j\\space ]$, åˆåŒ…æ‹¬ $[B\\rightarrow \\cdot\\beta,\\space c_i\\space ]$, å¦‚ä¸‹å›¾å·¦è¾¹æ‰€ç¤º:\n\n ![SLR(1) Transition States](notes/2021/2021.10/assets/SLR(1)%20Transition%20States.svg)\n\n- åœ¨ä¸Šå›¾ä¸­, å‡è®¾$\\beta$æ˜¯ä¸€ä¸ªç»ˆç»“ç¬¦,  å¡«è¡¨çš„æ—¶å€™åœ¨$Follow(B)$å¯¹åº”çš„åœ°æ–¹éƒ½å¡«ä¸ŠReduce, å…¶å®å°±ç›¸å½“äºå°†å›¾ä¸­å³è¾¹æ‰€æœ‰çš„é¡¹éƒ½å½“æˆè¦è§„çº¦çš„é¡¹.\n\n- ç›¸æ¯”ä¹‹ä¸‹, å¦‚æœæˆ‘ä»¬ä»…ä»…åŒ…æ‹¬$First(\\gamma a)$é‡Œé¢çš„é¡¹, åˆ™ç›¸å½“äºå»é™¤ä¸Šå›¾é‡Œé¢æ‰€æœ‰é»„è‰²çš„é¡¹. åŸºäº$[A\\rightarrow\\alpha\\cdot B\\gamma,\\space a]$è¿™ä¸ªå‰æ, è¿™äº›é»„è‰²çš„é¡¹å®é™…ä¸Šæ˜¯ä¸å¯èƒ½è¢«è§„çº¦çš„, å¯ä»¥è§å¾—, LR(1)åˆ†ææœ‰ç€\"æ›´ç²¾å‡†çš„å¥æŸ„è¯†åˆ«èƒ½åŠ›\", ç›¸æ¯”SLR(1)æ–‡æ³•, LR(1)æ–‡æ³•æœ‰ç€æ›´å¼ºçš„è¡¨ç°åŠ›.\n\n ![LR(1) Transition States](notes/2021/2021.10/assets/LR(1)%20Transition%20States.svg)\n\n### æ„é€ DFA\n\næˆ‘ä»¬è¿˜æ˜¯ä»åˆå§‹çŠ¶æ€å‡ºå‘, é€æ­¥æ„å»ºé—­åŒ…, ç›´åˆ°æ•´ä¸ªå›¾å½¢ä¸å†å˜åŒ–.\n\n- åˆå§‹çŠ¶æ€:\n $$[S^\\prime\\rightarrow\\cdot S, \\$]$$\n å…¶ä¸­$ä»£è¡¨å¥å­çš„ç»“æŸ.\n\n- ä¸‹é¢æ˜¯å–é—­åŒ…çš„æ“ä½œä¸è½¬ç§»æ“ä½œçš„ç®—æ³•:\n![](notes/2021/2021.10/assets/Pasted%20image%2020211109222126.png)[^7]\n\n- ä¸‹é¢æ˜¯ Reduce çš„ç®—æ³•, æˆ‘ä»¬åªåœ¨è¿™ä¸ªé¡¹å‰ç»ç¬¦å·å¯¹åº”çš„åœ°æ–¹å¡«ä¸Š Reduce, ä¹Ÿå°±æ˜¯ $First (\\gamma a)$ æŒ‡ä»£çš„åœ°æ–¹.\n![400](notes/2021/2021.10/assets/Pasted%20image%2020211109222451.png)\n\n### å¼€å§‹åˆ†æ\n\n- åƒæ‰ç»ˆç»“ç¬¦(Shift)æˆ–è€…éç»ˆç»“ç¬¦(Goto)éƒ½åªéœ€è¦å°†ç¬¦å·å‹æ ˆ, ç§»åŠ¨åˆ°æ‹¥æœ‰å¯¹åº”é¡¹çš„çŠ¶æ€:\n $$[A\\rightarrow \\alpha\\cdot X\\beta,\\space a]\\overset{shift(X)}\\longrightarrow[A\\rightarrow \\alpha X\\cdot\\beta,\\space a]$$\n- Reduce æ“ä½œéœ€è¦å‰ç»ä¸€ä¸ªç¬¦å·. æ¯”å¦‚ç°åœ¨çš„çŠ¶æ€é‡Œé¢æœ‰ $[A\\rightarrow\\alpha\\space ., a\\space ]$ å¦‚æœè¾“å…¥ä¸²é‡Œé¢ä¸‹ä¸€ä¸ªç¬¦å·æ˜¯ $a$, æ‰è¿›è¡Œ Reduce æ“ä½œ.\n\n- é‡åˆ° $[S^â€² â†’ S., \\$]$, è¯´æ˜åˆ†ææˆåŠŸ.\n\n- å¦‚æœå½“å‰è¡¨é¡¹ä¸ºç©º, åˆ™æŠ¥é”™\n\n[^6]: CCP\u0026P 5.4èŠ‚\n[^7]: è¿™ä¸ªå›¾æ˜¯è™ä¹¦é‡Œé¢çš„ç®—æ³•, æ‰€ä»¥ç¬¦å·å’Œå‰é¢ç¨æœ‰ä¸åŒ, è¯·æ³¨æ„\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-4-5_LALR1":{"title":"Compiler-4-5_LALR(1)","content":"## LALR (1)\n\n- LR (1) çš„åˆ†æè¡¨é€šå¸¸ååˆ†å·¨å¤§, ä¸ºäº†åœ¨èŠ‚çœç©ºé—´çš„åŒæ—¶ä¿ç•™ LR (1) å¤§éƒ¨åˆ†çš„ä¼˜ç‚¹, æˆ‘ä»¬å¸¸å¸¸é‡‡ç”¨ LALR (1) åˆ†ææ–¹æ³•, LALR ä»£è¡¨ Look-Ahead LR.\n\n- LR (1) åˆ†æçš„ DFA é‡Œé¢å¸¸å¸¸æœ‰ä¸¤ä¸ªçŠ¶æ€çš„äº§ç”Ÿå¼å®Œå…¨ç›¸åŒ, åªæœ‰å‰ç»ç¬¦å·ä¸åŒ. LALR åˆ†æå°±æ˜¯å°†è¿™æ ·çš„çŠ¶æ€åˆå¹¶ä¸ºä¸€ä¸ªçŠ¶æ€.\n\n- åœ¨åˆå¹¶çŠ¶æ€ä»¥å, LALR çš„ DFA å’Œ LR (0) çš„ DFA æ‹“æ‰‘ç»“æ„ä¸Šæ˜¯ä¸€æ ·çš„, å”¯ä¸€ä¸åŒçš„æ˜¯æ¯ä¸ªçŠ¶æ€é‡Œé¢éƒ½æ˜¯ LR (1) é¡¹, åŒ…å«äº†å‰ç»ç¬¦å·.\n\n- æˆ‘ä»¬å¯ä»¥ä» LR (1) çš„ DFA æ„é€  LALR çš„ DFA, ä½†æ˜¯è¿™æ ·éœ€è¦äº‹å…ˆæ„é€  LR (1) åºå¤§çš„è¡¨. æ‰€ä»¥æˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨ä¸€ç§ç§°ä¸º \"å‰ç»ä¼ æ’­ (Look-ahead Propagation) \" çš„æ–¹æ³•æ¥ä» LR (0) çš„ DFA æ„é€  LALR çš„ DFA.\n  - Look-ahead Propagation å¾ˆç®€å•, è¯·å‚è§ã€CCP\u0026Pã€‘Compiler Construction Principles and Practice by Kenneth C. Louden å¯¹åº”çš„éƒ¨åˆ†\n\n- æ‰€æœ‰åˆç†çš„ç¨‹åºè®¾è®¡è¯­è¨€éƒ½æœ‰ä¸€ä¸ª LALR (1) æ–‡æ³•ï¼Œå¹¶ä¸”å­˜åœ¨ç€è®¸å¤šå¯¹ LALR (1) æ–‡æ³•æœ‰æ•ˆçš„è¯­æ³•åˆ†æå™¨ç”Ÿæˆå™¨å·¥å…·ã€‚ç”±äºè¿™ä¸€åŸå› ï¼Œ LALR (1) æ–‡æ³•å·²å˜æˆç¨‹åºè®¾è®¡è¯­è¨€å’Œè‡ªåŠ¨è¯­æ³•åˆ†æå™¨ç”Ÿæˆå™¨çš„æ ‡å‡†ã€‚[^8]\n\n- Yacc å°±æ˜¯ä¸€ä¸ª LALR (1) åˆ†æå™¨çš„è‡ªåŠ¨ç”Ÿæˆå™¨\n\n[^8]: è™ä¹¦ 3.3.5\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Compiler-4_LR%E5%88%86%E6%9E%90":{"title":"Compiler-4_LRåˆ†æ","content":"# LR åˆ†æ\n\n\u003cdiv align=\"right\"\u003e 2021-11-05\u003c/div\u003e\n\nTags: #Compiler #Course \n\n- åœ¨è‡ªåº•å‘ä¸Šè¯­æ³•åˆ†æä¸­, å¦‚ä½•**å¯»æ‰¾å¥æŸ„**æ˜¯å…³é”®é—®é¢˜\n\n[Compiler-4-1_ä»€ä¹ˆæ˜¯ LR åˆ†æ](notes/2021/2021.10/Compiler-4-1_ä»€ä¹ˆæ˜¯%20LR%20åˆ†æ.md)\n\n[Compiler-4-2_LR(0)_Parse](notes/2021/2021.10/Compiler-4-2_LR(0)_Parse.md)\n\n[Compiler-4-3_SLR_parse](notes/2021/2021.10/Compiler-4-3_SLR_parse.md)\n\n[Compiler-4-4_LR(1)_åˆ†æ](notes/2021/2021.10/Compiler-4-4_LR(1)_åˆ†æ.md)\n\n[Compiler-4-5_LALR(1)](notes/2021/2021.10/Compiler-4-5_LALR(1).md)\n\n\n## æ€»ç»“\n- æˆ‘ä»¬ä» LR (0) åˆ†ææ–¹æ³•å¼€å§‹, äº†è§£äº†ç§»ä½å½’çº¦åˆ†ææ–¹æ³•çš„åŸºæœ¬è¦ç‚¹, è¿›ä¸€æ­¥å°†\"å‰ç»\"çš„æ€æƒ³åŠ å…¥åˆ°è‡ªåº•å‘ä¸Šåˆ†æçš„è¿‡ç¨‹ä¸­å», æœ€ç»ˆæ„å»ºäº†æ›´åŠ å¼ºå¤§çš„ SLR (1) åˆ†æå™¨å’Œ LR (1) åˆ†æå™¨.\n\n- ç›¸æ¯” SLR (1) åˆ†æå™¨, LR (1) åˆ†æå°†å‰ç»çš„æ€æƒ³èåˆåˆ°äº† DFA ç­‰ä»·ç±»çš„æ„å»ºä¸­å», æœ€å¤§ç¨‹åº¦ä¸Šåœ°åˆ©ç”¨äº†æ ˆå†…çš„å·²çŸ¥ä¿¡æ¯, é¿å…äº†æ— æ•ˆçš„å½’çº¦, å‡å°‘äº†å†²çª, æœ‰ç€æœ€å¼ºå¤§çš„è¡¨è¾¾èƒ½åŠ›.\n\n- LALR (1) æ˜¯å¯¹ LR (1) çš„åˆç†ç®€åŒ–, å®ƒåœ¨ä¿ç•™ LR (1) çš„å¤§éƒ¨åˆ†èƒ½åŠ›çš„åŒæ—¶æå¤§åœ°å‡å°äº†å¤æ‚åº¦.\n\n- ç¼–è¯‘å™¨æ˜¯å¯¹\"è®¡ç®—\"çš„ç­‰ä»·å˜æ¢, é‚£ä¹ˆè¯­æ³•åˆ†æè¿™ä¸€æ­¥å…¶å®ç›¸å½“äº\"é‡æ„/è§£é‡Š\"æ€ç»´è¿‡ç¨‹.\n- ç¼–è¯‘å™¨å°†æ›´æŠ½è±¡å½¢å¼çš„è®¡ç®—è§£é‡Šä¸ºè®¡ç®—æœºèƒ½å¤Ÿç†è§£çš„ä½çº§å½¢æˆ, è€Œè¿™è®©æˆ‘ä»¬èƒ½å¤Ÿåœ¨æ›´é«˜å±‚é¢ä¸Šå»æ€è€ƒè§£å†³é—®é¢˜çš„æ–¹æ³•, ç”¨æ›´ç²¾ç‚¼çš„è¯­è¨€æ¥è¡¨è¾¾è§£å†³è¿™ä¸ªé—®é¢˜æ‰€éœ€è¦çš„è®¡ç®—æ­¥éª¤\n- è¯æ³•, è¯­æ³•åˆ†æå°±æ˜¯åœ¨æ ¹æ®è§„åˆ™é‡æ„ä¸€ä¸ªå¥å­çš„ç»„æˆ(é‡æ„è¯­æ³•æ ‘). æˆ‘ä»¬æ‹¿åˆ°ä¸€ä¸ªé—®é¢˜, ä¸æ–­æ€è€ƒ, ä¿®æ”¹ æœ€ç»ˆå¾—åˆ°ä¸€ä¸ªå®Œæ•´çš„ç¨‹åº, é‚£ä¹ˆè¯­æ³•åˆ†æå°±æ˜¯é‡ç°æˆ‘ä»¬\"æ¨å¯¼è¿™ä¸ªç¨‹åºçš„è¿‡ç¨‹\", å³è§£å†³é—®é¢˜çš„è¿‡ç¨‹, æ€ç»´çš„è¿‡ç¨‹.\n---\nåé¢çš„éƒ¨åˆ†ç¬”è®°è¿˜æ²¡æœ‰, å…ˆæŠŠæ€è€ƒå†™åœ¨è¿™é‡Œ:\n\n- è¯­ä¹‰åˆ†æå…¶å®è¿˜æœ‰æ£€æŸ¥é”™è¯¯åœ°åŠŸèƒ½, é‚£ä¹ˆç¼–è¯‘å™¨å…¶å®è¿˜æœ‰ä¸€ä¸ªåŠŸèƒ½æ˜¯è´Ÿè´£\"æ¸…æ´—\", æ£€æŸ¥é”™è¯¯\n- å…¶å®\"è§£é‡Šæˆæ›´ä½çº§çš„è¿ç®—\"è¿™ä¸€æ­¥å¤§éƒ¨åˆ†æ˜¯ä¸­é—´ä»£ç /ç›®æ ‡ä»£ç ç”Ÿæˆè¿™ä¸€æ­¥åœ¨åš\n\n- ç¼–è¯‘å™¨çš„ä¸»è¦è´£ä»»/èŒè´£: è§£é‡Š(è®¡ç®—æ­¥éª¤), æ£€æŸ¥(ä»£ç é”™è¯¯), ä¼˜åŒ–(ä»£ç æ€§èƒ½)\n\n\n\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Dot_Product_and_Linear_Transformation-%E5%90%91%E9%87%8F%E5%86%85%E7%A7%AF%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2":{"title":"Dot_Product_and_Linear_Transformation-å‘é‡å†…ç§¯ä¸çº¿æ€§å˜æ¢","content":"# å†…ç§¯ä¸çº¿æ€§å˜æ¢\n\n\u003cdiv align=\"right\"\u003e 2021-10-29\u003c/div\u003e\n\nTags: #Math/LinearAlgebra #LinearTransformation #DotProduct #Vector\n\n- å‘é‡å†…ç§¯å³å¤šç»´ç©ºé—´åˆ°ä¸€ç»´ç©ºé—´çš„çº¿æ€§å˜æ¢. \n\t- å°†ç¬¬äºŒä¸ªå‘é‡å˜æ¢åˆ°ç¬¬ä¸€ä¸ªå‘é‡çš„æ–¹å‘ä¸Šå»\n\t- å¦‚æœç¬¬ä¸€ä¸ªå‘é‡çš„é•¿åº¦ä¸º1, é‚£ä¹ˆå°±æ˜¯ç¬¬äºŒä¸ªå‘é‡åˆ°ç¬¬ä¸€ä¸ªå‘é‡æ–¹å‘ä¸Šçš„æŠ•å½±å˜æ¢\n## Highlights\n![](notes/2021/2021.10/assets/img_2022-10-15-63.png)\n![](notes/2021/2021.10/assets/img_2022-10-15-1.gif)\n![](notes/2021/2021.10/assets/img_2022-10-15-2.gif)\n![](notes/2021/2021.10/assets/img_2022-10-15-3.gif)\n\n## è§†é¢‘\n\n\u003ciframe width=\"800\" height=\"480\" src=\"https://www.youtube.com/embed/LyGKycYT2v0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Odyssey-%E5%A5%A5%E5%BE%B7%E8%B5%9B":{"title":"Odyssey-å¥¥å¾·èµ›","content":"# Odyssey - å¥¥å¾·èµ›\n\n\u003cdiv align=\"right\"\u003e 2021-11-06\u003c/div\u003e\n\nTags: #Greek #Poems #Homer #Literature\n\nã€Šå¥¥å¾·èµ›ã€‹ï¼ˆå¤å¸Œè…Šè¯­ï¼šá½ˆÎ´ÏÏƒÏƒÎµÎ¹Î±ï¼Œè½¬å†™ï¼šOdÃ½sseiaï¼Œè‹±è¯­ï¼šOdysseyï¼‰æ˜¯å¤å¸Œè…Šæœ€é‡è¦çš„ä¸¤éƒ¨å²è¯—ä¹‹ä¸€ï¼ˆå¦ä¸€éƒ¨æ˜¯ã€Šä¼Šåˆ©äºšç‰¹ã€‹ï¼‰ã€‚ã€Šå¥¥å¾·èµ›ã€‹å»¶ç»­äº†ã€Šä¼Šåˆ©äºšç‰¹ã€‹çš„æ•…äº‹æƒ…èŠ‚ï¼Œç”±ç›²è¯—äººè·é©¬æ‰€ä½œã€‚è¿™éƒ¨å²è¯—æ˜¯è¥¿æ–¹æ–‡å­¦çš„å¥ åŸºä¹‹ä½œï¼Œæ˜¯é™¤ã€Šä¼Šåˆ©äºšç‰¹ã€‹å¤–ç°å­˜æœ€å¤è€çš„è¥¿æ–¹æ–‡å­¦ä½œå“ã€‚\n\nIt follows the Greek hero Odysseus, king of Ithaca, and his journey home after the Trojan War. After the war itself, which lasted ten years, his journey lasted for ten additional years, during which time he encountered many perils and all his crew mates were killed. In his absence, Odysseus was assumed dead, and his wife Penelope and son Telemachus had to contend with a group of unruly suitors who were competing for Penelope's hand in marriage. \n\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Part.28_Cost_Function-Neural_NetworkML_Andrew.Ng.":{"title":"Part.28_Cost_Function-Neural_Network(ML_Andrew.Ng.)","content":"# Cost Function - Neural Network\n\n\u003cdiv align=\"right\"\u003e 2021-10-09\u003c/div\u003e\n\nTags: #MachineLearning #NeuralNetwork #CostFunction \n\n## Basic Concepts\n![](notes/2021/2021.10/assets/img_2022-10-15-64.png)\n$$\\left\\{\\left(x^{(1)}, y^{(1)}\\right),\n\\left(x^{(2)}, y^{(2)}\\right), \\ldots,\n\\left(x^{(m)}, y^{(m)}\\right)\\right\\}$$\n\n- $m$: Number of **Training Samples** - è®­ç»ƒæ ·æœ¬æ•°\n- $L$: Total Number of **Layers** in the network - ç½‘ç»œå±‚æ•°\n- $s_{l}$ =no. of **units** (not counting bias unit) in  layer - æ¯ä¸€å±‚æ¿€æ´»å•å…ƒæ•°ï¼ˆä¸åŒ…æ‹¬å¸¸æ•°ï¼‰\n\n## Cost Function: Representation\nç¥ç»ç½‘ç»œç”¨æ¥åˆ†ç±»çš„æ—¶å€™ï¼Œå®ƒçš„æŸå¤±å‡½æ•°å¯ä»¥é€šè¿‡å¯¹Logistic Regressionçš„æŸå¤±å‡½æ•°ç¨åŠ æ”¹é€ æ¥å¾—åˆ°ï¼š\n\n### å›é¡¾Cost Function of Logistic Regression (With Regularization)\n![æ­£åˆ™åŒ–ä»¥åçš„æŸå¤±å‡½æ•°](notes/2021/2021.9/Part.20_Regularized_Logistic_Regression(ML_Andrew.Ng.).md#æ­£åˆ™åŒ–ä»¥åçš„æŸå¤±å‡½æ•°)\n\n### Intuition of the relation\n- å›é¡¾å‰é¢æˆ‘ä»¬æåˆ°è¿‡çš„ç¥ç»ç½‘ç»œä¸Logisticå›å½’çš„è”ç³»ï¼š\n![ä¸Logistic Regressionçš„è”ç³»](notes/2021/2021.9/Part.23_Forward_Propagation-Neural_Network(ML_Andrew.Ng.).md#ä¸Logistic%20Regressionçš„è”ç³»)\n\n- åœ¨Output Layer, \n\n![](notes/2021/2021.10/assets/Pasted%20image%2020211009210215.png)\n\n\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/Part.29_Fisher_Linear_DiscriminantPattern_Classification-Chapter_4":{"title":"Part.29_Fisher_Linear_Discriminant(Pattern_Classification-Chapter_4)","content":"# Fisher Linear Discriminant\n\n\u003cdiv align=\"right\"\u003e 2021-10-28\u003c/div\u003e\n\nTags: #MachineLearning  #PatternClassification #Course \n#DimensionalityReduction \n\n- **é€šè¿‡é™ç»´è¿›è¡Œåˆ†ç±»**, é™åˆ°ä¸€ç»´å³ä¸ºçº¿æ€§åˆ¤åˆ«.\n- å…¶å®, **çº¿æ€§åˆ¤åˆ«åˆ†æ** (**LDA**)å°±æ˜¯å¯¹**Fisherçº¿æ€§åˆ¤åˆ«**çš„å½’çº³.[^1]\n\n![](notes/2021/2021.10/assets/img_2022-10-15-65.png)\n\n## Motivation\n- Curse of Dimensionality - æ¨¡å‹çš„è¡¨ç°éšç€ç»´åº¦çš„å¢åŠ è€Œå˜å, è€Œä¸”æ ¹æ®è®¾è®¡è€…çš„3ç»´ç›´è§‰, æ— æ³•å¾ˆå¥½çš„è§£å†³é«˜ç»´åº¦çš„é—®é¢˜.\n- æ‰€ä»¥ä¸€ä¸ªå¾ˆç›´è§‚çš„æ–¹æ³•ä¾¿æ˜¯å‡å°‘é—®é¢˜çš„ç»´åº¦, Fisherçš„æ–¹æ³•ä¾¿æ˜¯å°†å¤šç»´æ ·æœ¬ç›´æ¥æ˜ å°„åˆ°ä¸€ç»´çš„ä¸€ç§æ–¹æ³•.\n- ç›´æ¥æ˜ å°„åˆ°ä¸€ç»´æ˜¯å¦å¤ªç²—æš´? 2ç»´, 3ç»´å¯ä»¥å—?\n\t- çš„ç¡®, even if the samples formed well-separated, compact clusters in d-space, projection onto an arbitrary line will usually produce a confused mixture of samples from all of the classes, and thus poor recognition performance. **However**, ä¸€ç»´çš„é—®é¢˜æ˜¯ååˆ†ç®€å•çš„, by moving the line around, we might be able to find an orientation for which the projected samples are well separated. This is exactly the goal of classical discriminant analysis. äºŒç»´, ä¸‰ç»´ä¹Ÿæ˜¯å¯ä»¥çš„, æˆ‘ä»¬åé¢ä¼šè°ˆåˆ°å¯¹äºFisheræ–¹æ³•çš„å¤šç»´æ¨å¹¿.\n\n\n## Interlude - Linear Transformation \u0026 Dot Product\n[Dot_Product_and_Linear_Transformation-å‘é‡å†…ç§¯ä¸çº¿æ€§å˜æ¢](notes/2021/2021.10/Dot_Product_and_Linear_Transformation-å‘é‡å†…ç§¯ä¸çº¿æ€§å˜æ¢.md)\n\n\n## Interlude - Covariance and Covariance Matrix\n[åæ–¹å·®çŸ©é˜µ_Covariance_Matrix](notes/2021/2021.10/åæ–¹å·®çŸ©é˜µ_Covariance_Matrix.md)\n\n## Intuition\nhttps://sthalles.github.io/fisher-linear-discriminant/\n\nå¦‚æœæˆ‘ä»¬ç›´æ¥æŠ•å½±åˆ°**æ ·æœ¬å‡å€¼çš„è¿çº¿**çš„æ–¹å‘çš„è¯, å¯ä»¥çœ‹åˆ°å°†ä¼šæœ‰å¾ˆå¤šçš„é‡åˆ:\n![fisher-ld generator network|300](notes/2021/2021.10/assets/img_2022-10-15-66.png) ![fisher-ld generator network|300](notes/2021/2021.10/assets/img_2022-10-15-67.png)\n\n\nFisherçš„æ–¹æ³•åŸºäºä»¥ä¸‹ç›´è§‰:\n\n- æˆ‘ä»¬è¦ä½¿æŠ•å½±åçš„ç»“æœ: \n\t1. ä¸åŒç±»é—´éš”å¾—è¶Šå¼€è¶Šå¥½ (ç±»é—´æ–¹å·®æœ€å¤§)\n\t2. ç›¸åŒç±»å†…èšé›†çš„è¶Šç´§å¯†è¶Šå¥½ (ç±»å†…æ–¹å·®æœ€å°)\n\n![fisher-ld generator network](notes/2021/2021.10/assets/img_2022-10-15-68.png)\næ‰€ä»¥æˆ‘ä»¬è¿™æ ·æ„é€ å‡†åˆ™å‡½æ•°(Criterion Function):\n\n![fisher-ld generator network|500](notes/2021/2021.10/assets/img_2022-10-15-69.png)\næˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä½¿$J(w)$å–å¾—æœ€å¤§å€¼çš„$w$, å³æ‰¾åˆ°æœ€ä¼˜çš„æŠ•å½±æ–¹å‘.\n\n## è¯¦ç»†æ¨å¯¼\n\n### æ„é€ å‡†åˆ™å‡½æ•°\n- æˆ‘ä»¬è¿™æ ·è®¡ç®—æŠ•å½±:\n\t$$y=\\mathbf{w}^{t} \\mathbf{x_p}$$\n\tä¸Šé¢çš„å¼å­å°†æ ·æœ¬ç‚¹$\\mathbf{x_p}$æŠ•å½±åˆ°$\\mathbf{w}$æ–¹å‘çš„ä¸€æ¡ç›´çº¿ä¸Š\n- æˆ‘ä»¬è¿™æ ·è¡¨ç¤ºç±»åˆ«$i$æ ·æœ¬çš„å‡å€¼:\n\t$$\\mathbf{m}_{i}=\\frac{1}{n_{i}} \\sum_{\\mathbf{x} \\in \\mathcal{D}_{i}} \\mathbf{x}$$\n\tå…¶ä¸­$n_i$æ˜¯è¯¥ç±»åˆ«æ ·æœ¬çš„ä¸ªæ•°\n- æˆ‘ä»¬è¿™æ ·è®¡ç®—æŠ•å½±åçš„æ ·æœ¬å‡å€¼:\n\t$$\\begin{align}\n\t\\tilde{m}_{i}\u0026=\\frac{1}{n_{i}} \\sum_{y \\in \\mathcal{Y}_{i}} y \\\\\n\t\u0026=\\frac{1}{n_{i}} \\sum_{\\mathbf{x} \\in \\mathcal{D}_{i}} \\mathbf{w}^{t} \\mathbf{x}\\\\\n\t\u0026=\\mathbf{w}^{t} \\mathbf{m}_{i}\\end{align}$$\n\tå¯ä»¥å‘ç°, æŠ•å½±åçš„å‡å€¼ å…¶å®å°±æ˜¯ å‡å€¼$\\mathbf{m}_{i}$çš„æŠ•å½±\n- æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¿™æ ·è¡¡é‡æŠ•å½±åçš„ç›´çº¿ä¸Šé¢ä¸åŒç±»é—´å‡å€¼çš„è·ç¦»:\n\t$$\\left|\\tilde{m}_{1}-\\tilde{m}_{2}\\right|\n\t=\\left|\\mathbf{w}^{t}\\left(\\mathbf{m}_{1}-\\mathbf{m}_{2}\\right)\\right|$$\n\t\n- ä¸ºäº†è¡¡é‡æŠ•å½±åæ ·æœ¬çš„åˆ†æ•£ç¨‹åº¦, æˆ‘ä»¬å®šä¹‰ \"ç±»å†…æ•£åº¦\"\n\t$$\\tilde{s}_{i}^{2}=\n\t\\sum_{y \\in \\mathcal{Y}_{i}}\\left(y-\\tilde{m}_{i}\\right)^{2}$$\n\tç›´è§‚çœ‹æ¥, å°±æ˜¯æŠ•å½±åæ ·æœ¬ä¸å‡å€¼è·ç¦»çš„å¹³æ–¹\n\t\n- ç„¶åæˆ‘ä»¬å°±å¯ä»¥æ ¹æ®ç›´è§‰, ç»™å‡ºFisherå‡†åˆ™å‡½æ•°å¦‚ä¸‹:\n\t$$J(\\mathbf{w})=\n\t\\frac{\\left|\\tilde{m}_{1}-\\tilde{m}_{2}\\right|^{2}}{\\tilde{s}_{1}^{2}+\\tilde{s}_{2}^{2}}$$\n\tåˆ†å­æ˜¯ç±»é—´çš„æ–¹å·®(è¶Šå¤§è¶Šå¥½), åˆ†æ¯æ˜¯ç±»å†…çš„æ–¹å·®(è¶Šå°è¶Šå¥½)\n\n### ==æœ€å¤§åŒ–==å‡†åˆ™å‡½æ•°\n\n#### å°†wæå‡ºæ¥\n- $J(\\mathbf{w})$å¹¶ä¸æ˜¯ä¸$\\mathbf{w}$ç›´æ¥ç›¸å…³çš„, æ‰€ä»¥å…ˆè¿›å¦‚ä¸‹å˜æ¢:\n\n- æˆ‘ä»¬å…ˆå®šä¹‰Scatter Matrix $\\mathbf{S_i, S_w}$:\n\t$$\\mathbf{S}_{i}=\n\t\\sum_{\\mathbf{x} \\in \\mathcal{D}_{i}}\n\t\\left(\\mathbf{x}-\\mathbf{m}_{i}\\right)\\left(\\mathbf{x}-\\mathbf{m}_{i}\\right)^{t}$$\n\t$$\\mathbf{S_{w}} = \\mathbf{S_1+S_2}$$\n\n- æ‰€ä»¥, ç±»å†…æ•£åº¦å¯ä»¥å˜ä¸º:\n\t$$\\begin{aligned}\n\t\\tilde{s}_{i}^{2} \u0026=\\sum_{\\mathbf{x} \\in \\mathcal{D}_{i}}\\left(\\mathbf{w}^{t} \\mathbf{x}-\\mathbf{w}^{t} \\mathbf{m}_{i}\\right)^{2} \\\\\n\t\u0026=\\sum_{\\mathbf{x} \\in \\mathcal{D}_{i}}\n\t\\mathbf{w}^{t}\\left(\\mathbf{x}-\\mathbf{m}_{i}\\right)\n\t\\left(\\mathbf{w}^{t}\\left(\\mathbf{x}-\\mathbf{m}_{i}\\right)\\right)^T \\\\\n\t\u0026=\\sum_{\\mathbf{x} \\in \\mathcal{D}_{i}}\n\t\\mathbf{w}^{t}\\left(\\mathbf{x}-\\mathbf{m}_{i}\\right)\\left(\\mathbf{x}-\\mathbf{m}_{i}\\right)^{t} \\mathbf{w} \\\\\n\t\u0026=\\mathbf{w}^{t} \\mathbf{S}_{i} \\mathbf{w}\n\t\\end{aligned}$$\n\n- ç„¶å\n\t$$\\tilde{s}_{1}^{2}+\\tilde{s}_{2}^{2}=\\mathbf{w}^{t} \\mathbf{S}_{W} \\mathbf{w}$$\n\tè¿™æ ·, æˆ‘ä»¬å°†åˆ†æ¯é‡Œé¢çš„$\\mathbf{w}$æå–åˆ°äº†å¤–é¢\n- å¯¹äºåˆ†å­, æˆ‘ä»¬å¯ä»¥æœ‰ç›¸ä¼¼çš„æ“ä½œ:\n$$\\begin{aligned}\n\\left(\\tilde{m}_{1}-\\tilde{m}_{2}\\right)^{2} \u0026=\\left(\\mathbf{w}^{t} \\mathbf{m}_{1}-\\mathbf{w}^{t} \\mathbf{m}_{2}\\right)^{2} \\\\\n\u0026=\\mathbf{w}^{t}\\left(\\mathbf{m}_{1}-\\mathbf{m}_{2}\\right)\\left(\\mathbf{m}_{1}-\\mathbf{m}_{2}\\right)^{t} \\mathbf{w} \\\\\n\u0026=\\mathbf{w}^{t} \\mathbf{S}_{B} \\mathbf{w}\n\\end{aligned}$$\nè§‚å¯Ÿé‡Œé¢çš„ä¸­é—´éƒ¨åˆ†, æˆ‘ä»¬å®šä¹‰:\n$$\\mathbf{S}_{B}=\\left(\\mathbf{m}_{1}-\\mathbf{m}_{2}\\right)\\left(\\mathbf{m}_{1}-\\mathbf{m}_{2}\\right)^{t}$$\n\n- æ‰€ä»¥Criterion Function å˜ä¸ºäº†:\n\t$$J(\\mathbf{w})=\\frac{\\mathbf{w}^{t} \\mathbf{S}_{B} \\mathbf{w}}{\\mathbf{w}^{t} \\mathbf{S}_{W} \\mathbf{w}}$$\n\t\n\tè¿™ä¸€è¡¨è¾¾å¼åœ¨æ•°å­¦ç‰©ç†ä¸­è¢«ç§°ä½œå¹¿ä¹‰Rayleigh å•†(generalized Rayleigh quotient)\n\n#### å…³äºä¸¤ä¸ªçŸ©é˜µ\nWe call $S_{W}$ the within-class scatter matrix. It is proportional to the sample covariance matrix for the pooled $d$-dimensional data. It is symmetric and positive semi-definite, and is usually non-singular if $n\u003ed$. \nLikewise, $\\mathbf{S}_{B}$ is called the between class scatter matrix. It is also symmetric and positive semi-definite, but because it is the outer product of two vectors, its rank is at most one. In particular, for any $\\mathrm{w}$, $\\mathbf{S}_{B} \\mathbf{w}$ is in the direction of $\\mathbf{m}_{1}-\\mathbf{m}_{2}$, and $\\mathbf{S}_{B}$ is quite singular.\n\n#### è§£$\\mathbf{w}$\nè§£$\\mathbf{w}$éœ€è¦ç”¨åˆ°æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•:\næ€è·¯:\nç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•å¾—åˆ°ä»¥ä¸‹æ¡ä»¶\n$$\\mathbf{S}_{B} \\mathbf{w}=\\lambda \\mathbf{S}_{W} \\mathbf{w}$$\nIf $\\mathbf{S}_{W}$ is non-singular we can obtain a conventional eigenvalue problem by writing\n$$\\mathbf{S}_{W}^{-1} \\mathbf{S}_{B} \\mathbf{w}=\\lambda \\mathbf{w}$$\nIn our particular case, it is unnecessary to solve for the eigenvalues and eigenvectors of $\\mathbf{S}_{W}^{-1} \\mathbf{S}_{B}$ due to the fact that $\\mathbf{S_B w}$ is always in the direction of $m_1 âˆ’m_2$. Since the scale factor for $\\mathbf{w}$ is immaterial, we can immediately write the solution for the $\\mathbf{w}$ that optimizes $J(Â·)$:\n\n$$\\mathbf{w}=\\mathbf{S}_{W}^{-1}\\left(\\mathbf{m}_{1}-\\mathbf{m}_{2}\\right)$$\n\n\nè¯¦ç»†è¿‡ç¨‹\n- Ref æ¨¡å¼è¯†åˆ«(ç¬¬ä¸‰ç‰ˆ) - å¼ å­¦å·¥, Page 64\n![](notes/2021/2021.10/assets/img_2022-10-15-70.png)\n\n- Ref æœºå™¨å­¦ä¹  å‘¨å¿—å\n![](notes/2021/2021.10/assets/img_2022-10-15-71.png)\n![](notes/2021/2021.10/assets/img_2022-10-15-72.png)\n- Ref å—ç“œä¹¦\n![](notes/2021/2021.10/assets/img_2022-10-15-73.png)\n\n## å¯ä»¥å°†è¿™ä¸ªæ–¹æ³•æ¨å¹¿åˆ°å¤šç»´çš„æƒ…å†µ\næ¨å¹¿åˆ°é«˜ç»´:[^2]\næˆ‘ä»¬éœ€è¦æ”¹å˜ä»¥ä¸‹åœ°æ–¹:\n- ![fisher-id samples|500](notes/2021/2021.10/assets/img_2022-10-15-74.png)\n- ç±»å†… Scatter Matrix, $S_W$ç›´è§‚çš„æ¥è¯´, å³ä»ä¸¤ä¸ªç±»çš„ $S_1+S_2$ å˜æˆå¤šä¸ªç±» $S_i$ çš„å’Œ\n- å¯¹äº$S_B$, å˜æˆäº† \"æ¯ä¸ªç±»ç›¸å¯¹äºå…¨å±€å¹³å‡çš„å·®\" çš„åŠ æƒå’Œ, è¿™é‡Œå’Œåªæœ‰ä¸¤ä¸ªç±»çš„æƒ…å†µå¹¶ä¸æ˜¯å®Œå…¨ä¸€è‡´çš„, å…·ä½“å‚è§ Duda æ¨¡å¼åˆ†ç±», page49\n\nè‹¥å°† W è§†ä¸ºä¸€ä¸ªæŠ•å½±çŸ©é˜µï¼Œåˆ™å¤šåˆ†ç±» LDA å°†æ ·æœ¬æŠ•å½±åˆ° N-1 ç»´ç©ºé—´ï¼ŒN-1 é€šå¸¸è¿œå°å­æ•°æ®åŸæœ‰çš„å±æ€§æ•°. äºæ˜¯ï¼Œå¯é€šè¿‡è¿™ä¸ªæŠ•å½±æ¥å‡å°æ ·æœ¬ç‚¹çš„ç»´æ•°ï¼Œä¸”æŠ•å½±è¿‡ç¨‹ä¸­ä½¿ç”¨äº†ç±»åˆ«ä¿¡æ¯, å› æ­¤ LDA ä¹Ÿå¸¸è¢«è§†ä¸ºä¸€ç§ç»å…¸çš„ç›‘ç£é™ç»´æŠ€æœ¯[^3]\n\n\n[^1]: https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n[^2]: https://sthalles.github.io/fisher-linear-discriminant/\n[^3]: å‘¨å¿—å æœºå™¨å­¦ä¹ ","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.10/ad_hoc-Latin_Phrase":{"title":"ad_hoc-Latin_Phrase","content":"# Ad hoc\n\n\u003cdiv align=\"right\"\u003e 2021-11-04\u003c/div\u003e\n\nTags: #Latin #English \n\n`adjective`\t\nuk/ËŒÃ¦d ËˆhÉ’k/    us/ËŒÃ¦d ËˆhÉ‘Ëk/\n\n- made or happening only for a particular purpose or need, not planned before it happens\n\tç‰¹åˆ«çš„ï¼›ä¸“é—¨çš„ï¼›ä¸´æ—¶å®‰æ’çš„\n\t- an ad hoc committee/meeting \n\t\tç‰¹åˆ«å§”å‘˜ä¼šï¼ä¼šè®®\n\t- We deal with problems on an ad hoc basis (= as they happen). \n\t\tæˆ‘ä»¬åº”å¯¹é—®é¢˜çš„æ–¹å¼æ˜¯åªè¦å‡ºç°å°±éšæ—¶è§£å†³ã€‚\n\n---\n**Ad hoc** is a Latin phrase meaning literally '**to this**'. In English, it typically signifies a solution for a specific purpose, problem, or task rather than a generalized solution adaptable to collateral instances. (Compare with a priori.)\n\nCommon examples are ad hoc committees and commissions created at the national or international level for a specific task. In other fields the term could refer to, for example, a military unit created under special circumstances (see task force), a tailor-made suit, a handcrafted network protocol (e.g., ad hoc network), a temporary banding together of geographically-linked franchise locations (of a given national brand) to issue advertising coupons, or a purpose-specific equation. \n\n","lastmodified":"2023-11-19T19:19:33.798462016Z","tags":null},"/notes/2021/2021.11/%E5%85%B3%E4%BA%8E%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E4%B8%80%E4%B8%AA%E7%BB%93%E8%AE%BA":{"title":"å…³äºç‰¹å¾å€¼çš„ä¸€ä¸ªç»“è®º","content":"**If $A$ is $m$ by $n$ and $B$ is $n$ by $m$, then $AB$ and $BA$ have the same nonzero eigenvalues.**\n\n**è¯æ˜:**\n\n![](notes/2021/2021.11/assets/Pasted%20image%2020211116205055.png)\n\n**æ¨è®º:**\n$A^TA$å’Œ$AA^T$çš„éé›¶ç‰¹å¾å€¼ç›¸åŒ\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/%E5%85%B3%E4%BA%8E%E7%A7%A9%E7%9A%84%E4%B8%80%E4%B8%AA%E7%BB%93%E8%AE%BA":{"title":"å…³äºç§©çš„ä¸€ä¸ªç»“è®º","content":"$Rank(A)=Rank(A^TA)=Rank(AA^T)$\n\n**è¯æ˜:**\n\nä¸€æ–¹é¢:\n$Ax=0\\Rightarrow A^TAx=0$\n\nå¦ä¸€æ–¹é¢:\n$A^TAx=0\\Rightarrow x\\cdot0=x\\cdot A^TAx=0$\n\n$x\\cdot A^TAx=0\\Rightarrow x^TA^TAx=0$\n\n$x^TA^TAx=0\\Rightarrow (Ax)^TAx=0 \\Rightarrow ||Ax||^2=0\\Rightarrow Ax=0$\n\næ‰€ä»¥$A$ä¸$A^TA$æ ¸ç©ºé—´ç›¸åŒï¼Œæ‰€ä»¥ç§©ç›¸ç­‰\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/%E5%86%85%E7%A7%AF%E5%92%8C%E7%9B%B8%E5%85%B3%E6%80%A7%E7%9A%84%E8%81%94%E7%B3%BB-DotInner_Product__Correlation":{"title":"å†…ç§¯å’Œç›¸å…³æ€§çš„è”ç³»-Dot(Inner)_Product_\u0026_Correlation","content":"# Inner Product \u0026 Correlation\n\n\u003cdiv align=\"right\"\u003e 2021-11-16\u003c/div\u003e\n\nTags: #Math #InnerProduct\n\nSource: [David Joyce's answer to Is there any relation between 'correlation of two signals' and 'dot product of two vectors'? - Quora](https://qr.ae/pGmGkx)\n\n## Original Version\n\n### Q: Is there any relation between 'correlation of two signals' and 'dot product of two vectors'?\n\n**Answer:**\nYes, there is a connection between correlation and dot products (also called inner products).\n\nConsider the vector space of real-valued random variables. These random variables don't have to be independent, so they may have a covariance\n\n$$X \\cdot Y=\\operatorname{Cov}(X, Y)=E\\left(\\left(X-\\mu_{X}\\right)\\left(Y-\\mu_{Y}\\right)\\right)$$\n\nCovariance is bilinear, so it can be used to define an inner product on the vector space of random variables making it an inner product space.\n\nWith an inner product, you can define the norm of a vector (also called the length of the vector by as the square root of the inner product with itself. So $\\|X\\|=\\sqrt{X \\cdot X}$ is defined as the square root of $\\operatorname{Cov}(X, X)=E\\left(\\left(X-\\mu_{X}\\right)^{2}\\right)$. This norm is the standard deviation $\\sigma_{X}$ of $X$.\n\nThe correlation of two random variables is defined by\n$$\n\\rho_{X Y}=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}}\n$$\n\nThat is precisely the definition of the the cosine of the angle $Î¸$ between two vectors\n\n$$\n\\cos \\theta=\\frac{X \\cdot Y}{\\|X\\|\\|Y\\|}\n$$\n\nIn summary, covariance is an inner product, standard deviations are norms, and correlations are cosines of angles.\n\n\n## Translation - ç¿»è¯‘\n\n### é—®é¢˜: \"ç›¸å…³åº¦\"å’Œ\"å†…ç§¯\"è¿™ä¸¤ä¸ªæ¦‚å¿µä¹‹é—´æœ‰ä»€ä¹ˆè”ç³»å—? \n\nç­”: çš„ç¡®, ç›¸å…³åº¦å’Œå†…ç§¯(ä¹Ÿå«åšç‚¹ç§¯)ä¹‹é—´æœ‰ç€ä¸€å®šçš„è”ç³».\n\nè€ƒè™‘ä¸€ä¸ªç”±å®æ•°éšæœºå˜é‡ç»„æˆçš„å‘é‡ç©ºé—´. è¿™äº›éšæœºå˜é‡ä¹‹é—´ä¸ä¸€å®šæ˜¯ç›¸äº’ç‹¬ç«‹çš„, å®ƒä»¬çš„åæ–¹å·®ç”±ä¸‹é¢è¿™ä¸ªå¼å­ç»™å‡º:\n\n$$X \\cdot Y=\\operatorname{Cov}(X, Y)=E\\left(\\left(X-\\mu_{X}\\right)\\left(Y-\\mu_{Y}\\right)\\right)$$\n\nåæ–¹å·®æ˜¯ä¸€ä¸ªåŒçº¿æ€§å‡½æ•°, æ‰€ä»¥å®ƒèƒ½å¤Ÿåœ¨å®æ•°éšæœºå˜é‡ç»„æˆçš„å‘é‡ç©ºé—´é‡Œé¢å®šä¹‰ä¸€ä¸ªå†…ç§¯, ä½¿å…¶æˆä¸ºå†…ç§¯ç©ºé—´.\n\næœ‰äº†å†…ç§¯ç©ºé—´, æˆ‘ä»¬ä¾¿èƒ½å®šä¹‰ä¸€ä¸ªå‘é‡çš„èŒƒæ•°(ä¹Ÿå°±æ˜¯å‘é‡çš„é•¿åº¦, å³ä¸€ä¸ªå‘é‡ä¸å…¶è‡ªèº«å†…ç§¯çš„å¹³æ–¹æ ¹): $\\|X\\|=\\sqrt{X \\cdot X}$ . è€Œè¿™ä¸ªå®šä¹‰ä¸‹çš„å†…ç§¯ä¹Ÿæ˜¯åæ–¹å·® $\\operatorname{Cov}(X, X)=E\\left(\\left(X-\\mu_{X}\\right)^{2}\\right)$ çš„å¹³æ–¹æ ¹. å³éšæœºå˜é‡ $X$ çš„æ ‡å‡†å·® $\\sigma_{X}$.\n\nä¸¤ä¸ªéšæœºå˜é‡ä¹‹é—´çš„ç›¸å…³åº¦çš„å®šä¹‰å¦‚ä¸‹:\n$$\n\\rho_{X Y}=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}}\n$$\nè€Œè¿™æ­£æ˜¯ä¸¤ä¸ªå˜é‡ä¹‹é—´å¤¹è§’ $\\theta$ çš„ä½™å¼¦çš„å®šä¹‰:\n$$\n\\cos \\theta=\\frac{X \\cdot Y}{\\|X\\|\\|Y\\|}\n$$\næ€»ä¹‹, åæ–¹å·®ç­‰ä»·äºå†…ç§¯, æ ‡å‡†å·®ç­‰ä»·äºèŒƒæ•°, è€Œç›¸å…³åº¦ç­‰ä»·äºå¤¹è§’çš„ä½™å¼¦å€¼. (ä½™å¼¦ç›¸ä¼¼åº¦)","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/%E7%90%86%E8%A7%A3%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5":{"title":"ç†è§£ç›¸ä¼¼çŸ©é˜µ","content":"# ç†è§£ç›¸ä¼¼çŸ©é˜µ\n\n\u003cdiv align=\"right\"\u003e 2021-11-14\u003c/div\u003e\n\nTags: #Math/LinearAlgebra \n\n\n- è®¾ $A,B$ éƒ½æ˜¯ $n$ é˜¶çŸ©é˜µï¼Œè‹¥æœ‰å¯é€†çŸ©é˜µ $P$ , ä½¿å¾— $B=P^{-1}AP$ , åˆ™ç§°$B$æ˜¯$A$çš„ç›¸ä¼¼çŸ©é˜µã€‚\n\n- ç›¸ä¼¼çŸ©é˜µæ˜¯åŒä¸€ä¸ªçº¿æ€§å˜æ¢åœ¨**ä¸åŒåŸºå‘é‡**ä¸‹çš„ä¸åŒçŸ©é˜µè¡¨ç¤º.\n\n\t- $P$æ˜¯**åŸºå˜æ¢çŸ©é˜µ(Base Change Matrix)**, å®ƒæ˜¯ä¸€ä¸ªä¸æ”¹å˜ç©ºé—´ç»´æ•°çš„å¯é€†çº¿æ€§å˜æ¢, å…¶ç›®çš„æ˜¯æ”¹å˜å½“å‰çº¿æ€§ç©ºé—´çš„åŸºåº•: $(\\space \\vec i',\\space  \\vec j'\\space )\\rightarrow (\\space \\vec i,\\space \\vec j\\space )$, ä¹Ÿå¯ä»¥ç†è§£ä¸ºè¿›è¡Œåæ ‡æ¢ç®—, ä½†æ˜¯ä¸æ”¹å˜ç©ºé—´é‡Œé¢çš„å®é™…ä½ç½®\n\næ‰€ä»¥å›¾é‡Œé¢å³è¾¹çš„\n$$v'\\rightarrow Bv'$$\nç­‰ä»·äº\n- å…ˆå˜æ¢åŸºåº•åˆ°$V_1$, å¾—åˆ°ä½ç½®ç›¸åŒä½†æ˜¯åæ ‡ä¸åŒçš„å‘é‡$v$\n$$v'\\rightarrow Pv'$$\n- ç„¶åè¿›è¡Œ$V_1$ä¸‹é¢ç­‰ä»·çš„çº¿æ€§å˜æ¢$A$, å¾—åˆ°$V_1$ä¸‹çš„ç»“æœ$Av$\n$$v'\\rightarrow Pv'\\rightarrow APv'$$\n- æœ€åå†æŠŠåŸºåº•æ¢å›æ¥, å¾—åˆ°$V_2$é‡Œé¢çš„ç»“æœ\n$$v'\\rightarrow Pv'\\rightarrow APv'\\rightarrow P^{-1}APv'$$\n\næˆ‘ä»¬æœ‰: \n$$P^{-1}AP =  B$$\n\n\n![](notes/2021/2021.11/assets/img_2022-10-15.png)[^1]\n\n\n\n[^1]: [å¦‚ä½•ç†è§£ç›¸ä¼¼çŸ©é˜µï¼Ÿ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/31003468)","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98-%E5%85%B3%E4%BA%8E%E7%BB%B4%E5%BA%A6%E7%9A%84%E6%96%B0%E8%A7%86%E8%A7%92":{"title":"çŸ©é˜µç›¸ä¹˜-å…³äºç»´åº¦çš„æ–°è§†è§’","content":"# å…³äºçŸ©é˜µç›¸ä¹˜ç»´åº¦å…³ç³»çš„æ–°è§†è§’\n\n\u003cdiv align=\"right\"\u003e 2021-11-16\u003c/div\u003e\n\nTags: #Math/LinearAlgebra \n\n\n![çŸ©é˜µç›¸ä¹˜ ç»´åº¦1](notes/2021/2021.11/assets/çŸ©é˜µç›¸ä¹˜%20ç»´åº¦1.svg)\n\n![çŸ©é˜µç›¸ä¹˜ ç»´åº¦2](notes/2021/2021.11/assets/çŸ©é˜µç›¸ä¹˜%20ç»´åº¦2.svg)\n\n![çŸ©é˜µç›¸ä¹˜ ç»´åº¦3](notes/2021/2021.11/assets/çŸ©é˜µç›¸ä¹˜%20ç»´åº¦3.svg)\n\n![çŸ©é˜µç›¸ä¹˜ ç»´åº¦4](notes/2021/2021.11/assets/çŸ©é˜µç›¸ä¹˜%20ç»´åº¦4.svg)!","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/%E9%85%89%E7%9F%A9%E9%98%B5%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AB%E9%85%89%E7%9F%A9%E9%98%B5":{"title":"é…‰çŸ©é˜µä¸ºä»€ä¹ˆå«é…‰çŸ©é˜µ","content":"# é…‰çŸ©é˜µä¸ºä»€ä¹ˆå«é…‰çŸ©é˜µ\n\n\u003cdiv align=\"right\"\u003e 2021-11-16\u003c/div\u003e\n\nTags: #Math/LinearAlgebra #English \n\n- é…‰çŸ©é˜µé‡Œé¢çš„\"**é…‰**\"å…¶å®æ˜¯å­—æ¯$U$çš„éŸ³è¯‘\n\nï¼ˆåˆè¯‘ä½œå¹ºæ­£çŸ©é˜µï¼Œè‹±è¯­ï¼šunitary matrixï¼‰\n\n\n### unitary\nadjective\n`uk` /ËˆjuË.nÉª.tÉ™r.i/ `us` /ËˆjuË.nÉª.ter.i/\n- of a system of local government in the UK in which official power is given to one organization that deals with all matters in a local area instead of to several organizations that each deal with only a few matters\nï¼ˆè‹±å›½åœ°æ–¹æ”¿åºœï¼‰é›†æƒåˆ¶çš„ï¼Œå•ä¸€è‡ªæ²»ä½“çš„\n\n- Wales will be divided into 21 unitary authorities instead of eight counties and 37 districts. å¨å°”å£«å°†è¢«åˆ’åˆ†ä¸º21ä¸ªå•ä¸€è‡ªæ²»ä½“ï¼Œä»¥å–ä»£8éƒ¡ã€37ä¸ªåœ°åŒºçš„è¡Œæ”¿åŒºåˆ’ã€‚\n\n\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/%E9%85%89%E7%9F%A9%E9%98%B5-Unitary-Matrix":{"title":"é…‰çŸ©é˜µ Unitary Matrix","content":"\nå…±è½­è½¬ç½®æ˜¯å…¶è‡ªèº«çš„é€†çš„çŸ©é˜µ:\n\n $$U^{-1}=U^{*}$$\n\n- æ˜¯ nÃ—n å¤æ•°æ–¹å—çŸ©é˜µï¼Œæ»¡è¶³ï¼š\n\n$$U^{*}U=UU^{*}=I_{n}$$\n\nå…¶ä¸­ $U^*$ æ˜¯ $U$ çš„å…±è½­è½¬ç½®ï¼Œ$I_n$ æ˜¯ nÃ—n å•ä½çŸ©é˜µã€‚\n\né…‰çŸ©é˜µæ˜¯**å®æ•°ä¸Šçš„æ­£äº¤çŸ©é˜µï¼Œåœ¨å¤æ•°çš„æ¨å¹¿**\n$$U^{T}U=UU^{T}=I_{n}$$\n\n## æ€§è´¨\n\n- é…‰çŸ©é˜µä»£è¡¨çš„é…‰å˜æ¢ä¸æ”¹å˜å‘é‡çš„**é•¿åº¦**ä¸**å¤¹è§’**\n  - ä¸æ”¹å˜é•¿åº¦æ˜¯æ­£äº¤æ‰€å¸¦æ¥çš„\n  - ä¸æ”¹å˜å¤¹è§’æ˜¯ä»€ä¹ˆå¸¦æ¥çš„ï¼Ÿ\n[Unitary Transformations - YouTube](https://www.youtube.com/watch?v=46Hpy4FiGls\u0026list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv\u0026index=10)\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/A-Fancy-Example-of-SVD":{"title":"A Fancy Example of SVD","content":"==Example==\n\nConsider the $4 Ã— 5$ matrix\n\n$$\\mathbf{M} = \\begin{bmatrix}\n\n 1 \u0026 0 \u0026 0 \u0026 0 \u0026 2 \\\\\n\n 0 \u0026 0 \u0026 3 \u0026 0 \u0026 0 \\\\\n\n 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\\\\n\n 0 \u0026 2 \u0026 0 \u0026 0 \u0026 0\n\n \\end{bmatrix}\n\n$$\n\nA singular value decomposition of this matrix is given by $UÎ£V^â$\n\n$$\\begin{align}\n\n \\mathbf{U} \u0026= \\begin{bmatrix}\n\n \\color{Green}0 \u0026 \\color{Blue}-1 \u0026 \\color{Cyan}0 \u0026 \\color{Emerald}0 \\\\\n\n \\color{Green}-1 \u0026 \\color{Blue}0 \u0026 \\color{Cyan}0 \u0026 \\color{Emerald}0 \\\\\n\n \\color{Green}0 \u0026 \\color{Blue}0 \u0026 \\color{Cyan}0 \u0026 \\color{Emerald}-1 \\\\\n\n \\color{Green}0 \u0026 \\color{Blue}0 \u0026 \\color{Cyan}-1 \u0026 \\color{Emerald}0\n\n \\end{bmatrix} \\\\[6pt]\n\n \\boldsymbol{\\Sigma} \u0026= \\begin{bmatrix}\n\n 3 \u0026 0 \u0026 0 \u0026 0 \u0026 \\color{Gray}\\mathit{0} \\\\\n\n 0 \u0026 \\sqrt{5} \u0026 0 \u0026 0 \u0026 \\color{Gray}\\mathit{0} \\\\\n\n 0 \u0026 0 \u0026 2 \u0026 0 \u0026 \\color{Gray}\\mathit{0} \\\\\n\n 0 \u0026 0 \u0026 0 \u0026 \\color{Red}\\mathbf{0} \u0026 \\color{Gray}\\mathit{0}\n\n \\end{bmatrix} \\\\[6pt]\n\n \\mathbf{V}^* \u0026= \\begin{bmatrix}\n\n \\color{Violet}0 \u0026 \\color{Violet}0 \u0026 \\color{Violet}-1 \u0026 \\color{Violet}0 \u0026\\color{Violet}0 \\\\\n\n \\color{Plum}-\\sqrt{0.2}\u0026 \\color{Plum}0 \u0026 \\color{Plum}0 \u0026 \\color{Plum}0 \u0026\\color{Plum}-\\sqrt{0.8} \\\\\n\n \\color{Magenta}0 \u0026 \\color{Magenta}-1 \u0026 \\color{Magenta}0 \u0026 \\color{Magenta}0 \u0026\\color{Magenta}0 \\\\\n\n \\color{Orchid}0 \u0026 \\color{Orchid}0 \u0026 \\color{Orchid}0 \u0026 \\color{Orchid}1 \u0026\\color{Orchid}0 \\\\\n\n \\color{Purple} - \\sqrt{0.8} \u0026 \\color{Purple}0 \u0026 \\color{Purple}0 \u0026 \\color{Purple}0 \u0026 \\color{Purple}\\sqrt{0.2}\n\n \\end{bmatrix}\n\n\\end{align}$$\n\nThe scaling matrix $\\mathbf{\\Sigma}$ is zero outside of the diagonal (grey italics) and one diagonal element is zero (red bold). Furthermore, because the matrices $U$ and $V^T$ are unitary matrix|unitary, multiplying by their respective conjugate transposes yields identity matrix|identity matrices, as shown below. Â In this case, because $U$ and $V^T$ are real valued, each is an orthogonal matrix.\n\n$$\\begin{align}\n\n \\mathbf{U} \\mathbf{U}^* \u0026=\n\n \\begin{bmatrix}\n\n 1 \u0026 0 \u0026 0 \u0026 0 \\\\\n\n 0 \u0026 1 \u0026 0 \u0026 0 \\\\\n\n 0 \u0026 0 \u0026 1 \u0026 0 \\\\\n\n 0 \u0026 0 \u0026 0 \u0026 1\n\n \\end{bmatrix} = \\mathbf{I}_4 \\\\[6pt]\n\n \\mathbf{V} \\mathbf{V}^* \u0026=\n\n \\begin{bmatrix}\n\n 1 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\\\\n\n 0 \u0026 1 \u0026 0 \u0026 0 \u0026 0 \\\\\n\n 0 \u0026 0 \u0026 1 \u0026 0 \u0026 0 \\\\\n\n 0 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \\\\\n\n 0 \u0026 0 \u0026 0 \u0026 0 \u0026 1\n\n \\end{bmatrix} = \\mathbf{I}_5\n\n\\end{align}$$\n\nThis particular singular value decomposition is not unique. Â Choosing $\\mathbf V$ such that\n\n$$\\mathbf{V}^* = \\begin{bmatrix}\n\n \\color{Violet}0 \u0026 \\color{Violet}1 \u0026 \\color{Violet}0 \u0026 \\color{Violet}0 \u0026 \\color{Violet}0 \\\\\n\n \\color{Plum}0 \u0026 \\color{Plum}0 \u0026 \\color{Plum}1 \u0026 \\color{Plum}0 \u0026 \\color{Plum}0 \\\\\n\n \\color{Magenta}\\sqrt{0.2} \u0026 \\color{Magenta}0 \u0026 \\color{Magenta}0 \u0026 \\color{Magenta}0 \u0026 \\color{Magenta}\\sqrt{0.8} \\\\\n\n \\color{Orchid}\\sqrt{0.4} \u0026 \\color{Orchid}0 \u0026 \\color{Orchid}0 \u0026 \\color{Orchid}\\sqrt{0.5} \u0026 \\color{Orchid}-\\sqrt{0.1} \\\\\n\n \\color{Purple}-\\sqrt{0.4} \u0026 \\color{Purple}0 \u0026 \\color{Purple}0 \u0026 \\color{Purple}\\sqrt{0.5} \u0026 \\color{Purple}\\sqrt{0.1}\n\n\\end{bmatrix}$$\n\nis also a valid singular value decomposition.\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/Balance_of_trade-%E5%87%80%E5%87%BA%E5%8F%A3-%E8%B4%B8%E6%98%93%E4%BD%99%E9%A2%9D":{"title":"Balance_of_trade-å‡€å‡ºå£-è´¸æ˜“ä½™é¢","content":"# Balance of trade\n\n\u003cdiv align=\"right\"\u003e 2021-11-11\u003c/div\u003e\n\nTags: #Economy\n\n**å‡€å‡ºå£**ï¼Œæˆ–ç§°**è´¸æ˜“ä½™é¢**ï¼Œæ˜¯æŒ‡ä¸€å›½åœ¨ä¸€å®šæ—¶é—´å†…çš„å‡ºå£æ€»å€¼ä¸å…¶è¿›å£æ€»å€¼çš„å·®é¢ã€‚\n- $\\text{å‡€å‡ºå£} = Sum(\\text{å‡ºå£}) - Sum(\\text{è¿›å£})$\n\t- å‡€å‡ºå£ä¸ºæ­£å€¼æ—¶ï¼Œç§°ä¸ºè´¸æ˜“é»‘å­—ã€è´¸æ˜“é¡ºå·®ã€è´¸æ˜“ç›ˆä½™æˆ–å‡ºè¶…ã€‚\n\n\t- å‡€å‡ºå£ä¸ºè´Ÿå€¼æ—¶ï¼Œç§°ä¸ºè´¸æ˜“èµ¤å­—ã€è´¸æ˜“é€†å·®æˆ–å…¥è¶…ã€‚\n\n## ç¾å›½å‡€å‡ºå£çš„å˜åŒ–\n![](notes/2021/2021.11/assets/img_2022-10-15-1.png)\n- ä»å›¾ä¸­å¯è§, ç¾å›½é•¿æ—¶é—´å¤„äºè´¸æ˜“é€†å·®çŠ¶æ€, å³:\n\t- é”€å¾€ç¾å›½çš„å•†å“æ€»å€¼\u003eç¾å›½å‡ºå£çš„è´¸æ˜“æ€»å€¼\n- åœ¨2008ç»æµå±æœºæœŸé—´, ç¾å›½è´¸æ˜“é€†å·®å‡å°å¾ˆå¤š\n- è¿‘å¹´æ¥é€æ¸å›è½\n\n## å…¨çƒå‡€å‡ºå£ä½™é¢çŠ¶æ€\n### 1980å¹´ï¼2008å¹´å¹³å‡\n![Cumulative_Current_Account_Balance](notes/2021/2021.11/assets/img_2022-10-15-2.png)\n- ä¸­ç¾å·®å¼‚æ˜æ˜¾","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/Invertable-word":{"title":"Invertable-word","content":"# Invertable\n\n\u003cdiv align=\"right\"\u003e 2021-11-18\u003c/div\u003e\n\nTags: #English \n\n- æˆ‘çªç„¶æ„è¯†åˆ° \"**Invertable**\" å…¶å®æ˜¯ \"**invert**\" + \"**able**\", å³å¯ä»¥æ±‚é€†çš„, ä½ å¯ä»¥æ±‚å®ƒçš„ \"Inverse\"\n- å®ƒçš„è¯æ ¹å¹¶ä¸æ˜¯ **in**\n\n\n\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/LU%E5%88%86%E8%A7%A3%E7%9A%84%E4%BE%8B%E5%AD%90":{"title":"LUåˆ†è§£çš„ä¾‹å­","content":"å°†ä¸€ä¸ªç®€å•çš„$3Ã—3$çŸ©é˜µAè¿›è¡ŒLUåˆ†è§£ï¼š\n$$ A=\n        \\begin{bmatrix}\n           1 \u0026 2 \u0026 3 \\\\\n           2 \u0026 5 \u0026 7 \\\\\n           3 \u0026 5 \u0026 3 \\\\\n        \\end{bmatrix}\n$$\n\nå…ˆå°†çŸ©é˜µç¬¬ä¸€åˆ—å…ƒç´ ä¸­$a_{11}$ä»¥ä¸‹çš„æ‰€æœ‰å…ƒç´ å˜ä¸º0ï¼Œå³\n$$ L_{1}A=\n        \\begin{bmatrix}\n           1 \u0026 0 \u0026 0 \\\\\n          -2 \u0026 1 \u0026 0 \\\\\n          -3 \u0026 0 \u0026 1 \\\\\n        \\end{bmatrix} \\times\n        \\begin{bmatrix}\n           1 \u0026 2 \u0026 3 \\\\\n           2 \u0026 5 \u0026 7 \\\\\n           3 \u0026 5 \u0026 3 \\\\\n        \\end{bmatrix}  =\n        \\begin{bmatrix}\n           1 \u0026 2 \u0026 3 \\\\\n           0 \u0026 1 \u0026 1 \\\\\n           0 \u0026 -1 \u0026 -6 \\\\\n        \\end{bmatrix}\n$$\nå†å°†çŸ©é˜µç¬¬äºŒåˆ—å…ƒç´ ä¸­$a_{22}$ä»¥ä¸‹çš„æ‰€æœ‰å…ƒç´ å˜ä¸º0ï¼Œå³\n$$ L_{2}(L_{1}A)=\n        \\begin{bmatrix}\n           1 \u0026 0 \u0026 0 \\\\\n           0 \u0026 1 \u0026 0 \\\\\n           0 \u0026 1 \u0026 1 \\\\\n        \\end{bmatrix} \\times\n        \\begin{bmatrix}\n           1 \u0026 2 \u0026 3 \\\\\n           0 \u0026 1 \u0026 1 \\\\\n           0 \u0026 -1 \u0026 -6 \\\\\n        \\end{bmatrix}  =\n        \\begin{bmatrix}\n           1 \u0026 2 \u0026 3 \\\\\n           0 \u0026 1 \u0026 1 \\\\\n           0 \u0026 0 \u0026 -5 \\\\\n        \\end{bmatrix} =U\n$$\nç„¶åæˆ‘ä»¬å°† $L_1, L_2$ ç§»åˆ°ç­‰å·çš„å³è¾¹, å°±å¾—åˆ°äº†æ‰€æœ‰æ­¥éª¤çš„æ€»å’Œ$L$:\n\n$$L= L_{1}^{-1}L_{2}^{-1}=\n        \\begin{bmatrix}\n           1 \u0026 0 \u0026 0 \\\\\n           2 \u0026 1 \u0026 0 \\\\\n           3 \u0026 0 \u0026 1 \\\\\n        \\end{bmatrix} \\times\n        \\begin{bmatrix}\n           1 \u0026 0 \u0026 0 \\\\\n           0 \u0026 1 \u0026 0 \\\\\n           0 \u0026 -1 \u0026 1 \\\\\n        \\end{bmatrix} =\n        \\begin{bmatrix}\n           1 \u0026 0 \u0026 0 \\\\\n           2 \u0026 1 \u0026 0 \\\\\n           3 \u0026 -1 \u0026 1 \\\\\n        \\end{bmatrix} $$\n  \nRef: [LUåˆ†è§£ - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-hans/LU%E5%88%86%E8%A7%A3)\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT-18.065-Matrix-Methods-in-Data-Analysis-Signal-Processing-and-Machine-Learning":{"title":"MIT 18.065 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning,","content":"# MIT 18.065 - Matrix Methods in Data Analysis, Signal Processing, and Machine Learning,\n\n\u003cdiv align=\"right\"\u003e 2021-11-12\u003c/div\u003e\n\nTags: #Matrix #Math/LinearAlgebra #Math \n\n- å­¦ä¹ è¿™é—¨è¯¾çš„ä¸»è¦åŠ¨åŠ›æ˜¯çº¿æ€§ä»£æ•°çš„çŸ¥è¯†åœ¨å¤§äºŒçš„ä¸€å¹´å†…å·²ç»æœ‰æ‰€é—å¿˜äº†, å¹¶ä¸”åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ æœŸé—´å¸¸å¸¸è®¾è®¡çº¿æ€§ä»£æ•°ä¸çŸ©é˜µçš„ç›¸å…³çŸ¥è¯†, æ‰€ä»¥æƒ³è¦æœ‰é’ˆå¯¹æ€§åœ°æ·±å…¥å­¦ä¹ ä¸å¤ä¹ ä¸€ä¸‹.\n\t- ä¹Ÿæƒ³ä½“éªŒä¸€ä¸‹Gilbert Strangçš„è¯¾å ‚\n \n \u003e (Gilbert Strang, during class)\n \u003e \"This is what I want to say the most, and I say it to every class I teach near the start of the semester. My feeling about my job is to teach you things, or to join with you in learning things, as has happened today. It's not to grade you.\"\n\n## Resources\n- [MIT 18.065, Spring 2018 - YouTube](https://www.youtube.com/playlist?list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k)\n\n### Road Map\n![](notes/2021/2021.11/assets/img_2022-10-15-3.png)[^1]\n\n\n## Syllabus\n[MIT OpenCourseWare](https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/readings/)\n\n\n[^1]:[Relationship](https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/18-065s18_big2.jpg) among linear algebra, probability and statistics, optimization, and deep learning. Courtesy of Jonathan Harmon. ","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_1-A_Column_Space_Perspective":{"title":"MIT_18.065-Part_1-A_Column_Space_Perspective","content":"# The Column Space of A Contains All Vectors Ax \n\n\u003cdiv align=\"right\"\u003e 2021-11-12\u003c/div\u003e\n\nTags: #Math/LinearAlgebra \n\nVideo Link: [1. The Column Space of A Contains All Vectors Ax - YouTube](https://www.youtube.com/watch?v=YiqIkSHSmyc\u0026list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k\u0026index=3)\n\n- This video reviewed some of the basic ideas of Linear algebra, especially \"the right way to think of a matrix\".\n\n## ç†è§£Ax - åˆ—ç©ºé—´\n$$Ax$$\n![](notes/2021/2021.11/assets/img_2022-10-15-4.png)\nçœ‹å¾…çŸ©é˜µä¸å‘é‡ä¹˜ç§¯çš„ä¸¤ç§æ–¹å¼:\n- Açš„è¡Œå‘é‡ä¸xçš„dot product - Not Intuitive\n- Açš„åˆ—å‘é‡çš„çº¿æ€§ç»„åˆ - Intuitive\n\nè¿›ä¸€æ­¥, Axå¯ä»¥è¡¨ç¤ºCol(A), å³Açš„åˆ—ç©ºé—´.\n\n- Rank(A)å°±æ˜¯Aé‡Œé¢ç‹¬ç«‹çš„åˆ—å‘é‡ä¸ªæ•°\n\nè¿™å¯ä»¥å¸¦æ¥ä¸€ç§æœ‰è¶£çš„åˆ†è§£å½¢å¼:\n\n![](notes/2021/2021.11/assets/img_2022-10-15-5.png)\n\n$$A=CR$$\n\n$$A_{3\\times 3}=C_{3\\times 2}R_{2\\times 3}$$\n\n- åœ¨çŸ©é˜µCé‡Œé¢åˆ—éƒ½æ˜¯ç‹¬ç«‹çš„, ä¸”æ„æˆCol(A)çš„åŸºå‘é‡, åœ¨çŸ©é˜µRé‡Œé¢è¡Œä¹Ÿéƒ½æ˜¯ç‹¬ç«‹çš„, ä¹Ÿæ„æˆRow(A)çš„åŸºå‘é‡. è¿™è§£é‡Šäº†ä¸€ä¸ªé‡è¦çš„äº‹å®: \n\t- çŸ©é˜µçš„è¡Œç§©ç­‰äºåˆ—ç§©\n\n- The big factorization for data science is the \"SVD\" of A-when the first factor C\nhas r orthogonal columns and the second factor R has r orthogonal rows.\n\n- Actually R is a famous matrix in linear algebra:\nR = rref(A) = row-reduced echelon form of A (without zero rows).\n(Açš„è¡ŒåŒ–ç®€æœ€ç®€é˜¶æ¢¯å‹)[^1]\n\n- $A=CR$çš„ä¸€ä¸ªæ›´ä¸€èˆ¬çš„å½¢å¼:\n\t- ![](notes/2021/2021.11/assets/img_2022-10-15-6.png)[^2]\n\n\n## ç†è§£AB \n$$A_{m\\times n}B_{n\\times p}= M_{m\\times p}$$\n![](notes/2021/2021.11/assets/img_2022-10-15-7.png)\n\næˆ‘ä»¬ç”¨Açš„åˆ—å‘é‡ä¹˜ä¸ŠBçš„è¡Œå‘é‡, å¾—åˆ°ä¸€ä¸ªçŸ©é˜µ, è¿™ä¸ªçŸ©é˜µæ„æˆäº†\"the perfect building blocks for every matrix.\"\n\nä¸¤ä¸ªçŸ©é˜µçš„ç§¯å°±æ˜¯nä¸ªè¿™æ ·çŸ©é˜µçš„åŠ å’Œ.\n\næ¯ä¸€ä¸ªçŸ©é˜µçš„æ–¹å‘éƒ½æ˜¯Aé‡Œé¢ä¸€ä¸ªåˆ—å‘é‡çš„æ–¹å‘, å³ä¸Šé¢uçš„æ–¹å‘\n\næ¯ä¸€ä¸ªçŸ©é˜µçš„ç§©éƒ½ä¸º1, æ‰€ä»¥ABå³nä¸ªç§©ä¸ºä¸€çš„çŸ©é˜µçš„åŠ å’Œ:\n![](notes/2021/2021.11/assets/img_2022-10-15-8.png)\n\nå¯¹æ¯”ä¸€ä¸‹æˆ‘ä»¬åŸæ¥çš„æ€è€ƒæ–¹å¼, ä¸¤ç§æ–¹æ³•åˆ†åˆ«å¯¹åº”å‘é‡çš„å†…ç§¯ä¸å¤–ç§¯:\n![](notes/2021/2021.11/assets/img_2022-10-15-9.png)\n\n\n\n[^1]: ä¸€ä¸ªå¬èµ·æ¥ç†Ÿæ‚‰åˆé™Œç”Ÿçš„åå­—å“ˆå“ˆå“ˆ\n[^2]: Linear Algebra and Learning from Data by Gilbert Strang, ","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_10-SVD_in_Action":{"title":"MIT_18.065-Part_10-SVD_in_Action","content":"# SVD in Action\n\n\u003cdiv align=\"right\"\u003e 2021-11-17\u003c/div\u003e\n\nTags: #SVD #Math/LinearAlgebra \n\n\n\n## Economy SVD\nåœ¨è¢«åˆ†è§£çš„çŸ©é˜µAç‰¹åˆ«\"ç˜¦é«˜\"çš„æ—¶å€™(m\u003e\u003en), æˆ‘ä»¬å¯ä»¥åªå–$U$çš„å‰nåˆ—, å› ä¸ºåé¢çš„\"é‡è¦æ€§\"ä¸å¤§.\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/xy3QyyhiuY4?start=246\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n## Application\n\n### Digital Watermark\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/QQ8vxj-9OfQ?start=554\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\n## Hands-on Tips\n### Plot how the information varies\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/QQ8vxj-9OfQ?start=610\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\n\n### SVD Method of Snapshots\n- A different way to compute SVD if the data is so large that you can't store it into memory at once.\n\n[SVD Method of Snapshots - YouTube](https://youtu.be/rs63fnUWJkk)\n\n\n### Relation with Fourier\nSVD is kind of a data-driven generation of Fourier Transform/\n(å¦‚ä½•ç†è§£ï¼Ÿ)\n\nå‚…é‡Œå¶å˜æ¢çŸ©é˜µå°±æ˜¯ä¸€ä¸ªé…‰çŸ©é˜µï¼Œ SVDé‡Œé¢çš„Uä¹Ÿæ˜¯ä¸€ä¸ªé…‰çŸ©é˜µ\n[Unitary Transformations - YouTube](https://www.youtube.com/watch?v=46Hpy4FiGls\u0026list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv\u0026index=10)\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_11-SVD__Linear_System":{"title":"MIT_18.065-Part_11-SVD_\u0026_Linear_System","content":"# SVD \u0026 Linear System\n\n\u003cdiv align=\"right\"\u003e 2021-11-18\u003c/div\u003e\n\nTags: #LinearRegression #SVD #Math/LinearAlgebra \n\n## $Ax=b$\nå¯¹äºè¿™ä¸ªçº¿æ€§çº¦æŸæ–¹ç¨‹ç»„: $$Ax=b$$\n\nåªæœ‰åœ¨Aå¯é€†çš„æ–¹é˜µçš„æ—¶å€™, æ‰æœ‰å”¯ä¸€è§£: $$x=A^{-1}b$$\n\nè€Œåœ¨Aä¸ºå…¶ä»–å½¢çŠ¶çš„æ—¶å€™, å¸¸å¸¸ä¸èƒ½å¤Ÿç®€å•çš„åˆ©ç”¨$A^{-1}$æ¥æ±‚è§£è¿™ä¸ªæ–¹ç¨‹ç»„\n- Under-determined: (ä¸å®šæ–¹ç¨‹) \n\t- è¿™æ—¶æˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„çº¦æŸæ¥é™åˆ¶x, xå¸¸å¸¸æœ‰æ— ç©·è§£\n\t- æ¢ä¸€ä¸ªçœ‹æ³•, è¿™å¯ä»¥çœ‹ä½œå› ä¸º$Row(A)$æ²¡æœ‰å¡«æ»¡$R^n$, æ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨æ¯ä¸€ä¸ªè§£é‡Œé¢åŠ ä¸Šä¸€éƒ¨åˆ†æ ¸ç©ºé—´é‡Œé¢çš„å‘é‡$x_{kernel}$, åŒæ—¶ä¸å½±å“æ–¹ç¨‹çš„æˆç«‹: \n\t- $$\\begin{aligned}\u0026A(x+x_{kernel})=b \\\\\\Rightarrow \u0026Ax+Ax_{kernel}=b\\\\\\Rightarrow \u0026Ax+0=b\\end{aligned}$$\n\n![](notes/2021/2021.11/assets/img_2022-10-15-40.png)\n- Over-determined: (è¶…å®šæ–¹ç¨‹)\n\t- åœ¨è¿™ä¸ªæƒ…å†µä¸‹, æˆ‘ä»¬æœ‰å¤ªå¤šé™åˆ¶æ¥é™åˆ¶x, æ‰€ä»¥æœ‰å¯èƒ½å‡ºç°çŸ›ç›¾, å¯¼è‡´xæ²¡æœ‰è§£.\n\n![](notes/2021/2021.11/assets/img_2022-10-15-41.png)\n\n## Pseudo-Inverse \u0026 SVD\n- å¯¹äºé•¿æ–¹å½¢çš„æƒ…å†µ, æˆ‘ä»¬å¯ä»¥å®šä¹‰çŸ©é˜µAçš„\"ä¼ªé€†\"(Pseudo-Inverse): $A^+$. è¿™æ ·æˆ‘ä»¬å¯ä»¥è¿‘ä¼¼åœ°æ±‚è§£ä¸ç†æƒ³æƒ…å†µä¸‹çš„çº¿æ€§æ–¹ç¨‹ç»„\n\n- æˆ‘ä»¬å®šä¹‰$A^+$å¦‚ä¸‹\n\t- ç”±SVDæœ‰:\n\t$$A=U\\Sigma V^T$$\n\t$$\\begin{aligned}\u0026\\quad \\quad Ax=b \\\\\n\t\u0026\\Rightarrow\\quad U\\Sigma V^Tx=b\\\\\n\t\u0026\\Rightarrow\\quad x=V\\Sigma^{-1}U^Tb\\end{aligned}$$\n\t- $$A^+=V\\Sigma^{-1}U^T$$\n\nè¿™æ ·, æˆ‘ä»¬å°±é€šè¿‡SVDå¾—åˆ°äº†å¹¿ä¹‰é€†\n\nåœ¨$A$æ˜¯å¯é€†æ–¹é˜µçš„æ—¶å€™, å¹¿ä¹‰é€†ç­‰äº$A^{-1}$ :\n$$A^{-1}=(U\\Sigma V^T)^{-1}={(V^T)}^{-1}\\Sigma^{-1}U^{-1}=V\\Sigma^{-1}U^T$$\n\n- è¿™ä¸ªå¹¿ä¹‰é€†ä¹Ÿç§°ä¸º[Mooreâ€“Penrose inverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse#cite_note-Penrose1956-25)\n\n## Using Pseudo-Inverse to Solve $Ax=b$\n\n$$x=A^+b$$\n$$x=V\\Sigma^{-1}U^Tb$$\n- åœ¨ä¸å®šæ–¹ç¨‹çš„æƒ…å†µä¸‹, è¿™ä¸ªè§£æ˜¯æ— ç©·å¤šä¸ªè§£é‡Œé¢$l_2$ normæœ€å°çš„\n![](notes/2021/2021.11/assets/img_2022-10-15-42.png)\n\n- åœ¨è¶…å®šæ–¹ç¨‹çš„æƒ…å†µä¸‹, è¿™ä¸ªè§£æ˜¯æœ€å°äºŒä¹˜è§£, å³Least Squareè§£, æ˜¯bå‘é‡å¯¹Açš„åˆ—ç©ºé—´ä¸Šé¢çš„æŠ•å½±.\n![](notes/2021/2021.11/assets/img_2022-10-15-43.png)\n\næˆ‘ä»¬å¾—åˆ°çš„è¿‘ä¼¼è§£$\\hat x$åˆ°åº•æ˜¯ä»€ä¹ˆå‘¢? æˆ‘ä»¬å¯ä»¥å†è®¡ç®—$A\\hat x$ :\n$$\\begin{aligned}A\\hat x\u0026=AA^+b\\\\\n\u0026=(U\\Sigma V^T)(V\\Sigma^{-1}U^T)b\\\\\n\u0026=UU^Tb\\end{aligned}$$\n\n**æ³¨æ„**: å¦‚æœæˆ‘ä»¬çš„Uæ˜¯Economy SVDé‡Œé¢çš„$\\hat U$, å³åªå–æœ‰æ•ˆçš„å‰råˆ—çš„U, é‚£ä¹ˆ$UU^T\\neq I$.\n\n\nSource: [Linear Systems of Equations, Least Squares Regression, Pseudoinverse - YouTube](https://www.youtube.com/watch?v=PjeOmOz9jSY\u0026list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv\u0026index=13)","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_2-Matrix_Factorization":{"title":"MIT_18.065-Part_2-Matrix_Factorization","content":"# çŸ©é˜µåˆ†è§£\n\n\u003cdiv align=\"right\"\u003e 2021-11-12\u003c/div\u003e\n\nTags: #Matrix #Math/LinearAlgebra #Math \n\n![](notes/2021/2021.11/assets/img_2022-10-15-10.png)\n- æˆ‘ä»¬çœ‹å¾…çŸ©é˜µä¹˜ç§¯çš„æ–°æ–¹å¼æœ‰åŠ©äºæˆ‘ä»¬ç†è§£æ•°æ®ç§‘å­¦é‡Œé¢å¯¹çŸ©é˜µçš„å„ç§åˆ†è§£. æˆ‘ä»¬å¸¸å¸¸éœ€è¦å‘æ˜ä¸€ä¸ªçŸ©é˜µ$A$é‡Œé¢éšè—çš„ä¿¡æ¯, è€Œé€šè¿‡å°†$A$åˆ†è§£ä¸º$CR$, æˆ‘ä»¬å¯ä»¥è§‚å¯ŸAé‡Œé¢æœ€åŸºæœ¬çš„ç»„æˆéƒ¨åˆ†: ç§©ä¸º1çš„çŸ©é˜µ: $col_k(C)\\space row_k(R)$\n- ![](notes/2021/2021.11/assets/img_2022-10-15-11.png)\n\n\nä¸‹é¢åˆ—ä¸¾é‡è¦çš„åˆ†è§£, åœ¨è¯¦ç»†è®ºè¿°åå°†è¡¥å……ç›¸åº”ç»†èŠ‚\n\n## äº”ä¸ªé‡è¦çš„çŸ©é˜µåˆ†è§£\n![](notes/2021/2021.11/assets/img_2022-10-15-12.png)\n\n### $LU$åˆ†è§£ : $A=L U$\n- $A=L U$ å¯ä»¥ç†è§£ä¸ºçŸ©é˜µçš„åŒ–ç®€(elimination). \n- $L$ ä»£è¡¨ Lower Triangular, æ˜¯ä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µ, åŒç†, $U$ä»£è¡¨Upper Triangular, æ˜¯ä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µ.\n- LUåˆ†è§£å¯ä»¥è¢«è§†ä¸ºé«˜æ–¯æ¶ˆå»æ³•çš„çŸ©é˜µå½¢å¼ã€‚$L$ æ˜¯é«˜æ–¯æ¶ˆå…ƒæ³•çš„è¿‡ç¨‹, è€Œ$U$æ˜¯é«˜æ–¯æ¶ˆå…ƒæ³•çš„ç»“æœ. çœ‹ä¸‹é¢è¿™ä¸ªä¾‹å­:\n- [LUåˆ†è§£çš„ä¾‹å­](notes/2021/2021.11/LUåˆ†è§£çš„ä¾‹å­.md)\n\n### æ­£äº¤åˆ†è§£ : $A=Q R$\n- é€šè¿‡å°†çŸ©é˜µ $A$ çš„åˆ—$\\boldsymbol{a}_{1}$ åˆ° $\\boldsymbol{a}_{n}$\"æ­£äº¤åŒ–\" (orthogonalize), æˆ‘ä»¬å°±å¾—åˆ°äº†æ­£äº¤åˆ†è§£$A=Q R$\n\n- å…¶ä¸­:\n\t- çŸ©é˜µ $Q$ çš„åˆ—ç›¸äº’æ­£äº¤ (orthonormal),  å¦‚æœåˆ—å‘é‡é•¿åº¦ä¸ºä¸€, è¿˜æœ‰:  $Q^{\\mathrm{T}} Q=I$ , \n\t- $R$ æ˜¯ä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µ(å¯èƒ½ä¸æ˜¯æ–¹é˜µ).\n- æ­£äº¤åŒ–å¸¸ç”¨çš„æ–¹æ³•æ˜¯ \"Gram-Schmidt\" æ–¹æ³•.\n\n![](notes/2021/2021.11/assets/Pasted%20image%2020211112210720.png)\n\n### $S=Q \\Lambda Q^{\\mathrm{T}}$\n- $S=Q \\Lambda Q^{\\mathrm{T}}$ comes from the eigenvalues $\\lambda_{1}, \\ldots, \\lambda_{n}$ of a symmetric matrix $S=S^{\\mathrm{T}}$ Eigenvalues on the diagonal of $\\Lambda$. Orthonormal eigenvectors in the columns of $Q$.\n\n- Sæ˜¯å¯¹ç§°çŸ©é˜µ, Qæ˜¯Sçš„æ­£äº¤ç‰¹å¾åˆ—å‘é‡, $\\Lambda$æ˜¯ç‰¹å¾å€¼ç»„æˆçš„å¯¹è§’çŸ©é˜µ.\n- [MIT_18.065-Part_3-A_Different_Perspectvie_of_Matrix_Multiplication-An_Example](notes/2021/2021.11/MIT_18.065-Part_3-A_Different_Perspectvie_of_Matrix_Multiplication-An_Example.md)\n\n### $A=X \\Lambda X^{-1}$ \n- $A=X \\Lambda X^{-1}$ is diagonalization when $A$ is $n$ by $n$ with $n$ independent eigenvectors. Eigenvalues of $A$ on the diagonal of $\\Lambda$. Eigenvectors of $A$ in the columns of $X$.\n\n### $A=U \\Sigma V^{\\mathrm{T}}$ \n- $A=U \\Sigma V^{\\mathrm{T}}$ is the Singular Value Decomposition of any matrix $A$ (square or not). Singular values $\\sigma_{1}, \\ldots, \\sigma_{r}$ in $\\Sigma$. Orthonormal singular vectors in $U$ and $V$.","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_3-A_Different_Perspectvie_of_Matrix_Multiplication-An_Example":{"title":"MIT_18.065-Part_3-A_Different_Perspectvie_of_Matrix_Multiplication-An_Example","content":"\n# Math/LinearAlgebra #Matrix #Math\n\n$$S=Q \\Lambda Q^{\\mathrm{T}}$$\n\n- å…¶ä¸­Sæ˜¯ä¸€ä¸ªå¯¹ç§°çŸ©é˜µ, $S=S^{\\mathrm{T}}$\n- Qçš„è¡Œå‘é‡æ˜¯Sçš„ç‰¹å¾å‘é‡, è¿™äº›ç‰¹å¾å‘é‡ç›¸äº’æ­£äº¤\n$$Q=\\left[\\begin{array}{ccc}\n\\mid \u0026 \u0026 \\mid \\\\\nq_{1} \u0026 \\ldots \u0026 q_{n} \\\\\n\\mid \u0026 \u0026 \\mid\n\\end{array}\\right]$$\n- $\\Lambda$æ˜¯å¯¹è§’çŸ©é˜µ, ç”±Sçš„ç‰¹å¾å€¼ç»„æˆ\n\n- $S=(Q \\Lambda) (Q^{T})$ , æ‰€ä»¥è¿™ä¸ªçŸ©é˜µç”±$Q\\Lambda$çš„åˆ—å‘é‡ç»„æˆ:\n- $$Q\\Lambda=\\left[\\begin{array}{ccc}\\mid \u0026 \u0026 \\mid \\\\\nq_{1} \u0026 \\ldots \u0026 q_{n} \\\\\n\\mid \u0026 \u0026 \\mid\\end{array}\\right]\\left[\\begin{array}{ccc}\n\\lambda_1 \u0026 \u0026  \\\\\u0026 \\ddots \u0026  \\\\ \u0026 \u0026 \\lambda_n\n\\end{array}\\right]=\\left[\\begin{array}{ccc}\\mid \u0026 \u0026 \\mid \\\\\n\\lambda_1q_{1} \u0026 \\ldots \u0026 \\lambda_nq_{n} \\\\\n\\mid \u0026 \u0026 \\mid\\end{array}\\right]$$\n\n---\n$$S=(Q \\Lambda) Q^{\\mathrm{T}}=\n\\lambda_{1} \\boldsymbol{q}_{1}\\boldsymbol{q}_{1}^{\\mathrm{T}}+\n\\lambda_{2} \\boldsymbol{q}_{2}\\boldsymbol{q}_{2}^{\\mathrm{T}}+\n\\cdots+\n\\lambda_{n} \\boldsymbol{q}_{n} \\boldsymbol{q}_{n}^{\\mathrm{T}}$$\n---\n\n- è¿™æ ·, Så°±è¢«æ‹†åˆ†æˆäº†ç§©ä¸ºä¸€çš„å°çŸ©é˜µçš„åŠ å’Œ, å…¶ä¸­æ¯ä¸€ä¸ªå°çŸ©é˜µ$\\lambda_{i} \\boldsymbol{q}_{i}\\boldsymbol{q}_{i}^{\\mathrm{T}}$ä¹Ÿæ˜¯å¯¹ç§°çŸ©é˜µ, å› ä¸ºè¿™ä¸ªå°çŸ©é˜µæ˜¯ç‰¹å¾å‘é‡$\\boldsymbol{q}_{i}$è‡ªå·±ä¸è‡ªå·±çš„å¤–ç§¯$\\boldsymbol{q}_{i}\\boldsymbol{q}_{i}^{\\mathrm{T}}$çš„$\\lambda_i$å€\n\n- éªŒè¯: å¦‚æœæˆ‘ä»¬è®¡ç®—$Sq_1$:\n  - å› ä¸ºqç›¸äº’æ­£äº¤, æ‰€ä»¥: $\\boldsymbol{q}_{2}^{\\mathrm{T}}\\boldsymbol{q}_{1}=0$\n  - æ‰€ä»¥:\n $$\\lambda_{2} \\boldsymbol{q}_{2}\\boldsymbol{q}_{2}^{\\mathrm{T}}\\boldsymbol{q}_{1}=0$$\n- åˆå› ä¸ºqæ˜¯å•ä½å‘é‡, æ‰€ä»¥: $\\boldsymbol{q}_{1}^{\\mathrm{T}}\\boldsymbol{q}_{1}=1$\n $$S\\boldsymbol{q}_{1}=\n\\lambda_{1}\\boldsymbol{q}_{1}\\boldsymbol{q}_{1}^{\\mathrm{T}}\\boldsymbol{q}_{1}=\\lambda_{1}\\boldsymbol{q}_{1}$$\n ç¬¦åˆç‰¹å¾å‘é‡çš„å®šä¹‰.\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_4-LU_Factorization":{"title":"MIT_18.065-Part_4-LU_Factorization","content":"# LU åˆ†è§£\n\n\u003cdiv align=\"right\"\u003e 2021-11-12\u003c/div\u003e\n\nTags: #Math/LinearAlgebra #Math #Matrix \n\n- $A=L U$\n- Key Idea: **æ€æ ·ä»A = Sum of Rank 1 Matricesçš„è§’åº¦æ¥ç†è§£è¿™ä¸ªåˆ†è§£?**\n\n- ç®€å•çš„æ¦‚å¿µå›é¡¾:\n\t- [LU åˆ†è§£ $A=LU$](notes/2021/2021.11/MIT_18.065-Part_2-Matrix_Factorization.md#LU%20åˆ†è§£%20A%20L%20U)\n\n## çœ‹å¾…Ax=Bçš„ä¸¤ä¸ªè§’åº¦\n### Row Perspective\n![](notes/2021/2021.11/assets/img_2022-10-15-13.png)\n- å‡ ä¸ªçº¦æŸæ–¹ç¨‹çš„å…¬å…±è§£, å³è¶…å¹³é¢åœ¨ç©ºé—´é‡Œé¢å…±åŒçš„äº¤ç‚¹\n\n### Column Perspective\n![](notes/2021/2021.11/assets/img_2022-10-15-14.png)\n- åˆ©ç”¨åŸºå‘é‡æ¥è¡¨è¾¾ç›®æ ‡å‘é‡\n\n- å¯¹äºäºŒç»´çš„é—®é¢˜Row Perspective çœ‹èµ·æ¥è¿˜è¡Œ, ä½†æ˜¯å¯¹äºå¤šç»´çš„æƒ…å½¢, Column Perspectiveæ›´åŠ ç›´è§‚(æƒ³è±¡å¥½å‡ ä¸ªè¶…å¹³é¢çš„äº¤ç‚¹æ˜¯å¾ˆå›°éš¾çš„!)\n\n## å›é¡¾A=LUçš„åˆ†è§£æ­¥éª¤\n[LUåˆ†è§£çš„ä¾‹å­](notes/2021/2021.11/LUåˆ†è§£çš„ä¾‹å­.md)\n- ä»ä¸Šé¢çš„ä¾‹å­é‡Œé¢æˆ‘ä»¬èƒ½å¤Ÿå¾—åˆ°ä¸€ç§ç›´è§‰: æ±‚LUåˆ†è§£çš„è¿‡ç¨‹å°±æ˜¯æ¯æ¬¡è§£å†³ä¸€åˆ—, ç›´åˆ°ç»“æœå®Œå…¨å˜æˆä¸‰è§’çŸ©é˜µ.\n- **Intuition:**\n\t![](notes/2021/2021.11/assets/Pasted%20image%2020211113010753.png)\n\n## The \"Sum of Rank 1 Matrices\" Perspective\n- How is the original A related to the final matrix U ?\n\n$$\\boldsymbol{A}=\\boldsymbol{\\ell}_{\\mathbf{1}} \\boldsymbol{u}_{\\mathbf{1}}^{*}+\\boldsymbol{\\ell}_{\\mathbf{2}} \\boldsymbol{u}_{\\mathbf{2}}^{*}+\\boldsymbol{\\ell}_{\\mathbf{3}} \\boldsymbol{u}_{\\mathbf{3}}^{*}+\\boldsymbol{\\ell}_{\\mathbf{4}} \\boldsymbol{u}_{\\mathbf{4}}^{*}=\\left[\\begin{array}{cccc}\n1 \u0026 0 \u0026 0 \u0026 0 \\\\\n\\ell_{21} \u0026 1 \u0026 0 \u0026 0 \\\\\n\\ell_{31} \u0026 \\ell_{32} \u0026 1 \u0026 0 \\\\\n\\ell_{41} \u0026 \\ell_{42} \u0026 \\ell_{43} \u0026 1\n\\end{array}\\right]\\left[\\begin{array}{l}\n\\text { pivot row 1 } \\\\\n\\text { pivot row 2 } \\\\\n\\text { pivot row 3 } \\\\\n\\text { pivot row 4 }\n\\end{array}\\right]=\\boldsymbol{L} \\boldsymbol{U}$$\n\næ¯ä¸€ä¸ªRankä¸º1çš„çŸ©é˜µéƒ½\"å¤„ç†(peel off)\"å®ƒå¯¹åº”çš„ä¸€è¡Œä¸€åˆ—, æ‰€æœ‰çš„çŸ©é˜µåŠ èµ·æ¥å°±æ„æˆäº†A:\n![](notes/2021/2021.11/assets/Pasted%20image%2020211113011439.png)\n![](notes/2021/2021.11/assets/Pasted%20image%2020211113011500.png)\n\n- Intuition:\n![300](notes/2021/2021.11/assets/Pasted%20image%2020211113012248.png)\næ–¹å‘å¥½åƒç”»é”™äº†, ä½†æ˜¯You Get the Idea.\n\n### With Row Exchange\nä¸Šé¢çš„åˆ†è§£éƒ½æ˜¯ä¸å¸¦Row Exchangeçš„, ä½†æ˜¯æœ‰æ—¶å€™Pivotæ˜¯0, æˆ‘ä»¬å°±éœ€è¦äº¤æ¢ä¸€ä¸‹è¡Œ, ç”¨å¯¹åº”ä½ç½®éé›¶çš„è¡Œæ¥ä½œä¸ºPivot:\n![](notes/2021/2021.11/assets/Pasted%20image%2020211113012555.png)\n\nè¿™æ˜¯å°±å˜æˆäº†PLUåˆ†è§£, [ç»´åŸºç™¾ç§‘ä¸Šé¢æœ‰æ›´è¯¦ç»†çš„å™è¿°](https://zh.wikipedia.org/wiki/LU%E5%88%86%E8%A7%A3)\n\n\n\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_5-Four_Subspaces":{"title":"MIT_18.065-Part_5-Four_Subspaces","content":"# 4 Subspaces\n\n\u003cdiv align=\"right\"\u003e 2021-11-13\u003c/div\u003e\n\nTags: #Math/LinearAlgebra \n\n## What are they?\nThe Four Subspaces are:\n\n- $A$çš„åˆ—ç©ºé—´ $Col(A)$\n- $A$çš„è¡Œç©ºé—´ $Row(A)=Col(A^T)$\n- $A$çš„æ ¸(é›¶ç©ºé—´) $N(A) \\Rightarrow Ax=0$\n- $A^T$çš„æ ¸ $N(A^T) \\Rightarrow A^Ty=0$\n\nä¸ºäº†ä¸è¯¾æœ¬ä¸€è‡´, æˆ‘ä»¬å°†$Col(A)$ç®€ç§°ä¸º$C(A)$\n\n## What do they represent?\næ€æ ·ç†è§£è¿™å››ä¸ªå­ç©ºé—´å‘¢?\n\nå¯¹äº$A_{m\\times n}$, å‡è®¾$Rank(A)=r$\n- ä»çº¿æ€§æ˜ å°„çš„è§’åº¦æ¥çœ‹, $A_{m\\times n}$æ˜¯ä»$\\mathbf{R^n}$åˆ°$\\mathbf{R^m}$çš„ä¸€ä¸ªæ˜ å°„\n\n- $C(A)$æ˜¯Açš„åˆ—ç©ºé—´, å³åˆ—å‘é‡å¼ æˆçš„å­ç©ºé—´\n\t- æ¯ä¸ªåˆ—å‘é‡æ˜¯mç»´çš„, æ‰€ä»¥$C(A)$å±äº $\\mathbf{R^m}$\n\t- $dim(C(A))=r$\n\n\n- $C(A^T)$æ˜¯Açš„è¡Œç©ºé—´, å³è¡Œå‘é‡å¼ æˆçš„å­ç©ºé—´\n\t- æ¯ä¸ªè¡Œå‘é‡æ˜¯nç»´çš„, æ‰€ä»¥$C(A^T)$å±äº $\\mathbf{R^n}$\n\t- $dim(C(A))=r$\n\n- $N(A)$æ˜¯$Ax=0$çš„è§£ç©ºé—´, å±äºæ˜ å°„å‰çš„ç©ºé—´$\\mathbf{R^n}$. ä¸è¡Œå‘é‡åœ¨åŒä¸€ä¸ªç»´åº¦çš„ç©ºé—´ä¸‹.\n\t- $dim(N(A))=n-r$\n\t\t![](notes/2021/2021.11/assets/img_2022-10-15-15.png)[^1]\n\n![400](notes/2021/2021.11/assets/img_2022-10-15-16.png)\n\n-  $N(A^T)$æ˜¯$A^Ty=0$çš„è§£ç©ºé—´, å±äºæ˜ å°„åçš„ç©ºé—´$\\mathbf{R^m}$. ä¸åˆ—å‘é‡åœ¨åŒä¸€ä¸ªç»´åº¦çš„ç©ºé—´ä¸‹.\n\t- $dim(N(A^T))=m-r$\n\n\n## How do they relate?\n- A great video:\n\t[Visualizing the Four Fundamental Spaces - YouTube](https://www.youtube.com/watch?v=ZdlraR_7cMA)\n![](notes/2021/2021.11/assets/img_2022-10-15-17.png)\n- \"Açš„æ¯ä¸€è¡Œä¸xçš„å†…ç§¯éƒ½ä¸º0\", æ‰€ä»¥$N(A)\\perp Row(A)\\Rightarrow N(A)\\perp C(A^T)$\n- åŒç†, $C(A)\\perp N(A^T)$\n![](notes/2021/2021.11/assets/img_2022-10-15-18.png)\n\n- ä¸¤ä¸ªå­ç©ºé—´åœ¨$\\mathbf{R^n}$, ä¸¤ä¸ªå­ç©ºé—´åœ¨$\\mathbf{R^m}$, åŒä¸€ä¸ªç»´åº¦çš„ä¸¤ä¸ªå­ç©ºé—´ç›¸äº’å‚ç›´, ä¸€èµ·å¡«æ»¡æ•´ä¸ªç©ºé—´\n\n- ä¸åŒç»´åº¦çš„ç©ºé—´é€šè¿‡ä¸€ä¸ªçº¿æ€§æ˜ å°„è”ç³»èµ·æ¥, $A_{m\\times n}$å°†$\\mathbf{R^n}$æ˜ å°„åˆ°$\\mathbf{R^m}$\n![500](notes/2021/2021.11/assets/img_2022-10-15-19.png)\n\n- æ¯ä¸€ä¸ª$\\mathbf{R^n}$é‡Œé¢çš„å‘é‡$\\mathbf{R^n}$éƒ½æœ‰ä¸€éƒ¨åˆ†åœ¨$Row(A)$é‡Œé¢, æœ‰ä¸€éƒ¨åˆ†åœ¨$Null(A)$é‡Œé¢. æ˜ å°„è¿‡å»ä»¥å, ä¾¿éƒ½åœ¨ColAé‡Œé¢äº†.\n\t- xå…¨éƒ¨åœ¨$Null(A)$é‡Œé¢çš„æ—¶å€™, æ˜ å°„è¿‡å»å°±æ˜¯0å‘é‡\n\t- æ˜ å°„çš„è¿‡ç¨‹å…¶å®å¯ä»¥çœ‹æˆä¸¤éƒ¨åˆ†:\n\t\t![](notes/2021/2021.11/assets/img_2022-10-15-20.png)\n\t\tRow Spaceé‡Œé¢é‚£éƒ¨åˆ†è¢«æ˜ å°„åˆ°Col Space, è€ŒNull Spaceé‡Œé¢é‚£éƒ¨åˆ†åˆ™è¢«æ˜ å°„åˆ°0.\n\n\n---\n\u003e çº¿æ€§ä»£æ•°æœ‰å¥½å¤šçœ‹å¾…é—®é¢˜çš„è§’åº¦, å¯¹äºä¸åŒçš„é—®é¢˜, ä¸åŒè§’åº¦æ¥çœ‹æ˜¯å¾ˆä¸ä¸€æ ·çš„.\n\u003e æ¯”å¦‚æˆ‘ä»¬æœ‰çº¿æ€§å˜æ¢çš„è§’åº¦, åæ ‡çš„è§’åº¦, å†…ç§¯å¤–ç§¯çš„è§’åº¦, çŸ©é˜µç›¸ä¹˜çš„è§’åº¦......\n\u003e å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜, ä»å¤šä¸ªè§’åº¦å»æƒ³ä¸€æƒ³\n\n[^1]: C.lay, çº¿æ€§ä»£æ•°åŠå…¶åº”ç”¨, Chapter 4","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_6-Orthonormal-Columns-in-Q-Give-QQ-I":{"title":"MIT_18.065-Part_6-Orthonormal Columns in Q Give Q'Q = I","content":"# Orthonormal Columns in Q Give Q'Q = I\n\n\u003cdiv align=\"right\"\u003e 2021-11-13\u003c/div\u003e\n\nTags: #Math/LinearAlgebra \n\n\u003e orthogonal: æ­£äº¤çš„\n\u003e orthonormal: **Ortho**(gonal) + **normal**, å³åˆæ­£äº¤åˆæ˜¯å•ä½å‘é‡, é•¿åº¦ä¸º1.\n\n## Orthogonal Vectors\nå†…ç§¯çš„å‘é‡åŒ–è¡¨ç¤º:  $\\boldsymbol{x}^{\\mathrm{T}} \\boldsymbol{y}=x_{1} y_{1}+\\cdots+x_{n} y_{n}=0$\n\néœ€è¦æ³¨æ„çš„æ˜¯, å¦‚æœæ˜¯å¤æ•°ç›¸è¿çš„å†…ç§¯, æˆ‘ä»¬éœ€è¦ä½¿ç”¨å…±è½­å¤æ•°(Conjugate)ç»„æˆçš„å‘é‡æ¥è®¡ç®—å†…ç§¯: $\\overline{\\boldsymbol{x}}^{\\mathrm{T}} \\boldsymbol{y}=\\bar{x}_{1} y_{1}+\\cdots+\\bar{x}_{n} y_{n}=0$\n\n### ä¸å‹¾è‚¡å®šç†çš„è”ç³»\n$$\\begin{aligned}||x-y||^2\u0026=(x-y)^T(x-y)\\\\\u0026=x^Tx+y^Ty-x^Ty-y^Tx\\\\\u0026=||x||^2+||y||^2-2||x||\\space ||y||cos\\theta\\end{aligned}$$\n\n- x yæ­£äº¤çš„æ—¶å€™ $cos\\theta=0$, \n\n## Orthogonal Matrix\næœ‰äº†å‘é‡ç›¸äº’æ­£äº¤çš„è¡¨ç¤º, æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“çš„æ¨å¹¿åˆ°çŸ©é˜µ:\n\n- å¦‚æœä¸€ä¸ªçŸ©é˜µçš„è¡Œå‘é‡å’Œå‘é‡xæ­£äº¤, é‚£ä¹ˆæœ‰$Ax=0$, è¿™æ­£æ˜¯å‰é¢çš„æ ¸ç©ºé—´$Null(A)$\n\t![](notes/2021/2021.11/assets/img_2022-10-15-21.png)\n\t\n- å¦‚æœçŸ©é˜µQçš„åˆ—æ˜¯å•ä½æ­£äº¤çš„(Orthonormal), é‚£ä¹ˆæœ‰:\n\t![](notes/2021/2021.11/assets/img_2022-10-15-22.png)\n\t- æ³¨æ„è¿™ä¸ªçŸ©é˜µä¸ä¸€å®šæ˜¯æ–¹é˜µ, å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªåˆé«˜åˆç˜¦çš„çŸ©é˜µ\n\n- çŸ©é˜µQæœ‰Orthonormalçš„åˆ—å‘é‡, é‚£ä¹ˆQä»£è¡¨çš„çº¿æ€§å˜æ¢ä¸æ”¹å˜å‘é‡çš„é•¿åº¦, è¿™ä¸€ç‚¹å¾ˆæœ‰ç”¨. \n\t- è¯æ˜: ![](notes/2021/2021.11/assets/img_2022-10-15-23.png)\n\t- Computations with Q never overflow!\n\n- å¦‚æœQæ˜¯ä¸€ä¸ªæ–¹é˜µçš„è¯, $Q^{\\mathrm{T}} Q=I$ è¯´æ˜ $Q^{\\mathrm{T}}=Q^{-1}$, è¿™ä¹Ÿè¯´æ˜ $QQ^{\\mathrm{T}}=I$\n\t- ä½†æ˜¯è¦æ˜¯Qæ˜¯ä¸€ä¸ªåˆé«˜åˆç˜¦çš„çŸ©é˜µ (m\u003en), é‚£ä¹ˆå› ä¸ºmä¸ªåˆ—å‘é‡ä¸å¯èƒ½æ˜¯æ­£äº¤çš„(å› ä¸ºæ­£äº¤å‘é‡ä¸å¯èƒ½å¤šäºçŸ©é˜µçš„ç§©), æ‰€ä»¥å¤§å°ä¸º$m\\times m$çš„çŸ©é˜µ$QQ^{\\mathrm{T}}\\neq I$\n\n- \"Orthogonal matrices\" are square with orthonormal columns: $Q^{\\mathrm{T}}=Q^{-1}$\n\t- æ‰€ä»¥\"Orthogonal matrices\"å…¶å®å«\"Orthonormal matrices\"æ›´åˆé€‚\n\n$$Orthogonal\\space matrix: Q^{\\mathrm{T}} Q=QQ^{\\mathrm{T}}=I_{n\\times n}$$\n\n## é‡è¦çŸ©é˜µåˆ—ä¸¾\n\n### Rotation Matrix \u0026 Reflection Matrix\n$$Q_{\\text {rotate }}=\\left[\\begin{array}{rr}\n\\cos \\theta \u0026 -\\sin \\theta \\\\\n\\sin \\theta \u0026 \\cos \\theta\n\\end{array}\\right]=\\text { rotation through an angle } \\theta$$\n\n$$Q_{\\text {reflect }}=\\left[\\begin{array}{rr}\n\\cos \\theta \u0026 \\sin \\theta \\\\\n\\sin \\theta \u0026 -\\cos \\theta\n\\end{array}\\right]=\\text { reflection across the } \\frac{\\theta}{2}\\text { line. }$$\n![](notes/2021/2021.11/assets/img_2022-10-15-24.png)\n\n- å¹¶ä¸”æ­£è§„çŸ©é˜µçš„ç§¯ä¹Ÿæ˜¯æ­£è§„çŸ©é˜µ:\n\t$$Q_{1} Q_{2} \\text { is orthogonal: } \\quad\\left(Q_{1} Q_{2}\\right)^{\\mathrm{T}}\\left(Q_{1} Q_{2}\\right)=Q_{2}^{\\mathrm{T}} Q_{1}^{\\mathrm{T}} Q_{1} Q_{2}=Q_{2}^{\\mathrm{T}} Q_{2}=I$$\n\t\n- Rotation $\\times$ rotation = rotation. \n- Reflection $\\times$ reflection = rotation. \n- Rotation$\\times$ reflection = reflection\n\t\n### Hadamard matrices\n![](notes/2021/2021.11/assets/img_2022-10-15-25.png)\n\n\n### Householder Reflections\n- Why It's Called Reflection? Watch the vid below:\n[Householder transformations, part 1 - YouTube](https://www.youtube.com/watch?v=6TIVIw4B5VA)\n$$H_{n}=I-2 u u^{\\mathrm{T}}$$\n- Hæ˜¯ä¸€ä¸ªçŸ©é˜µ, è¿™ä¸ªçŸ©é˜µè¡¨ç¤ºè¿™æ ·çš„ä¸€ä¸ªçº¿æ€§å˜æ¢: \n\t- **æ±‚å‘é‡xä¸æŸä¸ªè¶…å¹³é¢çš„å¯¹ç§°å‘é‡**\n\t- å“ªä¸ªè¶…å¹³é¢? å•ä½æ³•å‘é‡ä¸º$u$çš„è¶…å¹³é¢\n\n- $H_n$æ˜¯ä¸€ä¸ªå¯¹ç§°çŸ©é˜µ, æœ‰:\n\t$$\\boldsymbol{H}^{\\mathrm{T}} \\boldsymbol{H}=\n\\boldsymbol{H}^{\\mathbf{2}}=\n\\left(I-2 \\boldsymbol{u} \\boldsymbol{u}^{\\mathrm{T}}\\right)\n\\left(I-2 \\boldsymbol{u} \\boldsymbol{u}^{\\mathrm{T}}\\right)=\nI-4 \\boldsymbol{u} \\boldsymbol{u}^{\\mathrm{T}}+\n4\\boldsymbol{u}\\boldsymbol{u}^{\\mathrm{T}}\\boldsymbol{u}\\boldsymbol{u}^{\\mathrm{T}}=\\boldsymbol{I}$$\n\n- å¦‚æœæˆ‘ä»¬é€‰è¿™ä¸€ä¸ªå•ä½å‘é‡: $u = (1, 1, ... , 1)/ \\sqrt n$\n\t- é‚£ä¹ˆ\n\t\t$$H_n=I-2 u u^{\\mathrm{T}}=I-\\frac 2 n \\mathrm{ones(n,n)}$$\n\nä¸¤ä¸ªä¾‹å­:\n$$\\boldsymbol{H}_{3}=I-\\frac{2}{3} \\text { ones }=\\frac{1}{3}\\left[\\begin{array}{rrr}\n1 \u0026 -2 \u0026 -2 \\\\\n-2 \u0026 1 \u0026 -2 \\\\\n-2 \u0026 -2 \u0026 1\n\\end{array}\\right] \\quad \\boldsymbol{H}_{4}=I-\\frac{2}{4} \\text { ones }=\\frac{1}{2}\\left[\\begin{array}{rrrr}\n\\mathbf{1} \u0026 -1 \u0026 -1 \u0026 -1 \\\\\n-1 \u0026 \\mathbf{1} \u0026 -1 \u0026 -1 \\\\\n-1 \u0026 -1 \u0026 \\mathbf{1} \u0026 -1 \\\\\n-1 \u0026 -1 \u0026 -1 \u0026 \\mathbf{1}\n\\end{array}\\right]$$\n\n- å…³äºç‰¹å¾å€¼è¿™ä¸€ç‚¹è¿˜ä¸æ˜¯å¾ˆç†è§£:\nThe \"eigenvalues\" of H are -1 (once) and +1 (n- 1 times). All reflection matrices have eigenvalues -1 and 1.\n\n\n### Haar wavelets\n![](notes/2021/2021.11/assets/img_2022-10-15-26.png)\nn=8\n$$\\left[\\begin{array}{ccc}1\u00261\u00261\u0026\u00261\u0026\u0026\u0026\\\\ 1\u00261\u00261\u0026\u0026-1\u0026\u0026\u0026\\\\ 1\u00261\u0026-1\u0026\u0026\u00261\u0026\u0026\\\\ 1\u00261\u0026-1\u0026\u0026\u0026-1\u0026\u0026\\\\ 1\u0026-1\u0026\u00261\u0026\u0026\u00261\u0026\\\\ 1\u0026-1\u0026\u00261\u0026\u0026\u0026-1\u0026\\\\ 1\u0026-1\u0026\u0026-1\u0026\u0026\u0026\u00261\\\\ 1\u0026-1\u0026\u0026-1\u0026\u0026\u0026\u0026-1\\end{array}\\right]$$\n\n## Eigenvectors of $S=S^T$ \u0026 $Q^TQ=I$\n- **The Eigenvectors of a Symmetric Matrix and an Orthogonal Matrix is Orthogonal.**\n- ä¸€ä¸ªä¾‹å­æ˜¯ä¸‹é¢çš„çŸ©é˜µPçš„ç‰¹å¾å‘é‡æ„æˆäº† 4 by 4 Fourier matrix F.\n$$P=\\left[\\begin{array}{llll}\n0 \u0026 1 \u0026 0 \u0026 0 \\\\\n0 \u0026 0 \u0026 1 \u0026 0 \\\\\n0 \u0026 0 \u0026 0 \u0026 1 \\\\\n1 \u0026 0 \u0026 0 \u0026 0\n\\end{array}\\right]$$\n$$F=\\left[\\begin{array}{ccrr}\n1 \u0026 1 \u0026 1 \u0026 1 \\\\\n1 \u0026 i \u0026 i_2 \u0026 i^3 \\\\\n1 \u0026 i^{2} \u0026 i_4 \u0026 i^6 \\\\\n1 \u0026 i^{3} \u0026 i^6 \u0026 i^9\n\\end{array}\\right]$$\nä¸‹é¢çš„çŸ©é˜µQæœ‰orthonormalçš„åˆ—å‘é‡:\n$$Q=\\frac{F}{2}=\\frac{1}{2}\\left[\\begin{array}{ccrr}\n1 \u0026 1 \u0026 1 \u0026 1 \\\\\n1 \u0026 i \u0026 -1 \u0026 -i \\\\\n1 \u0026 i^{2} \u0026 1 \u0026 -1 \\\\\n1 \u0026 i^{3} \u0026 -1 \u0026 i\n\\end{array}\\right]$$\n\næ³¨æ„å¤æ•°çš„å†…ç§¯éœ€è¦å–å…±è½­:\néªŒè¯, å¯¹äºF, ç¬¬äºŒåˆ—å’Œç¬¬å››åˆ—çš„å†…ç§¯:\n$[1,-i,i^2,-i^3]\\left[\\begin{array}{ccrr}1 \\\\i^3 \\\\i^6 \\\\ i^9\\end{array}\\right]=1-1+1-1=0$\n\n\n## æ¯ä¸€ä¸ªå‘é‡ç©ºé—´$R^n$éƒ½æœ‰ä¸€ç»„æ­£äº¤åŸº\n- è¿™å¯ä»¥ç”±Gram-Schmidtæ–¹æ³•å¾—åˆ°\n\n- å¥‡å¼‚å€¼åˆ†è§£å¯ä»¥æ‰¾åˆ°çŸ©é˜µ$A$çš„$Row\\space Space$çš„ä¸€ç»„æ­£äº¤åŸº: $u_1\\cdots u_r$, çŸ©é˜µ$A$çš„$Column\\space Space$çš„ä¸€ç»„æ­£äº¤åŸº: $v_1\\cdots v_r$, å…¶ä¸­ræ˜¯Açš„ç§©. \n\t- è¿™ä¸ªä¸¤ä¸ªæ­£äº¤åŸºç‰¹æ®Šçš„åœ°æ–¹åœ¨äºå®ƒä»¬ç”±çŸ©é˜µAè”ç³»èµ·æ¥:\n\t\n$$\\text { Singular vectors } \\quad A \\boldsymbol{v}_{1}=\\sigma_{1} \\boldsymbol{u}_{1} \\quad A \\boldsymbol{v}_{2}=\\sigma_{2} \\boldsymbol{u}_{2} \\quad \\cdots \\quad A \\boldsymbol{v}_{r}=\\sigma_{r} \\boldsymbol{u}_{r}$$\n\n- For the bases from the SVD, multiplying by A takes an orthogonal basis of v's to an orthogonal basis of u's.\n\n\n## æŠ•å½±çŸ©é˜µ\n![](notes/2021/2021.11/assets/img_2022-10-15-27.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-28.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-29.png)\n\n$$Px=QQ^{\\mathrm{T}}x=Q(Q^{\\mathrm{T}}x)=$$\n$$Col(Q)(Inner\\space product\\space of\\space Row(Q)\\space and\\space x)$$\nå°±æ˜¯å…ˆè®¡ç®—xä¸Qé‡Œé¢å„ä¸ªæ­£äº¤åŸºåº•çš„å†…ç§¯, å¾—åˆ°åœ¨è¿™ä¸ªæ­£äº¤åŸºåº•ä¸‹çš„\"åæ ‡\", ç„¶åå†ç”¨Col(Q)è¡¨ç¤ºå‡ºæ¥.\n\n\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_7-Eigenvalues-and-Eigenvectors":{"title":"MIT_18.065-Part_7-Eigenvalues and Eigenvectors","content":"# Eigenvalues and Eigenvectors\n\n\u003cdiv align=\"right\"\u003e 2021-11-14\u003c/div\u003e\n\nTags: #Math/LinearAlgebra #Math/LinearAlgebra/Eigenvalue \n\n## ç‰¹å¾å€¼çš„ä¸€äº›æ€§è´¨\n![](notes/2021/2021.11/assets/img_2022-10-15-30.png)\n\n\n## ç›¸ä¼¼çŸ©é˜µ\n\n[[notes/2021/2021.11/ç†è§£ç›¸ä¼¼çŸ©é˜µ]]\n\n### ç›¸ä¼¼çŸ©é˜µæœ‰ç›¸åŒçš„ç‰¹å¾å€¼\n$$P^{-1}AP =  B$$\nå‡è®¾çŸ©é˜µ$B$æœ‰ç‰¹å¾å€¼$\\lambda$:\n$$Bx=\\lambda x$$\nåˆ™\n$$\\begin{aligned}P^{-1}APx\u0026=\\lambda x \\\\\n\u0026\\Rightarrow \\\\ APx\u0026=P\\lambda x \\\\\n\u0026\\Rightarrow \\\\ A(Px)\u0026=\\lambda (Px)\\end{aligned}$$\n\nAä¹Ÿæœ‰ç‰¹å¾å€¼$\\lambda$, å¯¹åº”ç‰¹å¾å‘é‡$Px$\n- è€Œä¸”$Px$åˆšå¥½æ˜¯ æŠŠBé‡Œé¢çš„ç‰¹å¾å‘é‡x é€šè¿‡åŸºå˜æ¢çŸ©é˜µP è½¬æ¢åˆ°Açš„åæ ‡ä¸‹.\n\n\n## Symmetric Matrix: $S=S^T$\n\n### S have Real Eigenvalues\nSee the document below:\n[Symmetric matrices have real eigenvalues](notes/2021/2021.11/Symmetric%20matrices%20have%20real%20eigenvalues.pdf)\n\n\n### S have Orthogonal Eigenvectors\n- This is a good video, è§†é¢‘çš„å¼€å¤´åŒæ—¶ä¹Ÿè¯´æ˜äº†Eigenvalueå¯èƒ½é‡åˆ°çš„\"Defective Case\"\n[Eigenvectors of Symmetric Matrices Are Orthogonal - YouTube](https://www.youtube.com/watch?v=gJhlkEBZsfI)\n\n- é¦–å…ˆ, å¯¹äºå®å¯¹ç§°çŸ©é˜µS, æœ‰$S=S^T$\n- å¯¹äºä¸åŒçš„ä¸¤ä¸ªç‰¹å¾å€¼$\\lambda_1, \\lambda_2$, æœ‰\n$$\\begin{aligned}Sx\u0026=\\lambda_1 x\\\\Sy\u0026=\\lambda_2 y\\end{aligned}$$\n- æˆ‘ä»¬åšä¸‹é¢çš„å˜å½¢, å°†ä¸¤è¾¹éƒ½å˜æˆå†…ç§¯:\n$$\\begin{aligned}y^TSx\u0026=\\lambda_1y^T x\\\\\nx^TSy\u0026=\\lambda_2x^T y\\end{aligned}$$\n- å¯¹äºç¬¬ä¸€ä¸ªå¼å­çš„å·¦è¾¹, å› ä¸ºæ˜¯$y^T$ä¸$Sx$çš„å†…ç§¯, æ˜¯ä¸€ä¸ªæ•°, å…¶è½¬ç½®è¿˜æ˜¯è‡ªå·±:\n$$(y^TSx)^T=x^TS^Ty=x^TSy=\\text{ç¬¬äºŒä¸ªå¼å­çš„å·¦è¾¹}$$\n- ä¸¤å¼ç›¸å‡, æ‰€ä»¥æœ‰:\n$$0=(\\lambda_1-\\lambda_2)x^T y=(\\lambda_1-\\lambda_2)x\\cdot y$$\n- å› ä¸ºå‡è®¾ç‰¹å¾å€¼æ˜¯ä¸ç›¸åŒçš„, æ‰€ä»¥xä¸yçš„å†…ç§¯ä¸º0, æ‰€ä»¥ä»»æ„ä¸¤ä¸ªç‰¹å¾å‘é‡ç›¸äº’å‚ç›´.\n\næ³¨æ„: æœ‰çš„ç‰¹å¾ç©ºé—´å¯èƒ½æ˜¯å¤šç»´çš„, ä½†æ˜¯åœ¨è¿™ä¸ªç‰¹å¾ç©ºé—´é‡Œé¢ä¹Ÿå¯ä»¥æ‰¾åˆ°ä¸€ä¸ªæ­£äº¤çš„åŸº, å¹¶ä¸”å…¶ä»–ç‰¹å¾ç©ºé—´é‡Œé¢çš„ç‰¹å¾å‘é‡æ˜¯å’Œè¿™ä¸ªç‰¹å¾ç©ºé—´å‚ç›´çš„, è‡ªç„¶ä¹Ÿå’Œè¿™ä¸ªæ­£äº¤çš„åŸºå‚ç›´.\n\n---\n- **ç»¼ä¸Š:** å®å¯¹ç§°çŸ©é˜µæ˜¯ä¸€ä¸ªå¾ˆç‰¹æ®Šçš„çŸ©é˜µ, å®ƒåªæœ‰å®ç‰¹å¾å€¼, å¹¶ä¸”ç‰¹å¾å‘é‡éƒ½æ˜¯ç›¸äº’æ­£äº¤çš„.\n\t- è¿™æ˜¯ä¸€ç§æ‰¾æ­£äº¤çŸ©é˜µçš„å¾ˆæ–¹ä¾¿çš„æ–¹æ³•\n\n## å¯¹è§’åŒ–çŸ©é˜µ\n![](notes/2021/2021.11/assets/img_2022-10-15-31.png)\n\nå¯¹äºå¯¹ç§°çŸ©é˜µ, åˆ™æ›´ä¸ºç‰¹æ®Š:\n$$S=Q\\Lambda Q^{-1}$$\nå› ä¸ºå¯¹ç§°çŸ©é˜µçš„ç‰¹å¾å‘é‡éƒ½æ˜¯æ­£äº¤çš„, æˆ‘ä»¬æœ‰$Q^T=Q^{-1}$:\n$$S=Q\\Lambda Q^{T}$$\n- $S=Q\\Lambda Q^{T}$ä¹Ÿè¢«ç§°ä¸º\"Spectral Theorem\"(è°±å®šç†) ^a919e0\n\næ¯ä¸€ä¸ªå®å¯¹ç§°çŸ©é˜µç”±ä¸¤éƒ¨åˆ†ç»„æˆ: ç›¸äº’æ­£äº¤çš„ç‰¹å¾å‘é‡ç»„æˆçš„Qå’Œå®ç‰¹å¾å€¼ç»„æˆçš„å¯¹è§’çŸ©é˜µ$\\Lambda$","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_8-Positive-Definite-and-Semidefinite-Matrices":{"title":"MIT_18.065-Part_8-Positive Definite and Semidefinite Matrices","content":"# Positive Definite and Semi-definite Matrices\n\n\u003cdiv align=\"right\"\u003e 2021-11-14\u003c/div\u003e\n\nTags: #Math/LinearAlgebra\n\n- Positive Definite Matrices are the Best of the Symmetric Matrices.\n\n## äº”ä¸ªåˆ¤åˆ«æ¡ä»¶\n- åŒæ—¶ä¹Ÿæ˜¯æ­£å®šçŸ©é˜µçš„é‡è¦æ€§è´¨:\n![](notes/2021/2021.11/assets/img_2022-10-15-32.png)\n- Positive Eigenvalues\n\t- æ‰€æœ‰çš„ç‰¹å¾å€¼éƒ½æ˜¯æ­£æ•°\n- Energy $x^TSx\u003e0$,  $\\forall x\\neq 0$\n\t- æœ‰æ­£çš„\"èƒ½é‡\", è¿™ç‚¹åé¢ä¼šè¯¦è¿°\n- $S=A^TA$, A has Independent Columns\n\t- Så¯ä»¥è¢«åˆ†è§£ä¸ºä¸€ä¸ªçŸ©é˜µçš„è½¬ç½®ä¸è‡ªå·±çš„ä¹˜ç§¯\n- All leading Determinants \u003e 0\n\t- ![](notes/2021/2021.11/assets/img_2022-10-15-33.png)\n- All Pivots in Elimination \u003e 0\n\t- ![](notes/2021/2021.11/assets/img_2022-10-15-34.png)\n\n### Energy\n(åœ¨è§†é¢‘é‡Œé¢æ²¡æœ‰æ‰¾åˆ°è¯¦ç»†çš„å®šä¹‰, ç½‘ä¸Šä¹Ÿæ²¡æœ‰ç›¸å…³çš„èµ„æ–™, åº”å½“æ˜¯ä¸€ä¸ªç›´è§‚çš„æ¦‚å¿µ)\n- \"èƒ½é‡\"åœ¨è¿™é‡Œä½“ç°ä¸ºä¸€ç§\"äºŒæ¬¡(quadratic)\"çš„æ¦‚å¿µ, æ¯”å¦‚åœ¨åŠ¨èƒ½, åŠ¿èƒ½ç­‰å®šä¹‰é‡Œé¢, éƒ½æœ‰äºŒæ¬¡é¡¹çš„å­˜åœ¨.\n\n- xé‡Œé¢çš„èƒ½é‡é€šè¿‡è®¡ç®—$x^TSx$æ¥å¾—å‡º, ç±»ä¼¼äºå†…ç§¯, ä½†æ˜¯ä¸­é—´å¤šäº†ä¸€ä¸ª$S$\n\nä»¥æ­£å®šçŸ©é˜µ$$\\left[\\begin{array}{ll}\n2 \u0026 4 \\\\\n4 \u0026 9\n\\end{array}\\right]$$ä¸ºä¾‹:\n\n$$[x, y]\\left[\\begin{array}{ll}\n2 \u0026 4 \\\\ 4 \u0026 9\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\ y \\end{array}\\right]=f(x, y)$$\n$$\\begin{align}\u0026=2x^2+9y^2+4xy+4yx\\\\\u0026=2x^2+9y^2+8xy\\\\\u0026=2(x+2y)^2+y^2\u003e0\n\\end{align}$$\n- ä¸ºä»€ä¹ˆèƒ½é‡å¤§äºé›¶, è¿™ä¸ªçŸ©é˜µå°±æ˜¯æ­£å®šçš„å‘¢?\né¦–å…ˆ, å¯¹äºç‰¹å¾å‘é‡:\n$$\\text { If } S x=\\lambda x \\text { then } x^{\\mathrm{T}} S x=\\lambda x^{\\mathrm{T}} x \\text {. So } \\lambda\u003e0 \\text { leads to } x^{\\mathrm{T}} S x\u003e0 \\text {. }$$\n- è€Œåœ¨æ­£è§„çŸ©é˜µé‡Œé¢ç‰¹å¾å‘é‡å¯ä»¥è¡¨ç¤ºä»»æ„å‘é‡x, (å› ä¸ºå®ƒä»¬æ„æˆä¸€ç»„æ­£äº¤åŸºåº•):\n$$\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}} S \\boldsymbol{x} \u0026=\\left(c_{1} \\boldsymbol{x}_{1}^{\\mathrm{T}}+\\cdots+c_{n} \\boldsymbol{x}_{n}^{\\mathrm{T}}\\right) S\\left(c_{1} \\boldsymbol{x}_{1}+\\cdots+c_{n} \\boldsymbol{x}_{n}\\right) \\\\\n\u0026=\\left(c_{1} \\boldsymbol{x}_{1}^{\\mathrm{T}}+\\cdots+c_{n} \\boldsymbol{x}_{n}^{\\mathrm{T}}\\right)\\left(c_{1} \\lambda_{1} \\boldsymbol{x}_{1}+\\cdots+c_{n} \\lambda_{n} \\boldsymbol{x}_{n}\\right) \\\\\n\u0026=c_{1}^{2} \\lambda_{1} \\boldsymbol{x}_{1}^{\\mathrm{T}} \\boldsymbol{x}_{1}+\\cdots+c_{n}^{2} \\lambda_{n} \\boldsymbol{x}_{n}^{\\mathrm{T}} \\boldsymbol{x}_{n}\u003e\\mathbf{0} \\text { if every } \\boldsymbol{\\lambda}_{i}\u003e\\mathbf{0}\n\\end{aligned}$$\nå¯ä»¥çœ‹åˆ°æ­£å®šçŸ©é˜µé‡Œé¢çš„å¯¹è§’çº¿å…ƒç´ å¯¹åº”äºŒæ¬¡é¡¹, è€Œå…¶ä»–å…ƒç´ å¯¹åº”äº¤å‰é¡¹.\nè¿™ä¸ªå‡½æ•°çš„å›¾åƒå¦‚ä¸‹å›¾æ‰€ç¤º:\n![](notes/2021/2021.11/assets/img_2022-10-15-35.png)\n\nè€Œè¿™ä¸æœºå™¨å­¦ä¹ é‡Œé¢çš„æŸå¤±å‡½æ•°æœ‰ç€å¯†åˆ‡çš„è”ç³»: æœ€å°åŒ–æŸå¤± \u003c=\u003e æœ€å°åŒ–èƒ½é‡\n[Cost_Function_Intuition](notes/2021/2021.8/Part.4_Cost_Function_Intuition(ML_Andrew.Ng.).md)\n- å¦‚æœä¸€ä¸ªå‡½æ•°æ˜¯ä¸¥æ ¼å‡¸çš„, é‚£ä¹ˆå®ƒçš„äºŒé˜¶å¯¼æ•°çŸ©é˜µåœ¨æ¯ä¸€ç‚¹éƒ½æ˜¯æ­£å®šçš„.\n- å¯¹äºæå°å€¼:\n![](notes/2021/2021.11/assets/img_2022-10-15-36.png)\n\n![](notes/2021/2021.11/assets/img_2022-10-15-37.png)\nå¦‚æœçŸ©é˜µSæœ‰è´Ÿçš„ç‰¹å¾å€¼, é‚£ä¹ˆfçš„å›¾åƒä¼šåœ¨0ä»¥ä¸‹. åœ¨Sæ˜¯è´Ÿå®šçš„æ—¶å€™(æ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯è´Ÿçš„), ä¸æ­£å®šçš„æ—¶å€™ç›¸å, å‡½æ•°ä¼šæœ‰æœ€å¤§å€¼. å‡½æ•°æœ‰çš„ç‰¹å¾å€¼å¤§äºé›¶æœ‰çš„å°äºé›¶, é‚£ä¹ˆå®ƒä¼šæœ‰\"éç‚¹\", A saddle point matrix is \"indefinite\".\n![](notes/2021/2021.11/assets/img_2022-10-15-38.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-39.png)\n\n\n## åŠæ­£å®šçŸ©é˜µ\n- Semi-definite allows energy / eigenvalues / determinants / pivots of S to be zero.\n\n- ç¬¬ä¸‰ç‚¹é‡Œé¢ä¹Ÿå…è®¸ä¸ç‹¬ç«‹çš„åˆ—\n\nè§è§†é¢‘é‡Œé¢çš„è¿™æ®µ:\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/xsP-S7yKaRA?controls=0\u0026amp;start=2504\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n## $S=A^TA$\n$S=A^TA$å®¹æ˜“çŸ¥é“æ˜¯ä¸€ä¸ªå¯¹ç§°çŸ©é˜µ, åœ¨è¿™ä¸ªæƒ…å†µä¸‹:\n\n$$Energy=x^TSx=x^TA^TAx = (Ax)^TAx= ||Ax||^2\\geq0$$\n\n- æ‰€ä»¥Sä¸€å®šæ˜¯æ­£å®šæˆ–è€…åŠæ­£å®šçš„\n\nå½“Aæœ‰çº¿æ€§ç›¸å…³çš„åˆ—çš„æ—¶å€™, Axå¯ä»¥=0, è¿™ä¸ªæ—¶å€™Sä¸ºåŠæ­£å®šçŸ©é˜µ.\n\n\n\n\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/MIT_18.065-Part_9-Singular-Value-Decomposition-SVD":{"title":"MIT_18.065-Part_9-Singular Value Decomposition-SVD","content":"# Singular Value Decomposition\n\n\u003cdiv align=\"right\"\u003e 2021-11-14\u003c/div\u003e\n\nTags: #Math/LinearAlgebra #SVD\n\n![Singular-Value-Decomposition|500](notes/2021/2021.11/assets/Singular-Value-Decomposition.svg)[^2]\n- SVDå°†ä»»æ„çŸ©é˜µ$A$åˆ†è§£æˆäº†ä¸‰ä¸ªéƒ¨åˆ†:\n\t- $U$ çš„åˆ—æ˜¯ç›¸äº’æ­£äº¤çš„. -  Left Singular Vectors\n\t- $\\Sigma$ çš„å¯¹è§’çº¿ä¸Šé¢æ˜¯é€’å‡çš„å¥‡å¼‚å€¼. -  Singular Values\n\t- $V^T$ çš„è¡Œæ˜¯ç›¸äº’æ­£äº¤çš„. - Right Singular Vectors\n\n\n## Basic Concepts\nåœ¨æœ€æ£’çš„æƒ…å†µä¸‹, æˆ‘ä»¬çš„çŸ©é˜µæ˜¯ä¸€ä¸ªå®å¯¹ç§°çŸ©é˜µ$S$: å®ƒæœ‰å®ç‰¹å¾å€¼å’Œæ­£äº¤çš„ç‰¹å¾å‘é‡. æ ¹æ®[è°±å®šç†](notes/2021/2021.11/MIT_18.065-Part_7-Eigenvalues%20and%20Eigenvectors.md#^a919e0), æˆ‘ä»¬èƒ½å¤Ÿå°†è¿™ä¸ªçŸ©é˜µåˆ†è§£æˆä»¥ä¸‹å½¢å¼:\n$$S=Q\\Lambda Q^T$$\n\nä½†æ˜¯åœ¨å¾ˆå¤šæƒ…å†µä¸‹, æˆ‘ä»¬çš„ç‰¹å¾ç©ºé—´å¹¶æ²¡æœ‰é‚£ä¹ˆå¤§, æ‰€ä»¥æˆ‘ä»¬éœ€è¦å°†ä¸Šè¿°åˆ†è§£è¿›è¡Œä¸€äº›æ¨å¹¿. SVDä¾¿æ˜¯ä¸€ç§ä¼˜ç¾çš„æ¨å¹¿å½¢å¼:\n\n$$A=U\\Sigma V^T$$\n\n\n\n\n\n\n![Singular_value_decomposition](notes/2021/2021.11/assets/Singular_value_decomposition.gif)[^1]\n## SVDçš„ä¸¤ç§å½¢å¼\n- **å®Œæ•´å½¢å¼çš„SVDé•¿è¿™æ ·:**\n$$A_{m\\times n}=U_{m\\times m}\\Sigma_{m\\times n}V^T_{n\\times n}$$\n\n![](notes/2021/2021.11/assets/Pasted%20image%2020211116203007.png)\n\nè¿™æ ·çš„è¯æœ‰è®¸å¤š\"æ²¡ç”¨çš„éƒ¨åˆ†\": $\\Sigma$é‡Œé¢æœ‰å¾ˆå¤šé›¶, å¹¶ä¸”U, Vé‡Œé¢æœ‰è®¸å¤šé›¶ç©ºé—´é‡Œé¢çš„å‘é‡(åé¢ä¼šè§£é‡Š).\n![400](notes/2021/2021.11/assets/Pasted%20image%2020211114211808.png)[^3]\n\n- **ç²¾ç®€ç‰ˆçš„SVDé•¿è¿™æ ·(The Reduced Form):**\n\n$$A_{m\\times n}=U_{m\\times r}\\Sigma_{r\\times r}V^T_{r\\times n}$$\nå…¶ä¸­$r$æ˜¯çŸ©é˜µ$A$çš„ç§©\n![](notes/2021/2021.11/assets/Pasted%20image%2020211116203445.png)\nè¿™æ˜¯$\\Sigma$æ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µäº†, å¹¶ä¸”$V, U$åªåŒ…å«\"æœ‰ç”¨çš„ç‰¹å¾å‘é‡\"äº†\n\n## Proof\n### é¢„å¤‡éƒ¨åˆ†\n[å…³äºç‰¹å¾å€¼çš„ä¸€ä¸ªç»“è®º](notes/2021/2021.11/å…³äºç‰¹å¾å€¼çš„ä¸€ä¸ªç»“è®º.md)\n[å…³äºç§©çš„ä¸€ä¸ªç»“è®º](notes/2021/2021.11/å…³äºç§©çš„ä¸€ä¸ªç»“è®º.md)\n[$S=A^TA$è‡³å°‘æ˜¯åŠæ­£å®šçš„, æ‰€ä»¥å®ƒçš„ç‰¹å¾å€¼ä¸€å®šæ˜¯éè´Ÿçš„](notes/2021/2021.11/MIT_18.065-Part_8-Positive%20Definite%20and%20Semidefinite%20Matrices.md#S%20A%20TA)\n\n### æ­£å¼å¼€å§‹\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CpD9XlTu3ys?start=182\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n[^4]\n\nè¯æ˜å’ŒçŸ©é˜µ$A^TA$ä¸$AA^T$æœ‰ç€ç´§å¯†çš„è”ç³»:\n\n- [å®¹æ˜“çŸ¥é“](notes/2021/2021.11/MIT_18.065-Part_8-Positive%20Definite%20and%20Semidefinite%20Matrices.md#S%20A%20TA)$A^TA$ä¸$AA^T$éƒ½æ˜¯å¯¹ç§°çŸ©é˜µ:\n\t- $A^TA$æ˜¯$Col(A)$ç›¸äº’ä¹˜, $AA^T$æ˜¯$Row(A)$ç›¸äº’ä¹˜\n\næ ¹æ®å¯¹ç§°çŸ©é˜µçš„[è°±å®šç†](notes/2021/2021.11/MIT_18.065-Part_7-Eigenvalues%20and%20Eigenvectors.md#^a919e0)è¿™ä¸ªè‰¯å¥½çš„æ€§è´¨, æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸‹é¢çš„è¿™ä¸¤ä¸ªåˆ†è§£:\n$$\\begin{aligned}\n \u0026A^\\mathrm{T} A= V \\Sigma_1 V^{\\mathrm{T}} \\\\\n \u0026A A^\\mathrm{T}=U \\Sigma_2 U^{\\mathrm{T}}\n\\end{aligned}$$\n- å…¶ä¸­$V,U$å‡ä¸ºæ­£äº¤çŸ©é˜µ, ä¸º$A^\\mathrm{T} A$å’Œ$AA^\\mathrm{T}$çš„ç‰¹å¾å‘é‡. \n\nå¦‚æœæˆ‘ä»¬å‡è®¾SVDè¿™ä¸ªåˆ†è§£æ˜¯æˆç«‹çš„, é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å¾—åˆ°å¦‚ä¸‹åˆ†è§£:\n$$\\begin{aligned}\n\u0026A^\\mathrm{T} A=(V \\Sigma^\\mathrm{T} U^\\mathrm{T})(U \\Sigma V^\\mathrm{T}) = V \\Sigma^2 V^\\mathrm{T} \\\\\n\u0026A A^\\mathrm{T}=(U \\Sigma V^\\mathrm{T})(V \\Sigma^\\mathrm{T} U^\\mathrm{T})=U \\Sigma^2 U^\\mathrm{T}\n\\end{aligned}$$\nå¯ä»¥çŒœæƒ³, ä¸Šä¸‹ä¸¤ä¸ªç­‰å¼çš„$V,U,\\Sigma$ éƒ½æ˜¯å¯¹åº”çš„, åé¢æˆ‘ä»¬å°†ä¼šè¯æ˜è¿™æ˜¯æˆç«‹çš„, å³:\n- SVDåˆ†è§£$A=U\\Sigma V^T$é‡Œé¢çš„\n\t- $V^T$çš„è¡Œå‘é‡æ˜¯$A^\\mathrm{T} A$çš„ç‰¹å¾å‘é‡, å®ƒä»¬orthonormal\n\t- $U$çš„åˆ—å‘é‡æ˜¯$AA^\\mathrm{T}$çš„ç‰¹å¾å‘é‡, å®ƒä»¬orthonormal\n\t- $\\sigma^2_1$ åˆ° $\\sigma^2_r$ æ˜¯ $A^TA$ ä¸ $AA^T$ çš„éé›¶ç‰¹å¾å€¼, åé¢ä¼šè¯¦ç»†å™è¿°.\n\næˆ‘ä»¬ä¸‹ä¸€æ­¥å°†è¯æ˜$A$å°†è¿™ä¸¤ç»„æ­£äº¤å‘é‡$U,V$ä¸€ä¸€è”ç³»èµ·æ¥, å³:\n$$A v_{k}=\\sigma_{k} u_{k}$$\n\nè§‚å¯Ÿæˆ‘ä»¬ä¸Šé¢çš„çŒœæƒ³, æˆ‘ä»¬å‡è®¾$\\sigma_{k}=\\sqrt{\\lambda_{k}}$, é€‰æ‹©$A^TA$å•ä½æ­£äº¤çš„ä¸€ç»„ç‰¹å¾å‘é‡$v_1, \\cdots v_r$\n- å› ä¸º$v_k$æ˜¯$A^\\mathrm{T} A$çš„ç‰¹å¾å‘é‡, æ‰€ä»¥æœ‰\n$$A^{\\mathbf{T}} A v_{k}=\\sigma_{k}^{2} v_{k}$$\n- æ ¹æ®è¯æ˜çš„ç›®æ ‡$A v_{k}=\\sigma_{k} u_{k}$, æˆ‘ä»¬æ„é€ \n$$u_{k}=\\frac{A v_{k}}{\\sigma_{k}}$$\n- ä¸‹é¢æˆ‘ä»¬åªéœ€è¦è¯æ˜$u_k$ä¹Ÿæ˜¯$A A^\\mathrm{T}$å•ä½æ­£äº¤çš„ç‰¹å¾å‘é‡å³å¯:\n\t- è¯æ˜æ˜¯ç‰¹å¾å‘é‡:\n\t$$AA^\\mathbf{T}\\boldsymbol{u}_{k}=\n\tAA^{\\mathrm{T}}\\left(\\frac{A\\boldsymbol{v}_{k}}{\\sigma_{k}}\\right)=\n\tA\\left(\\frac{A^\\mathrm{T}A \\boldsymbol{v}_{k}}{\\sigma_{k}}\\right)=\n\tA\\frac{\\sigma_{k}^{2} \\boldsymbol{v}_{k}}{\\sigma_{k}}=\n\t\\sigma_{k}^{2} \\boldsymbol{u}_{k}=\\lambda_k\\boldsymbol{u}_{k}$$\n\t- è¯æ˜å•ä½æ­£äº¤:\n\t\t$$\\boldsymbol{u}_{j}^{\\mathrm{T}} \\boldsymbol{u}_{k}=\\left(\\frac{A \\boldsymbol{v}_{j}}{\\sigma_{j}}\\right)^{\\mathrm{T}}\\left(\\frac{A \\boldsymbol{v}_{k}}{\\sigma_{k}}\\right)=\\frac{\\boldsymbol{v}_{j}^{\\mathrm{T}}\\left(A^{\\mathrm{T}} A \\boldsymbol{v}_{k}\\right)}{\\sigma_{j} \\sigma_{k}}=\\frac{\\sigma_{k}}{\\sigma_{j}} \\boldsymbol{v}_{j}^{\\mathrm{T}} \\boldsymbol{v}_{k}= \\begin{cases}1 \u0026 \\text { if } j=k \\\\ 0 \u0026 \\text { if } j \\neq k\\end{cases}$$\n\nå¦‚æœæˆ‘ä»¬è¯æ˜çš„æ˜¯ç¼©å‡å½¢å¼çš„SVD, é‚£ä¹ˆè¯æ˜å·²ç»ç»“æŸäº†, å¦‚æœè¯æ˜çš„æ˜¯ä¸€èˆ¬å½¢å¼çš„SVD, é‚£ä¹ˆéœ€è¦å°†çŸ©é˜µ$U, V$è¡¥å…¨:\n\n- å¯¹äº$V_{n\\times n}$æˆ‘ä»¬å¯ä»¥ä»$Null(A)$é‡Œé¢é€‰æ‹©ç›¸äº’æ­£äº¤çš„$n-r$ä¸ªå‘é‡$v_{r+1}, \\cdots v_n$æ¥è¡¥è¶³æ­£äº¤å‘é‡\n- å¯¹äº$U_{m\\times m}$æˆ‘ä»¬å¯ä»¥ä»$Null(A^T)$é‡Œé¢é€‰æ‹©ç›¸äº’æ­£äº¤çš„$m-r$ä¸ªå‘é‡$u_{r+1}, \\cdots u_m$æ¥è¡¥è¶³æ­£äº¤å‘é‡\n\nå› ä¸ºæ ¸ç©ºé—´$Null(A)$å’Œ$Row(A)$ç›¸äº’æ­£äº¤, $\\{v_1, \\cdots v_r\\}\\subset Row(A)$, $Null(A^T)$å’Œ$Col(A)$ç›¸äº’æ­£äº¤, $\\{u_1, \\cdots u_r\\}\\subset Col(A)$, æ‰€ä»¥è¡¥è¶³åçš„æ­£äº¤å‘é‡ä¾ç„¶ç›¸äº’æ­£äº¤.\n\nè¿™æ ·, æˆ‘ä»¬å°±è¯æ˜äº†SVD.\n\n\n## ä¸åŒçš„è§†è§’\n\n### è§†è§’ä¸€\n- $AV=U\\Sigma$è¯´æ˜äº†, Aå°†ä¸€ä¸ªæ­£äº¤åŸºåº•$V$æ˜ å°„åˆ°$U$, è€Œ$U$ä¾ç„¶æ˜¯æ­£äº¤çš„\n\n![](notes/2021/2021.11/assets/Pasted%20image%2020211115195835.png)\n\nè¿™ä¸ªè§†é¢‘çš„å¼€å¤´éƒ¨åˆ†æ¼”ç¤ºäº†è¿™ä¸ªè§†è§’:\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CpD9XlTu3ys\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n### è§†è§’äºŒ\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CpD9XlTu3ys?start=320\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\n### è§†è§’ä¸‰\n\n\u003e The eigenvectors give $AX = XA$. But $AV = U\\Sigma$: needs two sets of singular vectors.\n\n- Right Singular vectors in $V$ contains orthonormal eigenvectors of $A^T A$\n\t- å› ä¸º$A^T A$åœ¨Açš„Row Spaceé‡Œé¢, VåŒ…å«äº†Row(A)çš„ä¿¡æ¯\n- Left Singular vectors in $U$ contains orthonormal eigenvectors of $AA^T$\n\t- å› ä¸º$AA^T$åœ¨Açš„Column Spaceé‡Œé¢, UåŒ…å«äº†Col(A)çš„ä¿¡æ¯\n- $\\sigma_1^2$ to $\\sigma_r^2$ are the nonzero eigenvalues of both $A^T A$ and $AA^T$\n\t - å¥‡å¼‚å€¼åŒ…å«çš„ä¿¡æ¯åˆ™æ˜¯ä¸åŒç‰¹å¾å‘é‡çš„\"é‡è¦æ€§\"\n\n\n### è§†è§’ 3.5\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WmDnaoY2Ivs?start=246\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n[^5]\nä¸Šé¢è¿™ä¸ªè§†é¢‘çš„é‡ç‚¹æ˜¯:$AA^T$, $A^TA$æ˜¯æœ‰å®é™…å«ä¹‰çš„: **Correlation Matrix**\n- Uå’ŒVæ˜¯ä¸¤ä¸ªç›¸å…³çŸ©é˜µçš„ç‰¹å¾å€¼\n\n\n\n\n### è§†è§’å››\n- $U$: \"Eigen-Faces\"\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/nbBvuuNVfco?start=277\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- $V$: \"Eigen-Time\"/\"Eigen-Composition\"\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/nbBvuuNVfco?start=550\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n### è§†è§’äº”\n**Sum of Rank 1 Matrices**: Different Importance \n\n - Why is the SVD so important for this subject and this book? Like the other factorizations A = LU and A = QR and $S = Q\\Lambda Q^T$, it separates the matrix into rank one pieces.\n- A special property of the SVD is that those pieces come **in order of importance**.\n![](notes/2021/2021.11/assets/Pasted%20image%2020211116214859.png)\n- The first piece of $\\sigma_1 u_1 v_1^T$ is the closest rank one matrix to $A$. More than that is true: The sum of the first k pieces is best possible for rank k:\n$$A_{k}=\\sigma_{1} u_{1} v_{1}^{\\mathrm{T}}+\\cdots+\\sigma_{k} u_{k} v_{k}^{\\mathrm{T}}$$\n\n\u003e ![](notes/2021/2021.11/assets/Pasted%20image%2020211116215418.png)\n\nä¸‹é¢è¿™ä¸ªæ¼”ç¤ºä¹Ÿæ˜¯è¿™ä¸ªè§†è§’, è¿™æ˜¯PCAé‡Œé¢çš„ä¸»è¦è§†è§’\n[SVD Intuition](notes/2021/2021.11/SVD%20Intuition.md)\n\n\n\n\n## Example\n\n[[notes/2021/2021.11/A Fancy Example of SVD]]\n\n\n## More Illustrations\n[SVD Intuition](notes/2021/2021.11/SVD%20Intuition.md)\n- å…³äºSVDç½‘ä¸Šæœ‰å¾ˆå¤šå¾ˆæ£’çš„è®²è§£ä¸æ¼”ç¤º, è¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£ä¹Ÿå¾ˆé‡è¦çš„ä¸»é¢˜.\n\n\n\n\n\n\n\n\n[^1]: [Singular value - Wikipedia](https://en.wikipedia.org/wiki/Singular_value)\n[^2]: [Singular value decomposition - Wikipedia](https://en.wikipedia.org/wiki/Singular_value_decomposition)\n[^3]: [Podcast: Gilbert Strang's Feeling about Singular Value Decomposition - YouTube](https://www.youtube.com/watch?v=YPe5OP7Clv4)\n[^4]: What is the Singular Value Decomposition? - YouTube: https://youtu.be/CpD9XlTu3ys?t=182\n[^5]: Singular Value Decomposition (SVD): Dominant Correlations - YouTube: https://www.youtube.com/watch?v=WmDnaoY2Ivs\u0026list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv\u0026index=4","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/OS-11_%E4%B8%AD%E6%96%AD":{"title":"OS-11_ä¸­æ–­","content":"# ä¸­æ–­\n\n\u003cdiv align=\"right\"\u003e 2021-11-28\u003c/div\u003e\n\nTags: #OperatingSystem \n\n- æˆ‘è§‰å¾—æˆ‘å¯¹UNIXè¿›ç¨‹ç®¡ç†ä¸€ç›´è¿·è¿·ç³Šç³Šçš„åŸå› å°±æ˜¯è¿˜æ˜¯å¯¹ä¸­æ–­ä¸ä¸Šä¸‹æ–‡åˆ‡æ¢è¿·è¿·ç³Šç³Š, å­¦ä¹ çš„é¡ºåºæ²¡æœ‰ç†æ¸….\n\n- æˆ‘ä»¬æ¥é‡æ–°æ¢³ç†ä¸€ä¸‹:\n\n## ç¡¬ä»¶\n- UNIX v6++ å»ºç«‹åœ¨x86å¹³å°ä¸Šé¢, ä¸‹é¢çš„å™è¿°éƒ½æ˜¯åŸºäº x86 çš„\n\n### ä¸­æ–­æ§åˆ¶å™¨\n- ä¸­æ–­éœ€è¦ç¡¬ä»¶æ”¯æŒ, å³ä¸­æ–­æ§åˆ¶å™¨, ç”¨äºå¤„ç†**å¤–è®¾ä¸­æ–­**\n- ä¸­æ–­æ§åˆ¶å™¨ç›¸å½“äºCPUçš„ç§˜ä¹¦, å°†å„ç§å¤–è®¾å‘é€æ¥çš„ä¸­æ–­è¯·æ±‚æ±‡æ€»(è€ƒè™‘ä¼˜å…ˆçº§), ä¸€ä¸ªä¸€ä¸ªåœ°ä¼ ä¸ªCPUè¿›è¡Œå¤„ç†\n\n\t- åœ¨MIPSæ¶æ„é‡Œé¢, ä¸­æ–­å¤„ç†å™¨å¯¹åº”åå¤„ç†å™¨0, å³CP0\n\t\t[CP0_CoProcessor0_in_CPU](../../../1_Project/2021.6_CPU/CP0_CoProcessor0_in_CPU.md)\n\t- i386çš„ä¸­æ–­æ§åˆ¶å™¨ç”±ä¸¤ä¸ªä¸²è”çš„`8259A`èŠ¯ç‰‡æ„æˆ:\n\t![400](notes/2021/2021.11/assets/img_2022-10-15-44.png)\n\n- ä¸­æ–­æ§åˆ¶å™¨ä¿å­˜å½“å‰è¿›ç¨‹çš„ä¼˜å…ˆçº§, ä»¥æ­¤åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘é€æ–°çš„ä¸­æ–­è¯·æ±‚, è¿™ä¸ªä¼˜å…ˆçº§å­˜æ”¾åœ¨ä¸­æ–­æ§åˆ¶å™¨çš„\"å¤„ç†æœºä¼˜å…ˆçº§å¯„å­˜å™¨\"é‡Œé¢\n\n\t- MIPS é‡Œé¢ å¯¹åº”Statuså¯„å­˜å™¨: Status register\n\n\t- åœ¨i386é‡Œé¢å€’æ˜¯æ²¡æœ‰å•ç‹¬çš„å¤„ç†åŠä¼˜å…ˆçº§å¯„å­˜å™¨, è€Œæ˜¯ç”¨CSå¯„å­˜å™¨(ä»£ç æ®µå¯„å­˜å™¨, åœ¨CPUé‡Œé¢)çš„æœ€åä¸¤ä½ä»£è¡¨å½“å‰è¿›ç¨‹çš„ä¼˜å…ˆçº§(Current Privilege Level, CPL)\n\n### ä¸­æ–­æ§åˆ¶å™¨å¦‚ä½•ä¸CPUäº¤äº’?\n![](notes/2021/2021.11/assets/img_2022-10-15-45.png)\n\næ³¨æ„: \n- CPUéœ€è¦å›é€Acceptä¿¡å·(ACK)\n- CPUéœ€è¦å›é€ä¸­æ–­å®Œæˆçš„ä¿¡å·(EOI, End of Interrupt)\n- ä¸­æ–­æ§åˆ¶å™¨ä¹Ÿåœ¨å‘ç¡¬ä»¶å›é€ACKä¿¡å·\n\n\n## è½¯ä»¶\n### ä¸­æ–­æè¿°ç¬¦ / ä¸­æ–­é—¨\nä¸­æ–­é—¨å­˜æ”¾å¯¹ä¸­æ–­çš„æè¿°æ•°æ®: \n![](notes/2021/2021.11/assets/img_2022-10-15-46.png)\n\n- æ•°æ®å­˜åœ¨å“ªé‡Œ?\n\t- Offset Segment Selector\n- ä¸€äº›æ ‡å¿—ä½\n\t- DPL: Descriptor Privilege Level æè¿°ç¬¦ä¼˜å…ˆçº§\n\t- P: æ®µæ˜¯å¦åœ¨å†…å­˜ä¸­\n\t- ç­‰ç­‰\n\n#### How it works[^1]\n- CPU åœ¨ä¸­æ–­å‘ç”Ÿæ—¶å°† Segment Selector è£…å…¥CS å¯„å­˜å™¨ã€Offset è£…å…¥EIP å¯„å­˜å™¨ï¼Œè¿™æ ·å°±è·³è½¬åˆ°äº†ç›¸åº”çš„ä¸­æ–­å…¥å£ç¨‹åºã€‚\n- ç”±äºä¸­æ–­é—¨å’Œé™·å…¥é—¨ä¸­selector å­—æ®µçš„æœ€åä¸¤ä½ä¸º00, æ‰€ä»¥ä¸€æ—¦å°† selector è£…å…¥CSåï¼Œæ— è®ºä¸­æ–­å‘ç”Ÿå‰å¤„ç†å™¨å¤„åƒä½•ç§è¿è¡ŒçŠ¶æ€ï¼Œæ‰§è¡Œä¸­æ–­å¤„ç†ç¨‹åºæ—¶ï¼Œå¤„ç†å™¨å‡åœ¨æ ¸å¿ƒæ€è¿è¡Œã€‚\n\t- å‰é¢æåˆ°è¿‡, i386ä¸­, CSå¯„å­˜å™¨æœ€åä¸¤ä½ä½œä¸ºå¤„ç†æœºçŠ¶æ€å­—\n\n\n#### Interrupt Gate In UNIX v6++\n```c\n//src\\include\\IDT.h\n\n/* å®šä¹‰äº†IDTä¸­æ¯ä¸€ä¸ªé—¨æè¿°ç¬¦çš„æ ¼å¼ */\nstruct GateDescriptor\n{\n\tunsigned short\tm_Low16BitsOffset;\t\t/*OFFSETçš„ä½16ä½*/\n\tunsigned short\tm_SegmentSelector;\t\t/*æ®µé€‰æ‹©å­*/\n\tunsigned char\tm_Reserved : 5;\t\t\t/*ä¿ç•™åŒºåŸŸï¼Œé•¿5ä¸ªbit*/\n\tunsigned char\tm_Zero : 3;\t\t\t\t/*å…¨é›¶åŒºåŸŸ*/\n\tunsigned char\tm_Type : 4;\t\t\t/*æè¿°ç¬¦ç±»å‹.  0xEä¸ºä¸­æ–­é—¨  0xFä¸ºé™·å…¥é—¨*/\n\tunsigned char\tm_System : 1;\t\t/*1ï¼šç³»ç»Ÿæè¿°ç¬¦  0ï¼šä»£ç ã€æ•°æ®æ®µæè¿°ç¬¦*/\n\tunsigned char\tm_DPL : 2;\t\t\t\t\t/*æè¿°ç¬¦è®¿é—®ä¼˜å…ˆçº§*/\n\tunsigned char\tm_SegmentPresent : 1;\t\t/*å­˜åœ¨æ ‡å¿—ä½*/\n\tunsigned short\tm_High16BitsOffset;\t\t\t/*OFFSETçš„é«˜16ä½*/\n}__attribute__((packed));\n\n```\n### IDT ä¸­æ–­æè¿°ç¬¦è¡¨\nIDT: Interrupt Descriptor Table, é‡Œé¢å­˜æ”¾äº†æ‰€æœ‰çš„ä¸­æ–­, å¼‚å¸¸, ç³»ç»Ÿè°ƒç”¨æè¿°ç¬¦\n\n- ç³»ç»Ÿå¯åŠ¨åï¼Œ IDT å¸¸é©»å†…å­˜ï¼Œä½ç½®ä¸å˜ï¼Œå®ƒçš„åŸºåœ°å€å’Œé•¿åº¦ç™»è®°åœ¨ **CPU å†…**çš„IDTR å¯„å­˜å™¨ä¸­ã€‚\n\n#### IDTR \n![400](notes/2021/2021.11/assets/img_2022-10-15-47.png)\n\n- IDTR é•¿ 48 ä½: é«˜ 32 ä½ä¿å­˜IDTçš„**åŸºåœ°å€**ï¼Œä½ 16 ä½ä¿å­˜ IDT çš„**é•¿åº¦**\n\n```cpp\n//IDT.h\nstruct IDTR\n{\n\tunsigned short\tm_Limit;\t\t/* IDTçš„é™é•¿ */\n\tunsigned int\tm_BaseAddress;\t/* IDTçš„èµ·å§‹åœ°å€(çº¿æ€§åœ°å€) */\n}__attribute__((packed));\n```\n\n\n\n#### IDT in UNIX v6++\n\n![](notes/2021/2021.11/assets/img_2022-10-15-48.png)\n##### åˆå§‹åŒ–\n- IDTå¯¹è±¡æ˜¯Machineç±»é‡Œé¢çš„ç§æœ‰æˆå‘˜:\n```cpp\n//Machine.h\nclass Machine\n{\n...\npublic:\n\tvoid LoadIDT();\t\t/* æŠŠå»ºç«‹å¥½çš„IDTè¡¨çš„åŸºåœ°å€å’Œé•¿åº¦åŠ è½½è¿›IDTRå¯„å­˜å™¨ */\n\tvoid InitIDT();\n\tIDT\u0026 GetIDT();\t\t\t\t\t\t/* è·å–å½“å‰æ­£åœ¨ä½¿ç”¨çš„IDT */\nprivate:\n\tIDT* m_IDT;   /* è¿™é‡Œå®ä¾‹åŒ–äº†IDT */\n...\n```\n\n- åœ¨ç³»ç»Ÿå¯åŠ¨çš„æ—¶å€™, å®ä¾‹åŒ–Machineå¯¹è±¡, åŒæ—¶è°ƒç”¨`InitIDT`å°†IDTè¡¨åŠ è½½è¿›å†…å­˜, è°ƒç”¨`LoadIDT`å°†IDTåŸºåœ°å€å’Œé•¿åº¦åŠ è½½è¿›IDTRå¯„å­˜å™¨\n```cpp\n//main.cpp\nextern \"C\" int main0(void)\n{\n\tMachine \u0026machine = Machine::Instance();\n...\n\t//init idt\n\tmachine.InitIDT();\n\tmachine.LoadIDT();\n...\n```\n\n##### å¦‚ä½•åˆå§‹åŒ–IDTè¡¨\nåœ¨IDTç±»é‡Œé¢åªå®ç°äº†\"è®¾ç½®å•ä¸ªæè¿°ç¬¦\"çš„åŠŸèƒ½:\n```c\n//IDT.cpp\nvoid IDT::SetInterruptGate(int number, unsigned int handler)\n{\n\tthis-\u003em_Descriptor[number].m_Low16BitsOffset\t= handler;\n\tthis-\u003em_Descriptor[number].m_High16BitsOffset\t= handler\u003e\u003e16;\n\tthis-\u003em_Descriptor[number].m_SegmentSelector\t= 0x8;\n\tthis-\u003em_Descriptor[number].m_Reserved\t= 0;\n\tthis-\u003em_Descriptor[number].m_Zero\t\t= 0;\n\tthis-\u003em_Descriptor[number].m_System\t\t= 0;\n\tthis-\u003em_Descriptor[number].m_Type\t\t= 0xE;\t//ä¸­æ–­é—¨ï¼Œæ¸…IFä½\n\tthis-\u003em_Descriptor[number].m_DPL\t\t= 0x3;\n\tthis-\u003em_Descriptor[number].m_SegmentPresent\t= 1;\n}\nvoid IDT::SetTrapGate(int number, unsigned int handler)\n{\n...\t//å…¶ä»–çš„å’Œä¸Šé¢ä¸€æ ·\n\tthis-\u003em_Descriptor[number].m_Type\t\t= 0xF;\t//é™·å…¥é—¨ï¼Œä¸æ¸…IFä½\n...\t\n}\n```\n\n- `InitIDT`: IDTè¡¨çš„åˆå§‹åŒ–æ˜¯åœ¨Machineç±»é‡Œé¢å®ç°çš„:\n```c\n//machine.cpp\nvoid Machine::InitIDT()\n{\n\tthis-\u003em_IDT = \u0026g_IDT;\n\tfor (int i = 0; i \u003c= 255; i++)\n\t{\n\tif (i \u003c 32)\n\tthis-\u003eGetIDT().SetTrapGate(i, (unsigned long)IDT :: DefaultExceptionHandler);\n\telse\n\tthis-\u003eGetIDT().SetInterruptGate(i, (unsigned long)IDT :: DefaultInterruptHandler);\n\t}\n\t/* åˆå§‹åŒ–INT 0 - 31å·å¼‚å¸¸ */\n\tthis-\u003eGetIDT().SetTrapGate(0, (unsigned long)Exception::DivideErrorEntrance);\n\t...Sililar Code....\n\tthis-\u003eGetIDT().SetTrapGate(19, (unsigned long) Exception::SIMDExceptionEntrance);\n\tthis-\u003eGetIDT().SetInterruptGate(0x20, (unsigned long) Time::TimeInterruptEntrance);\n\tthis-\u003eGetIDT().SetInterruptGate(0x21, (unsigned long) KeyboardInterrupt::KeyboardInterruptEntrance);\n\tthis-\u003eGetIDT().SetInterruptGate(0x2E, (unsigned long) DiskInterrupt::DiskInterruptEntrance);\n\t/* 0x80å·ä¸­æ–­å‘é‡ä½œä¸ºç³»ç»Ÿè°ƒç”¨ï¼Œè®¾ç½®ç³»ç»Ÿè°ƒç”¨å¯¹åº”çš„é™·å…¥é—¨ */\n\tthis-\u003eGetIDT().SetTrapGate(0x80, (unsigned long)SystemCall::SystemCallEntrance);\n}\n```\næˆ‘ä»¬å•ç‹¬çœ‹å…¶ä¸­ä¸€é¡¹: \n```c\nthis-\u003eGetIDT().SetInterruptGate(0x21, (unsigned long) KeyboardInterrupt :: KeyboardInterruptEntrance);\n```\nå¯ä»¥çœ‹åˆ°, è¿™æ˜¯é”®ç›˜ä¸­æ–­, ä¸­æ–­å·æ˜¯0x21, ä¸­æ–­å…¥å£ç¨‹åºæ˜¯`KeyboardInterruptEntrance`:\n![](notes/2021/2021.11/assets/img_2022-10-15-49.png)\nåé¢ä¼šä»‹ç»ä¸€ä¸ªä¸­æ–­çš„å®Œæ•´æµç¨‹.\n\n- `LoadIDT`: å°†é•¿åº¦ä¸èµ·å§‹åœ°å€å­˜å…¥IDTR\n```c\nvoid Machine::LoadIDT()\n{\n\tIDTR idtr;\n\tGetIDT().FormIDTR(idtr);\n\tX86Assembly::LIDT((unsigned short *)(\u0026idtr));\n}\n```\n\n### ä¸­æ–­å¤„ç†\næˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„IDTè¡¨, ç°åœ¨æ¥çœ‹çœ‹ä¸€ä¸ªä¸­æ–­çš„å…·ä½“æµç¨‹æ˜¯ä»€ä¹ˆ.\n\n#### ä¸­æ–­éšæŒ‡ä»¤[^2]\n- CPUåœ¨æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ä¹‹å, é¦–å…ˆéœ€è¦ä½¿ç”¨IDTè¡¨, è¯»å–é‡Œé¢çš„ä¿¡æ¯. è¿™ä¸ªè¿‡ç¨‹æ˜¯ä¸­æ–­éšæŒ‡ä»¤è‡ªåŠ¨å®Œæˆçš„.\n- ä¸­æ–­éšæŒ‡ä»¤å…¶å®å¹¶ä¸æ˜¯æŒ‡ä»¤, è€Œæ˜¯ç”±ç¡¬ä»¶(CPU)è‡ªåŠ¨å®Œæˆçš„.\n- ä¸­æ–­éšæŒ‡ä»¤å®Œæˆäº†ä»\"CPUæ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·\"åˆ°\"è¿›å…¥ä¸­æ–­å…¥å£ç¨‹åº\"è¿™ä¸€æ®µçš„è½¬æ¢, åœ¨UNIX v6++é‡Œé¢æ²¡æœ‰è¿™ä¸€æ®µçš„ä»£ç , å› ä¸ºè¿™æ˜¯CPUç¡¬ä»¶å®Œæˆçš„å†…å®¹, ä¸æ˜¯æ“ä½œç³»ç»Ÿçš„å·¥ä½œ\n\n##### ä¸­æ–­éšæŒ‡ä»¤çš„è¿‡ç¨‹\n![400](notes/2021/2021.11/assets/img_2022-10-15-50.png)\n1. æŸ¥è¯¢IDT, è·å¾—ç›¸åº”ä¸­æ–­æºçš„ä¸­æ–­é—¨\n2. å…³ä¸­æ–­\n3. ç°åœºä¿æŠ¤\n\t- å°†å½“å‰ EFLAGS ã€CS å’Œ EIP å¯„å­˜å™¨çš„å€¼ä¾æ¬¡å‹å…¥æ ˆï¼ˆ å¦‚æœä¸­æ–­å‰ï¼Œè¿›ç¨‹è¿è¡Œåœ¨ç”¨æˆ·æ€ï¼Œè¿˜éœ€å‹å…¥ SS å’Œ ESP çš„å€¼ï¼‰\n\t- å¯¹äºä¼šäº§ç”Ÿå‡ºé”™ç çš„å¼‚å¸¸ï¼Œé™¤äº†å°†åŸºæœ¬çš„EFLAGS ã€CS ã€EIP å‹å…¥å †æ ˆä¹‹å¤–ï¼Œè¿˜ä¼šåœ¨åé¢å‹å…¥ä¸€ä¸ªErrorCode \n\t- ä¸­æ–­éšæŒ‡ä»¤ä¿å­˜çš„ç°åœºç§°ä¸º**ç¡¬ä»¶ç°åœº**\n4. è£…å…¥ä¸­æ–­æè¿°ç¬¦\n\t- å°†å–å¾—çš„ä¸­æ–­é—¨ä¸­çš„Segment Selector è£…å…¥CS, Offset è£…å…¥EIPã€‚ä¹‹åï¼ŒCPU å°†è½¬å…¥æ‰§è¡Œå„ç§ä¸­æ–­å…¥å£ç¨‹åº\n\n![](notes/2021/2021.11/assets/img_2022-10-15-51.png)\n\n### ä¸­æ–­å…¥å£ç¨‹åº Interrupt service routines (ISR)\n\n![](notes/2021/2021.11/assets/img_2022-10-15-52.png)\nä¸­æ–­å…¥å£ç¨‹åºè´Ÿè´£ä»¥ä¸‹åŠŸèƒ½:\n```\n1. SaveContext();\t\t\t\t/*ä¿å­˜ç°åœº*/\n2. SwitchToKernel();\t\t\t/*åˆ‡æ¢è‡³æ ¸å¿ƒæ€*/\n3. CallHandler(Class, Handler); /*è°ƒç”¨ä¸­æ–­ã€å¼‚å¸¸å¤„ç†å­ç¨‹åº*/\n(è¿™é‡Œå¯èƒ½æœ‰ä¾‹è¡Œè°ƒåº¦)\n4. RestoreContext(); \t\t\t/*æ¢å¤ç°åœº*/\n5. Leave(); \t\t\t\t\t/*æ‰‹å·¥æ’¤é”€æ ˆå¸§*/\n6. InterruptReturn();  \t\t\t/*ä¸­æ–­è¿”å›*/\n```\n\n- æ¯ä¸ªå­ç¨‹åºçš„å…·ä½“ä½œç”¨å‚è§å­¦æ ¡è®²ä¹‰, ä¸Šé¢æ¯”è¾ƒè¯¦ç»†\n- ä¸‹é¢æ˜¯è‡ªå·±è¡¥å……çš„è¯´æ˜:\n- å…¶ä¸­ç¬¬ä¸‰æ­¥`CallHandler(Class, Handler);`æ˜¯ä¸åŒä¸­æ–­åŒºåˆ«æœ€å¤§çš„åœ°æ–¹, ä¸åŒçš„ä¸­æ–­æ ¹æ®IDTè¡¨æœ‰ä¸åŒçš„ä¸­æ–­å¤„ç†å­ç¨‹åº.\n\n![](notes/2021/2021.11/assets/img_2022-10-15-53.png)\n#### æ¯”è¾ƒä¸åŒçš„ä¸­æ–­å…¥å£ç¨‹åº\n- ä»£ç : \n[æ¯”è¾ƒä¸åŒçš„ä¸­æ–­å…¥å£ç¨‹åº](notes/2021/2021.11/assets/æ¯”è¾ƒä¸åŒçš„ä¸­æ–­å…¥å£ç¨‹åº.cpp)\n- å¤–è®¾ä¸­æ–­éœ€è¦åœ¨ä¸­æ–­å¤„ç†å­ç¨‹åºè¿”å›åå‘é€EOIä¿¡å·, è¿™æ˜¯æœ€æ ‡å‡†çš„ä¸­æ–­æµç¨‹.\n- æ—¶é’Ÿä¸­æ–­çš„ç‰¹åˆ«ä¹‹å¤„åœ¨ä¸­æ–­å¤„ç†å­ç¨‹åºClocké‡Œé¢:\n\t- æ—¶é’Ÿä¸­æ–­å‘é€EOIåœ¨ä¸­æ–­å¤„ç†å­ç¨‹åºé‡Œé¢, å› ä¸ºæ—¶é’Ÿä¸­æ–­æœ‰ä¸€äº›å¾ˆè´¹æ—¶é—´çš„å·¥ä½œ, ä¸èƒ½ç­‰åˆ°è¿™äº›éƒ½å®Œæˆäº†æ‰ç»§ç»­æ¥å—ä¸­æ–­\n\t\t![](notes/2021/2021.11/assets/img_2022-10-15-54.png)\n- ç³»ç»Ÿè°ƒç”¨çš„ç‰¹åˆ«ä¹‹å¤„åªåœ¨ä¸­æ–­å¤„ç†å­ç¨‹åºTrapé‡Œé¢, å› ä¸ºç³»ç»Ÿè°ƒç”¨ä¸æ¶‰åŠå¤–è®¾, æ‰€ä»¥ä¸éœ€è¦å‘é€EOI\n- å¼‚å¸¸çš„ä¸­æ–­å…¥å£ç¨‹åºæœ€ä¸ºç‰¹åˆ«\n\t- é¦–å…ˆå¼‚å¸¸æ²¡æœ‰ä¾‹è¡Œè°ƒåº¦\n\t- å…¶æ¬¡å› ä¸ºå¼‚å¸¸çš„ä¸­æ–­éšæŒ‡ä»¤å¯èƒ½ä¼šå‹å…¥ErrorCode, æ‰€ä»¥åœ¨æ¢å¤ç°åœºçš„æ—¶å€™éœ€è¦è·³è¿‡ErrorCode.\n\t- ~~è¿˜æœ‰ä¸çŸ¥é“ä¸ºä»€ä¹ˆ,~~ Unix v6++é‡Œé¢çš„å¼‚å¸¸çš„å…¥å£ç¨‹åºéƒ½æ˜¯ç”¨å®å®šä¹‰çš„\n\t\t- Unix v6++é‡Œé¢ç”¨å®å®šä¹‰æ˜¯ä¸ºäº†ä¸€æ¬¡æ€§å®šä¹‰å¤§é‡çš„å…¥å£ç¨‹åº, è¿™æ ·æ¯”è¾ƒç®€æ´.\n\n#### ä¸­æ–­å¤„ç†æ—¶çš„ä¸­æ–­ä¿æŠ¤\n- ä¸­æ–­çš„ä¼˜å…ˆçº§å¤„ç†æ˜¯å®Œå…¨ç”±ä¸­æ–­æ§åˆ¶å™¨å†³å®šçš„, CPUä¸è€ƒè™‘è¿™ä¸ªé—®é¢˜\n\n- CPUåªæœ‰ä¸€ä¸ªIFæ ‡å¿—ä½, IFæ ‡å¿—ä½åœ¨EFLAGSå¯„å­˜å™¨é‡Œé¢, å®ƒæ§åˆ¶äº†CPUæ˜¯å¦æ¥å—æ–°çš„ä¸­æ–­\n\t- `IF==1`, è¡¨ç¤ºæ¥å—ä¸­æ–­(ä¸­æ–­å¼€), `IF==0`, è¡¨ç¤ºä¸æ¥å—ä¸­æ–­(ä¸­æ–­å…³)\n\t- CLI(CLear Interrupt)å°†æ ‡å¿—ä½æ¸…é›¶, è¡¨ç¤ºå…³ä¸­æ–­\n\t- STI(SeT Interrupt)å°†æ ‡å¿—ä½ç½®ä¸€, è¡¨ç¤ºå¼€ä¸­æ–­[^4]\n\n- é‡è¦æ€§: CPUçš„æ ‡å¿—ä½IF\u003eä¸­æ–­æ§åˆ¶å™¨çš„è¯·æ±‚\n\n- æ‰€ä»¥å¦‚æœä¸€ä¸ªä¸­æ–­Aåè·Ÿç€æ›´é«˜ä¼˜å…ˆçº§çš„ä¸­æ–­B, è€Œä¸­æ–­Aè¿˜æ²¡æœ‰å¼€ä¸­æ–­, é‚£ä¹ˆCPUä¸ä¼šç«‹å³å“åº”ä¸­æ–­B. \n\t- ä¸­æ–­çš„åµŒå¥—è¦åœ¨åŸå­æ“ä½œ(ä¸å¯åˆ†å‰²çš„æ“ä½œ)ä»¥å¤–è¿›è¡Œ, å³ä¸­æ–­Aå®ŒæˆåŸå­æ“ä½œä»¥å, å¼€ä¸­æ–­(STI), å†ç«‹å³å“åº”ä¸­æ–­B.\n\n- å…¶å®ä¸­æ–­è¿˜åˆ†ä¸ºmaskableå’ŒNon-maskableçš„ä¸­æ–­, IFæ ‡å¿—ä½åªå¯¹Maskableçš„æ ‡å¿—ä½æœ‰æ•ˆ, Non-Maskableçš„ä¸­æ–­ä¸€èˆ¬æ˜¯ä¸å¯æŒ½å›çš„ç¡¬ä»¶é”™è¯¯, è¦æ±‚ç«‹å³å“åº”.[^3]\n\n#### ä¸­æ–­åµŒå¥—çš„ä¸€äº›é—®é¢˜\n- ç°åœ¨å…³äºä¸­æ–­åµŒå¥—æœ‰ä¸€äº›çŸ›ç›¾çš„è¯´æ³•:\n\n##### The ideal way\n![](https://bbs-img.huaweicloud.com/data/forums/attachment/forum/202107/15/1636074zw5kme065cb89hp.png)\n1) å…³ä¸­æ–­ã€‚CPUå“åº”ä¸­æ–­åï¼Œé¦–å…ˆè¦ä¿æŠ¤ç¨‹åºçš„ç°åœºçŠ¶æ€ï¼Œåœ¨ä¿æŠ¤ç°åœºçš„è¿‡ç¨‹ä¸­ï¼ŒCPU ä¸åº”å“åº”æ›´é«˜çº§ä¸­æ–­æºçš„ä¸­æ–­è¯·æ±‚ã€‚å¦åˆ™ï¼Œè‹¥ç°åœºä¿å­˜ä¸å®Œæ•´ï¼Œåœ¨ä¸­æ–­æœåŠ¡ç¨‹åºç»“æŸåï¼Œä¹Ÿå°±ä¸èƒ½æ­£ç¡®åœ°æ¢å¤å¹¶ç»§ç»­æ‰§è¡Œç°è¡Œç¨‹åºã€‚\n\n2) ä¿å­˜æ–­ç‚¹ã€‚ä¸ºä¿è¯ä¸­æ–­æœåŠ¡ç¨‹åºæ‰§è¡Œå®Œæ¯•åèƒ½æ­£ç¡®åœ°è¿”å›åˆ°åŸæ¥çš„ç¨‹åºï¼Œå¿…é¡»å°†åŸæ¥çš„ç¨‹åºçš„æ–­ç‚¹ï¼ˆå³ç¨‹åºè®¡æ•°å™¨PCï¼‰ä¿å­˜èµ·æ¥ã€‚\n\n3) ä¸­æ–­æœåŠ¡ç¨‹åºå¯»å€ã€‚å…¶å®è´¨æ˜¯å–å‡ºä¸­æ–­æœåŠ¡ç¨‹åºçš„å…¥å£åœ°å€é€å…¥ç¨‹åºè®¡æ•°å™¨PCã€‚\n\n4) ä¿å­˜ç°åœºå’Œå±è”½å­—ã€‚è¿›å…¥ä¸­æ–­æœåŠ¡ç¨‹åºåï¼Œé¦–å…ˆè¦ä¿å­˜ç°åœºï¼Œç°åœºä¿¡æ¯ä¸€èˆ¬æ˜¯æŒ‡ç¨‹åºçŠ¶æ€å­—å¯„å­˜å™¨PSWRå’ŒæŸäº›é€šç”¨å¯„å­˜å™¨çš„å†…å®¹ã€‚\n\n5) å¼€ä¸­æ–­ã€‚å…è®¸æ›´é«˜çº§ä¸­æ–­è¯·æ±‚å¾—åˆ°å“åº”ã€‚\n\n6) æ‰§è¡Œä¸­æ–­æœåŠ¡ç¨‹åºã€‚è¿™æ˜¯ä¸­æ–­è¯·æ±‚çš„ç›®çš„ã€‚\n\n7) å…³ä¸­æ–­ã€‚ä¿è¯åœ¨æ¢å¤ç°åœºå’Œå±è”½å­—æ—¶ä¸è¢«ä¸­æ–­ã€‚\n\n8) æ¢å¤ç°åœºå’Œå±è”½å­—ã€‚å°†ç°åœºå’Œå±è”½å­—æ¢å¤åˆ°åŸæ¥çš„çŠ¶æ€ã€‚  \n\n9) å¼€ä¸­æ–­ã€ä¸­æ–­è¿”å›ã€‚ä¸­æ–­æœåŠ¡ç¨‹åºçš„æœ€åä¸€æ¡æŒ‡ä»¤é€šå¸¸æ˜¯ä¸€æ¡ä¸­æ–­è¿”å›æŒ‡ä»¤ï¼Œä½¿å…¶è¿”å›åˆ°åŸç¨‹åºçš„æ–­ç‚¹å¤„ï¼Œä»¥ä¾¿ç»§ç»­æ‰§è¡ŒåŸç¨‹åºã€‚  \n\n - å…¶ä¸­ï¼Œ1~3æ­¥æ˜¯åœ¨CPUè¿›å…¥ä¸­æ–­å‘¨æœŸåï¼Œç”±ç¡¬ä»¶è‡ªåŠ¨ï¼ˆä¸­æ–­éšæŒ‡ä»¤ï¼‰å®Œæˆçš„; 4~9æ­¥ç”±ä¸­æ–­æœåŠ¡ç¨‹åºå®Œæˆã€‚\n - æ¢å¤ç°åœºæ˜¯æŒ‡åœ¨ä¸­æ–­è¿”å›å‰ï¼Œå¿…é¡»å°†å¯„å­˜å™¨çš„å†…å®¹æ¢å¤åˆ°ä¸­æ–­å¤„ç†å‰çš„çŠ¶æ€ï¼Œè¿™éƒ¨åˆ†å·¥ä½œç”±ä¸­æ–­æœåŠ¡ç¨‹åºå®Œæˆã€‚\n - ä¸­æ–­è¿”å›ç”±ä¸­æ–­æœåŠ¡ç¨‹åºçš„æœ€åä¸€æ¡ä¸­æ–­è¿”å›æŒ‡ä»¤å®Œæˆã€‚[^5]\n\n##### Intel Manual[^6]\nåœ¨Intel Manualé‡Œé¢è¯´æ˜äº†ä»¥ä¸‹å‡ ç‚¹:\n- STI CLIåœ¨ä»…åœ¨CPL\u003c=IOPLçš„æ—¶å€™æ‰èƒ½ä½¿ç”¨:\n\t\u003e IOPLæ˜¯EFLAGSé‡Œé¢çš„ä¸¤ä¸ªä¿æŠ¤ä½, ç”¨äºä¿æŠ¤IO\n\t\u003e ![](notes/2021/2021.11/assets/img_2022-10-15-55.png) \n\n- IF ä¸­æ–­æ ‡å¿—ä½ä¼šè¢«ä»¥ä¸‹æ±‡ç¼–æŒ‡ä»¤å½±å“:\n\t- PUSHF, POPF, å°†EFLAGSå¯„å­˜å™¨çš„å€¼å­˜å…¥/å¼¹å‡ºæ ˆ\n\t- è¿›ç¨‹åˆ‡æ¢ä¼šåŠ è½½EFLAGSå¯„å­˜å™¨, æ‰€ä»¥å¯èƒ½æ”¹å˜IF\n\t- IRETæŒ‡ä»¤æ‰§è¡Œå’Œä¸­æ–­éšæŒ‡ä»¤ç›¸åçš„å†…å®¹, åŒ…æ‹¬å¼¹å‡ºå¹¶æ¢å¤ä¿å­˜çš„EFLAGSå¯„å­˜å™¨, æ‰€ä»¥ä¹Ÿå¯èƒ½æ”¹å˜IF\n\t- å½“Interruptæ˜¯é€šè¿‡**Interrupt Gate**å®ç°çš„æ—¶å€™, **IFæ ‡å¿—ä½ä¼šè¢«è‡ªåŠ¨æ¸…é›¶(å…³é—­maskableä¸­æ–­)**\n\t\t- ä¸æ­¤å¯¹åº”çš„æ˜¯, å¦‚æœä¸€ä¸ªä¸­æ–­æ˜¯é€šè¿‡**Trap Gate**å®ç°çš„æ—¶å€™, IFæ ‡å¿—ä½ä¸ä¼šè¢«è‡ªåŠ¨æ¸…é›¶\n\n- ä¸Šé¢è¿™ä¸€ç‚¹æ˜¯Interrupt Gateå’ŒTrap Gateçš„å”¯ä¸€åŒºåˆ«: \n\u003e - The only difference between an interrupt gate and a trap gate is the way the processor handles the **IF flag** in the EFLAGS register. \n\u003e - When accessing an exception- or interrupt-handling procedure through an **interrupt gate**, the processor **clears the IF flag** to prevent other interrupts from interfering with the current interrupt handler. \n\u003e - A subsequent **IRET** instruction **restores the IF flag** to its value in the saved contents of the EFLAGS register on the stack. \n\u003e - Accessing a handler procedure through a **trap gate does not affect the IF flag**.\n\nåœ¨Intelæ‰‹å†Œé‡Œé¢æ²¡æœ‰æåˆ°ä¸­æ–­åµŒå¥—çš„é—®é¢˜, æ ¹æ®ä¸Šé¢çš„å™è¿°, ä¸€ä¸ªInterrupt Gateå‘èµ·çš„ä¸­æ–­ä¸ä¼šè¢«å…¶ä»–ä¸­æ–­æŠ¢å .\n\n##### Linux Assembly Language Programming[^7] -  by Bob Neveln\n- 8086çš„è®¾è®¡ä½¿æˆ‘ä»¬èƒ½å¤Ÿç”¨ä¸€ç§éå¸¸ç®€å•çš„ç­–ç•¥æ¥é¿å…ä¸­æ–­ç›¸äº’å†²çªå¯¼è‡´çš„æ­»é”ä¸æ ˆæº¢å‡º. æˆ‘ä»¬å¯ä»¥åœ¨è¿è¡Œä¸­æ–­å…¥å£ç¨‹åº(ISR)ä¹‹å‰è‡ªåŠ¨å±è”½ä¸­æ–­(IF == 0), åœ¨ISRè¿è¡Œç»“æŸä»¥åå†ç»“æŸå±è”½ (æ¢å¤IFåŸæ¥çš„å€¼). \n- è¿™æ ·, å¯¹äºä¸¤ä¸ªè¿ç»­çš„ä¸­æ–­A, B, ä¸­æ–­æ§åˆ¶å™¨åªéœ€è¦ä¸€ç›´å‘CPUå‘é€ä¸­æ–­B, ç›´åˆ°ä¸­æ–­Bè¢«æ¥å—.\n- ä½†æ˜¯è¿™ç§ç­–ç•¥çš„æ•ˆç‡è¾ƒä½, è¾ƒä¸ºç¼“æ…¢çš„ç£ç›˜ä¸­æ–­ä¼šé˜»æŒ¡å…¶ä»–æ›´ä¸ºé‡è¦çš„ä¸­æ–­.\n- ä¸­æ–­åµŒå¥—å¯ä»¥è®©é«˜ä¼˜å…ˆçº§çš„ä¸­æ–­interruptä½ä¼˜å…ˆçº§çš„ä¸­æ–­, è¦å®ç°ä¸­æ–­çš„åµŒå¥—, CPUå’Œä¸­æ–­æ§åˆ¶å™¨éƒ½éœ€è¦é¢å¤–çš„å·¥ä½œ:\n\t- ISRéœ€è¦åœ¨ä¸€å¼€å§‹åˆ©ç”¨STIå°†CPUçš„IFä½ç½®ä¸º1, å¼€å¯ä¸­æ–­\n\t- ä¸­æ–­æ§åˆ¶å™¨éœ€è¦è¿›è¡Œä¸­æ–­çš„ä¼˜å…ˆçº§æ§åˆ¶, åªå‘CPUè½¬å‘æ¯”å½“å‰ä¸­æ–­ä¼˜å…ˆçº§æ›´é«˜çš„ä¸­æ–­\n\t- CPUéœ€è¦åœ¨ä¸€ä¸ªä¸­æ–­ç»“æŸçš„æ—¶å€™å‘ä¸­æ–­æ§åˆ¶å™¨å‘é€EOIæŒ‡ä»¤, å…è®¸è½¬å‘ç›¸åŒæˆ–æ›´ä½ä¼˜å…ˆçº§çš„ä¸­æ–­.\n\n##### Interrupts - Stonely Brook University Slide[^8]\nInterrupt - Slide(@nim04interruptsStonely)\n- ä¸­æ–­ä¸åº”è¯¥è¢«å±è”½, æ‰€ä»¥Trap Gateè¿›å…¥çš„æ—¶å€™ä¸åº”è¯¥å…³é—­IF\n\n##### todo\n- çœ‹Lionsé‡Œé¢åŸæ¥çš„æ˜¯æ€ä¹ˆå†™çš„\n- åŠ äº†STIè¯•è¯•\n\t- åŠ äº†è¿˜æ˜¯å¯ä»¥æ­£å¸¸è¿è¡Œ, è‡³å°‘é”®ç›˜ä¸­æ–­æ˜¯è¿™æ ·\n- EOIåœ¨ä¸­æ–­å­ç¨‹åºä¹‹å‰?\n\n\n#### ä¸­æ–­å¤„ç†å­ç¨‹åºç»“æŸä»¥å\n\n\n\n- å€¼å¾—æ³¨æ„çš„æ˜¯, EOI\n\n\nä¸€ä¸ªå®Œæ•´çš„ä¾‹å­;\n[Basic x86 interrupts | There is no magic here](https://alex.dzyoba.com/blog/os-interrupts/#x86%20interrupts)\n\n\n[^1]: æœ¬ç¬”è®°é‡Œé¢Unix v6++ç›¸å…³çš„å†…å®¹å‡ä¸ºåŒæµå¤§å­¦æ“ä½œç³»ç»Ÿè¯¾ç¨‹ç›¸å…³èµ„æ–™\n[^2]: æ‰¾äº†åŠå¤©ä¹Ÿæ²¡æœ‰æ‰¾åˆ°ä¸­æ–­éšæŒ‡ä»¤çš„è‹±æ–‡å¯¹åº”è¯, è®¸å¤šèµ„æ–™éƒ½åªæ˜¯æŠŠå®ƒå½“ä½œäº† Interrupt service routines (ISR)ä¹‹å‰çš„ä¸€æ­¥, æ²¡æœ‰å…·ä½“è¯´æ˜.\n[^3]: [Non-maskable interrupt - Wikipedia](https://en.wikipedia.org/wiki/Non-maskable_interrupt)\n[^4]: [Interrupt flag - Wikipedia](https://en.wikipedia.org/wiki/Interrupt_flag)\n[^5]: [æˆ‘ä»¬å¸¸è¯´çš„ä¸­æ–­å’Œå¼‚å¸¸åˆ°åº•æ˜¯ä»€ä¹ˆ_AltlasClub_HEROè”ç›Ÿ](https://developer.huaweicloud.com/hero/thread-140036-1-1.html) è¿™é‡Œæ‰€è¯´çš„ä¸­æ–­æœåŠ¡ç¨‹åºå³å‰æ–‡ä¸­çš„ä¸­æ–­å…¥å£ç¨‹åº, ä¹Ÿå³ISR: Interrupt Service Routine\n[^6]: 64-ia-32-architectures-software-developer-vol-3a-part-1-manual \n[^7]: Linux Assembly Language Programming (Open Source Technology Series) by Bob Neveln\n[^8]: - Nima Honarmand","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/Part.30_Dimensionality_ReductionML_Andrew.Ng.":{"title":"Part.30_Dimensionality_Reduction(ML_Andrew.Ng.)","content":"# Dimensionality Reduction - é™ç»´\n\n\u003cdiv align=\"right\"\u003e 2021-11-11\u003c/div\u003e\n\nTags: #MachineLearning #DimensionalityReduction\n\n## Motivation\n![](notes/2021/2021.11/assets/img_2022-10-15-56.png)\n### Data Compression\nå°†æ•°æ®ç»´æ•°å‡å°‘å, å¯ä»¥èŠ‚çº¦å­˜å‚¨æ•°æ®çš„ç©ºé—´\n\n### Visualization\né«˜ç»´æ•°æ®é™ç»´åæ‰èƒ½å¯è§†åŒ–, è€Œå¯è§†åŒ–æœ‰åŠ©äºæˆ‘ä»¬ç†è§£é«˜ç»´æ•°æ®çš„å†…åœ¨å«ä¹‰.\n\n## Principal Component Analysis\n[[notes/2021/2021.11/Part.31_Principal_Component_Analysis(ML_Andrew.Ng.)]]\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/Part.31_Principal_Component_AnalysisML_Andrew.Ng.":{"title":"Part.31_Principal_Component_Analysis(ML_Andrew.Ng.)","content":"# Principal Component Analysis - ä¸»æˆåˆ†åˆ†æ\n\n\u003cdiv align=\"right\"\u003e 2021-11-11\u003c/div\u003e\n\nTags: #MachineLearning #DimensionalityReduction #PCA\n\n## åŸºæœ¬æ­¥éª¤\n### Step 0 - Data Preprocessing\n- [Normalization å½’ä¸€åŒ–](notes/2021/2021.8/Part.7_Feature_Scaling(ML_Andrew.Ng.).md#Normalization%20å½’ä¸€åŒ–)\n- [Standardization æ ‡å‡†åŒ–](notes/2021/2021.8/Part.7_Feature_Scaling(ML_Andrew.Ng.).md#Standardization%20æ ‡å‡†åŒ–)\n\n[PCAä¾èµ–äºæ¬§æ°è·ç¦»](notes/2021/2021.8/Part.7_Feature_Scaling(ML_Andrew.Ng.).md#^375f2a), æ‰€ä»¥é¢„å¤„ç†æ•°æ®å¯ä»¥è®©é™ç»´æ•ˆæœæ›´å¥½.\n\n### Step 1 - Compute the Covariance Matrix\n$$\\Sigma=\\frac{1}{m} \\sum_{i=1}^{n}\\left(x^{(i)}\\right)\\left(x^{(i)}\\right)^{T}$$\n\n### Step 2 - Compute Eigenvectors of Matrix $\\Sigma$\n- Using Singular Value Decomposition\n- `[U,S,V] = svd(Sigma);`\n- We need to use\n\t $$U=\\left[\\begin{array}{cccc}\n\\mid \u0026 \\mid \u0026 \u0026 \\mid \\\\\nu^{(1)} \u0026 u^{(2)} \u0026 \\ldots \u0026 u^{(n)} \\\\\n\\mid \u0026 \\mid \u0026 \u0026 \\mid\n\\end{array}\\right] \\in \\mathbb{R}^{n \\times n}$$\n\n### Step 3 - Mapping the Data\n- å–å‡º$U$é‡Œé¢çš„å‰$k$ä¸ªç‰¹å¾å‘é‡:\n \t$$\\left[\\begin{array}{cccc}\n\t\\mid \u0026 \\mid \u0026 \u0026 \\mid \\\\\n\tu^{(1)} \u0026 u^{(2)} \u0026 \\ldots \u0026 u^{(k)} \\\\\n\t\\mid \u0026 \\mid \u0026 \u0026 \\mid\n\t\\end{array}\\right] \\in \\mathbb{R}^{n \\times k}$$\n\t- è¿™å°±æ˜¯æˆ‘ä»¬çš„æŠ•å½±çŸ©é˜µ \n\n- å•ä¸ªæ•°æ®ç‚¹çš„æŠ•å½±:\n\t$$z^{(i)}=\\left[\\begin{array}{cccc}\n\t\\mid \u0026 \\mid \u0026 \u0026 \\mid \\\\\n\tu^{(1)} \u0026 u^{(2)} \u0026 \\ldots \u0026 u^{(k)} \\\\\n\t\\mid \u0026 \\mid \u0026 \u0026 \\mid\n\t\\end{array}\\right]^{T} x^{(i)}_{n \\times 1}=\\left[\\begin{array}{c}\n-\\left(u^{(1)}\\right)^T- \\\\\n\\vdots \\\\\n-\\left(u^{(k)}\\right)^T-\n\\end{array}\\right]_{k \\times n}x^{(i)}_{n \\times 1}$$\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/Quid-pro-quo-Latin-Phrase":{"title":"Quid pro quo - Latin Phrase","content":"# Quid pro quo \n\n\u003cdiv align=\"right\"\u003e 2021-11-11\u003c/div\u003e\n\nTags: #Latin #English \n\n- **Quid pro quo** ('what for what' in Latin) is a Latin phrase used in English to mean an exchange of goods or services, in which one transfer is contingent upon the other; \"a favor for a favor\". \n- Phrases with similar meanings include: \"give and take\", \"tit for tat\", \"you scratch my back, and I'll scratch yours\", and \"one hand washes the other\". \n\nSource: [Quid pro quo - Wikipedia](https://en.wikipedia.org/wiki/Quid_pro_quo)","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/Roll-Pitch-Yaw":{"title":"Roll-Pitch-Yaw","content":"# Roll Pitch \u0026 Yaw\n\n\u003cdiv align=\"right\"\u003e 2021-11-14\u003c/div\u003e\n\nTags: #English\n\n![400](notes/2021/2021.11/assets/img_2022-10-15-57.png)\n\nä¸‰ç»´ç©ºé—´é‡Œé¢çš„ä¸‰ä¸ªæ—‹è½¬æ–¹å‘\n\n[Roll, Pitch, and Yaw | How Things Fly](https://howthingsfly.si.edu/flight-dynamics/roll-pitch-and-yaw)\n\n![pitch-roll-yaw_0](notes/2021/2021.11/assets/img_2022-10-15.gif)","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/SVD-Intuition":{"title":"SVD Intuition","content":"## Section 1\n\n![](notes/2021/2021.11/assets/img_2022-10-15-58.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-59.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-60.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-61.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-62.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-63.png)\nSource:\n\n- [Singular Value Decomposition (SVD) and Image Compression - YouTube](https://www.youtube.com/watch?v=DG7YTlGnCEo\u0026t=693s)\n\nThe Notebook in the link below is a good demonstration of what each rank 1 matrices represents:\n[GitHub - singular_value_decomposition](https://github.com/luisguiserrano/singular_value_decomposition)\n![](notes/2021/2021.11/assets/img_2022-10-15-64.png)\n![](notes/2021/2021.11/assets/img_2022-10-15-65.png)\n\n## Section 2\n\n[Podcast: Gilbert Strang's Feeling about Singular Value Decomposition - YouTube](https://www.youtube.com/watch?v=YPe5OP7Clv4)\n","lastmodified":"2023-11-19T19:19:33.850462864Z","tags":null},"/notes/2021/2021.11/et-al.":{"title":"et al.","content":"# et al.\n\n\u003cdiv align=\"right\"\u003e 2021-11-30\u003c/div\u003e\n\nTags: #Latin \n\n    And others; to complete a list, especially of persons, as authors of a published work.\n\n\n- From Latin, abbreviation of et aliÄ« (â€œand othersâ€)\n\n## Usage notes\n- Formally preferred by some over `etc.` for lists of people in all contexts, reserving etc. for lists of things (inanimate objects); the distinction is sometimes ignored in casual use, and the two abbreviations are used synonymously in many contexts for completing lists except in very careful or formal use. However, in lists of authors of a published work, et al. is still regularly used.","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.11/somebody-is-golden":{"title":"somebody is golden","content":"# somebody is golden\n\n\u003cdiv align=\"right\"\u003e 2021-11-13\u003c/div\u003e\n\nTags: #\n\n\n- `informal` \n- used to say that someone is in a very good situation and is likely to be successful \n\nIf the right editor looks at your article, youâ€™re golden.\n\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/k095NdrHxY4?start=313\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1-Parameter_Estimation":{"title":"å‚æ•°ä¼°è®¡-Parameter_Estimation","content":"# å‚æ•°ä¼°è®¡\n\n\u003cdiv align=\"right\"\u003e 2021-12-25\u003c/div\u003e\n\nTags: #MachineLearning #ParameterEstimation #Math/Statistics \n\n- åœ¨è®¾è®¡åˆ†ç±»å™¨æˆ–è€…è¿›è¡Œå›å½’é¢„æµ‹çš„æ—¶å€™, æˆ‘ä»¬éœ€è¦çŸ¥é“ç›®æ ‡é—®é¢˜çš„æ¦‚ç‡åˆ†å¸ƒæƒ…å†µ. ä½†æ˜¯é€šå¸¸æˆ‘ä»¬èƒ½å¾—åˆ°çš„æ•°æ®åªæ˜¯ä¸€äº›ç‰¹ä¾‹(å³è®­ç»ƒæ ·æœ¬). ä¸ºäº†å¯¹é—®é¢˜è¿›è¡Œå»ºæ¨¡, æˆ‘ä»¬ä¸ä»…éœ€è¦ç¡®å®šåˆé€‚çš„æ¦‚ç‡åˆ†å¸ƒæ¨¡å‹, è¿˜éœ€è¦æ ¹æ®è®­ç»ƒæ ·æœ¬ç¡®å®šæ¨¡å‹é‡Œé¢çš„å…·ä½“å‚æ•°. å‚æ•°ä¼°è®¡å°±æ˜¯åœ¨æ¨¡å‹å·²çŸ¥çš„æƒ…å†µä¸‹å¾—åˆ°æœ€ä¼˜å‚æ•°çš„è¿‡ç¨‹.\n\n\n- å¯¹äºè´å¶æ–¯åˆ†ç±»å™¨, ä¼°è®¡å…ˆéªŒæ¦‚ç‡$P(\\omega_i)$é€šå¸¸ä¸æ˜¯å¾ˆå›°éš¾. éš¾ç‚¹åœ¨äºä¼°è®¡ç±»æ¡ä»¶æ¦‚ç‡å¯†åº¦$p(x|\\omega_i)$, è¿™æ˜¯å› ä¸º: \n\t- åœ¨å¾ˆå¤šæƒ…å†µä¸‹, æˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„æ ·æœ¬\n\t- åœ¨è¡¨ç¤ºç‰¹å¾çš„å‘é‡$x$ç»´æ•°è¾ƒå¤§çš„æƒ…å†µä¸‹, è®¡ç®—å¤æ‚åº¦å¾ˆé«˜.\n\n- ç›®å‰æ¯”è¾ƒå¸¸ç”¨çš„å‚æ•°ä¼°è®¡æ–¹æ³•æœ‰æå¤§ä¼¼ç„¶ä¼°è®¡(Maximum LIkelihood Estimation)å’Œè´å¶æ–¯ä¼°è®¡(Bayesian Estimation).\n\n\t- [Maximum_Likelihood_Estimation-æå¤§ä¼¼ç„¶ä¼°è®¡](notes/2021/2021.12/Maximum_Likelihood_Estimation-æå¤§ä¼¼ç„¶ä¼°è®¡.md)\n\n\n\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.12/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83-Mutivariate_Gaussian":{"title":"å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ-Mutivariate_Gaussian","content":"# Multivariate Gaussian\n\n\u003cdiv align=\"right\"\u003e 2021-12-24\u003c/div\u003e\n\nTags: #GaussianDistribution #Math/Probability \n\n[æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution](notes/2021/2021.9/æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution.md)\n\n$$p(x ; \\mu, \\Sigma)=\\frac{1}{(2 \\pi)^{n / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}(x-\\mu)^{T} \\Sigma^{-1}(x-\\mu)\\right)$$\n\n- å…¶ä¸­$\\Sigma$æ˜¯éšæœºå‘é‡$X$çš„åæ–¹å·®çŸ©é˜µ, å¯ä»¥è¯æ˜: $\\Sigma$ä¸€å®šæ˜¯å¯¹ç§°çš„æ­£å®šçŸ©é˜µ.\n\n---\n---\n\nå…³äºå¤šå…ƒé«˜æ–¯åˆ†å¸ƒæœ‰å¾ˆå¤šå¾ˆå¥½çš„èµ„æ–™:\n- CS229çš„Lecture Note\n- [CS229: Machine Learning](https://cs229.stanford.edu/syllabus.html)\n- çŸ©é˜µæ±‚å¯¼çš„é‚£ä¸ªPDFé‡Œé¢ä¹Ÿæœ‰å¾ˆå¥½çš„æ¨å¯¼è¿‡ç¨‹\n- è¿™ä¸¤ä¸ªé“¾æ¥:\n\t- [ææ‡‚å¤šç»´é«˜æ–¯åˆ†å¸ƒçš„ç”±æ¥ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/39763207)\n\t- [å¤šå…ƒé«˜æ–¯åˆ†å¸ƒå®Œå…¨è§£æ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/58987388)\n\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.12/%E6%96%B9%E5%B7%AE%E7%9A%84%E6%80%A7%E8%B4%A8":{"title":"æ–¹å·®çš„æ€§è´¨","content":"\n\n- $$\\begin{aligned}\n\\operatorname{Var}(X)\n\u0026=\\mathrm{E}\\left[X^{2}-2 X \\mathrm{E}[X]+(\\mathrm{E}[X])^{2}\\right]\\\\\n\u0026=\\mathrm{E}\\left[X^{2}\\right]-2 \\mathrm{E}[X] \\mathrm{E}[X]+(\\mathrm{E}[X])^{2}\\\\\n\u0026=\\mathrm{E}\\left[X^{2}\\right]-(\\mathrm{E}[X])^{2}\n\\end{aligned}$$\n\nä¸Šè¿°çš„è¡¨ç¤ºå¼å¯è®°ä¸º\"å¹³æ–¹çš„æœŸæœ›å‡æ‰æœŸæœ›çš„å¹³æ–¹\"ã€‚\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.12/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E7%9A%84%E5%88%A4%E5%88%AB%E5%87%BD%E6%95%B0":{"title":"æ­£æ€åˆ†å¸ƒçš„åˆ¤åˆ«å‡½æ•°","content":"# Discriminant Function of Gaussian\n\n\u003cdiv align=\"right\"\u003e 2021-12-24\u003c/div\u003e\n\nTags: #MachineLearning #DiscriminantFunction #GaussianDistribution \n\n\u003e ä¸‹é¢æ˜¯å­¦ä¹ Dudaæ¨¡å¼åˆ†ç±»ç¬¬äºŒç« åšçš„ç®€å•çš„ç¬”è®°, æœ‰æ—¶é—´åº”è¯¥è¿›ä¸€æ­¥æ¢³ç†\n\né«˜æ–¯åˆ†å¸ƒçš„åˆ¤åˆ«å‡½æ•°(è´å¶æ–¯åˆ†ç±»å™¨)çš„ä¸€ä¸ªå¸¸è§å½¢å¼æ˜¯æŠŠBayeså®šç†çš„åˆ†å­å–ä¸‹æ¥, å†å–å¯¹æ•°.\n\nå³ä»¥ä¸‹å½¢å¼:\n$$g_{i}(\\mathbf{x})=\\ln p\\left(\\mathbf{x} \\mid \\omega_{i}\\right)+\\ln P\\left(\\omega_{i}\\right)$$\n\nå¦‚æœåéªŒæ¦‚ç‡$p\\left(\\mathrm{x} \\mid \\omega_{i}\\right) \\sim N\\left(\\boldsymbol{\\mu}_{i}, \\boldsymbol{\\Sigma}_{i}\\right)$, é‚£ä¹ˆå°†å¤šå…ƒé«˜æ–¯åˆ†å¸ƒçš„å…¬å¼å¸¦è¿›å»å¯ä»¥å¾—åˆ°:\n[å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ-Mutivariate_Gaussian](notes/2021/2021.12/å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ-Mutivariate_Gaussian.md)\n\n$$g_{i}(\\mathrm{x})=-\\frac{1}{2}\\left(\\mathrm{x}-\\mu_{i}\\right)^{t} \\Sigma_{i}^{-1}\\left(\\mathrm{x}-\\mu_{i}\\right)-\\frac{d}{2} \\ln 2 \\pi-\\frac{1}{2} \\ln \\left|\\Sigma_{i}\\right|+\\ln P\\left(\\omega_{i}\\right)$$\n\nåé¢ä¹¦ä¸Šåˆ†ä¸‰ä¸ªæƒ…å†µ,ç”±ç‰¹æ®Šåˆ°ä¸€èˆ¬, åˆ†åˆ«è¯´æ˜äº†\n- $\\Sigma_{i}=\\sigma^{2} \\mathbf{I}$ : ç©ºé—´é‡Œé¢åˆ†å¸ƒç€å¤§å°ç›¸åŒçš„çƒçƒ\n- $\\Sigma_{i}=\\Sigma$: ç©ºé—´é‡Œé¢åˆ†å¸ƒç€å¤§å°ç›¸åŒçš„æ¤­çƒ\n- $\\Sigma=$ä»»æ„\n\nä¸‰ç§æƒ…å†µä¸‹åˆ¤åˆ«å‡½æ•°çš„æ ·å­ä¸ä½ç½®:\nå‰ä¸¤ç§æƒ…å†µéƒ½æ˜¯çº¿æ€§çš„, ä½†æ˜¯å¯èƒ½ä¸è¿‡ä¸­ç‚¹(è¿˜è¦çœ‹å…ˆéªŒæ¦‚ç‡)\nç¬¬ä¸‰ç§æƒ…å†µåˆ¤åˆ«å‡½æ•°æ˜¯ä»»æ„äºŒæ¬¡å‹\n\nåˆ†æçš„è¿‡ç¨‹å°±æ˜¯æŠŠå¼å­å±•å¼€, åˆ†åˆ«çœ‹å“ªä¸ªéƒ¨åˆ†æ˜¯å’Œiæ— å…³çš„.\n\n\n\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.12/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E6%9C%9F%E6%9C%9B":{"title":"éšæœºå˜é‡å‡½æ•°çš„æœŸæœ›","content":"ä¸€èˆ¬çš„è¯´ï¼Œä¸€ä¸ªéšæœºå˜é‡çš„å‡½æ•°çš„æœŸæœ›å€¼å¹¶ä¸ç­‰äºè¿™ä¸ªéšæœºå˜é‡çš„æœŸæœ›å€¼çš„å‡½æ•°ã€‚\n$$\n\\mathrm{E}(g(X))=\\int_{\\Omega} g(x) f(x) \\mathrm{d} x \\neq g(\\mathrm{E}(X))\n$$\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.12/Bayesian-Decision-Theory-Part1":{"title":"Bayesian Decision Theory - Part1","content":"# è´å¶æ–¯å†³ç­–è®º - Part1\n\n\u003cdiv align=\"right\"\u003e 2021-12-21\u003c/div\u003e\n\nTags: #MachineLearning #Bayes \n\n- è´å¶æ–¯å†³ç­–å…¶å®å°±æ˜¯æŠŠç”Ÿæ´»ä¸­æˆ‘ä»¬åŸºäºç›´è§‰å’Œå¸¸è¯†çš„å†³ç­–æ–¹æ³•å½¢å¼åŒ–äº†, å¹¶åŠ ä»¥è¿›ä¸€æ­¥åœ°æ¨å¹¿.\n- è´å¶æ–¯å†³ç­–ç»¼åˆè€ƒé‡æ¯ç§æƒ…å†µçš„æ¦‚ç‡å’Œå†³ç­–å¸¦æ¥çš„ä»£ä»·.\n- è´å¶æ–¯å†³ç­–å‡è®¾é—®é¢˜å¯ä»¥ç”¨æ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼æ¥åˆ»ç”», å±äºè´å¶æ–¯å­¦æ´¾çš„ä¸€ç§æ–¹æ³•.\n\n## Intro\n### A Sad Case\n- å‡å¦‚åœ£è¯è€äººæ‰“åŒ…äº†100ç›’ç³–æœ, å…¶ä¸­20ç›’æ˜¯å·§å…‹åŠ›($\\omega_1$), 80ç›’æ˜¯æ°´æœç¡¬ç³–($\\omega_2$), ç°åœ¨ä»–ä»é‡Œé¢éšæœºæŒ‘äº†ä¸€ç›’ç»™å°ä¼é¹…, ç›’å­çš„é¢œè‰²å’Œé‡é‡éƒ½ä¸€æ ·, é‚£ä¹ˆå°ä¼é¹…å¾—åˆ°çš„æ˜¯å·§å…‹åŠ›è¿˜æ˜¯æ°´æœç¡¬ç³–å‘¢?\n\t- å¦‚æœæˆ‘ä»¬çŒœå¯¹äº†, å°±å¯ä»¥å¾—åˆ°ä¸€ç›’ç³–æœ!\n- å› ä¸ºæˆ‘ä»¬åªçŸ¥é“ä¸åŒç¤¼ç‰©çš„æ¯”ä¾‹, ä¹Ÿå°±æ˜¯$P(\\omega_1)=0.2, P(\\omega_2)=0.8$, æ‰€ä»¥ä¸ºäº†ä½¿æ­£ç¡®çš„æ¦‚ç‡æœ€å¤§, æˆ‘ä»¬åº”è¯¥çŒœç¤¼ç‰©æ˜¯ $\\omega_2$.\n- ä½†æ˜¯è¦æ˜¯åœ£è¯è€äººè¦ç»™æ•´ä¸ªå—ææ´²çš„ä¼é¹…æ¯äººä¸€ä¸ªç¤¼ç‰©å‘¢? å¦‚æœæˆ‘ä»¬ä¸€ç›´çŒœ, ä¸ºäº†è·å¾—æ›´å¤šçš„ç³–æœ, æˆ‘ä»¬åªèƒ½ä¸€ç›´çŒœç¤¼ç‰©æ˜¯ $\\omega_2$ ! è¿™æ˜¾ç„¶å¤ªå‚»äº†.\n\n### More Information\n- å¹¸è¿çš„æ˜¯, æˆ‘ä»¬å‘ç°äº†è§„å¾‹, åœ£è¯è€äººä¼šæ ¹æ®å°ä¼é¹…çš„ä½“é‡($x$)æ¥å‘æ”¾ä¸åŒçš„ç¤¼ç‰©, è¶Šèƒ–çš„å°ä¼é¹…è¶Šä¸å®¹æ˜“å¾—åˆ°å·§å…‹åŠ›($\\omega_1$).\n- å‡è®¾æˆ‘ä»¬ç»™æ‰€æœ‰å·²ç»æœ‰äº†ç¤¼ç‰©çš„å°ä¼é¹…éƒ½ç§°äº†ä¸€éä½“é‡, å¹¶ä¸”å·å·çœ‹äº†å®ƒä»¬çš„ç¤¼ç‰©æ˜¯ä»€ä¹ˆ. ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†\"æœºå¯†\": ä¸åŒç¤¼ç‰©å°ä¼é¹…çš„ä½“é‡åˆ†å¸ƒæƒ…å†µ$P(x\\mid \\omega_i)$\n- æˆ‘ä»¬åˆä»å®˜æ–¹æ‰‹å†Œä¸ŠæŸ¥åˆ°äº†å°ä¼é¹…çš„ä½“é‡åˆ†å¸ƒæƒ…å†µ$P(x)$.\n- ç°åœ¨åœ£è¯è€äººåˆæ¥ç»™å°ä¼é¹…å‘ç³–æœäº†! ä½†æ˜¯ç°åœ¨æˆ‘ä»¬å¯ä»¥å…ˆå·å·ç»™å°ä¼é¹…ç§°ä½“é‡, å†çŒœå®ƒä»¬ä¼šå¾—åˆ°ä»€ä¹ˆç¤¼ç‰©. å‡è®¾ä¸‹ä¸€åªå°ä¼é¹…\"Pupu\"çš„ä½“é‡ä¸º$x$:\n- [æ ¹æ®Bayeså®šç†](notes/2021/2021.12/Understanding%20Bayes'%20Theorem.md):\n\t$$P(\\omega_i \\mid x)=\\frac{P(x\\mid \\omega_i) P(\\omega_i)}\n\t{P(x)}$$\n\tä¹Ÿå°±æ˜¯:\n\t$$postprior=\\frac{likelihood\\times prior}{evidence}$$\n\t- åéªŒæ¦‚ç‡$postprior$å°±æ˜¯æˆ‘ä»¬ç»¼åˆæ‰€æœ‰ä¿¡æ¯åä½œå‡ºçš„å†³ç­–: å¦‚æœ$P(\\omega_1 \\mid x)\u003eP(\\omega_2 \\mid x)$, é‚£ä¹ˆè¯´æ˜Pupuæ›´å¯èƒ½å¾—åˆ°å·§å…‹åŠ›, åä¹‹äº¦ç„¶\n\t- $likelihood$å°±æ˜¯æˆ‘ä»¬æŒæ¡çš„\"æœºå¯†\": ç¤¼ç‰©å·²çŸ¥çš„ä½“é‡åˆ†å¸ƒå…³ç³»$P(x\\mid \\omega_i)$.\n\t- $evidence$æ˜¯æˆ‘ä»¬çš„\"çº¿ç´¢\": Pupuçš„ä½“é‡.\n\t- $prior$å°±æ˜¯åœ£è¯è€äººå‘Šè¯‰æˆ‘ä»¬çš„ç¤¼ç‰©ç»„æˆ: 20%çš„å·§å…‹åŠ›, 80%çš„æ°´æœç¡¬ç³–.\n\n- å¯ä»¥çœ‹åˆ°, æˆ‘ä»¬ç°åœ¨èƒ½å¤Ÿæ›´èªæ˜åœ°ä½œå‡ºå†³ç­–äº†! æˆ‘ä»¬é€šè¿‡å°ä¼é¹…çš„ä½“é‡$x$, ç»¼åˆ prior åˆ†å¸ƒå’Œ likelihood åˆ†å¸ƒå¾—åˆ°äº†ä¸€ä¸ªæ›´èªæ˜çš„åˆ†å¸ƒ: postprior åˆ†å¸ƒ. ä¹Ÿå°±æ˜¯è¯´, æˆ‘ä»¬ç»¼åˆè€ƒè™‘äº†\"èƒ–ä¼é¹…å¾—ä¸åˆ°å·§å…‹åŠ›\" å’Œ \"å·§å…‹åŠ›æœ‰å¤šå°‘\", è€Œä¸æ˜¯åƒä¹‹å‰é‚£æ ·ä¸€ç›´çŒœåŒä¸€ä¸ªä¸œè¥¿. è¿™å°±æ˜¯è´å¶æ–¯å†³ç­–çš„ä¸»è¦æ€æƒ³.\n\n### å·²çŸ¥çš„ä¿¡æ¯ä¸é‡è¦\n- å› ä¸ºåœ¨å†³ç­–çš„æ—¶å€™æˆ‘ä»¬å…³å¿ƒçš„åªæœ‰$\\omega_1$è¿˜æ˜¯$\\omega_2$çš„æ¦‚ç‡å¤§.  æ‰€ä»¥å¯ä»¥æŠŠåˆ†æ¯ä¸Šçš„evidence: $P(x)$çœ‹ä½œä¸€ä¸ªæ¯”ä¾‹ç³»æ•°, ä½œç”¨æ˜¯è®©xæ‰€æœ‰å–å€¼ä¸‹çš„$P(\\omega_i \\mid x)$åŠ èµ·æ¥ä¸º 1. è€ŒçœŸæ­£å’Œå†³ç­–å¯¹è±¡$\\omega$æœ‰å…³çš„åªæ˜¯åˆ†å­ä¸Šçš„$P(x\\mid \\omega_i) P(\\omega_i)$\n\n## åŠ å…¥é£é™©\n- ä¸‹é¢æˆ‘ä»¬ç”¨æ›´å½¢å¼åŒ–çš„æ–¹æ³•æ¥ä»‹ç»è´å¶æ–¯å†³ç­–çš„è¿›ä¸€æ­¥æ¨å¹¿.\n\n- æœ‰çš„æ—¶å€™ä¸åŒçš„é€‰æ‹©çš„ä»£ä»·æ˜¯ä¸ä¸€æ ·çš„, æˆ‘ä»¬å¯ä»¥å®šé‡åœ°åˆ»ç”»ä»£ä»·çš„ä¸åŒ, å¹¶åœ¨å†³ç­–çš„æ—¶å€™è¿›è¡Œç»¼åˆè€ƒè™‘:\n\t- æˆ‘ä»¬ä»¤$\\lambda\\left(\\alpha_{i} \\mid \\omega_{j}\\right)$ä¸ºå®é™…ç±»åˆ«ä¸º$\\omega_{j}$çš„æ—¶å€™é‡‡å–è¡ŒåŠ¨$\\alpha_{i}$çš„ä»£ä»·, é€šå¸¸å½“$i=j$çš„æ—¶å€™è¿™ä¸ªå€¼è¾ƒå°.\n\t- é‚£ä¹ˆé‡‡å–è¡ŒåŠ¨$\\alpha_{i}$çš„æ€»ä½“ä»£ä»·å¯ä»¥è¡¨ç¤ºä¸º:\n\t$$R\\left(\\alpha_{i} \\mid \\mathbf{x}\\right)=\\sum_{j=1}^{c} \\lambda\\left(\\alpha_{i} \\mid \\omega_{j}\\right) P\\left(\\omega_{j} \\mid \\mathbf{x}\\right)$$\n\t$R\\left(\\alpha_{i} \\mid \\mathbf{x}\\right)$ä¹Ÿè¢«ç§°ä¸ºæ¡ä»¶é£é™©.\n\t- æ›´è¿›ä¸€æ­¥, å¯¹äºä»»æ„çš„$\\mathbf{x}$, æˆ‘ä»¬çš„å†³ç­–è§„åˆ™å¯ä»¥æŠ½è±¡ä¸ºä¸€ä¸ªå‡½æ•°$\\alpha(\\mathbf{x})$, è‡ªåŠ¨ç»™å‡ºæƒ…å†µ$\\mathbf{x}$ä¸‹æœ€ä¼˜çš„å†³ç­–æ–¹æ¡ˆ$\\alpha_i$. æ‰€ä»¥æƒ…å†µ$\\mathbf{x}$ä¸‹çš„\"åŠ æƒé£é™©\"å¯ä»¥è¡¨ç¤ºä¸º: \n\t\t$$R(\\alpha(\\mathbf{x}) \\mid \\mathbf{x}) p(\\mathbf{x})$$\n\t- ç»¼åˆä¸‹æ¥, å¯¹äºæ‰€æœ‰å¯èƒ½çš„$\\mathbf{x}$, æ•´ä¸ªå†³ç­–æ–¹æ¡ˆçš„é£é™©ä¸º:\n\t\t$$R=\\int R(\\alpha(\\mathbf{x}) \\mid \\mathbf{x}) p(\\mathbf{x}) d \\mathbf{x}$$ \n\t\tè¿™å°±æ˜¯æˆ‘ä»¬æƒ³è¦æœ€å°åŒ–çš„ä¸œè¥¿.\n\n- æœ€å°çš„ä»£ä»·ä¹Ÿå«è´å¶æ–¯é£é™©(Bayes risk), æ˜¯æ•´ä¸ªå†³ç­–æ–¹æ¡ˆæ‰€èƒ½å¤Ÿè¾¾åˆ°çš„æœ€ä½³æ°´å¹³.\n\n\n### ä¾‹å­: äºŒåˆ†ç±»é—®é¢˜\näºŒåˆ†ç±»é—®é¢˜ä¸¤ä¸ªå†³ç­–çš„ä»£ä»·å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹:\n$$\\begin{aligned}\n\u0026R\\left(\\alpha_{1} \\mid \\mathbf{x}\\right)=\\lambda_{11} P\\left(\\omega_{1} \\mid \\mathbf{x}\\right)+\\lambda_{12} P\\left(\\omega_{2} \\mid \\mathbf{x}\\right) \\\\\n\u0026R\\left(\\alpha_{2} \\mid \\mathbf{x}\\right)=\\lambda_{21} P\\left(\\omega_{1} \\mid \\mathbf{x}\\right)+\\lambda_{22} P\\left(\\omega_{2} \\mid \\mathbf{x}\\right)\n\\end{aligned}$$\n- å½“ç„¶, å¦‚æœ$R\\left(\\alpha_{1} \\mid \\mathbf{x}\\right)\u003cR\\left(\\alpha_{2} \\mid \\mathbf{x}\\right)$, æˆ‘ä»¬ä¼šé€‰æ‹©$\\alpha_1$, å› ä¸ºæ­¤æ—¶é£é™©æ›´å°.\n- æ¢ä¸ªå½¢å¼, ä¹Ÿå°±æ˜¯$$\\left(\\lambda_{21}-\\lambda_{11}\\right) P\\left(\\omega_{1} \\mid \\mathbf{x}\\right)\u003e\\left(\\lambda_{12}-\\lambda_{22}\\right) P\\left(\\omega_{2} \\mid \\mathbf{x}\\right)$$æˆ–è€…$$\\left(\\lambda_{21}-\\lambda_{11}\\right) p\\left(\\mathbf{x} \\mid \\omega_{1}\\right) P\\left(\\omega_{1}\\right)\u003e\\left(\\lambda_{12}-\\lambda_{22}\\right) p\\left(\\mathbf{x} \\mid \\omega_{2}\\right) P\\left(\\omega_{2}\\right)$$æ—¶é€‰æ‹©æ–¹æ¡ˆ1.\n- æˆ‘ä»¬ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºåˆ†æ•°çš„å½¢å¼:$$\\frac{p\\left(\\mathbf{x} \\mid \\omega_{1}\\right)}{p\\left(\\mathbf{x} \\mid \\omega_{2}\\right)} \u003e\\frac{\\lambda_{12}-\\lambda_{22}}{\\lambda_{21}-\\lambda_{11}} \\frac{P\\left(\\omega_{2}\\right)}{P\\left(\\omega_{1}\\right)}$$è¿™æ—¶å†³ç­–æŒ‡æ ‡$\\frac{p\\left(\\mathbf{x} \\mid \\omega_{1}\\right)}{p\\left(\\mathbf{x} \\mid \\omega_{2}\\right)}$ä¸ºä¸€ä¸ªæ•°$\\theta$, ç§°ä¸ºlikelihood ratio(ä¼¼ç„¶æ¯”). è¿™æ—¶æ§åˆ¶å†³ç­–è¾¹ç•Œçš„é‡è¦å‚æ•°:\n![](notes/2021/2021.12/assets/Pasted%20image%2020211221211244.png)\nåœ¨ä¸Šé¢è¿™ä¸ªå›¾ä¸­, å¦‚æœå°†$\\omega_2$è¯¯åˆ¤ä¸º$\\omega_2$çš„ä»£ä»·æ›´å¤§, å³ $\\lambda_{12}\u003e\\lambda_{21}$ . é‚£ä¹ˆä¼šå¯¼è‡´$\\theta$ä¸Šå‡åˆ°$\\theta_b$, å³$\\mathcal{R}_{1}$å˜å°, åˆ¤æ–­ä¸º$\\omega_1$çš„æƒ…å†µè¡¨å°‘.\n\n### è¯¯å·®ç‡\n- äºŒåˆ†ç±»æƒ…å†µä¸‹, ä¸€æ¬¡å†³ç­–çš„è¯¯å·®ç‡å¯ä»¥è¡¨ç¤ºä¸º$$P(\\text { error } \\mid x)= \\begin{cases}P\\left(\\omega_{1} \\mid x\\right) \u0026 \\text { if we decide } \\omega_{2} \\\\ P\\left(\\omega_{2} \\mid x\\right) \u0026 \\text { if we decide } \\omega_{1}\\end{cases}$$\n- æ€»çš„æƒ…å†µä¸‹, å¹³å‡è¯¯å·®ç‡å¯ä»¥è¡¨ç¤ºä¸º:$$P(\\text { error })=\\int_{-\\infty}^{\\infty} P(\\text { error }, x) d x=\\int_{-\\infty}^{\\infty} P(\\text { error } \\mid x) p(x) d x$$\n\n- ä¸ºäº†ä½¿è¯¯å·®ç‡æœ€å°, å†³ç­–æ–¹æ¡ˆä¸º: \n\tDecide $\\omega_{1}$ if $P\\left(\\omega_{1} \\mid x\\right)\u003eP\\left(\\omega_{2} \\mid x\\right) ;$ otherwise decide $\\omega_{2}$, \nä¹Ÿå°±æ˜¯:$$P(\\text { error } \\mid x)=\\min \\left[P\\left(\\omega_{1} \\mid x\\right), P\\left(\\omega_{2} \\mid x\\right)\\right]$$\n\n### ä¾‹å­: æœ€å°è¯¯å·®ç‡åˆ†ç±»\n- åœ¨å¾ˆå¤šæƒ…å†µä¸‹, æˆ‘ä»¬ä¼šå¸Œæœ›è¯¯åˆ¤çš„æ¬¡æ•°æœ€å°‘, å³è¯¯å·®ç‡æœ€å°. æˆ‘ä»¬å¯ä»¥è¿™æ ·æ„é€ æŸå¤±å‡½æ•°æ¥è·å¾—è´å¶æ–¯å†³ç­–ä¸‹çš„æœ€å°è¯¯å·®ç‡:\n$$\\lambda\\left(\\alpha_{i} \\mid \\omega_{j}\\right)=\\left\\{\\begin{array}{ll}0 \u0026 i=j \\\\1 \u0026 i \\neq j\n\\end{array} \\quad i, j=1, \\ldots, c\\right.$$\nåœ¨åˆ¤æ–­æ­£ç¡®æ—¶ä¸º0, åœ¨å…¶ä»–é”™è¯¯æƒ…å†µä¸‹éƒ½ä¸º1, æ•…è¿™ä¸ªæŸå¤±å‡½æ•°ä¹Ÿç§°0-1æŸå¤±å‡½æ•°.\n- æˆ‘ä»¬å¯ä»¥è¯æ˜åœ¨0-1æŸå¤±å‡½æ•°ä¸‹æœ‰ç€æœ€å°è¯¯å·®ç‡:\n\t- æ­¤æ—¶æ¡ä»¶æŸå¤±ä¸º:\n\t\t$$\\begin{aligned}\n\tR\\left(\\alpha_{i} \\mid \\mathbf{x}\\right) \u0026=\\sum_{j=1}^{c} \\lambda\\left(\\alpha_{i} \\mid \\omega_{j}\\right) P\\left(\\omega_{j} \\mid \\mathbf{x}\\right) \\\\\n\t\u0026=\\sum_{j \\neq i} P\\left(\\omega_{j} \\mid \\mathbf{x}\\right) \\\\\n\t\u0026=1-P\\left(\\omega_{i} \\mid \\mathbf{x}\\right)\n\t\\end{aligned}$$\n\t- ä¸ºäº†è·å¾—æœ€å°çš„æ€»ä»£ä»·, æˆ‘ä»¬éœ€è¦è®©æ¯ä¸€ä¸ªæ¡ä»¶ä»£ä»·éƒ½å°½å¯èƒ½åœ°å°, ä¹Ÿå°±æ˜¯è®©$P(\\omega_{i} \\mid \\mathbf{x})$å°½å¯èƒ½å¤§, ä¹Ÿå°±æ˜¯é€‰æ‹©$\\mathbf{x}$å·²çŸ¥æ—¶å‡ºç°æ¦‚ç‡æœ€å¤§çš„$\\omega_{i}$: $$P(\\text { error } \\mid x)=\\min \\left[P\\left(\\omega_{i} \\mid x\\right) \\right]$$\n\n## å…ˆéªŒæ¦‚ç‡æœªçŸ¥: Minimax Criterion\n- æœ‰æ—¶å€™å…ˆéªŒæ¦‚ç‡æ˜¯ä¸ç¡®å®šçš„, ä½†æ˜¯likelihoodæ˜¯ç¡®å®šçš„, æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿåœ¨è¿™ç§æƒ…å†µä¸‹ä¹Ÿèƒ½å¤Ÿæœ‰è¾ƒå¥½çš„è¡¨ç°.\n- prioræ˜¯ä¸ç¡®å®šçš„ä¼šå¯¼è‡´æœ€ä½³è¡¨ç°(Bayes Risk)æ˜¯å…³äºpriorçš„ä¸€ä¸ªå‡½æ•°, åé¢æˆ‘ä»¬ä¼šçœ‹åˆ°Bayes Risk $R$æ˜¯å…³äº$P(\\omega_i)$çš„ä¸€ä¸ªçº¿æ€§å‡½æ•°, æˆ‘ä»¬å¸Œæœ›å¾—åˆ°è¿™ä¸ªçº¿æ€§å‡½æ•°åœ¨æœ€åæƒ…å†µä¸‹çš„æœ€å¥½è¡¨ç°(Mini-Max, \"æœ€å°çš„æœ€å¤§\")\n\n- æ€ä¹ˆå¯»æ‰¾è¿™ä¸ª\"æœ€å¥½è¡¨ç°\"?\n\t- é¦–å…ˆ, æˆ‘ä»¬å›ºå®šPrior: $P(\\omega_i)$, è®¡ç®—åœ¨$P(\\omega_i)$ä¸åŒå–å€¼ä¸‹, è´å¶æ–¯å†³ç­–çš„æœ€å¥½è¡¨ç°(Bayes Risk), å¾—åˆ°ä¸‹å›¾ä¸­çš„æ‹±å½¢æ›²çº¿. \n\t\t(ä¸‹å›¾ä¸­Bayes Riskä»¥æœ€å°è¯¯å·®ä¸ºä¾‹, æ‰€ä»¥çºµåæ ‡ä¸º$P(error)$)\n\t![](notes/2021/2021.12/assets/Pasted%20image%2020211221221529.png)å¯ä»¥çœ‹åˆ°, å¦‚æœå…ˆéªŒæ¦‚ç‡ä¸å˜, åœ¨$P(\\omega_1)=0.6$æ—¶, æ¨¡å‹æœ‰æœ€åçš„è¡¨ç°.\n\t- åœ¨è¿™äº›æ‰€æœ‰æœ€å¥½è¡¨ç°é‡Œé¢, å¦‚æœ$P(\\omega_1)$åç§»äº†æœ€ä½³æƒ…å†µä¸‹çš„å–å€¼, é‚£ä¹ˆæ¨¡å‹è¯¯å·®ç‡éšç€$P(\\omega_1)$çº¿æ€§å˜åŒ–, è¿™è¡¨ç°ä¸ºå›¾ä¸­çš„è™šçº¿. \n\t\t- åœ¨è™šçº¿ä»£è¡¨çš„\"æœ€å¥½\"è¡¨ç°ä¸Šå¯èƒ½å‘å±•åˆ°çš„\"æœ€å\"ç»“æœåœ¨$P(\\omega_1)=1$æ—¶å–å¾—, å¤§çº¦ä¸º0.34\n\t- æˆ‘ä»¬å¯ä»¥çœ‹åˆ°, ä¸ºäº†é™åˆ¶è¿™ä¸ª\"æœ€å¥½è¡¨ç°\"ä¸Šå¯èƒ½å‘å±•åˆ°çš„\"æœ€åç»“æœ\", åŸæ¥åœ¨0.6å–åˆ°çš„æœ€å·®çš„Bayes Riskåè€Œæˆä¸ºäº†æœ€å¥½çš„æƒ…å†µ, æ¢å¥è¯è¯´, $P(\\omega_1)=0.6$æ—¶æ¨¡å‹è¡¨ç°æ²¡æœ‰é‚£ä¹ˆå¥½, ä½†æ˜¯å¾ˆç¨³å¦¥.\n\t- æ¨¡å‹åœ¨è¿™ä¸€ç‚¹å–å¾—çš„Bayes Riskå³$R_{mm}$, minimax risk.\n\nä¸‹é¢æˆ‘ä»¬è¯æ˜likelihoodä¸å˜çš„æƒ…å†µä¸‹, æ¨¡å‹çš„è¡¨ç°éšå…ˆéªŒæ¦‚ç‡å‘ˆçº¿æ€§å˜åŒ–.\n- æ€»çš„é£é™©å¯ä»¥è¡¨ç¤ºä¸º:$$\\begin{aligned}\nR \u0026=\\int_{\\mathcal{R}_{1}}\\left[\\lambda_{11} P\\left(\\omega_{1}\\right) p\\left(\\mathbf{x} \\mid \\omega_{1}\\right)+\\lambda_{12} P\\left(\\omega_{2}\\right) p\\left(\\mathbf{x} \\mid \\omega_{2}\\right)\\right] d \\mathbf{x} \\\\\n\u0026+\\int_{\\mathcal{R}_{2}}\\left[\\lambda_{21} P\\left(\\omega_{1}\\right) p\\left(\\mathbf{x} \\mid \\omega_{1}\\right)+\\lambda_{22} P\\left(\\omega_{2}\\right) p\\left(\\mathbf{x} \\mid \\omega_{2}\\right)\\right] d \\mathbf{x}\n\\end{aligned}$$\n- åˆ©ç”¨æ’ç­‰å¼ $P\\left(\\omega_{2}\\right)=1-P\\left(\\omega_{1}\\right)$ å’Œ $\\int_{\\mathcal{R}_{1}} p\\left(\\mathbf{x} \\mid \\omega_{1}\\right) d \\mathbf{x}=1-\\int_{\\mathcal{R}_{2}} p\\left(\\mathbf{x} \\mid \\omega_{1}\\right) d \\mathbf{x}$ æˆ‘ä»¬å¯ä»¥æŠŠä¸Šå¼é‡æ–°è¡¨ç¤ºä¸º:\n$$\\begin{aligned}\nR\\left(P\\left(\\omega_{1}\\right)\\right) \u0026=\\overbrace{\\lambda_{22}+\\left(\\lambda_{12}-\\lambda_{22}\\right) \\int_{\\mathcal{R}_{1}} p\\left(\\mathbf{x} \\mid \\omega_{2}\\right) d \\mathbf{x}}^{=R_{m m}, \\operatorname{minimax} \\text { risk }} \\\\\n\u0026+P\\left(\\omega_{1}\\right)[\\underbrace{\\left[\\left(\\lambda_{11}-\\lambda_{22}\\right)-\\left(\\lambda_{21}-\\lambda_{11}\\right) \\int_{\\mathcal{R}_{2}} p\\left(\\mathbf{x} \\mid \\omega_{1}\\right) d \\mathbf{x}-\\left(\\lambda_{12}-\\lambda_{22}\\right) \\int_{\\mathcal{R}_{1}} p\\left(\\mathbf{x} \\mid \\omega_{2}\\right) d \\mathbf{x}\\right]}_{=0 \\text { for minimax solution }} .\n\\end{aligned}$$\nåœ¨åé¢é‚£éƒ¨åˆ†ä¸º0çš„æ—¶å€™, æå°åŒ–æå¤§é£é™©ä¸º:\n$$\\begin{aligned}\nR_{m m} \u0026=\\lambda_{22}+\\left(\\lambda_{12}-\\lambda_{22}\\right) \\int_{\\mathcal{R}_{1}} p\\left(\\mathbf{x} \\mid \\omega_{2}\\right) d \\mathbf{x} \\\\\n\u0026=\\lambda_{11}+\\left(\\lambda_{21}-\\lambda_{11}\\right) \\int_{\\mathcal{R}_{2}} p\\left(\\mathbf{x} \\mid \\omega_{1}\\right) d \\mathbf{x}\n\\end{aligned}$$\n\n\n## å¯¹é£é™©æœ‰çº¦æŸ: Neyman-Pearsonå‡†åˆ™\næœ‰æ—¶å€™æˆ‘ä»¬éœ€è¦åœ¨æŸä¸ªçº¦æŸæ¡ä»¶ä¸‹æœ€å°åŒ–æ€»é£é™©, æ¯”å¦‚æˆ‘ä»¬åšæŸä¸ªå†³ç­–çš„èµ„æºæ˜¯ä¸€å®šçš„, å°±æœ‰çº¦æŸ:$$\\int R\\left(\\alpha_{i} \\mid \\mathbf{x}\\right) d \\mathbf{x}\u003c\\text { constant for some particular } i .$$\nåœ¨è¿™ä¸ªæƒ…å†µä¸‹çš„è´å¶æ–¯å†³ç­–éœ€è¦æ»¡è¶³Neyman-Pearsonå‡†åˆ™, æˆ‘ä»¬é€šå¸¸ç”¨å¤šæ¬¡è°ƒèŠ‚å†³ç­–è¾¹ç•Œçš„æ–¹æ³•æ¥è¾¾åˆ°ç›®çš„.\n\n\n\n\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Bayesian_EstimationInference%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1":{"title":"Bayesian_Estimation(Inference)è´å¶æ–¯ä¼°è®¡","content":"# è´å¶æ–¯ä¼°è®¡\n\n\u003cdiv align=\"right\"\u003e 2021-12-27\u003c/div\u003e\n\nTags: #Bayes #MachineLearning \n\n\nè´å¶æ–¯ä¼°è®¡ æœ‰ç‚¹éš¾, è¿˜è¦è¿›ä¸€æ­¥å­¦ä¹ \n\n- è´å¶æ–¯ä¼°è®¡æ˜¯ä¸€ç§å‚æ•°ä¼°è®¡æ–¹æ³•, ä¸åªå±€é™äºè®¾è®¡è´å¶æ–¯åˆ†ç±»å™¨\n- è´å¶æ–¯ä¼°è®¡çš„æ ¸å¿ƒåœ¨äºç”¨æ–°çš„æ ·æœ¬æ¥æ›´æ–°æ—§çš„Prior, ä¸€èµ·å¾—åˆ°ä¸€ä¸ªPostPriorçš„å‚æ•°çš„æ¦‚ç‡åˆ†å¸ƒ, åˆå¹¶çš„è¿‡ç¨‹åˆ©ç”¨çš„æ˜¯è´å¶æ–¯åˆ†å¸ƒ.\n- è´å¶æ–¯ä¼°è®¡å’Œæå¤§ä¼¼ç„¶ä¼°è®¡çš„æœ€å¤§ä¸åŒå°±æ˜¯è´å¶æ–¯ä¼°è®¡çš„æ˜¯å‚æ•°å¯èƒ½çš„æ¦‚ç‡åˆ†å¸ƒ, è€Œä¸æ˜¯ä¸€ä¸ªç¡®å®šçš„å€¼. é€šè¿‡å¯¹è¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒè¿›è¡Œç§¯åˆ†, æˆ‘ä»¬å¯ä»¥å¹³å‡åœ°å¾—åˆ°æ‰€æœ‰æƒ…å†µä¸‹æœ€å¯èƒ½å‡ºç°çš„å‚æ•°.\n\n\n\nè¿™ä¸¤ç¯‡æ–‡ç« å†™çš„å¾ˆå¥½: \n- [Conjugate Prior Explained. With examples \u0026 proofs | by Aerin Kim | Towards Data Science](https://towardsdatascience.com/conjugate-prior-explained-75957dc80bfb)\n- [Bayesian Inference â€” Intuition and Example | by Aerin Kim | Towards Data Science](https://towardsdatascience.com/bayesian-inference-intuition-and-example-148fd8fb95d6)\n\nDudaä¹¦ä¸Šçš„é€»è¾‘æ˜¯æœ‰ç‚¹ä¹±çš„, åœ¨æ•´ç†ç¬”è®°çš„æ—¶å€™å…ˆçœ‹ä¸Šé¢çš„ä¸¤ç‰‡æ–‡ç« , ç„¶åçœ‹ä¹¦ä¸Šçš„è¿‡ç¨‹, ç„¶åå†è‡ªå·±æ¨ä¸€éæ­£æ€åˆ†å¸ƒçš„æƒ…å†µ.\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Chernoff-Bounds":{"title":"Chernoff Bounds","content":"# Chernoff Bounds\n\n\u003cdiv align=\"right\"\u003e 2021-12-04\u003c/div\u003e\n\nTags: #Math/Statistics \n\n[probabilitycourse.com - Chernoff Bounds](https://www.probabilitycourse.com/chapter6/6_2_3_chernoff_bounds.php)\n\nzotero:@ChernoffBounds(zotero://select/items/@ChernoffBounds)\n\n\n- The generic Chernoff bound for a random variable $X$ is attained by applying Markov's inequality to $e^{tX}$. This gives a bound in terms of the [moment-generating function](https://en.wikipedia.org/wiki/Moment-generating_function \"Moment-generating function\") of $X$. For every $t â‰¥ 0$:\n\n$$\\operatorname{Pr}(X \\geq a)=\\operatorname{Pr}\\left(e^{t \\cdot X} \\geq e^{t \\cdot a}\\right) \\leq \\frac{E\\left[e^{t \\cdot X}\\right]}{e^{t \\cdot a}}$$\n\n- $E\\left[e^{t \\cdot X}\\right]$å®é™…ä¸Šå°±æ˜¯moment-generating function: $M_{X}(s)$\n\n$$\\begin{array}{ll}\nP(X \\geq a) \\leq e^{-t a} M_{X}(t), \u0026 \\text { for all } t\u003e0 \\\\\nP(X \\leq a) \\leq e^{-t a} M_{X}(t), \u0026 \\text { for all } t\u003c0\n\\end{array}$$","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Chi-Squared_Distribution-%E5%8D%A1%E6%96%B9%E5%88%86%E5%B8%83":{"title":"Chi-Squared_Distribution-å¡æ–¹åˆ†å¸ƒ","content":"# Chi-Squared Distribution\n\n\u003cdiv align=\"right\"\u003e 2021-12-04\u003c/div\u003e\n\nTags: #Math/Statistics \n\n[A very Good Website](https://www.probabilitycourse.com/chapter8/8_3_3_confidence_intervals_for_norm_samples.php)\n[Chi-squared distribution - Wikipedia](https://en.wikipedia.org/wiki/Chi-squared_distribution)\n\n## é‡è¦ç»“è®º\n\n$Z_{1},Z_{2},\\cdots,Z_{n}$ are independent standard normal random variables,\n\n- **The Sum of independent Standard Normal Variables are still Normal:**\n$$X=Z_{1}+Z_{2}+\\cdots+Z_{n}$$\n\nLink: [æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution](notes/2021/2021.9/æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution.md)\n\n- ä½†æ˜¯æ­£æ€ç‹¬ç«‹éšæœºå˜é‡çš„**å¹³æ–¹å’Œ**æ˜¯å¡æ–¹åˆ†å¸ƒçš„:\n\n$$Y=Z_{1}^{2}+Z_{2}^{2}+\\cdots+Z_{n}^{2}$$\nthen $Y$ is said to have a chi-squared distribution with $n$ degrees of freedom shown by $$Y \\sim \\chi^{2}(n)$$\n\n- å¡æ–¹åˆ†å¸ƒå…¶å®æ˜¯ä¸€ç§ç‰¹æ®Šçš„Gammaåˆ†å¸ƒ: $$Y\\sim Gamma\\left(\\frac n2,\\frac1 2\\right)$$\n\n- ä¸‹é¢æ˜¯å¡æ–¹åˆ†å¸ƒçš„å›¾åƒéšç€è‡ªç”±åº¦çš„å˜åŒ–:\n\n![The chi-Square distribution](notes/2021/2021.12/assets/The%20chi-Square%20distribution.svg)","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Covariance-%E5%8D%8F%E6%96%B9%E5%B7%AE":{"title":"Covariance-åæ–¹å·®","content":"# Covariance\n\n\u003cdiv align=\"right\"\u003e 2021-12-11\u003c/div\u003e\n\nTags: #Math/Statistics \n\n\n æœŸæœ›å€¼åˆ†åˆ«ä¸º  $E(X)=\\mu$  ä¸  $E(Y)=\\nu$ çš„ä¸¤ä¸ªéšæœºå˜é‡  X  ä¸  Y  ä¹‹é—´çš„åæ–¹å·®å®šä¹‰ä¸º: \n$$\\begin{aligned}\n\\operatorname{cov}(X,Y)\u0026=\\mathrm{E}((X-\\mu)(Y-\\nu))\\\\\n\u0026=\\mathrm{E}(X \\cdot Y-\\nu X-\\mu Y +\\mu\\nu)\\\\\n\u0026=\\mathrm{E}(X \\cdot Y)-\\nu \\mathrm{E}(X)-\\mu \\mathrm{E}(Y) +\\mu\\nu\\\\\n\u0026=\\mathrm{E}(X \\cdot Y)-\\mu\\nu-\\mu\\nu +\\mu\\nu\\\\\n\u0026=\\mathrm{E}(X \\cdot Y)-\\mu \\nu\n\\end{aligned}$$ \n\næˆ–è€…ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸º:\n$$\\operatorname{cov}(X,Y)=\\mathrm{E}(X \\cdot Y)-\\mathrm{E}(X)\\mathrm{E}(Y)$$\n\n- å¦‚æœ$X,Y$æ˜¯ç›¸äº’ç‹¬ç«‹çš„, é‚£ä¹ˆå®ƒä»¬ä¹‹é—´çš„åæ–¹å·®ä¸º$0$ :\n\t$$\\begin{aligned}\n\\operatorname{cov}(X,Y)\u0026=\\mathrm{E}(X \\cdot Y)-\\mu \\nu\\\\\n\u0026=\\mathrm{E}(X)\\mathrm{E}(Y)-\\mu \\nu\\\\\n\u0026=\\mu \\nu-\\mu \\nu\\\\\n\u0026=0\n\\end{aligned}$$ ","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Cross-Validation":{"title":"Cross Validation","content":"# Cross Validation\n\n\u003cdiv align=\"right\"\u003e 2021-12-19\u003c/div\u003e\n\nTags: #MachineLearning \n\n- äº¤å‰éªŒè¯æ˜¯ä¸€ç§è¯„ä»·æ¨¡å‹å¥½åçš„æ–¹æ³•.\n- è®¾ç½®éªŒè¯é›†çš„ç›®çš„åœ¨äºå‡å°‘æ ·æœ¬ç»™æ¨¡å‹å¸¦æ¥çš„Bias, å³æˆ‘ä»¬æƒ³è¦æ‰¾åˆ°ä¸€ä¸ªæ™®éé€‚ç”¨çš„æ¨¡å‹, è€Œä¸æ˜¯åªåœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¾ˆå¥½çš„æ¨¡å‹.\n\t- äº¤å‰éªŒè¯æ˜¯ä¸€ç§å¢å¤§éªŒè¯é›†, å……åˆ†åˆ©ç”¨æ•°æ®çš„æ–¹æ³•.\n\n\n## äº¤å‰éªŒè¯çš„æ–¹æ³•\n- [Cross-validation (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation)\n- [Machine Learning Fundamentals: Cross Validation - YouTube](https://www.youtube.com/watch?v=fSytzGwwBVw)\n\nç®€å•çš„æ¥è¯´, äº¤å‰éªŒè¯ä¼šæŠŠè®­ç»ƒé›†éšæœºåˆ†æˆå‡ ä¸ªéƒ¨åˆ†. æ¯æ¬¡é€‰ä¸€å°éƒ¨åˆ†å½“ä½œæµ‹è¯•é›†(Validation Set). ä¸€å…±è®­ç»ƒå¤šä¸ªæ¨¡å‹, ç»¼åˆæ‰€æœ‰ç»“æœè¯„ä»·æ¨¡å‹çš„å¥½å.\n\n## äº¤å‰éªŒè¯çš„ç”¨å¤„\n- äº¤å‰éªŒè¯å¯ä»¥ç”¨æ¥:\n\t- å¯¹äºåŒä¸€ä¸ªé—®é¢˜, é€‰å‡ºè¡¨ç°æœ€å¥½çš„æ¨¡å‹\n\t- å¯¹äºåŒä¸€ä¸ªæ¨¡å‹, é€‰å‡ºæœ€å¥½çš„å‚æ•°.\n\n## äº¤å‰éªŒè¯çš„åˆ†ç±»\näº¤å‰éªŒè¯å¤§è‡´å¯ä»¥åˆ†ä¸ºä¸¤ç±»: Exhaustive \u0026 Non-exhaustive\n- Exhaustiveæ–¹æ³•çš„è®­ç»ƒæ¬¡æ•°å¾ˆå¤š, æ¯æ¬¡åªç”¨å‡ ä¸ªæ ·æœ¬æ¥æµ‹è¯•æ¨¡å‹, è¿™ç§æ–¹æ³•é€šå¸¸è¢«ç§°ä½œ Leave-p-Out Cross Validation, å³æ¯æ¬¡åªleave out p ä¸ªæ ·æœ¬ç”¨æ¥æµ‹è¯•\n![LOOCV|350](notes/2021/2021.12/assets/img_2022-10-15.gif)\n- Non-exhaustive æ–¹æ³•çš„è®­ç»ƒæ¬¡æ•°æ›´å°‘, æµ‹è¯•é›†æ›´å¤§, æ¯”å¦‚KæŠ˜äº¤å‰éªŒè¯(K-Fold Cross Validation)å°±æ˜¯æŠŠæ ·æœ¬åˆ†æˆKä¸ªéƒ¨åˆ†, æ¯æ¬¡èˆå¼ƒä¸€ä¸ªä½œä¸ºæµ‹è¯•é›†, ä¸€å…±è®­ç»ƒKä¸ªæ¨¡å‹.\n![KfoldCV|400](notes/2021/2021.12/assets/img_2022-10-15-1.gif)\n\n\n## äº¤å‰éªŒè¯ä¼šç”Ÿæˆä¸€å †æ¨¡å‹å—?\nä¸ä¼š, The purpose of cross-validation is model checking, not model building.[^1] åœ¨äº¤å‰éªŒè¯ä¹‹å, æˆ‘ä»¬ä¼šç”¨æ‰€æœ‰çš„æ•°æ®ä½œä¸ºè®­ç»ƒé›†æ¥è®­ç»ƒä¸€ä¸ªæœ€ç»ˆçš„æ¨¡å‹.\n\n- è¿™ä¸ªå›ç­”å†™çš„éå¸¸å¥½:  [How to choose a predictive model after k-fold cross-validation? - Cross Validated](https://stats.stackexchange.com/a/52277/354372)\n\n[^1]: [How to choose a predictive model after k-fold cross-validation? - Cross Validated](https://stats.stackexchange.com/a/52277/354372)","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Dilemmalemma":{"title":"Dilemma\u0026lemma","content":"# The relation between Dilemma and lemma\n\n\u003cdiv align=\"right\"\u003e 2021-12-10\u003c/div\u003e\n\nTags: #English #Etymology #Latin \n\n- di: two, ä¸¤ä¸ª\n- lemma: premise å‡å®š, å…ˆå†³æ¡ä»¶\n- åœ¨ä¸¤ä¸ª(ä¸å¥½çš„)å¯èƒ½æ€§ä¸­é—´åšå‡ºæŠ‰æ‹©, å³è¿›é€€ä¸¤éš¾.\n- a form of argument involving a choice between equally unfavorable alternatives\n\n![](notes/2021/2021.12/assets/img_2022-10-15-1.png)\n\n\u003e A form of argument in which it is shown that whoever maintains a certain proposition must accept one or other of two alternative conclusions, and that each of these involves the denial of the proposition in question. [Century Dictionary]\n\nLoosely, \"choice between two undesirable alternatives,\" from 1580s. It should be used only of situations where someone is forced to choose between two alternatives, both unfavorable to him (the alternatives are called the horns of a dilemma). But even logicians disagree on whether certain situations are dilemmas or mere syllogisms. Related: Dilemmatic.[^1]\n\n\n[^1]: [dilemma | Etymology, origin and meaning of dilemma by etymonline](https://www.etymonline.com/word/dilemma)\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Johnson-Lindenstrauss-Lemma-Publish-Version":{"title":"Johnson Lindenstrauss Lemma - Publish Version","content":"# Johnson Lindenstrauss Lemma\n\n\u003cdiv align=\"right\"\u003e 2021-12-03\u003c/div\u003e\n\nTags: #MachineLearning #Math \n\n- å¯¹äºé«˜ç»´æ•°æ®ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨é™ç»´çš„è¿‡ç¨‹ä¸­ä¿ç•™å…¶å¤§éƒ¨åˆ†çš„å‡ ä½•ç‰¹å¾ï¼Œå³ä½¿é™ç»´çš„å¹…åº¦éå¸¸å¤§ã€‚\n\n\u003e è¿™æ˜¯å¾äº¦è¾¾è€å¸ˆè®©æˆ‘ä»¬å­¦ä¹ çš„ç¬¬ä¸€ä¸ªä¸»é¢˜\n\n![](notes/2021/2021.12/assets/Pasted%20image%2020211205113411.png)[^1]\n\n## Study Materials\n- MIT 6.854 Spring 2016 Lecture 5: Johnson Lindenstrauss Lemma and Extensions PDF(zotero://select/items/@mcnally2021RethinkingKeypoint)\n\t- [MIT 6.854 Spring 2016 Lecture 5: Johnson Lindenstrauss Lemma and Extensions - YouTube](https://youtu.be/Tw0J5Xv6xQw)\n\t- Course Website: [6.854/18.415 Advanced Algorithms, Spring 2016](http://people.csail.mit.edu/moitra/854.html)\n\n- Course notes on dimensionality reduction from [TTI](http://ttic.uchicago.edu/~gregory/courses/LargeScaleLearning/lectures/jl.pdf) and [UBC](http://www.cs.ubc.ca/~nickhar/W12/Lecture6Notes.pdf)\n\t- [UBC Course homepage](https://www.cs.ubc.ca/~nickhar/W12/) PDF(zotero://select/items/@prof.nickharvey2011UBCCPSC) \n\t\t**This is the most Clear Version to me**\n\t- [TTI Course homepage - CMSC 3590 - Large Scale Learning, Spring 2009](https://home.ttic.edu/~gregory/courses/LargeScaleLearning/)PDF(zotero://select/items/@shamkakade2009TTICMSC)\n\n- Wikipedia: \n\t- [Johnsonâ€“Lindenstrauss lemma - Wikipedia](https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma)\n\t- [çº¦ç¿°é€Š-æ—ç™»æ–¯ç‰¹åŠ³æ–¯å®šç† - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-hans/%E7%BA%A6%E7%BF%B0%E9%80%8A-%E6%9E%97%E7%99%BB%E6%96%AF%E7%89%B9%E5%8A%B3%E6%96%AF%E5%AE%9A%E7%90%86)\n## Johnson Lindenstrauss Lemma\n - $x_{1}, \\cdots, x_{m} \\in \\mathbb{R}^{n}$ æ˜¯$n$ç»´ç©ºé—´é‡Œé¢çš„ä»»æ„$m$ä¸ªç‚¹,   $\\epsilon\\in(0,1)$. \n - åˆ™å­˜åœ¨ $d$ ç»´ç©ºé—´é‡Œé¢çš„$m$ä¸ªç‚¹ $y_{1}, \\ldots, y_{m} \\in \\mathbb{R}^{d}$, å…¶ä¸­  $d=O\\left(\\log (m) / \\epsilon^{2}\\right)$ , ä½¿å¾—:\n$$\n\\begin{array}{rcl}\n(1-\\epsilon)\\left\\|x_{j}\\right\\|  \\leq\u0026\n\\left\\|y_{j}\\right\\|  \u0026\\leq\n(1+\\epsilon)\\left\\|x_{j}\\right\\| \\qquad \\forall j \\\\\n(1-\\epsilon)\\left\\|x_{j}-x_{j^{\\prime}}\\right\\| \\leq\u0026\n\\left\\|y_{j}-y_{j^{\\prime}}\\right\\| \u0026\\leq\n(1+\\epsilon)\\left\\|x_{j}-x_{j^{\\prime}}\\right\\| \\qquad \\forall j, j^{\\prime} .\n\\end{array}\n$$\n\n- å¹¶ä¸”æˆ‘ä»¬èƒ½åœ¨å¤šé¡¹å¼æ—¶é—´é‡Œé¢æ‰¾åˆ°ä¸€ä¸ª  $y_{j}:=L\\left(x_{j}\\right)$ çš„çº¿æ€§å˜æ¢ $L: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{d}$ ä½¿å¾—ä¸ç­‰å¼æˆç«‹çš„æ¦‚ç‡è‡³å°‘ä¸º $1-2 / \\mathrm{m} .$\n\n- åé¢æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸ªçº¿æ€§å˜æ¢å¯ä»¥æ˜¯ä¸€ä¸ªç”±è®¸å¤šæ­£æ€åˆ†å¸ƒçš„éšæœºå˜é‡æ„æˆçš„éšæœºçŸ©é˜µ$A \\in \\mathbb{R}^{k \\times d}$.\n\n## Some random facts about JL lemma\n- è¿™ä¸ªå¼•ç†å¯ä»¥ä»é™ç»´çš„è§’åº¦æ¥åŠ é€Ÿç®—æ³•\n\t- ä¸¾ä¸ªä¾‹å­, æ¯”å¦‚æ±‚æœ€å°ç”Ÿæˆæ ‘çš„Kruskalç®—æ³•, å¦‚æœæˆ‘ä»¬éœ€è¦è®¡ç®—$H$ç»´ç©ºé—´é‡Œé¢$n$ä¸ªç‚¹æœ€å°ç”Ÿæˆæ ‘, é‚£ä¹ˆéœ€è¦è®¡ç®—$C_n^2=O(n^2)$ä¸ªè·ç¦», æ¯ä¸ªè·ç¦»çš„è®¡ç®—èŠ±è´¹$O(H)$çš„æ—¶é—´($H$è¾ƒå¤§æ—¶), é‚£ä¹ˆæ€»çš„æ—¶é—´å¤æ‚åº¦æ˜¯$O(n^2H)$\n\t- æ ¹æ®JLå¼•ç†, æˆ‘ä»¬å¯ä»¥é™ç»´çš„è¿‡ç¨‹ä¸­ä¿ç•™å…¶å¤§éƒ¨åˆ†çš„å‡ ä½•ç‰¹å¾, åœ¨é™åˆ°$d$ç»´åKruskalç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º:\n\t\t- æ¯ä¸€ä¸ªé™ç»´çš„ä½“ç°ä¸ºä¸€æ¬¡çŸ©é˜µè¿ç®—$A_{d\\times H}\\vec v_{H\\times 1}$, æ—¶é—´å¤æ‚åº¦ä¸º$O(dH)$, $n$ä¸ªç‚¹æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º$O(dHn)$\n\t\t- æ¯ä¸€ä¸ªè·ç¦»çš„è®¡ç®—èŠ±è´¹$O(d)=O\\left(\\log (m) / \\epsilon^{2}\\right)$, æ€»çš„è·ç¦»è®¡ç®—éœ€è¦èŠ±è´¹$O\\left(n^2d\\right)$çš„æ—¶é—´.\n\t\t- ç»¼ä¸Š,æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º$O(dHn+n^2d)$, åœ¨$d\u003c\u003cH$çš„æ—¶å€™, è¿™ä¸ªæå‡æ˜¯å¾ˆå¤§çš„.\n\n- å³ä½¿ä¸‹é¢è¯æ˜ä½¿ç”¨çš„æ˜¯çº¿æ€§å˜æ¢, JLå¼•ç†åŒæ ·é€‚ç”¨äºéçº¿æ€§å˜æ¢. JL Lemma is tight.\n- JLçš„è¯æ˜æ˜¯æ„é€ æ€§(Constructive)çš„, ä»è¯æ˜é‡Œé¢å¯ä»¥çœ‹åˆ°, è™½ç„¶è½¬æ¢çŸ©é˜µæ˜¯ä¸€ä¸ªéšæœºçŸ©é˜µ, ä½†æ˜¯æ±‚å¾—è¿™ä¸ªçŸ©é˜µçš„æ¦‚ç‡æ˜¯å¾ˆé«˜çš„, å¤šè¯•å‡ æ¬¡æ€»ä¼šå¾—åˆ°ä¸€ä¸ªåˆé€‚çš„çŸ©é˜µ.\n- [When to use the Johnson-Lindenstrauss lemma over SVD? - Theoretical Computer Science Stack Exchange](https://cstheory.stackexchange.com/questions/21487/when-to-use-the-johnson-lindenstrauss-lemma-over-svd)\n\u003e - The JL Lemma says essentially \"you give me the error you want, and I'll give you a low dimensional space that captures the distances upto that error\". It's also a **worst-case** pairwise guarantee: for **each pair of points**, etc etc\n\u003e - The SVD essentially promises \"you tell me what dimension you want to live in, and I'll give you the best possible embedding\", where \"best\" is defined as **on average**: the total error of true similarity versus projected similarity is minimum.\n\n\n## Proof\n\nè¯æ˜çš„æ€è·¯å¦‚ä¸‹å›¾æ‰€ç¤º:\n\n![](notes/2021/2021.12/assets/JL_Proof.svg)\n\n### ç”¨Union Boundæ¨å‡ºJL\n#### Norm Preservation Property\n- æˆ‘ä»¬å…ˆå¦‚ä¸‹æ„é€ ä¸€ä¸ªçº¿æ€§å˜æ¢$f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{d}$\n\t\n\t- æ„é€ $d$ä¸ª$n$ç»´çš„éšæœºå‘é‡$r_i$, æ¯ä¸€ä¸ªå‘é‡éƒ½ç”±$n$ä¸ªç‹¬ç«‹åŒåˆ†å¸ƒçš„å…ƒç´  $r_{i,j}$ æ„æˆ. åˆ™$f$æ˜¯ä¸‹é¢è¿™ä¸ªçŸ©é˜µ $F$ , å®ƒå°†$n$ç»´å‘é‡æ˜ å°„ä¸º$d$ç»´å‘é‡:\n$$\nF=\\left[\n\\begin{array}{c}\n---r_{1}--- \\\\\t\n\\vdots \\\\\n---r_{d}---\\\\\n\\end{array}\n\\right]_{d\\times n}\n$$\n\n-  å¯¹äº$n$ç»´å•ä½å‘é‡ $v \\in \\mathbb{R}^{n}$ , $\\|v\\|=1$ å’Œ $d=O\\left(\\log (m) / \\epsilon^{2}\\right)$, æˆ‘ä»¬å¯ä»¥è¯æ˜ä»¥ä¸‹ç»“è®º: \n\n$$\\operatorname{Pr}\\left[1-\\epsilon \\leq \\frac{\\|f(v)\\|}{\\sqrt{d}} \\leq 1+\\epsilon\\right] \\geq 1-2 / m^{3} .$$\n\n- å‰é¢å¼•ç†é‡Œæåˆ°çš„çº¿æ€§å˜æ¢å³$L(v):=f(v) / \\sqrt{d}$, å› ä¸º$f$æ˜¯çº¿æ€§çš„, æ‰€ä»¥$L$ä¹Ÿæ˜¯çº¿æ€§çš„.\n\n- å› ä¸ºçº¿æ€§å˜æ¢æœ‰è¿™ä¸ªä¼˜è‰¯çš„æ€§è´¨: $f(ax)=af(x)$, æ‰€ä»¥ä¸Šå¼å…¶å®å¯ä»¥æ¨å‡ºä»»æ„å‘é‡$l_2$Normçš„ä¸å˜æ€§: å¯¹äºä»»æ„é•¿åº¦çš„ $v$, æœ‰$\\frac v {\\|v\\|}$ä¸ºå•ä½å‘é‡, å¸¦å…¥ä¸Šé¢çš„ä¸ç­‰å¼:\n$$\\operatorname{Pr}[(1-\\epsilon)\\leq\\|L(\\frac v {\\|v\\|})\\| \\leq(1+\\epsilon)] \\geq 1-2 / m^{3}$$\n$$\\Rightarrow$$\n$$\\operatorname{Pr}[(1-\\epsilon)\\|v\\| \\leq\\|L(v)\\| \\leq(1+\\epsilon)\\|v\\|] \\geq 1-2 / m^{3}$$\n\nå¦‚æœæˆ‘ä»¬å°†ç»“æœåº”ç”¨åˆ° $v=x_{j}$ å’Œä»»æ„çš„ $v=x_{j}-x_{j^{\\prime}}$ (å¯¹äº $j \\neq j^{\\prime}$ ). å› ä¸ºä¸€å…±æœ‰$(^m_2)=O(m^{2})$ å¯¹å‘é‡, æ‰€ä»¥è¿›ä¸€æ­¥åº”ç”¨ union bound å¯ä»¥å¾—åˆ°: ä»»æ„ä¸€å¯¹å‘é‡ä¸æ»¡è¶³ä¸Šé¢å¼å­çš„æ¦‚ç‡æœ€å¤§ä¸º $2 / \\mathrm{m}$, ä¹Ÿå°±æ˜¯æˆåŠŸçš„çš„æ¦‚ç‡ä¸º$1-2 / \\mathrm{m}$.\n\n#### Union Bound\n\n[[notes/2021/2021.12/Union_Bound-å¸ƒå°”ä¸ç­‰å¼-Boole's_inequality]]\n\nFor any events $A_{1}, A_{2}, \\ldots, A_{n}$, we have\n$$\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right) \\leq \\sum_{i=1}^{n} P\\left(A_{i}\\right)\n$$\n\nå±•å¼€å°±æ˜¯:\n\n$$\n\\mathbb{P}\\left(A_{1} \\bigcup A_{2} \\bigcup \\cdots\\right) \\leq \\mathbb{P}\\left(A_{1}\\right)+\\mathbb{P}\\left(A_{2}\\right)+\\cdots\n$$\n\n#### Using Union Bound\n\n- è¿™éƒ¨åˆ†è¿™ä¸ªTTIçš„è®²ä¹‰è®²çš„æ¯”è¾ƒå¥½(zotero://select/items/@shamkakade2009TTICMSC)\n\næ³¨æ„ç°åœ¨æœ‰ $O\\left(m^{2}\\right)$ å¯¹å‘é‡ $u, v .$ æ ¹æ® union bound,\n$$\n\\begin{aligned}\n\u0026 \\operatorname{Pr}\\left(\\exists u, v \\text { s.t. the following event fails: }(1-\\epsilon)\\|u-v\\| \\leq\\|L(u-v)\\| \\leq(1+\\epsilon)\\|u-v\\|\\right) \\\\\n\\leq \u0026 \\sum_{\\forall\nu, v} \\operatorname{Pr}\\left(\\text { s.t. the following event fails: }(1-\\epsilon)\\|u-v\\| \\leq\\|L(u-v)\\| \\leq(1+\\epsilon)\\|u-v\\|\\right) \\\\\n\\leq \u0026 \\space m^2\\times\\frac 2 {m^3} \\\\\n=\u0026 \\frac 2 {m}\n\\end{aligned}\n$$\næ‰€ä»¥æ€»çš„æˆåŠŸæ¦‚ç‡ä¸º$1-2 / \\mathrm{m}$.\n\n### Prove the Norm Preservation Property\n\n![](notes/2021/2021.12/assets/JL_Proof_2.svg)\n\n#### $N(0, \\sigma_X^2)+N(0, \\sigma_Y^2)=N(0,\\sigma_X^2+\\sigma_Y^2)$\n\n[æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution](notes/2021/2021.9/æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution.md)\n\n- æˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸ªæ€§è´¨è¿›ä¸€æ­¥æ¨å¹¿åˆ°$m$ä¸ªç‹¬ç«‹çš„éšæœºå˜é‡: $Y_{1}, \\ldots, Y_{m}$ ä¸” $Y_{i}$ æœä» $N(0,1)$. å¯¹äºæ ‡é‡ $\\sigma_{1}, \\ldots, \\sigma_{m}$, æœ‰ $\\sum_{i} \\sigma_{i} Y_{i}$ æœä» $N\\left(0, \\sum_{i} \\sigma_{i}^{2}\\right)$.\n\n#### Chi-Squared Distribution - å¡æ–¹åˆ†å¸ƒ\n\n[[notes/2021/2021.12/Chi-Squared_Distribution-å¡æ–¹åˆ†å¸ƒ]]\n\næ­£æ€ç‹¬ç«‹éšæœºå˜é‡çš„**å¹³æ–¹å’Œ**æ˜¯å¡æ–¹åˆ†å¸ƒçš„:\n\n$$Y=Z_{1}^{2}+Z_{2}^{2}+\\cdots+Z_{n}^{2}$$\nthen $Y$ is said to have a chi-squared distribution with $n$ degrees of freedom shown by $$Y \\sim \\chi^{2}(n)$$\n\n#### Prove The Norm Preservation Lemma\n\n$$\\operatorname{Pr}\\left[1-\\epsilon \\leq \\frac{\\|f(v)\\|}{\\sqrt{d}} \\leq 1+\\epsilon\\right] \\geq 1-\\frac2  {m^{3}}$$\n\nè¿™ä¸ªç»“è®ºå®é™…ä¸Šæ˜¯å¯¹ç§°çš„, æˆ‘ä»¬åªè¯æ˜ä¸€åŠ, å³åªè¯æ˜å³è¾¹é‚£åŠè¾¹çš„å¤±è´¥æ¦‚ç‡å°äº $1/m^3$ :\n\n$$\\operatorname{Pr}\\left[\\frac{\\|f(v)\\|}{\\sqrt{d}}\\geq 1+\\epsilon\\right] \\leq \\frac1 {m^{3}}$$\n\nä¸ºäº†æ–¹ä¾¿, æˆ‘ä»¬å¯ä»¥å¹³æ–¹ä¸€ä¸‹é‡Œé¢çš„éƒ¨åˆ†:\n\n$$\\operatorname{Pr}\\left[\\|f(v)\\|^{2}\u003e(1+\\epsilon)^2 d\\right]\\leq1/m^3$$\n\n- è¯æ˜çš„ç¬¬ä¸€æ­¥æ˜¯è¯æ˜ $\\|f(v)\\|^{2}$ å®é™…ä¸Šæœä»è‡ªç”±åº¦ä¸º $d$ çš„å¡æ–¹åˆ†å¸ƒ:\n\n$$\\|f(v)\\|^{2}=\\|Fv\\|^2=\\sum_{i=1}^{d}\\left(r_{i}^{T} v\\right)^{2}$$\n\nå…¶ä¸­ $r_{i}^{T} v$ æ˜¯ç¬¬ $i$ è¡Œä¸å‘é‡ $v$ çš„ç‚¹ä¹˜, å³è½¬åŒ–åçš„å‘é‡$f(v)$é‡Œé¢çš„ç¬¬$i$ä¸ªå…ƒç´ . æˆ‘ä»¬ä»¤å…¶ä¸º $X_i$, å®¹æ˜“çŸ¥é“ $X_i$ æ˜¯ $n$ ä¸ªæœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„éšæœºå˜é‡ $r_i$ çš„åŠ æƒå’Œ: $v_1r_{i1}+v_2r_{i2}+\\cdots+v_nr_{in}$, æƒå€¼æ˜¯ $v$ çš„å¯¹åº”å…ƒç´ , æ‰€ä»¥ $X_i\\sim N\\left(0, \\sum_{i} v_{i}^{2}\\right)=N(0,1)$. (å› ä¸º $\\sum_{i} v_{i}^{2}=\\|v\\|=1$)\n\næ‰€ä»¥ä¸Šé¢çš„å¼å­å¯ä»¥è¡¨ç¤ºä¸º:$$\\|f(v)\\|^{2}=\\sum_{i=1}^{d} X_{i}^{2}$$\n\nå®¹æ˜“è§å¾—$\\|f(v)\\|^{2}\\sim \\chi^{2}(d)$, $d$æ˜¯è‡ªç”±åº¦.\n\n- è¯æ˜çš„ç¬¬äºŒæ­¥æ˜¯åˆ©ç”¨ç±»ä¼¼äºChernoff Boundçš„æ–¹æ³•æ¥å¯¹äº‹ä»¶ ( $\\|f(v)\\|^{2}\u003e(1+\\epsilon)^2 d$ ) å‘ç”Ÿçš„æ¦‚ç‡ä¸Šé™è¿›è¡Œçº¦æŸ:\n\næˆ‘ä»¬å…ˆç®€åŒ–ä¸€ä¸‹é—®é¢˜çš„è¡¨è¿°:\n\nä»¤ $Y=\\|f(v)\\|^2=\\sum_{i=1}^{d} X_{i}^{2}$ ,  ä»¤ $\\alpha=d(1+\\epsilon)^{2}$. éœ€è¦è¯æ˜çš„å‘½é¢˜å¯ä»¥è¡¨è¿°ä¸º:$$\\operatorname{Pr}[Y\u003e\\alpha] \\leq \\frac1 {m^{3}} \\tag{1}$$\n\næˆ‘ä»¬ä¸‹é¢å°†è¯æ˜\n\n$$\\operatorname{Pr}[Y\u003e\\alpha] \\leq \\exp \\left(-(3 / 4) d \\epsilon^{2}\\right)\\tag{2}$$\n\n\u003e åœ¨ $d=4 \\ln (m) / \\epsilon^{2}$ çš„æ—¶å€™, $(1)$ä¸$(2)$ç­‰ä»·:\n\u003e $$\\begin{aligned}\\exp(\\frac{-3} 4 d \\epsilon^{2})\n\u0026=\\exp(\\frac{-3}4 \\epsilon^{2}\\frac{4\\ln(m)}{\\epsilon^{2}})\\\\\n\u0026=\\exp(-3\\ln(m))\\\\\n\u0026=\\exp(\\ln(m^{-3}))\\\\\n\u0026=\\frac1 {m^{3}}\n\\end{aligned}$$\n\nä»¤ $t\\in [0,1/2)$, åƒ[Chernoff Bounds](notes/2021/2021.12/Chernoff%20Bounds.md)é‡Œé¢ä¸€æ ·, æˆ‘ä»¬å¯ä»¥æŠŠä¸ç­‰å¼æ¢åˆ°æŒ‡æ•°éƒ¨åˆ†é‡Œé¢å», ç„¶åå†åº”ç”¨Markovä¸ç­‰å¼:\n\n$$\\operatorname{Pr}[Y\u003e\\alpha]=\\operatorname{Pr}\\left[e^{t Y}\u003ee^{t \\alpha}\\right] \\leq  \\frac {\\mathrm{E}\\left[e^{t Y}\\right]}{e^{t \\alpha}}\\tag{3}$$\n\néšå, å› ä¸º$Y=\\sum_{i=1}^{d} X_{i}^{2}$, è€Œ $X_i$ æ˜¯ç›¸äº’ç‹¬ç«‹çš„, æ‰€ä»¥æ±‚å’Œç¬¦å·å¯ä»¥æ¢åˆ°æ±‚æ•°å­¦æœŸæœ›çš„å¤–é¢å»:\n\n$$\\mathrm{E}\\left[e^{t Y}\\right]=\\mathrm{E}\\left[\\exp \\left(t \\sum_{i=1}^{d} X_{i}^{2}\\right)\\right]=\\prod_{i=1}^{d} \\mathrm{E}\\left[\\exp \\left(t X_{i}^{2}\\right)\\right]\\tag{4}$$\n\nå¯¹äº$\\mathrm{E}\\left[\\exp \\left(t X_{i}^{2}\\right)\\right]$, ç»“åˆ[å…³äºéšæœºå˜é‡å‡½æ•°çš„æœŸæœ›](notes/2021/2021.12/éšæœºå˜é‡å‡½æ•°çš„æœŸæœ›.md), æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªæœŸæœ›æŒ‰ç…§å®šä¹‰å±•å¼€:\n\n$$\\mathrm{E}(g(X))=\\int_{\\Omega} g(x) f(x) \\mathrm{d} x$$\n$$\\Rightarrow$$\n$$\\begin{aligned}\n\\mathrm{E}\\left[\\exp \\left(t X_{i}^{2}\\right)\\right]\n\u0026= \\int_{-\\infty}^{\\infty} \\exp \\left(t y^{2}\\right) f(y) d y\\qquad (å…¶ä¸­f(y)æ˜¯Xçš„æ¦‚ç‡å¯†åº¦å‡½æ•°)\\\\\n\u0026=\\int_{-\\infty}^{\\infty} \\exp \\left(t y^{2}\\right) \\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-y^{2} / 2\\right) d y\\\\\n\u0026=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} \\exp \\left(t y^{2}\\right) \\exp \\left(-y^{2} / 2\\right) d y\\\\\n\u0026=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} \\exp \\left(-y^{2}\\left(\\frac{1}{2}-t\\right)\\right) d y\\end{aligned}$$\n\nè§‚å¯Ÿä¸Šé¢çš„å¼å­, å¦‚æœ $t=0$, é‚£ä¹ˆè¿™ä¸ªå¼å­å°±æ˜¯ä¸€ä¸ªæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°åœ¨æ•´ä¸ªæ•°è½´ä¸Šé¢çš„ç§¯åˆ†, ç»“æœä¸º$1$. ä¸ºäº†è¾¾åˆ°ç›¸ä¼¼çš„æ•ˆæœ, æˆ‘ä»¬å¯ä»¥é€šè¿‡æ¢å…ƒå¾—åˆ°ä¸€ä¸ªç±»ä¼¼çš„å½¢å¼:\n\nä»¤$z=y \\sqrt{1-2 t}$, æœ‰:\n\n$$\\begin{aligned}\n\\mathrm{E}\\left[\\exp \\left(t X_{i}^{2}\\right)\\right] \n\u0026=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} \\exp \\left(\\frac{-(y \\sqrt{1-2 t})^{2}}2\\right) d y \\\\\n\u0026=\\frac{1}{\\sqrt{2 \\pi} \\sqrt{1-2 t}} \\int_{-\\infty}^{\\infty} \\exp \\left(-z^{2} / 2\\right) d z \\\\\n\u0026=\\frac{1}{\\sqrt{1-2 t}} \n\\end{aligned}$$\n\nç»“åˆ$(3), (4)$, å¯ä»¥å¾—åˆ°:\n$$\\begin{aligned}\n\\mathrm{E}\\left[e^{t Y}\\right]\u0026=\n\\prod_{i=1}^{d}\\mathrm{E}\\left[\\exp\\left(tX_i^{2}\\right) \\right]\\\\\n\u0026=(1-2 t)^{-d / 2}\n\\end{aligned}$$\n$$\\operatorname{Pr}[Y\u003e\\alpha] \\leq  \\frac {(1-2 t)^{-d / 2}}{e^{t \\alpha}}=e^{-t \\alpha}(1-2 t)^{-d / 2}$$\n\næ¥ä¸‹æ¥æˆ‘ä»¬åªéœ€è¦é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„ $t$ å³å¯, æˆ‘ä»¬ä»¤ $t=(1-d / \\alpha) / 2$ \n\n$$\\operatorname{Pr}[Y\u003e\\alpha] \\leq e^{-t \\alpha}(1-2 t)^{-d / 2}=e^{(d-\\alpha) / 2}(d / \\alpha)^{-d / 2}$$\n\nç°åœ¨æˆ‘ä»¬å¸¦å…¥$\\alpha=d(1+\\epsilon)^{2}$, å¾—åˆ°:\n$$\\exp \\left(\\frac{d}{2}\\left(1-(1+\\epsilon)^{2}\\right)-\\frac{d}{2} \\ln \\left(\\frac{1}{(1+\\epsilon)^{2}}\\right)\\right)\n=\\exp \\left(-d\\left(\\epsilon+\\epsilon^{2} / 2-\\ln (1+\\epsilon)\\right)\\right)$$\n\n%%æ³¨æ„æ‹¬å·é‡Œé¢çš„è¿™éƒ¨åˆ†: $\\epsilon+\\epsilon^{2} / 2-\\ln (1+\\epsilon)$%%\n\næˆ‘ä»¬çš„è¯æ˜ç›®æ ‡æ˜¯ $-(3 / 4) d \\epsilon^{2}=-d\\frac3 4\\epsilon^{2}$, æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦è¯æ˜:\n$$\\begin{aligned}\n-d\\left(\\epsilon+\\epsilon^{2} / 2-\\ln (1+\\epsilon)\\right)\u0026\\leq-d\\frac3 4\\epsilon^{2}\\\\\n\\epsilon+\\epsilon^{2} / 2-\\ln (1+\\epsilon)\u0026\\geq\\frac3 4\\epsilon^{2}\\\\\n(\\epsilon+\\epsilon^{2} / 2)-\\frac3 4\\epsilon^{2}\u0026\\geq\\ln (1+\\epsilon)\\\\\n\\epsilon-\\epsilon^{2} / 4\u0026\\geq\\ln (1+\\epsilon)\\\\\n\\end{aligned}$$\nå³å¯\n\nåˆ©ç”¨å‡½æ•°çš„å‡¹å‡¸æ€§, æˆ‘ä»¬å¯ä»¥è¯æ˜åœ¨$x \\in[0,1]$æœ‰ $\\ln (1+x) \\leq x-x^{2} / 4$\n\n\u003e ä¸¤è€…åœ¨0å–å€¼éƒ½æ˜¯0, ä¸€é˜¶å¯¼æ•°éƒ½æ˜¯1, äºŒé˜¶å¯¼æ•°$\\ln (1+x)$æ˜¯è´Ÿçš„, $x-x^{2} / 4$æ˜¯æ­£çš„.\n\nç»¼ä¸Š:\n$$\\operatorname{Pr}[Y\u003e\\alpha] \\leq \\exp \\left(-d\\left(\\epsilon+\\epsilon^{2} / 2-\\left(\\epsilon-\\epsilon^{2} / 4\\right)\\right)\\right) \\leq \\exp \\left(-(3 / 4) d \\epsilon^{2}\\right)$$\n\næˆ‘ä»¬å³è¯æ˜äº†Norm Preservation Lemma, ä»è€Œè¯æ˜äº†Johnson Lindenstrauss Lemma\n\n#### å¡æ–¹åˆ†å¸ƒçš„Chernoff Bound\næœ‰çš„è¯æ˜, æ¯”å¦‚ TTI (zotero://select/items/@shamkakade2009TTICMSC), MIT(zotero://select/items/@prof.ankurmoitra2016MIT854)è®²ä¹‰é‡Œé¢çš„è¯æ˜, éƒ½åº”ç”¨äº†Chi-Square Distributionçš„ä¸€ä¸ª[Chernoff Bounds](notes/2021/2021.12/Chernoff%20Bounds.md): \n\n\u003e Lemma 4 (Chernoff bound for chi-square distributions).\n\u003e $$\n\u003e \\begin{aligned}\n\u003e \u0026\\mathbb{P}\\left[\\sum_{i=1}^{k} Y_{i}^{2}\u003e(1+\\epsilon) k\\right] \\leq e^{-\\frac{k}{4}\\left(\\epsilon^{2}-\\epsilon^{3}\\right)} \\\\\n\u003e \u0026\\mathbb{P}\\left[\\sum_{i=1}^{k} Y_{i}^{2}\u003c(1-\\epsilon) k\\right] \\leq e^{-\\frac{k}{4}\\left(\\epsilon^{2}-\\epsilon^{3}\\right)}\n\u003e \\end{aligned}\n\u003e $$\n\u003e Now, we may set $k=O\\left(\\frac{\\log (1 / \\delta)}{\\epsilon^{2}}\\right)$ and get $\\|A x\\|_{2}^{2} {\\sim\\over1\\pm\\epsilon}\\|x\\|_{2}^{2}$ with probability at least $1-\\delta$.\n\nä½†æ˜¯Chernoff Boundçš„è¯æ˜å¾ˆå¤æ‚, æˆ‘è§‰å¾—UBCè¯¾ä»¶é‡Œé¢çš„è¯æ˜(å³ä¸Šé¢çš„è¯æ˜)æ›´å¥½.\n\n\n[^1]: [The Johnson-Lindenstrauss Lemma. Why you donâ€™t always need all of yourâ€¦ | by Haris Angelidakis | Cantorâ€™s Paradise](https://www.cantorsparadise.com/the-johnson-lindenstrauss-lemma-3058a123c6c) This is actually from a Presentation slides of Laurent Jacques.\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Markovs-and-Chebyshevs-Inequalities":{"title":"Markov's and Chebyshev's Inequalities","content":"# Markov and Chebyshev Inequalities\n\n\u003cdiv align=\"right\"\u003e 2021-12-04\u003c/div\u003e\n\nTags: #Math/Statistics \n\nFileLink(zotero://select/items/@InequalitiesMarkov) \n\n## Markov's Inequality\n $X$ æ˜¯ä¸€ä¸ªéè´Ÿçš„éšæœºå˜é‡. å¯¹äºä»»æ„æ­£å®æ•° $a$ , æœ‰\n$$\nP(X \\geq a) \\leq \\frac{E(X)}{a}\n$$\n\n### Proof\n- è¯æ˜é‡Œæˆ‘ä»¬å‡è®¾$X$æ˜¯ç¦»æ•£éšæœºå˜é‡, å¯¹äºè¿ç»­éšæœºå˜é‡åªéœ€è¦å°†æ±‚å’Œå˜æˆæ±‚ç§¯åˆ†å³å¯.\n\næŒ‰ç…§å®šä¹‰, $E(X)=\\sum_{x} x P(X=x)$. We'll split this sum into two pieces, depending on whether or not $x \\geq a$.\n$$\n\\begin{aligned}\nE(X) \u0026=\\sum_{x \\geq a} x P(X=x)+\\sum_{x\u003ca} x P(X=x) \\\\\n\u0026 \\geq \\sum_{x \\geq a} a P(X=x)+0 \\quad(\\text { since in the first sum we assume } x \\geq a) \\\\\n\u0026=a \\sum_{x \\geq a} P(X=x) \\\\\n\u0026=a P(X \\geq a)\n\\end{aligned}\n$$\n\n## Chebyshev's Inequality\nLet $X$ be any random variable with finite expected value and variance. Then for every positive real number a,\n$$\nP(|X-E(X)| \\geq a) \\leq \\frac{\\operatorname{Var}(X)}{a^{2}} .\n$$\n\n### Proof\nWe can prove it using Markov's Inequality:\n\nLet $Y=(X-E(X))^{2}$. Recall the definition of the variance of $X$:\n$$\\operatorname{Var}(X)=\\mathrm{E}\\left[(X-E(X))^{2}\\right]$$\n\nThen $Y$ is a non-negative valued random variable with expected value $E(Y)=\\operatorname{Var}(X)$. By Markov's inequality,\n$$\nP\\left(Y \\geq a^{2}\\right) \\leq \\frac{E(Y)}{a}=\\frac{\\operatorname{Var}(X)}{a^{2}} .\n$$\nBut notice that the event $Y \\geq a^{2}$ is the same as $|X-E(X)| \\geq a$, so we conclude that\n$$\nP(|X-E(X)| \\geq a) \\leq \\frac{\\operatorname{Var}(X)}{a^{2}}\n$$\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Maximum_Likelihood_Estimation-%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1":{"title":"Maximum_Likelihood_Estimation-æå¤§ä¼¼ç„¶ä¼°è®¡","content":"# æå¤§ä¼¼ç„¶ä¼°è®¡ MLE\n\n\u003cdiv align=\"right\"\u003e 2021-12-25\u003c/div\u003e\n\nTags: #MachineLearning #Math/Statistics \n\nLinks: [Likelihood_Function-ä¼¼ç„¶å‡½æ•°](notes/2022/2022.2/Likelihood_Function-ä¼¼ç„¶å‡½æ•°.md)\n\nå‡è®¾æ ·æœ¬ $X$ æœä»å·²çŸ¥çš„æ¦‚ç‡åˆ†å¸ƒ(æ¯”å¦‚æ­£æ€åˆ†å¸ƒ)\n- **æå¤§ä¼¼ç„¶ä¼°è®¡**å°±æ˜¯è¦æ‰¾ä¸€ä¸ªå‚æ•° $\\hat\\theta$,  ä½¿ä¼¼ç„¶å‡½æ•° $\\mathcal{L}(\\theta \\mid X)$ å–å¾—æœ€å¤§å€¼$$i.e.\\quad \\hat{\\theta}=\\operatorname{argmax}_{\\theta \\in \\Theta} \\mathcal{L}(\\theta \\mid X)$$\n- æå¤§ä¼¼ç„¶ä¼°è®¡è®¤ä¸º: æœ€ä½³çš„å‚æ•° $\\hat\\theta$ æœ€å¯èƒ½ä½¿å–æ ·ç»“æœä¸ºç°åœ¨çš„ $x$, ä¹Ÿå°±æ˜¯è¯´, æ¦‚ç‡$P(X=x\\mid \\theta)$æœ€å¤§:\n$$\\hat{\\theta}=\\operatorname{argmax}_{\\theta \\in \\Theta} P(X=x\\mid \\theta)$$\n\t\n\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Moment-Generating-Function-MGF":{"title":"Moment Generating Function-MGF","content":"# Moment Generating Function - MGF\n\n\u003cdiv align=\"right\"\u003e 2021-12-04\u003c/div\u003e\n\nTags: #Math/Statistics \n\n\n- **This article covers it all.**\n[Moment Generating Function Explained | by Aerin Kim | Towards Data Science](https://towardsdatascience.com/moment-generating-function-explained-27821a739035)\n\n\n- The moments are the expected values of $X$, e.g., $E(X), E(X^2), E(X^3)$, â€¦ etc.\n\n- what is Moment Generating Function (MGF)?\n\tAs its name hints, MGF is literally the function that generates the moments â€” **E(X), E(XÂ²), E(XÂ³), â€¦ , E(X^n).**\n\t\n- $M_{X}(t)=\\mathbb{E}\\left(e^{t X}\\right)$\n\n- ä»MGFå¾—åˆ°ç›¸åº”çš„Momentåªéœ€è¦å–å¯¼æ•°\n![](notes/2021/2021.12/assets/img_2022-10-15.png)","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/OS-12-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86":{"title":"OS-12-å†…å­˜ç®¡ç†","content":"# å†…å­˜ç®¡ç†\n\n\u003cdiv align=\"right\"\u003e 2021-12-11\u003c/div\u003e\n\nTags: #OperatingSystem/Memory\n\nç¨‹åºè¿è¡Œä¸ä»…éœ€è¦å¤„ç†æœº, è¿˜éœ€è¦æœ‰åœ°æ–¹æ¥ä¿å­˜ä»£ç ä¸æ•°æ®, è¿™ä¸€èŠ‚æˆ‘ä»¬è°ˆè®ºè®¡ç®—æœºåœ¨è¿è¡Œæ—¶, è¿™äº›è¿™äº›æ•°æ®æ˜¯å¦‚ä½•ç®¡ç†çš„.\n\n## ç›®æ ‡\n- ç”µè„‘çš„å†…å­˜æ€»æ˜¯æœ‰é™çš„, æˆ‘ä»¬æƒ³è¦ç”¨æœ‰é™çš„å†…å­˜æ»¡è¶³æ›´å¤šçš„ç¨‹åºçš„éœ€è¦, å¹¶ä¸”è¿˜æƒ³è¿™äº›ç¨‹åºè¿è¡Œå¾—è¶Šå¿«è¶Šå¥½.\n- åœ¨å®¹é‡ä¸Š, ä¸ºäº†è¥é€ ä¸€ä¸ªå†…å­˜\"æ— é™å¤§\"çš„å‡è±¡, æˆ‘ä»¬å¯ä»¥ä»\"å¼€æº\", \"èŠ‚æµ\"ä¸¤æ–¹é¢æ¥å…¥æ‰‹: \n\t- èŠ‚æµå°±æ˜¯è¦å‡å°‘ä¸å¿…è¦çš„å†…å­˜æµªè´¹. åˆ†æ®µæŠŠç¨‹åºåˆ†æˆå¤§å°ä¸åŒçš„æ®µ, é¿å…äº†ç¨‹åºå†…éƒ¨å¤§æ®µçš„ç©ºç™½. åˆ†é¡µåˆ™æŠŠç¨‹åºåˆ†æˆå¤§å°ç›¸åŒçš„é¡µ, åœ¨å‡å°‘å†…éƒ¨ç¢ç‰‡çš„åŒæ—¶ä¾¿äºç®¡ç†.\n\t\t- åˆ†é¡µç®¡ç†è¿›ä¸€æ­¥å¸¦æ¥äº†é¡µè¡¨è¿‡å¤§çš„é—®é¢˜: ä¸€ä¸ªè¿›ç¨‹å®Œæ•´åœ°å€ç©ºé—´çš„é¡µè¡¨æœ¬èº«ä¹Ÿå¯èƒ½æœ‰å¤§æ®µçš„ç©ºç™½. è¿™å‚¬ç”Ÿäº†å¯¹åˆ†æ®µå’Œåˆ†é¡µçš„ç»“åˆ: æ®µé¡µæ³•é€šè¿‡å¯¹é¡µè¡¨è¿›è¡Œåˆ†æ®µæ¥å‡å°‘é¡µè¡¨çš„å¤§å°. å½“ç„¶, æˆ‘ä»¬ä¹Ÿå¯ä»¥å¯¹é¡µè¡¨å†æ¬¡è¿›è¡Œåˆ†é¡µ, ç”¨å¤šçº§é¡µè¡¨æ¥è§£å†³è¿™ä¸ªé—®é¢˜.\n\t- å¼€æºåˆ™æ˜¯å°†ä¸å¸¸ç”¨çš„å†…å­˜æ•°æ®æš‚æ—¶å­˜å‚¨åœ¨ç£ç›˜, æ¥æ‰©å±•å†…å­˜çš„å¤§å°. è™šæ‹Ÿå†…å­˜åšåˆ°äº†è¿™ä¸€ç‚¹.\n- åœ¨é€Ÿåº¦ä¸Š, ä»¥ä¸Šç®¡ç†å†…å­˜çš„æ–¹æ³•éƒ½å¢åŠ äº†ç³»ç»Ÿçš„å¤æ‚æ€§, åœ°å€å˜æ¢ç­‰å·¥ä½œå‡æ…¢äº†è°ƒç”¨å†…å­˜æ•°æ®çš„é€Ÿåº¦. \n\t- åœ¨åˆ†é¡µé‡Œé¢, æˆ‘ä»¬å¯ä»¥å¢è®¾Cache, ç”¨TLBä¿å­˜æ›¾ç»ä½¿ç”¨è¿‡çš„åœ°å€å˜æ¢ç»“æœ, å‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°. \n\t- åœ¨è™šæ‹Ÿå†…å­˜é‡Œé¢, æˆ‘ä»¬å¯ä»¥è®¾ç½®é«˜ä½æ°´ä½çº¿, åœ¨åå°ä¸»åŠ¨åœ°é‡Šæ”¾ä¸€äº›å†…å­˜(åˆ°ç£ç›˜), é¿å…é‡è¦è¿›ç¨‹åœ¨è¿è¡Œæ—¶è§¦å‘Page Fault, é€ æˆæ—¶é—´çš„å¤§é‡æµªè´¹.\n\n### éšä¹‹è€Œæ¥çš„é—®é¢˜\nåˆ†é…é—®é¢˜ä¸æ›¿æ¢é—®é¢˜æ˜¯åœ¨è¿›è¡Œå†…å­˜ç®¡ç†æ—¶éœ€è¦å¤„ç†çš„å…±æ€§é—®é¢˜:\n\n- åˆ†é…é—®é¢˜å°±æ˜¯å¯¹äºæœ‰é™èµ„æº(ç©ºé—²å†…å­˜)çš„ç®¡ç†ä¸åˆ†é…. \n\t- ä¸å‡åŒ€åœ°åˆ†é…å†…å­˜ç©ºé—´ä¼šå¸¦æ¥å¤–éƒ¨ç¢ç‰‡, Best Fit / Worst Fit / First Fit / Next Fit ... å°±æ˜¯ä¸€äº›åŒ¹é…ç®—æ³•, æƒ³è¦å°½å¯èƒ½åˆç†åœ°åˆ†é…ç©ºé—²ç©ºé—´. \n\t- æ—¶ä¸æ—¶åœ°æ•´ç†å†…å­˜ç©ºé—´, è¿›è¡Œç©ºé—´å½’å¹¶ä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ–¹æ³•, ä½†æ˜¯å®ƒçš„å¼€é”€å¾ˆå¤§. \n\t- é™¤æ­¤ä»¥å¤–, æˆ‘ä»¬è¿˜å¯ä»¥ä»æ•°æ®ç»“æ„çš„è§’åº¦å…¥æ‰‹: é“¾è¡¨æ˜¯ç®¡ç†ç©ºé—²ç©ºé—´æœ€ç®€å•çš„æ–¹æ³•, ä½†åƒæ˜¯\"Binary Buddy Allocator\", å¹³è¡¡äºŒå‰æ ‘ç­‰æ–¹æ³•å¯ä»¥å¢åŠ æŸ¥æ‰¾ç©ºé—²ç©ºé—´çš„é€Ÿåº¦, å¢åŠ ç³»ç»Ÿçš„å¯æ‹“å±•æ€§, ä¹Ÿå¯ä»¥æ›´å¥½åœ°ç®¡ç†å†…å­˜.\n- æ›¿æ¢é—®é¢˜å°±æ˜¯æœ‰é™èµ„æº(å†…å­˜, TLB)å·²ç»è¢«å¡æ»¡æ—¶, è¯¥è¸¢å‡ºå“ªä¸ªæ—§å•å…ƒ, ä»è€Œå‘¨è½¬è¿›æ–°çš„å•å…ƒ.\n\t- è¿™ç±»é—®é¢˜çš„ä¸€ä¸ªå…¸å‹åœºæ™¯å°±æ˜¯æŸä¸ªå…ƒç´ å¯ä»¥åœ¨ä¸¤ä¸ªåœ°æ–¹å‘¨è½¬: ä¸€ä¸ªåœ°æ–¹å°è€Œå¿«, å¦ä¸€ä¸ªåœ°æ–¹å¤§è€Œæ…¢. (E.g. Register\u0026Memory, Cache(TLB)\u0026SlowerMemory, Memory\u0026Disk)\n\t- æ›¿æ¢ç®—æ³•æœ‰å¾ˆå¤š: FIFO, éšæœºæ–¹æ³•, LRU(Least Recently Used), LFU(Least Frequently Used), è¿‘ä¼¼LRUç­‰ç­‰\n\t- åœ¨è™šæ‹Ÿå­˜å‚¨é‡Œé¢è¿™æ˜¯ä¸€ä¸ªå¾ˆé‡è¦çš„é—®é¢˜, å› ä¸ºç£ç›˜å®åœ¨æ˜¯å¤ªæ…¢äº†, ç½®æ¢ç®—æ³•çš„æ€§èƒ½æå‡å¸¦æ¥çš„æ”¶ç›Šæ˜¯å¾ˆå¯è§‚çš„.\n\n- å¤šçº§çš„æ€æƒ³: å­˜å‚¨å™¨å±‚æ¬¡ç»“æ„, åº”å½“é˜…è¯»\u003cè®¡ç®—æœºç»„æˆä¸è®¾è®¡ï¼šç¡¬ä»¶ã€è½¯ä»¶æ¥å£\u003eç¬¬äº”ç« .\n- ç¨‹åºåœ¨è¿è¡Œæ—¶çš„å±€éƒ¨æ€§åŸç†æ˜¯ä¸Šé¢å¾ˆå¤šæ–¹æ³•çš„åŸºç¡€, å±€éƒ¨æ€§åŸç†åˆ†ä¸ºç©ºé—´å±€éƒ¨æ€§å’Œæ—¶é—´å±€éƒ¨æ€§.\n\n- å¹¶ä¸”, æˆ‘ä»¬åšçš„æ‰€æœ‰å†…å­˜ç®¡ç†å·¥ä½œéƒ½è¦å°½å¯èƒ½å¯¹ç¨‹åº(å‘˜)é€æ˜, åœ¨è¿è¡Œç¨‹åºçš„æ—¶å€™, æˆ‘ä»¬ä¸æƒ³è€ƒè™‘å¤ªå¤šä»¤äººå¤´ç–¼çš„å†…å­˜ç®¡ç†é—®é¢˜\n\n\n\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Ring-Hollow":{"title":"Ring Hollow","content":"# ring/sound hollow\n\n# English\n\n- If something someone says rings hollow, it does not sound true or sincere.\n- æ˜¾å¾—è™šå‡ï¼Œå¬èµ·æ¥ä¸è¯šæ³\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Sliver-Bullet":{"title":"Sliver Bullet","content":"# Silver bullet\n\n# English\n\n- a simple solution to a complicated problem\n- é“¶å¼¹ï¼ˆæŒ‡é’ˆå¯¹å¤æ‚é—®é¢˜çš„ç®€å•è§£å†³åŠæ³•ï¼‰ï¼Œè‰¯æ–¹ï¼Œé«˜æ‹›\n\nIn folklore, a bullet cast from silver is often one of the few weapons that are effective against a werewolf or witch. The term silver bullet is also a metaphor for a simple, seemingly magical, solution to a difficult problem: for example, penicillin circa 1930 was a \"silver bullet\" that allowed doctors to treat and successfully cure many bacterial infections.\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Understanding-Bayes-Theorem":{"title":"Understanding Bayes' Theorem","content":"# Understanding Bayes' Theorem\n\n\u003cdiv align=\"right\"\u003e 2021-12-19\u003c/div\u003e\n\nTags: #Math/Probability #Bayes\n\n- å•ä»å½¢å¼ä¸Šæ¥è¯´, Bayeså®šç†æ˜¯ååˆ†ç®€å•çš„. ä½†æ˜¯å¦‚æœæˆ‘ä»¬ç»“åˆå®é™…é—®é¢˜ä¸ä¸€ç‚¹å‡ ä½•ç›´è§‰, Bayeså®šç†å¯ä»¥ä»ä¸¤ä¸ªç‹¬ç‰¹çš„è§’åº¦æ¥ç›´è§‚ç†è§£:\n\n\n\t- **Update of Prior Beliefs \u0026 Change of Perspective**\n\n## Bayes' Theorem: Statement\n$$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}$$\n- å…¶ä¸­$P(A \\mid B)$ä¹Ÿç§°ä¸ºAçš„**åéªŒæ¦‚ç‡**(**posterior probability of A given B**), å› ä¸ºæˆ‘ä»¬å·²ç»çŸ¥é“äº†B.\n- è€Œ$P(A)$ç§°ä¸ºAçš„**å…ˆéªŒæ¦‚ç‡** (**prior probability or marginal probability**), å› ä¸ºæˆ‘ä»¬æ²¡æœ‰åŠ ä»»ä½•æ¡ä»¶.\n\nBayeså®šç†è¿˜æœ‰ä¸åŒçš„å½¢å¼:\n- æˆ‘ä»¬å¯ä»¥æŠŠ$P(B)$æ‹†å¼€:\n$$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B \\mid A) P(A)+P(B \\mid \\neg A) P(\\neg A)}$$\n\n- ä»æ¡ä»¶æ¦‚ç‡(Conditional Probability)çš„è§’åº¦æ¥ç†è§£, åˆ†å­ä¹Ÿå¯ä»¥æ›¿æ¢ä¸º$P(A\\cap B)$:\n$$P(A \\mid B)=\\frac{P(A\\cap B)}{P(B)}$$\nè¿™å…¶å®å°±æ˜¯æ¡ä»¶æ¦‚ç‡çš„å®šä¹‰.\n\n## Bayes' Theorem: Counter-intuitive Side\nè¿™äº›ç§‘æ™®è§†é¢‘éƒ½é›†ä¸­å±•ç°äº†Bayeså®šç†çš„åç›´è§‰çš„ä¸€é¢:\n- [How To Update Your Beliefs Systematically - Bayesâ€™ Theorem - YouTube](https://www.youtube.com/watch?v=R13BD8qKeTg)\n- [Bayes theorem, the geometry of changing beliefs - YouTube](https://www.youtube.com/watch?v=HZGCoVF3YvM)\n- [The medical test paradox, and redesigning Bayes' rule - YouTube](https://www.youtube.com/watch?v=lG4VkPoG3ko)\n\n[Wikipedia: ä¸€ä¸ªç±»ä¼¼çš„ä¾‹å­: å¸æ¯’è€…æ£€æµ‹](https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86#%E5%90%B8%E6%AF%92%E8%80%85%E6%A3%80%E6%B5%8B)\n\nBayeså®šç†ä¸ºä»€ä¹ˆåœ¨ä¸Šé¢çš„ä¾‹å­é‡Œé¢ä¼šç»™å‡ºåç›´è§‰çš„ç»“è®º?\nå› ä¸ºå³ä½¿è¯¯æ£€ç‡å¾ˆä½, è¦æ˜¯åŸºæ•°å¾ˆå¤§çš„è¯, å‘ˆé˜³æ€§çš„äººé‡Œé¢ä¹Ÿä¼šæœ‰å¾ˆå¤§ä¸€éƒ¨åˆ†æ˜¯æ‚£ç—…çš„äºº, æ‰€ä»¥å³ä½¿æ£€å‡ºäº†é˜³æ€§, å®é™…æ‚£ç—…çš„æ¦‚ç‡è¿˜æ˜¯å¾ˆå°çš„:\n![400](notes/2021/2021.12/assets/img_2022-10-15-2.png)\nè¦æƒ³æé«˜æ£€å‡ºæ­£ç¡®é˜³æ€§çš„æ¦‚ç‡, å°±åº”è¯¥å‡å°\"å¥åº·çš„äººæ£€å‡ºä¸ºé˜³æ€§çš„æ¦‚ç‡(Specificity)\"\n\n\u003e ä¸€ä¸ªæ£€æµ‹æ–¹æ³•çš„æ­£ç¡®ç‡å…¶å®éœ€è¦ä¸¤ä¸ªæŒ‡æ ‡æ¥è¡¡é‡:\n\u003e - **æ•æ„Ÿåº¦(Sensitivity)**: å¯¹äºæ‚£ç—…è€…, æœ‰å¤šå¤§æ¦‚ç‡æ£€å‡ºtaä¸ºæ‚£ç—…çš„(True Positive Rate)\n\u003e - **æ˜ç¡®åº¦(Specificity)**: å¯¹äºå¥åº·çš„äºº, æœ‰å¤šå¤§æ¦‚ç‡èƒ½æ­£ç¡®å¾—å‡ºtaä¸ºå¥åº·çš„(True Negative Rate)\n\n![400](notes/2021/2021.12/assets/img_2022-10-15-3.png)\n## Bayes' Theorem: Intuitive Geometry Representation\n\n- é¦–å…ˆ, æˆ‘ä»¬éœ€è¦æ³¨æ„å…¶å®\"æ¡ä»¶æ¦‚ç‡çš„è¡¨ç¤ºæ–¹æ³•\"è®©è´å¶æ–¯å®šç†æ²¡æœ‰é‚£ä¹ˆç›´è§‚äº†:\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9wCnvr7Xw4E?start=699\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n### Geometry Representation:\n\n![500](notes/2021/2021.12/assets/img_2022-10-15-4.png)\n- æˆ‘ä»¬å¯ä»¥ç”¨ä¸Šå›¾æ¥å½¢è±¡åœ°è¯´æ˜è´å¶æ–¯å®šç†çš„ç»„æˆ.\n\n- ä¸ºäº†å¾—åˆ°ä¸Šå›¾, é¦–å…ˆæˆ‘ä»¬å°†Açš„æ¦‚ç‡åˆ†å¸ƒ$P(A)$å’Œ$P(\\neg A)$è¡¨ç¤ºåˆ°ä¸€ä¸ªæ­£æ–¹å½¢é‡Œé¢:\n![250](notes/2021/2021.12/assets/img_2022-10-15-5.png)\nè¿™ä¸ªæ­£æ–¹å½¢è¾¹é•¿ä¸º1, æ»¡è¶³$P(A)+P(\\neg A)=1$\n\n- åŒæ ·, å¯¹äºäº‹ä»¶Bçš„æ¦‚ç‡åˆ†å¸ƒ, æˆ‘ä»¬ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸ªæ­£æ–¹å½¢:\n![250](notes/2021/2021.12/assets/img_2022-10-15-6.png)\n\n- å¦‚æœ$A, B$æ˜¯ç›¸äº’ç‹¬ç«‹çš„, é‚£ä¹ˆå®ƒä»¬çš„æ¦‚ç‡åˆ†å¸ƒå¯ä»¥è¡¨ç¤ºä¸º:\n![250](notes/2021/2021.12/assets/img_2022-10-15-7.png)\næœ‰$P(AB)=P(A)P(B)$\n\n- ä½†æ˜¯å¦‚æœ$A,B$æ˜¯ç›¸å…³çš„, åˆè¯¥æ€ä¹ˆè¡¨ç¤ºå®ƒä»¬çš„æ¦‚ç‡åˆ†å¸ƒå‘¢?\n\t- è‹¥$A,B$æ˜¯ç›¸å…³çš„, è¯´æ˜å¦‚æœæˆ‘ä»¬çŸ¥é“äº†$A$, é‚£ä¹ˆ$B$çš„æ¦‚ç‡åˆ†å¸ƒä¼šå› ä¸º$A$çš„å–å€¼çš„ä¸åŒè€Œä¸åŒ:\n\t\t\t![](notes/2021/2021.12/assets/img_2022-10-15-8.png)\n\t\t- åœ¨ä¸Šå›¾ä¸­, $A=1$çš„æ—¶å€™, Bçš„æ¦‚ç‡ä¸Šå‡äº†, $A=0$çš„æ—¶å€™, Bçš„æ¦‚ç‡ä¸‹é™äº†.\n\t\t - æ­¤æ—¶é˜´å½±éƒ¨åˆ†çš„é¢ç§¯ä¹‹å’Œè¡¨ç¤º$P(B)=P(B\\mid A)P(A)+P(B\\mid\\neg A)P(\\neg A)$\n\t\t - æ³¨æ„Båœ¨å·¦å³çš„æ¦‚ç‡åˆ†å¸ƒå˜åŒ–ä¸ä¸€å®šè¦ä¸€ä¸ªä¸Šå‡ä¸€ä¸ªä¸‹é™, å®ƒä»¬çš„å˜åŒ–æ˜¯å®Œå…¨æ— å…³çš„. å®ƒä»¬å¯ä»¥éƒ½ä¸Šå‡æˆ–è€…éƒ½ä¸‹é™:\n\t\t ![](notes/2021/2021.12/assets/img_2022-10-15-9.png) \n\t\t è¿™æ ·, æˆ‘ä»¬å°±ç”¨å‡ ä½•ç›´è§‚è¡¨è¾¾äº†ä¸¤ä¸ªç›¸å…³å˜é‡çš„æ¦‚ç‡åˆ†å¸ƒ. æ¯ä¸€ä¸ªå°é•¿æ–¹å½¢éƒ½ä»£è¡¨äº†ä¸€ç§ABçš„å–å€¼æƒ…å†µ.\n\n- é‚£ä¹ˆ, Bayeså®šç†æ€æ ·ä»å›¾å½¢é‡Œé¢å¾—åˆ°å‘¢?\n\tå°†å°é•¿æ–¹å½¢ä¸æ¦‚ç‡å¯¹åº”èµ·æ¥, æˆ‘ä»¬æœ‰:\n![400](notes/2021/2021.12/assets/img_2022-10-15-10.png)\n\n## Update of Prior Beliefs\n- ç°åœ¨æˆ‘ä»¬èƒ½å¤Ÿç”¨Update of Informationçš„è§‚ç‚¹æ¥çœ‹å¾…Bayeså®šç†äº†, åœ¨ä¸Šé¢çš„å›¾åƒé‡Œé¢, æˆ‘ä»¬å‡è®¾äº‹ä»¶Aä»£è¡¨æ‚£ç—…, äº‹ä»¶Bä»£è¡¨æ£€æµ‹ä¸ºé˜³æ€§. \n\t- åœ¨æˆ‘ä»¬è¿˜æ²¡æœ‰è¿›è¡Œæ£€æµ‹çš„æ—¶å€™, æˆ‘ä»¬å¯¹äºæ‚£ç—…çš„ç†è§£æ¦‚ç‡çš„ç†è§£æ˜¯è¿™æ ·çš„;\n\t\t![200](notes/2021/2021.12/assets/img_2022-10-15-5.png)\n\t- ä½†æ˜¯ç°åœ¨è¿›è¡Œäº†æ£€æµ‹B, æ„å‘³ç€æˆ‘ä»¬å¯¹äºæ˜¯å¦æ‚£ç—…æœ‰äº†æ›´å¤šçš„ä¿¡æ¯. å½“æˆ‘ä»¬å†æ¬¡è®¡ç®—æ‚£ç—…æ¦‚ç‡çš„æ—¶å€™, æˆ‘ä»¬åº”è¯¥æ›´æ–°ä¹‹å‰çš„è®¤è¯†, åœ¨æ–°çš„å›¾å½¢ä¸Šé¢è®¡ç®—æ‚£ç—…çš„åéªŒæ¦‚ç‡:\n\t- ![400](notes/2021/2021.12/assets/img_2022-10-15-10.png)\n\nä¸‹é¢è¿™ä¸ªè§†é¢‘ç‰‡æ®µä¹Ÿè®¸è§£é‡Šçš„æ›´æ¸…æ¥šä¸€ç‚¹:\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HZGCoVF3YvM?start=60\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­, æˆ‘ä»¬æ¯å¤©éƒ½åœ¨åšå¤§å¤§å°å°çš„å†³å®š. åœ¨å¤§éƒ¨åˆ†æƒ…å†µä¸‹, æˆ‘ä»¬éƒ½ä¼šç»¼åˆæƒè¡¡\"è¿‡å»çš„ç»éªŒ\"å’Œ\"å½“ä¸‹çš„å…·ä½“æƒ…å†µ\", ç„¶ååšå‡ºä¸€ä¸ª\"æœ€ä½³\"çš„å†³å®š.\n- å…¶å®æˆ‘ä»¬è¿‡å»çš„\"ç»éªŒ\"å°±ç›¸å½“äºå…ˆéªŒæ¦‚ç‡$P(A)$, è€Œå…·ä½“æƒ…å†µå°±æ˜¯æ–°å‡ºç°çš„äº‹ä»¶$B$. ç»¼åˆæƒè¡¡çš„è¿‡ç¨‹å°±æ˜¯åœ¨çœ‹è¿™ä¸ªæ–°å‡ºç°çš„äº‹ä»¶Bå¯¹äºæˆ‘ä»¬è¿‡å»çš„ç»éªŒäº§ç”Ÿäº†æ€æ ·çš„å½±å“(æ±‚åéªŒæ¦‚ç‡$P(A\\mid B)$)\n\n\n\n## Change of Perspective\n- ä¸‹é¢è¿™ä¸ªè§‚ç‚¹æ˜¯æˆ‘è‡ªå·±æ¢ç´¢å‡ºæ¥çš„, è¿™ä¸ªè§‚ç‚¹ä¾§é‡äºä»ä¸ªä½“è§’åº¦ä¸Šæ¥ç†è§£Bayeså®šç†:\n\n- é¦–å…ˆæˆ‘ä»¬éœ€è¦ä»‹ç»æ¦‚ç‡åˆ†å¸ƒçš„ç¬¬äºŒä¸ªè¡¨ç¤ºæ–¹æ³•.\n\t- å‰é¢æˆ‘ä»¬å°†$A, B$çš„æ¦‚ç‡åˆ†å¸ƒè¡¨ç¤ºä¸ºä¸‹å›¾çš„å½¢å¼:\n\t\t![300](notes/2021/2021.12/assets/Pasted%20image%2020211219225436.png)\n\t\tè§‚å¯Ÿè¿™ä¸ªå›¾, æˆ‘ä»¬å¯ä»¥çœ‹åˆ°Açš„æ¦‚ç‡åˆ†å¸ƒè¡¨ç¤ºå¾ˆç®€å•, ä½†æ˜¯Bçš„æ¦‚ç‡åˆ†å¸ƒè¡¨ç¤ºå¾ˆå¤æ‚.\n\t\tæˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºæˆ‘ä»¬å…ˆçŸ¥é“äº†Açš„æ¦‚ç‡åˆ†å¸ƒ, ç„¶åå†åœ¨æ­¤åŸºç¡€ä¸Šæ·»åŠ äº†B(ä»ä¸‹å‘ä¸Šçœ‹):\n\t\t![300](notes/2021/2021.12/assets/Pasted%20image%2020211219225601.png)\n- è¿™æ˜¾ç„¶å¯¹äºBæ˜¯ååˆ†ä¸å…¬å¹³çš„, æˆ‘ä»¬ç”¨å¯ä»¥ç±»ä¼¼çš„æ€è·¯å˜åŒ–ä¸€ä¸‹è¡¨ç¤ºæ–¹æ³•:\n\t![230](notes/2021/2021.12/assets/Pasted%20image%2020211219225717.png)\n\tæ³¨æ„å›¾åƒé‡Œé¢æ¯ä¸ªå°é•¿æ–¹å½¢ä»ç„¶å¯¹åº”ä¸åŒæƒ…å†µä¸‹çš„æ¦‚ç‡, åªæ˜¯å½¢çŠ¶å˜äº†, é¢ç§¯æ²¡æœ‰å˜.\n\t- æˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºå…ˆç¡®å®šäº†B, ç„¶åå†æ·»åŠ äº†Açš„æ¦‚ç‡åˆ†å¸ƒ:\n\t\t![300](notes/2021/2021.12/assets/Pasted%20image%2020211219225838.png)\n\t\t\nå¯¹æ¯”ä¸€ä¸‹ä¸¤ä¸ªè¡¨ç¤º:\n![](notes/2021/2021.12/assets/Pasted%20image%2020211219230041.png)\n- å¯¹äºå·¦è¾¹çš„å›¾, æˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºä¸€ç§\"æ€»ä½“çš„è§’åº¦\". å³å¯¹äºä¸€å¤§ç¾¤äºº, æœ‰æ‚£ç—…çš„, ä¹Ÿæœ‰ä¸æ‚£ç—…çš„, è€Œåæ¥åŠ å…¥çš„Bçš„æ¦‚ç‡åˆ†å¸ƒè§£é‡Šäº†è¿™ä¸ªæ£€æµ‹æ–¹æ³•å¯¹äºä¸åŒæƒ…å†µçš„äººç¾¤çš„æ•ˆæœ.\n- å¯¹äºå³è¾¹çš„å›¾, æˆ‘ä»¬è¿™å¯ä»¥ç†è§£ä¸ºä¸€ç§\"ä¸ªä½“çš„è§’åº¦\", å³å¯¹äºä¸€ä¸ªäºº, taåšäº†æ£€æµ‹åè¦ä¹ˆä¸ºé˜³æ€§è¦ä¹ˆä¸ºé˜´æ€§, æ²¡æœ‰å…¶ä»–æƒ…å†µ, è€Œåæ¥åŠ å…¥çš„Açš„åˆ†å¸ƒç»™å‡ºäº†è¿™ä¸ªäººä¸åŒæ£€æµ‹ç»“æœçš„æ‚£ç—…æ¦‚ç‡.\n\n- è€ŒBayes' Theoremå°±æ˜¯åœ¨è¿™ä¸¤ç§è§†è§’ä¹‹é—´è½¬æ¢çš„æ–¹å¼.\n\nç°åœ¨æˆ‘ä»¬æ¥è§‚å¯ŸBayesçš„å…¬å¼:\n$$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}$$\nå¦‚æœä½ å»åšäº†ç™Œç—‡æ£€æŸ¥, å¾—åˆ°äº†é˜³æ€§ç»“æœ(äº‹ä»¶B), é‚£ä¹ˆä½ ä¸€å®šå¾ˆæƒ³çŸ¥é“ä½ çœŸçš„æœ‰ç™Œç—‡çš„æ¦‚ç‡æœ‰å¤šå¤§ (å³æ¦‚ç‡$P(A\\mid B)$ ). ç”¨å³è¾¹çš„å›¾æ¥ç†è§£, å³ä½ å·²ç»ç¡®å®šBå‘ç”Ÿäº†, å¯ä»¥åªå…³æ³¨å›¾ç‰‡çš„ä¸‹åŠéƒ¨åˆ†: \n![450](notes/2021/2021.12/assets/Pasted%20image%2020211219230710.png)\n\nè€Œæˆ‘ä»¬å¸¸å¸¸è¿™æ ·è®¡ç®—$P(A\\mid B)$:\n$$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B \\mid A) P(A)+P(B \\mid \\neg A) P(\\neg A)}$$\nå…¶ä¸­$P(A), P(B \\mid A), P(B \\mid \\neg A)$åˆ†åˆ«è¡¨ç¤ºç–¾ç—…çš„å‘ç”Ÿç‡, æ£€æµ‹æ–¹æ³•çš„Sensitivityå’ŒSpecificity, è®¡ç®—æ—¶é€šå¸¸å®ƒä»¬éƒ½æ˜¯å·²çŸ¥çš„æˆ–è€…å¯ä»¥ä½¿ç”¨é¢‘ç‡è¿‘ä¼¼ä»£æ›¿æ¦‚ç‡.\n- ç”¨å›¾å½¢è¡¨ç¤ºå°±æ˜¯: (æˆ‘ä»¬åªéœ€è¦å…³æ³¨é˜´å½±éƒ¨åˆ†, å³å·²ç»ç¡®å®šçš„èŒƒå›´)\n![400](notes/2021/2021.12/assets/img_2022-10-15-10.png)\n\næ³¨æ„æˆ‘ä»¬è®¡ç®—è¿™ä¸ªæ¦‚ç‡ä½¿ç”¨çš„æ˜¯å·¦è¾¹çš„å›¾, å³\"æ€»ä½“çš„è§’åº¦\", è€Œæˆ‘ä»¬å¾—åˆ°çš„ç»“æœæ˜¯\"ä¸ªä½“çš„è§’åº¦\"é‡Œé¢çš„æŒ‡æ ‡$P(A\\mid B)$ : ä¸€ä¸ªå·²ç»æ£€æµ‹ä¸ºé˜³æ€§çš„äººçš„æ‚£ç—…æ¦‚ç‡. ä¹Ÿå°±æ˜¯è¯´, Bayeså®šç†å®ç°äº†è§†è§’çš„åˆ‡æ¢(Change of Perspective)\n\n- æ³¨æ„æ€»ä½“è§’åº¦å’Œä¸ªäººè§’åº¦å…¶å®æ˜¯å¯ä»¥äº¤æ¢çš„, æ¯”å¦‚æˆ‘ä»¬å°†å·¦è¾¹çš„å›¾çœ‹ä½œä¸ªä½“è§’åº¦, åˆ™å…¬å¼:\n\t$$P(B \\mid A)=\\frac{P(A \\mid B) P(B)}{P(A)}$$\n\tå¯ä»¥ç†è§£ä¸ºåœ¨ä¸€ä¸ªäººå·²ç»æ‚£ç—…çš„æƒ…å†µä¸‹, taæ£€æµ‹å¾—åˆ°é˜³æ€§ç»“æœçš„æ¦‚ç‡(æ£€æµ‹æ–¹æ³•çš„Sensitivity).\n\t\n\t\n### æ‹“å±•\næœ‰äº†ç›´è§‚çš„è¡¨ç¤ºæ–¹æ³•, Bayeså®šç†å¯ä»¥å¾ˆå®¹æ˜“åœ°æ¨å¹¿åˆ°å¤šä¸ªç±»çš„æƒ…å†µ:\n\n- å¦‚æœAæœ‰å¤šä¸ªç±»:\n$$\\begin{aligned}\n\u0026P(B)=\\sum_{j} P\\left(B \\mid A_{j}\\right) P\\left(A_{j}\\right) \\\\\n\u0026\\Rightarrow P\\left(A_{i} \\mid B\\right)=\\frac{P\\left(B \\mid A_{i}\\right) P\\left(A_{i}\\right)}{\\sum_{j} P\\left(B \\mid A_{j}\\right) P\\left(A_{j}\\right)}\n\\end{aligned}$$\nç”¨å›¾å½¢è¡¨ç¤ºå°±æ˜¯:\n![](notes/2021/2021.12/assets/Pasted%20image%2020211219232617.png)\n\n- å¦‚æœBåˆ†æˆäº†BCDä¸‰ä¸ªäº’æ–¥çš„æƒ…å†µ, ç”¨å›¾å½¢è¡¨ç¤ºå°±æ˜¯:\n![Bayes More Situations](notes/2021/2021.12/assets/Bayes%20More%20Situations.svg)\n\n\n\n\n","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/Union_Bound-%E5%B8%83%E5%B0%94%E4%B8%8D%E7%AD%89%E5%BC%8F-Booles_inequality":{"title":"Union_Bound-å¸ƒå°”ä¸ç­‰å¼-Boole's_inequality","content":"# Union Bound: å¸ƒå°”ä¸ç­‰å¼\n\n\u003cdiv align=\"right\"\u003e 2021-12-04\u003c/div\u003e\n\nTags: #Math/Statistics \n\n\n- This website explained it well:\n[The Union Bound and Extension](https://www.probabilitycourse.com/chapter6/6_2_1_union_bound_and_exten.php)\n\n## Intuition\n\n$$\\begin{aligned}\nP(A \\cup B) \u0026=P(A)+P(B)-P(A \\cap B) \\\\\n\u0026 \\leq P(A)+P(B) .\n\\end{aligned}$$\n\nåŒæ ·, å¯¹äºä¸‰ä¸ªéšæœºå˜é‡ä¹Ÿæœ‰ç›¸åº”çš„ä¸ç­‰å…³ç³»:\n\n$$\\begin{aligned}\nP(A \\cup B \\cup C) \u0026=P((A \\cup B) \\cup C) \\\\\n\u0026 \\leq P(A \\cup B)+P(C) \\\\\n\u0026 \\leq P(A)+P(B)+P(C)\n\\end{aligned}$$\n\nIn general, using induction we prove the following:\n\n**The Union Bound**\n\nFor any events $A_{1}, A_{2}, \\ldots, A_{n}$, we have\n$$\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right) \\leq \\sum_{i=1}^{n} P\\left(A_{i}\\right)\n$$\n\nå±•å¼€å°±æ˜¯:\n\n$$\n\\mathbb{P}\\left(A_{1} \\bigcup A_{2} \\bigcup \\cdots\\right) \\leq \\mathbb{P}\\left(A_{1}\\right)+\\mathbb{P}\\left(A_{2}\\right)+\\cdots\n$$","lastmodified":"2023-11-19T19:19:33.902463712Z","tags":null},"/notes/2021/2021.12/in-situ":{"title":"in situ","content":"# in situ\n\n\u003cdiv align=\"right\"\u003e 2021-12-09\u003c/div\u003e\n\nTags: #English #Latin \n\nåœ¨åŸåœ°\n\n_**In situ**_ ([/Éªn ËˆsÉªtjuË, - ËˆsaÉªtjuË, - ËˆsiË-/](https://en.wikipedia.org/wiki/Help:IPA/English \"Help:IPA/English\"); often not italicized in English) is a Latin phrase that translates literally to \"on site\" or \"in position.\" It can mean \"locally\", \"on site\", \"on the premises\", or \"in place\" to describe where an event takes place and is used in many different context\n\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.12/mentionnote-something-in-passing-%E9%A1%BA%E4%BE%BF%E6%8F%90%E5%88%B0":{"title":"mention(note) something in passing - é¡ºä¾¿æåˆ°","content":"# mention/note something in passing\n\n\u003cdiv align=\"right\"\u003e 2021-12-24\u003c/div\u003e\n\nTags: #English\n\n[mention/note something in passing | meaning of mention/note something in passing in Longman Dictionary of Contemporary English | LDOCE](https://www.ldoceonline.com/dictionary/mention-note-something-in-passing)\n\nif you say something in passing, you mention it while you are mainly talking about something else.\n\n- He did mention his brotherâ€™s wife, but only in passing. \n\n- He noted, in passing, that he had lasted longer than Texas Sen.\n- Like many more, presumably, we mention Ribblehead in passing.\n- In Exodus the quails were mentioned only in passing.","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/%E4%BB%A3%E6%8D%A2%E5%AF%86%E7%A0%81Substitution-Cipher%E4%B8%8E%E7%BD%AE%E6%8D%A2%E5%AF%86%E7%A0%81Permutation-Cipher":{"title":"ä»£æ¢å¯†ç ï¼ˆSubstitution Cipherï¼‰ä¸ç½®æ¢å¯†ç ï¼ˆPermutation Cipherï¼‰","content":"# ä»£æ¢å¯†ç ä¸ç½®æ¢å¯†ç ï¼ˆSubstitution Cipher \u0026 Permutation Cipherï¼‰\n\nTags: #Math #Cryptography  #Course\n\n\u003e åˆ†ä¸æ¸…æ¥šè¿™ä¸¤ä¸ªå®Œå…¨æ˜¯ç¿»è¯‘çš„é”…\n\n## ç½®æ¢ï¼ˆä¸æ˜¯ç½®æ¢å¯†ç ï¼‰Permutationï¼ˆNot Permutation Cipher)\n\né¦–å…ˆç½®æ¢æ˜¯æ•°å­¦ä¸Šçš„ä¸€ç§æ“ä½œï¼Œæ˜¯å¯¹ä¸€ç»„ç¡®å®šçš„å…ƒç´ è¿›è¡Œé‡æ–°æ’åˆ—\n\n- å…ƒç´ ä¸å˜\n- åªæ”¹å˜é¡ºåº\n\n![|100](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Permutations_RGB.svg/220px-Permutations_RGB.svg.png)\n\nWikipedia:\n\u003e In [mathematics](https://en.wikipedia.org/wiki/Mathematics \"Mathematics\"), a **permutation** of a [set](https://en.wikipedia.org/wiki/Set_(mathematics) \"Set (mathematics)\") is, loosely speaking, an arrangement of its members into a [sequence](https://en.wikipedia.org/wiki/Sequence \"Sequence\") or [linear order](https://en.wikipedia.org/wiki/Linear_order \"Linear order\"), or if the set is already ordered, a rearrangement of its elements. The word \"permutation\" also refers to the act or process of changing the linear order of an ordered set\n\n## è¾¨æ\n\nå½“ä»¥æ›¿æ¢å¼å¯†ç ä¸[ç½®æ¢å¼å¯†ç ï¼ˆTransposition Cipher)](https://zh.wikipedia.org/w/index.php?title=%E7%BD%AE%E6%8F%9B%E5%BC%8F%E5%AF%86%E7%A2%BC\u0026action=edit\u0026redlink=1)ï¼ˆæˆ–ç§°è½¬ä½å¼å¯†ç æˆ–ç§»è½¬å¼å¯†ç (Permutation Cipherå±äºTransposition Cipherçš„ä¸€ç§ï¼‰ç›¸æ¯”è¾ƒæ—¶ï¼Œå¯ä»¥å‘ç°è½¬ä½å¼å¯†ç åªæ˜¯æ”¹å˜æ˜æ–‡ä¸­å•å…ƒçš„ä½ç½®ï¼Œè€Œå•å…ƒæœ¬èº«æ²¡æœ‰è½¬å˜ï¼›ç›¸åï¼Œæ›¿æ¢å¼å¯†ç åªæ˜¯è½¬æ¢å•å…ƒï¼Œä½†å¯†æ–‡ä¸­å•å…ƒçš„ä½ç½®æ²¡æœ‰æ”¹å˜\n\n## ä»£æ¢å¯†ç  Substitution Cipher\n\n![500](notes/2021/2021.6/assets/img_2022-10-15.png)\n\nåˆç§°**æ›¿æ¢å¯†ç ã€å–ä»£å¼å¯†ç **\n\nå…³é”®æ˜¯â€**å…ƒç´ å˜ï¼Œä½ç½®ä¸å˜**â€œï¼Œè§‚å¯Ÿä¸Šå›¾ï¼ŒåŸæ¥æœ‰ä¸¤ä¸ªé»„è‰²çš„æ–¹å—ï¼ŒåŠ å¯†åå˜æˆäº†ä¸¤ä¸ªçº¢è‰²çš„åœ†åœˆã€‚\nè¿™è¯´æ˜ **\"å…ƒç´ ç±»å‹/åˆ†å¸ƒ/ç»„æˆ\"** å‘ç”Ÿäº†å˜åŒ–ï¼ŒåŸæ¥æ˜¯æ­£æ–¹å½¢ï¼Œç°åœ¨å˜æˆäº†åœ†å½¢ï¼›åŸæ¥æ˜¯é»„è‰²æœ€å¤šï¼Œç°åœ¨å˜æˆçº¢è‰²æœ€å¤šäº†ã€‚\n\nä¸ºä»€ä¹ˆ**ä»£æ¢**å¯†ç ä¸­æ¶‰åŠåˆ°**ç½®æ¢ï¼ˆSubstitutionï¼‰**ï¼Ÿ\n![](notes/2021/2021.6/assets/img_2022-10-15-1.png)\nå› ä¸ºä»–çš„æ„æ€å…¶å®æ˜¯ï¼Œâ€æ›´æ¢26ä¸ªå­—å¹•å¯¹åº”çš„å…ƒç´ ç›¸å½“äºå°†ä¸¤ä¸ªPermutationä¸Šä¸‹å¯¹åº”åœ°æ”¾èµ·æ¥â€œ\n$$\n\\begin{alignat}{}\n\u0026A\u0026B\u0026C\u0026D\u0026E\\\\\n\u0026\\downarrow\n\u0026\\downarrow\n\u0026\\downarrow\n\u0026\\downarrow\n\u0026\\downarrow\n\\\\\n\u0026E\u0026A\u0026D\u0026C\u0026B\n\\end{alignat}\n$$\n\n## ç½®æ¢å¯†ç  Permutation Cipher\n\n![](notes/2021/2021.6/assets/img_2022-10-15-2.png)\nå…ˆé˜…è¯»è¿™ä¸ªç½‘ç«™ï¼š\n[Transposition Cipher - Columnar Transposition Cipher](https://crypto.interactive-maths.com/columnar-transposition-cipher.html)\nå†é˜…è¯»è¿™ä¸ªï¼š\n[Permutation Cipher](https://crypto.interactive-maths.com/permutation-cipher.html)\n\nå¯ä»¥çœ‹å‡ºï¼Œç½®æ¢å¯†ç å³ä¸€ç§ä¸€æ®µä¸€æ®µåœ°äº¤æ¢ä½ç½®çš„åŠ å¯†æ–¹å¼ï¼Œå¦‚æœè¿™ä¸ªâ€ä¸€å°æ®µ\"çš„é•¿åº¦æ˜¯æ•´ä¸ªå­—ç¬¦ä¸²ï¼Œé‚£ä¹ˆä¾¿æ˜¯ä¸€ç§Transposition Cipher\n\nåœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œåªæœ‰å…ƒç´ é¡ºåºå‘ç”Ÿäº†å˜åŒ–ï¼Œå…ƒç´ ç»„æˆæ²¡æœ‰å˜åŒ–ã€‚\nIn classical cryptography, a permutation cipher is a transposition cipher in which the key is a permutation.\n[reference](https://en.wikibooks.org/wiki/Cryptography/Permutation_cipher)\n","lastmodified":"2023-11-19T19:19:33.942464365Z","tags":null},"/notes/2021/2021.6/%E5%9B%BE%E7%81%B5%E5%BD%92%E7%BA%A6-Turing-Reduction":{"title":"å›¾çµå½’çº¦ Turing Reduction","content":"\n**æŠŠè¿˜æ²¡è§£å†³çš„é—®é¢˜å½’çº¦åˆ°å·²ç»è§£å†³çš„é—®é¢˜ä¸Š**\n\n**ç”¨å·²ç»è§£å†³çš„é—®é¢˜å»è§£å†³è¿˜æ²¡è§£å†³çš„é—®é¢˜**\n\n\u003e å¯†ç å­¦åŸç†ä¸å®è·µ Page 167\n\u003e\n\u003e ![](notes/2021/2021.6/assets/img_2022-10-15-3.png)\n\nå‡è®¾æˆ‘ä»¬å·²ç»å­˜åœ¨ä¸€ä¸ªè§£å†³é—®é¢˜ A çš„ç®—æ³• $G(x)$\n\nä¸€ä¸ªAåˆ°Bçš„å›¾çµå½’çº¦å³åˆ©ç”¨$G(x)$æ„é€ ä¸€ä¸ªè§£å†³é—®é¢˜Bçš„ç®—æ³•$H(x)$, å¹¶ä¸”$H(x)$æ˜¯å¤šé¡¹å¼æ—¶é—´çš„.\n\n\u003e ![](notes/2021/2021.6/assets/img_2022-10-15-4.png)\n\n\u003e \u003chttps://zhuanlan.zhihu.com/p/194313998\u003e\n\u003e è¿™ç¯‡æ–‡ç« è¯‘è‡ª[reductions-and-jokes](https://rjlipton.wpcomstaging.com/2020/02/28/reductions-and-jokes/)\n\u003e\n\u003e \u003e ä¸€ä¸ªç‰©ç†å­¦å®¶å’Œä¸€ä¸ªæ•°å­¦å®¶æ­£ååœ¨æ•™å¸ˆä¼‘æ¯å®¤é‡Œã€‚çªç„¶é—´ï¼Œä¼‘æ¯å®¤é‡Œçš„å’–å•¡æœºç€ç«äº†ã€‚ç‰©ç†å­¦å®¶å°±æ‹¿äº†ä¸€ä¸ªåƒåœ¾æ¡¶ï¼ŒæŠŠé‡Œé¢çš„åƒåœ¾æ¸…ç©ºï¼Œè·‘åˆ°æ°´æ± å‰ï¼Œç»™åƒåœ¾æ¡¶çŒæ»¡æ°´ï¼Œéšåæ‰‘ç­äº†ç«ã€‚ç”±äºè¿™ä¸ªå’–å•¡æœºç€è¿‡ä¸€æ¬¡ç«äº†ï¼Œå¤§å®¶éƒ½åŒæ„æŠŠåƒåœ¾æ¡¶è£…æ»¡æ°´æ”¾åœ¨è¿™ä¸ªå’–å•¡æœºæ—è¾¹ã€‚  \n\u003e \u003e ç¬¬äºŒå¤©ï¼ŒåŒæ ·çš„ä¸¤ä¸ªäººåˆååœ¨åŒæ ·çš„ä¼‘æ¯å®¤é‡Œï¼Œå’–å•¡æœºåˆä¸€æ¬¡ç€ç«äº†ã€‚è¿™ä¸€æ¬¡ï¼Œæ•°å­¦å®¶ç«™äº†èµ·æ¥ï¼ŒæŠŠè£…æ»¡æ°´çš„åƒåœ¾æ¡¶æ‹¿äº†èµ·æ¥ï¼ŒæŠŠé‡Œé¢çš„æ°´å€’æ‰ï¼Œåˆæ”¾äº†ä¸€äº›åƒåœ¾åœ¨é‡Œé¢ï¼Œäº¤ç»™äº†ç‰©ç†å­¦å®¶ã€‚è¿™æ ·å°±æŠŠé—®é¢˜å½’çº¦åˆ°äº†ä¸€ä¸ªä¹‹å‰å·²ç»è§£å†³è¿‡çš„é—®é¢˜ä¸Šã€‚\n\u003e\n\u003e è™½ç„¶è¿™ä¸ªç¬‘è¯æ˜¯è®½åˆºæ•°å­¦å®¶çš„ï¼Œä½†ç¡®å®å¾ˆå¥½åœ°è§£é‡Šäº†å½’çº¦è¿™ä¸ªæ¦‚å¿µã€‚å…¶æƒ³æ³•å¾ˆç®€å•ï¼šæˆ‘ä»¬ç°åœ¨é‡åˆ°äº†ä¸ªé—®é¢˜ï¼Œå¯ä»¥æŠŠå®ƒè½¬åŒ–åˆ°ä¸€ä¸ªæŸä¸ªå·²è§£å†³çš„é—®é¢˜ä¸Šï¼Œè€Œä¸æ˜¯ä¸€å®šè¦ç›´æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ä»è¿™ä¸ªæ„ä¹‰ä¸Šæ¥è¯´ï¼Œå½’çº¦å…¶å®æ˜¯ä¸€ç§æ¯”è¾ƒæ‡’çš„è§£å†³é—®é¢˜çš„æ–¹å¼ã€‚\n\u003e\n\u003e Instead of putting out a fire, the following [video](https://thumbs.gfycat.com/DifficultVapidAmericanredsquirrel-size_restricted.gif?fbclid=IwAR2AXbtag_WFTP9bmipr4JOhvViHAQbvEgE8h1oCdG_71IttR28EgcSTqhg) is about retrieving a shoe that is floating away.\n\u003e ![https://thumbs.gfycat.com/DifficultVapidAmericanredsquirrel-size_restricted.gif?fbclid=IwAR2AXbtag_WFTP9bmipr4JOhvViHAQbvEgE8h1oCdG_71IttR28EgcSTqhg](https://thumbs.gfycat.com/DifficultVapidAmericanredsquirrel-size_restricted.gif?fbclid=IwAR2AXbtag_WFTP9bmipr4JOhvViHAQbvEgE8h1oCdG_71IttR28EgcSTqhg)\n\n\u003e ## Another Example\n\u003e\n\u003e Here is an example of reductions that are not so silly and a little less simple.\n\u003e\n\u003e Imagine that Alice and Bob are at it again. Bob wants to be able to multiply integers fast and he plans on building a hardware system that stores the answers in a table. Then his hardware system will be able to compute the product of two integers by just looking up the answers. Okay, there are really better ways to do this, but just play along for the moment.\n\u003e\n\u003e [![](https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2020/02/tables2.jpg?resize=200%2C200\u0026ssl=1)](https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2020/02/tables2.jpg?ssl=1)\n\u003e\n\u003e Bobâ€™s table is big and he is troubled. The above table has ![{100}](https://s0.wp.com/latex.php?latex=%7B100%7D\u0026bg=ffffff\u0026fg=000000\u0026s=0\u0026c=20201002) entries just to multiply numbers less than ![{10}](https://s0.wp.com/latex.php?latex=%7B10%7D\u0026bg=ffffff\u0026fg=000000\u0026s=0\u0026c=20201002). Clearly for a more extensive table the cost grows fast. He asks his friend Alice for some help. She says:â€Just store the diagonal values and I can show you how to handle the general case.â€ Here is her old trick.\n\u003e\n\u003e ![\\displaystyle  a \\times b = \\frac{\\left(\\left(a + b\\right)^{2} - a^{2} - b^{2}\\right)}{2}. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Ctimes+b+%3D+%5Cfrac%7B%5Cleft%28%5Cleft%28a+%2B+b%5Cright%29%5E%7B2%7D+-+a%5E%7B2%7D+-+b%5E%7B2%7D%5Cright%29%7D%7B2%7D.+\u0026bg=ffffff\u0026fg=000000\u0026s=0\u0026c=20201002)\n\u003e\n\u003e Using this allows Bob to just store the diagonal of the multiplication table, and forget all the rest. It is a powerful reduction that shows:\n\u003e\n\u003e _One can reduce integer multiplication to addition and taking the square of a number._\n\u003e\n\u003e For example,\n\u003e\n\u003e ![\\displaystyle  \\begin{array}{rcl}        37 \\times 15 \u0026=\u0026 ( 52^{2} - 37^{2} - 15^{2} )/2 \\\\              \u0026=\u0026 (2704 - 1369 - 225)/2 \\\\            \u0026=\u0026 555. \\end{array} ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++++++++37+%5Ctimes+15+%26%3D%26+%28+52%5E%7B2%7D+-+37%5E%7B2%7D+-+15%5E%7B2%7D+%29%2F2+%5C%5C++++++++++++++%26%3D%26+%282704+-+1369+-+225%29%2F2+%5C%5C++++++++++++%26%3D%26+555.+%5Cend%7Barray%7D+\u0026bg=ffffff\u0026fg=000000\u0026s=0\u0026c=20201002)\n","lastmodified":"2023-11-19T19:19:33.942464365Z","tags":null},"/notes/2021/2021.6/Diffie-Hellman%E9%97%AE%E9%A2%98":{"title":"Diffie-Hellmané—®é¢˜","content":"# Diffie-Hellmané—®é¢˜\n\n## ä¸¤ä¸ªDiffie-Hellmané—®é¢˜\n\n### Computation Diffie-Hellman / CDH\n\nå³ç»™å®šä¸€ä¸ªåŸºæ•°ä¸ä¸¤ä¸ªæŒ‡æ•°, è®¡ç®—åˆå¹¶çš„æŒ‡æ•°\n\n- ç»™å®š$(\\alpha, \\alpha^b, \\alpha^c)$, **æ±‚** $\\alpha^{bc}$\n\n### Decision Diffie-Hellman / DDH\n\nå³ç»™ä½ ä¸‰ä¸ªæŒ‡æ•°, è®©ä½ åˆ¤æ–­æœ€åä¸€ä¸ªæ˜¯ä¸æ˜¯å‰ä¸¤ä¸ªçš„åˆå¹¶\n\n- ç»™å®š $(\\alpha^b, \\alpha^c, \\alpha^d)$, **åˆ¤æ–­æœ‰æ²¡æœ‰** $\\alpha^d=\\alpha^{bc}\\space?$\n\n**æ³¨æ„:** ç»™å®šçš„ $\\alpha$ æ˜¯ $n$ é˜¶å…ƒç´ , æ‰€ä»¥ä¸Šé¢çš„è¿ç®—éƒ½æ˜¯ $mod\\space  \\alpha^n$ çš„\n\n### è¾¨æ: CDH / DDH\n\n- CDHæ˜¯è®¡ç®—ä¸€ä¸ªæ•°, DDHæ˜¯åˆ¤æ–­è®¡ç®—ç»“æœæ˜¯å¦æˆç«‹\n- è®¡ç®—éš¾åº¦æ¯”è¾ƒ:\n  - ![](notes/2021/2021.6/assets/img_2022-10-15-5.png)(æ¥è‡ªè¯¾ä»¶)\n- ç›´è§‰ä¸Šç†è§£: æŠŠå¯èƒ½çš„ç­”æ¡ˆç»™å‡ºæ¥äº†è®©ä½ åˆ¤æ–­å¯¹ä¸å¯¹(DDH)è‚¯å®šæ¯”è®©ä½ è‡ªå·±æ±‚ç­”æ¡ˆ(CDH)ç®€å•, è€Œè¦ä½ æŠŠå¯¹æ•°æ±‚å‡ºæ¥(ç¦»æ•£å¯¹æ•°é—®é¢˜)æ˜¯æœ€éš¾çš„, å› ä¸ºå’ŒCDHç›¸æ¯”, è¿™ç›¸å½“äºå…ˆæŠŠæ¯ä¸ªéƒ¨åˆ†çš„æŒ‡æ•°ç®—å‡ºæ¥, å†è®¡ç®—CDHé‡Œé¢çš„åˆå¹¶çš„å…ƒç´ (å³å…ˆç”¨$\\alpha^b,\\alpha^c$ç®—$b,c$ å†è®¡ç®—$b\\times c,$å†ç®—å‡º$\\alpha^{bc}$)\n\n## DDH $\\propto_T$ CDH $\\propto_T$ Discrete Logarithm / ä¸‰ä¸ªé—®é¢˜çš„å›¾çµå½’çº¦å…³ç³»\n\n[å›¾çµå½’çº¦ Turing Reduction](notes/2021/2021.6/å›¾çµå½’çº¦%20Turing%20Reduction.md)\n\n### CDH $\\propto_T$ Discrete Logarithm\n\nå¾ˆç®€å•, æ­£å¦‚å‰é¢å·²ç»æåˆ°çš„ä¸€æ ·, å¯ä»¥å…ˆç”¨ $\\alpha^b,\\alpha^c$ ç®—  $b,c$ å†è®¡ç®— $b\\times c,$ å†ç®—å‡º $\\alpha^{bc}$.\n\u003e ![](notes/2021/2021.6/assets/img_2022-10-15-6.png)\n\nCDH $\\propto_T$ Discrete Logarithm è¯´æ˜äº† Discrete Logarithm è‡³å°‘å’Œ CDH ä¸€æ ·éš¾\n\nè¿™æ ·æƒ³æ›´æ¸…æ™°: **Discrete Logarithmè‡³å°‘æ¯”CDHéš¾**\n\n### DDH $\\propto_T$ CDH\n\nå› ä¸ºæˆ‘ä»¬éƒ½å¯ä»¥æ±‚æ­£ç¡®çš„$\\alpha^{bc}$äº†,æˆ‘ä»¬åªéœ€è¦éªŒè¯$\\alpha^{bc}$å’Œ$\\alpha^{d}$æ˜¯ä¸æ˜¯ä¸€æ ·å°±å¯ä»¥è§£å†³DDHäº†\n\u003e ![](notes/2021/2021.6/assets/img_2022-10-15-7.png)\n\nDDH $\\propto_T$ CDH**è¯´æ˜äº†CDHè‡³å°‘æ¯”DDHéš¾**\n\n### ä¸€ä¸ªæ€è€ƒ, DDH / CDH / Discrete Logarithmåˆ°åº•å“ªä¸ªæœ€éš¾?\n\n\u003e *ä¸€ä¸ªé”™è¯¯æƒ³æ³•:*\n\u003e\n\u003e æœ‰ DDH $\\propto_T$ CDH, *~~è¯´æ˜ DDH è‡³å°‘æ˜¯å’Œ CDH ä¸€æ ·éš¾çš„(å› ä¸ºè§£å†³äº† CDH ä¸€å®šå°±å¯ä»¥è§£å†³ DDH)~~*\n\u003e\n\u003e æœ‰ CDH $\\propto_T$ Discrete Logarithm, *~~è¯´æ˜ CDH è‡³å°‘æ˜¯å’Œ Discrete Logarithm ä¸€æ ·éš¾çš„(å› ä¸ºè§£å†³äº† Discrete Logarithm ä¸€å®šå°±å¯ä»¥è§£å†³ CDH)~~*\n\u003e\n\u003e *~~è¿™æ ·çœ‹æ¥, å¥½åƒ Discrete Logarithm æœ€ç®€å•. CDH ç¬¬äºŒç®€å•, DDH æœ€éš¾, ä½†æ˜¯ä¸ºä»€ä¹ˆå®é™…æ˜¯åè¿‡æ¥çš„å‘¢?~~*\n\n**æ­£ç¡®æƒ³æ³•:**\n\næœ‰DDH $\\propto_T$ CDH, è¯´æ˜CDHè‡³å°‘æ˜¯å’ŒDDHä¸€æ ·éš¾çš„(å› ä¸ºè§£å†³äº†CDHä¸€å®šå°±å¯ä»¥è§£å†³DDH)\n\næœ‰CDH $\\propto_T$ Discrete Logarithm, è¯´æ˜Discrete Logarithmè‡³å°‘CDHæ˜¯å’Œä¸€æ ·éš¾çš„(å› ä¸ºè§£å†³äº†Discrete Logarithmä¸€å®šå°±å¯ä»¥è§£å†³CDH)\n\nè¿™æ ·çœ‹æ¥, **Discrete Logarithmæœ€éš¾, CDHç¬¬äºŒéš¾,  DDHæœ€ç®€å•**\n\n[ç¬¬åä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼šDLP,CDHå’ŒDDHé—®é¢˜éƒ½æ˜¯ä»€ä¹ˆ](https://www.cnblogs.com/zhuowangy2k/p/11901028.html)\n\n\u003e â€¦â€¦\n\u003e\n\u003eCDHæ˜¯å’ŒDLPç›¸å…³çš„,ä½†æ˜¯å“ªä¸ªæ›´éš¾å‘¢?å¦‚æœæˆ‘èƒ½æœ‰æ•ˆç‡çš„è§£å†³DLP,é‚£ä¹ˆæˆ‘å°±å¯ä»¥æ‰¾å‡º$a$,ç„¶åè½»æ¾çš„è®¡ç®—å‡º$g^{ab}$å°±åƒBobåšçš„é‚£æ ·,å› æ­¤æˆ‘ä»¬å°±è§£å†³äº†CDH.æ‰€ä»¥æˆ‘ä»¬è¯´èƒ½è§£å†³DLPé‚£ä¹ˆä¸€å®šèƒ½è§£å†³CDH,è¿™å°±æ˜¯è¯´DLPè‡³å°‘å’ŒCDHä¸€æ ·éš¾.\n\u003e\n\u003eâ€¦â€¦\n\u003e\n\u003eå¦‚æœå¯¹æ‰‹èƒ½å¤Ÿè§£å†³DDH(è¾“å‡ºæ­£ç¡®çš„xçš„æ¦‚ç‡å¤§äº1/2).é‚£ä¹ˆå°±æ˜¯è¯´$G,g^a,g^b$ä¸€å®šæ³„éœ²äº†ä¸€äº›å…³äº$g^{ab}$çš„ä¿¡æ¯,ä½¿å¾—æ”»å‡»è€…èƒ½æŠŠå®ƒä»éšæœºçš„å…ƒç´ ä¸­åˆ†è¾¨å‡ºæ¥,å°½ç®¡ä¸èƒ½ç›´æ¥è®¡ç®—å‡ºæ¥.è€Œä¸”å¾ˆæ˜æ˜¾,å¦‚æœå¯¹æ‰‹èƒ½è§£å†³CDHé—®é¢˜,é‚£ä¹ˆå®ƒå¯ä»¥æœ‰æ•ˆç‡çš„è§£å†³DDH,å› ä¸ºå®ƒå·²ç»å¯ä»¥å¾—åˆ°$g^{ab}$ çš„å€¼.è¿™æ„å‘³ç€,CDHè‡³å°‘å’ŒDDHä¸€æ ·éš¾.\n\u003e\n\u003e è¿™å°±æ˜¯æˆ‘ä»¬è¿™ç¯‡ä¸­è®¨è®ºçš„ä¸‰ä¸ªé—®é¢˜,æˆ‘ä»¬ç»™å‡ºäº†ä¸€ä¸ªç®€æ˜çš„è¯æ˜å¯¹ä»–ä»¬çš„å›°éš¾æ€§è¿›è¡Œæ’åº:DLPæœ€éš¾,ç„¶åæ˜¯CDH,æœ€åæ˜¯DDH.å°±åƒæˆ‘ä»¬çœ‹åˆ°çš„é‚£æ ·,DLPæœ‰æ—¶å€™æ˜¯ç®€å•çš„,ä¼šè®©CDHå’ŒDDHéƒ½å˜ç®€å•.å› æ­¤ç¾¤$G$å’Œç”Ÿæˆå™¨$g$çš„é€‰æ‹©åœ¨åšå¯†ç å­¦çš„æ—¶å€™æ˜¯ååˆ†é‡è¦çš„!\n\n### è§£CDHçš„ç®—æ³•å’Œè§£ElGamalçš„ç®—æ³•æ˜¯ç­‰ä»·çš„\n\nin ElGamal:\n![](notes/2021/2021.6/assets/img_2022-10-15-8.png)\n\n**æ³¨æ„$\\alpha, \\beta$éƒ½æ˜¯å…¬é’¥**\n\n$$\n\\begin{align}\ny_1\u0026=\\alpha^k\\\\\nK\u0026=\\beta^k=\\alpha^{ak}\\\\\ny_2\u0026=xK=x\\beta^k=x\\alpha^{ak}\\\\\n\u0026\\Downarrow\\\\\nx=d_k(y_1,y_2)\u0026=y_2\\cdot (\\alpha^{ak})^{-1}=y_2\\cdot (y_1^a)^{-1}\n\\end{align}\n$$\n\n#### $OracleCDH\\space\\Rightarrow\\space ElGamal$\n\n$\\delta=OracleCDH(\\alpha,\\beta,y_1)=OracleCDH(\\alpha,\\alpha^k,\\alpha^k)$\n\nç”±æ­¤ç®—å‡º $\\delta=\\alpha^{ak}$,å°±ç›¸å½“äº$y_1^a$äº†\n\næ‰€ä»¥$x=y_2\\cdot\\delta^{-1}$\n\n#### $CDH \\quad\\Leftarrow\\quad OracleElGamal$\n\n$$\\begin{align}\nx\u0026=OracleElGamal(\\alpha,\\beta,(y_1,y_2))\\\\\n\u0026=OracleElGamal(\\alpha,\\alpha^a,(\\alpha^k,y_2))\\\\\n\u0026=y_2\\cdot (\\alpha^{ak})^{-1}\n\\end{align}\n$$\næ‰€ä»¥$\\alpha^{ak}=y_2\\cdot (y_2\\cdot (\\alpha^{ak})^{-1})^{-1}=\\alpha^{ak}$\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/Function_Procedure_Difference_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%92%8C%E5%87%BD%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB":{"title":"Function_Procedure_Difference_(å­˜å‚¨)è¿‡ç¨‹å’Œå‡½æ•°çš„åŒºåˆ«","content":"# Difference Between Function and Procedure\n\n\n[Link](https://www.jianshu.com/p/2eaa094adf9e)\n\n\nå‡½æ•°æœ‰1ä¸ªè¿”å›å€¼,è€Œå­˜å‚¨è¿‡ç¨‹æ˜¯é€šè¿‡å‚æ•°è¿”å›çš„,å¯ä»¥æœ‰å¤šä¸ªæˆ–è€…æ²¡æœ‰\n\n#### E.g.\n\n```cpp\nZZ x, a, n;  \nx = InvMod(a, n);Â Â _// functional form_  \nInvMod(x, a, n);Â Â Â _// procedural form_\n```","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/Hamming_Distance_%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB":{"title":"Hamming_Distance_æ±‰æ˜è·ç¦»","content":"# Hamming Distance / æ±‰æ˜è·ç¦»\n\n\n\næ±‰æ˜è·ç¦»æ˜¯å¯¹äºä¸¤ä¸ª**ç›¸åŒé•¿åº¦**çš„å­—ç¬¦ä¸²è€Œè¨€, the number of positions at which the corresponding symbols are different(ç›¸åŒçš„ä½ç½®ä¸Šå¯¹åº”å­—ç¬¦ä¸åŒçš„ä½ç½®ä¸ªæ•°)\n\n### å›¾ä¾‹\nå¸¦è‰²çº¿æ¡æ˜¯è·¯å¾„ç¤ºæ„\n\n![3-bit binary cube|350](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Hamming_distance_3_bit_binary.svg/1280px-Hamming_distance_3_bit_binary.svg.png)\n\nTwo example distances: 100â†’011 has distance 3; 010â†’111 has distance 2\n\n![3-bit binary cube Hamming distance examples|350](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Hamming_distance_3_bit_binary_example.svg/1280px-Hamming_distance_3_bit_binary_example.svg.png)\n\n![4-bit binary tesseract|600](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Hamming_distance_4_bit_binary.svg/1920px-Hamming_distance_4_bit_binary.svg.png)\n![4-bit binary tesseract Hamming distance examples|600](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Hamming_distance_4_bit_binary_example.svg/1920px-Hamming_distance_4_bit_binary_example.svg.png)\n\n## Hamming Weight / æ±‰æ˜é‡é‡\nä¸€ä¸ªå­—ç¬¦ä¸²ä¸ç›¸åŒé•¿åº¦çš„å…¨é›¶å­—ç¬¦ä¸²ä¹‹é—´çš„æ±‰æ˜è·ç¦»\n\nThe Hamming weight of a string is the number of symbols that are different from the zero-symbol of the alphabet used. \nIt is thus equivalent to the Hamming distance from the **all-zero string of the same length**. \n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/Hash%E5%87%BD%E6%95%B0_Pt.1_%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7":{"title":"Hashå‡½æ•°_Pt.1_æ•°æ®å®Œæ•´æ€§","content":"# 4.1 Hash å‡½æ•°ä¸æ•°æ®å®Œæ•´æ€§\n\nHash å‡½æ•°çš„ä¸»è¦ç›®çš„å°±æ˜¯ä¸ºäº†**ä¿æŒæ•°æ®çš„å®Œæ•´æ€§**\nä¸\"åŠ å¯†\"ä¸åŒ, hashå‡½æ•°çš„ç›®çš„ä¸æ˜¯ä¸ºäº†è®©ä¸€ä¸ªæ¶ˆæ¯å¯¹å…¶ä»–äºº\"ä¸å¯çŸ¥,ä¸å¯ç†è§£\", è€Œæ˜¯ä¸ºäº†ä¿è¯è¿™æ¡ä¿¡æ¯æ²¡æœ‰è¢«ç¯¡æ”¹, ä¸ºäº†\"ä¸å˜è´¨\"åœ°ä¿å­˜ä¸€æ¡ä¿¡æ¯, å³ä¿æŒè¿™æ¡ä¿¡æ¯åŸæ¥çš„æ¨¡æ ·\n\nHashå‡½æ•°æœ‰ä¸¤ç§, ä¸€ç§æ˜¯å¸¦å¯†é’¥çš„, ä¸€ç§æ˜¯ä¸å¸¦å¯†é’¥çš„, ä¸¤ç§åœ¨åº”ç”¨åœºæ™¯ä¸Šæœ‰ä¸€äº›åŒºåˆ«\n\nä¸å¸¦å¯†é’¥çš„Hashå‡½æ•°å¯ä»¥åœ¨ä¸€æ®µæ—¶é—´å†…éªŒè¯æ•°æ®çš„å®Œæ•´æ€§ã€‚\næƒ³è±¡ä¸€ä¸ªOracle(å…ˆçŸ¥, è°•ç¤ºå™¨), ä½ æä¾›ç»™ä»–ä¸€æ¡ä¿¡æ¯, å¥¹æ€»ä¼šè¿”å›ç»™ä½ ä¸€ä¸ªç‹¬ç‰¹çš„ä¿¡æ¯ï¼Œé€šè¿‡æ¯”å¯¹è¿™ä¸ªä¿¡æ¯ï¼Œä½ å°±èƒ½å¤ŸçŸ¥é“è‡ªå·±çš„ä¿¡æ¯ä»ä¸Šæ¬¡è¯¢é—®åˆ°ç°åœ¨ä¹‹é—´æ˜¯å¦è¢«ç¯¡æ”¹äº†ï¼ˆä½†æ˜¯è¿™ä¸ªä¿¡æ¯æœ¬èº«å¹¶æ²¡æœ‰ä»€ä¹ˆå®é™…å«ä¹‰ï¼‰\n\næ³¨æ„, ä½ å¿…é¡»è¦å®‰å…¨çš„ä¿å­˜ $y=h(x)$, å¦åˆ™åè›‹å¯ä»¥åŒæ—¶æ›´æ¢ä½ çš„ $x$ -\u003e $x^\\prime$ å’Œ $y$ -\u003e $y^\\prime=h(x^\\prime)$, ä½ åœ¨è¯¢é—®çš„æ—¶å€™ä¾ç„¶æœ‰ $h(x^\\prime)=y^\\prime$, æ»¡è¶³æ ¡éªŒæ¡ä»¶.\n\nå¸¦å¯†é’¥çš„Hashå‡½æ•°åˆ™å¯ä»¥åœ¨é€šè®¯ä¸­ä¿è¯æ•°æ®çš„å®Œæ•´æ€§ï¼ˆMessage_Authentication_Codeï¼ŒMAC, æ¶ˆæ¯æ ¡éªŒç ï¼‰\nä½ å’Œ Bob éƒ½äº‹å…ˆçº¦å®šå¥½äº†ä¸€ä¸ªå¯†é’¥ Kï¼Œé€šè¿‡è¿™ä¸ªå¯†é’¥ K å¯ä»¥ç”Ÿæˆå¯¹åº”çš„ Hash å‡½æ•° $h_k$, ä½ åœ¨ä¸ Bob é€šè®¯çš„æ—¶å€™ï¼ŒåŒæ—¶å‘é€æ¶ˆæ¯ $x$ å’Œ $y=h_k(x)$, è¿™æ · Bob åœ¨æ”¶åˆ°æ¶ˆæ¯åä¾¿å¯ä»¥æ ¡éªŒ x å’Œ y æ˜¯å¦å¯¹åº”, ä»¥æ­¤æ¥åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦è¢«ç¯¡æ”¹äº†\n\næ³¨æ„, ä½ å¿…é¡»è¦ç¡®ä¿¡æ¶ˆæ¯çš„ç¡®æ¥è‡ª Bob, å¦åˆ™åè›‹ä»ç„¶å¯ä»¥åŒæ—¶ä¼ªè£…æˆ Bob å‘ä½ å‘é€ $x^\\prime$ å’Œ $y^\\prime$, è¿™ä¾ç„¶æ»¡è¶³æ ¡éªŒæ¡ä»¶\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/Hash%E5%87%BD%E6%95%B0_Pt.2_%E6%94%BB%E5%87%BB%E6%96%B9%E6%B3%95_%E5%AE%89%E5%85%A8%E6%80%A7":{"title":"Hashå‡½æ•°_Pt.2_æ”»å‡»æ–¹æ³•_å®‰å…¨æ€§","content":"# Hashå‡½æ•°çš„æ”»å‡»æ–¹æ³•/å®‰å…¨æ€§\n\n\u003e å¯†ç å­¦åŸç†ä¸å®è·µ page99\n\n## ç†æƒ³çš„å®‰å…¨æ€§:éšæœºè°•ç¤ºæ¨¡å‹(Random Oracle Model)\n\n**å®Œå…¨çš„éšæœºå¯¹åº”æ€§:**\n\nä»åç§°æ¥ç†è§£, å³ç†æƒ³çš„Hashå‡½æ•°ç›¸å½“äºä¸€ä¸ª\"å…ˆçŸ¥\", èƒ½å¤Ÿå¯¹æ¯ä¸€ä¸ª$x$ç»™å‡ºä¸€ä¸ªå®Œå…¨éšæœºçš„$hash(x)$, å¹¶ä¸”è®¡ç®—$hash(x)$çš„å”¯ä¸€æ–¹æ³•ä¾¿æ˜¯è¯¢é—®Oracle(è°•ç¤ºå™¨)\n\nåœ¨è¿™ä¸ªå‡è®¾ä¸‹,æœ‰å¦‚ä¸‹å®šç†:\n\u003e å¯†ç å­¦åŸç†ä¸å®è·µ page94\n\u003e\n\u003e ![img_2022-10-15-9](notes/2021/2021.6/assets/img_2022-10-15-9.png)\n\n**ç›´è§‚ç†è§£:**\n\nç”¨ä¸€éƒ¨åˆ†xå»ç¡®å®šhashå‡½æ•°å,å‰©ä¸‹çš„xå–ä»»æ„å¯èƒ½å¯†æ–‡çš„æ¦‚ç‡æ˜¯ç›¸åŒçš„.\n\nå³å¯†æ–‡ä¸æ˜æ–‡çš„å¯¹åº”å®Œå…¨éšæœº, å¯†æ–‡ä¸å–å†³äºæ˜æ–‡çš„ä»»ä½•æ€§è´¨(å½“ç„¶æ˜æ–‡æ¯æ¬¡å¯¹åº”çš„å¯†æ–‡å¾—ä¸€æ ·)\n\nè¿™å°±è¦æ±‚æˆ‘ä»¬è€ƒè™‘å¦‚ä½•è®¾è®¡ä¸€ä¸ªhashå‡½æ•°, æ—¢èƒ½ä¿ç•™æŸç§ *\"ç‹¬ç‰¹æ€§\"*,  (å³ä¸èƒ½æŠŠæ‰€æœ‰çš„æ˜æ–‡éƒ½å¯¹åº”åˆ°åŒä¸€ä¸ªå¯†æ–‡ä¸Š,ä¸åŒçš„xå¯¹åº”ä¸åŒçš„y)\n\nåˆèƒ½ä¿ç•™æŸç§ *ç‹¬ç«‹æ€§* å³xå¯¹åº”ä¸åŒçš„yéƒ½æ˜¯ç­‰æ¦‚ç‡çš„, ä¸èƒ½å› ä¸ºè¿™ä¸ªxçš„æŸäº›ç‰¹å¾å†³å®šå®ƒå–æŸäº›yçš„æ¦‚ç‡æ›´é«˜\n\n## æ”»å‡»æ–¹æ³•\n\nåœ¨éšæœºè°•ç¤ºæ¨¡å‹ä¸‹,æˆ‘ä»¬å¯¹ä¸‰ç§é—®é¢˜æœ‰ä»¥ä¸‹ç®—æ³•:\n(æ³¨æ„,è¿™äº›ç®—æ³•éƒ½æ˜¯Las Vegasç®—æ³•, å³ä¸ä¸€å®šæˆåŠŸçš„ç®—æ³•)\næˆ‘ä»¬è§„å®šè¿™ä¸ªç®—æ³•æœ€å¤šè®¡ç®—Qæ¬¡hashå€¼, è¿™ä¸ªç®—æ³•çš„å¹³å‡æˆåŠŸç‡ä¸º $\\varepsilon$\n\n### åŸåƒé—®é¢˜\n\nå¯¹äºä¸€ä¸ªå¯†æ–‡y,æˆ‘ä»¬å°è¯•ç”¨éšæœºçš„Qä¸ªxå»éªŒè¯æ˜¯ä¸æ˜¯yçš„åŸåƒ\n\n**æˆåŠŸç‡:**\n1-Qæ¬¡éƒ½æ‰¾ä¸åˆ°çš„æ¦‚ç‡\n$$\n1-(1-\\frac{1}{M})^Q\n$$\n\n### ç¬¬äºŒåŸåƒé—®é¢˜\n\nå¯¹äºä¸€ä¸ªx,æˆ‘ä»¬å°è¯•ç”¨å¦å¤–Q-1ä¸ª$x^\\prime$å»éªŒè¯æ˜¯ä¸æ˜¯ä¸x hashå€¼ç›¸åŒ\n\n**æˆåŠŸç‡:**  \n1-(Q-1æ¬¡éƒ½æ‰¾ä¸åˆ°çš„æ¦‚ç‡)\n$$\n1-(1-\\frac{1}{M})^{Q-1}\n$$\n\n### ç¢°æ’é—®é¢˜\n\néªŒè¯ Q ä¸ª x ä¸­æœ‰æ²¡æœ‰ y å€¼ç›¸åŒçš„ä¸¤ä¸ª x\n\n**æˆåŠŸç‡:**\n1-(Qä¸ªx hashå€¼å„ä¸ç›¸åŒçš„æ¦‚ç‡)\n$$\n1-\\frac{M}{M}\\cdot\\frac{M-1}{M}\\cdots\\frac{M-(Q-1)}{M}\n$$\nä¸è¦å› ä¸ºä½ ä¸èƒ½æ§åˆ¶ç¢°æ’å¯¹ä¾¿è®¤ä¸ºç¢°æ’é—®é¢˜æ²¡æœ‰å®é™…å¨èƒ\n\n#### ç”Ÿæ—¥æ‚–è®º\n\nä»ç¢°æ’é—®é¢˜, æˆ‘ä»¬å¯ä»¥å¼•å‡ºè‘—åçš„ç”Ÿæ—¥æ‚–è®º, è¿™ä¸¤ä¸ªé—®é¢˜åœ¨ç»Ÿè®¡æ„ä¹‰ä¸Šæ˜¯ç›¸åŒçš„, å³å¤šä¸ªç‹¬ç«‹äº‹ä»¶å‘ç”Ÿé‡å¤æƒ…å½¢çš„æ¦‚ç‡\né€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªè¿‘ä¼¼, æˆ‘ä»¬å¯ä»¥ä¼°ç®—å‡ºæ ·æœ¬æ€»æ•°(ç­çº§äººæ•°)ä¸å‘ç”Ÿç¢°æ’çš„æ¦‚ç‡(è‡³å°‘æœ‰ä¸¤ä¸ªäººç”Ÿæ—¥æ˜¯åŒä¸€å¤©çš„æ¦‚ç‡)ä¹‹é—´çš„å…³ç³»:\n\n![img_2022-10-15-10](notes/2021/2021.6/assets/img_2022-10-15-10.png)\n\næœ€åçš„ç»“æœæ˜¯:\n$$\nQ \\approx \\sqrt{2 M \\ln \\frac{1}{1-\\epsilon}}\n$$\nå…¶ä¸­,Mæ˜¯æ‰€æœ‰å¯èƒ½çš„æƒ…å½¢(ä¸€å¹´ä¸­çš„365å¤©), å¦‚æœæˆ‘ä»¬å–$\\epsilon=0.5, Q\\approx 22.3$å³23äººçš„ç­çº§é‡Œé¢å°±æœ‰50%çš„å¯èƒ½æ€§æœ‰è‡³å°‘æœ‰ä¸¤ä¸ªäººç”Ÿæ—¥ç›¸åŒ.\n\nå•ç‹¬æ¥çœ‹, ä¸€ä¸ªäººå–ç”Ÿæ—¥æ˜¯ä¸€å¹´ä¸­ä»»æ„ä¸€å¤©çš„æ¦‚ç‡æ˜¯$\\frac1{365}$, æ˜¯å¾ˆå°çš„, ä½†æ˜¯å½“å¤šä¸ªç‹¬ç«‹äº‹ä»¶åå¤å‘ç”Ÿ, å‘ç”Ÿç›¸åŒæƒ…å½¢çš„\"å·§åˆ\"çš„æ¦‚ç‡å´å‡ºå¥‡çš„é«˜(23ä¸ªäººç›¸æ¯”365æ˜¾ç„¶æ˜¯å¾ˆå°çš„ä¸€ä¸ªæ•°)!\n\nè¿™ä¸ªç»“è®ºå¯¹äº Hash å‡½æ•°çš„è®¾è®¡æœ‰ä»€ä¹ˆå¯å‘æ„ä¹‰å‘¢?\n\næ‰€æœ‰å¯èƒ½çš„ç”Ÿæ—¥å¯¹åº” Hash å‡½æ•°çš„æ‰€æœ‰å¯èƒ½å–å€¼\n\nç­çº§äººæ•°åˆ™ç›¸å½“äºä¸Šé¢ç®—æ³•é‡Œé¢çš„å°è¯•æ¬¡æ•°Q\n\nç±»ä¼¼çš„, å¦‚æœæˆ‘ä»¬çš„Hashå‡½æ•°çš„æ‰€æœ‰å¯èƒ½å–å€¼åªæœ‰365ä¸ª, åˆ™åªè¦å°è¯•23æ¬¡å°±å¾ˆæœ‰å¯èƒ½æ‰¾åˆ°ä¸€å¯¹hashå€¼ç›¸åŒçš„æ•°æ®äº†! è¿™æ˜¾ç„¶ä¸å¤ªå®‰å…¨(æ‰¾åˆ°ä¸€å¯¹ç›¸åŒçš„çœ‹èµ·æ¥è¿˜ä¸å¤ªä¸¥é‡,ä½†æ˜¯ä»ä¸‹é¢çš„è§„çº¦å…³ç³»èƒ½çœ‹å‡º, è§£å†³äº†ç¢°æ’é—®é¢˜, ä¹Ÿè§£å†³äº†)\n\n## å®‰å…¨æ€§å‡†åˆ™çš„æ¯”è¾ƒ/æ”»å‡»æ–¹æ³•çš„åŒ…å«(å½’çº¦)å…³ç³»\n\n![img_2022-10-15-11](notes/2021/2021.6/assets/img_2022-10-15-11.png)\n![img_2022-10-15-12](notes/2021/2021.6/assets/img_2022-10-15-12.png)\n\nç”±ä¸Šå›¾ä¸­çš„ç®­å¤´x--\u003eyçš„å«ä¹‰æ˜¯: if a hash function is secure in the $xxx$-sense, then it is secure in the $yyy$-sense.\n\nä¹¦ä¸­ä¸‹é¢ä¸¤ä¸ªé—®é¢˜çš„è¯æ˜æ€è·¯éƒ½æ˜¯\"é€†å¦è¯æ³•\"\n\n### ç¢°æ’ç¨³å›ºä¸ç¬¬äºŒåŸåƒç¨³å›º\n\n![img_2022-10-15-13](notes/2021/2021.6/assets/img_2022-10-15-13.png)\n\n- å¦‚æœ **ç¢°æ’ç¨³å›º** åˆ™ **ç¬¬äºŒåŸåƒç¨³å›º**\n\n**è¯æ˜æ–¹æ³•:**\n\nè¯æ˜å¦‚æœæœ‰ä¸€ä¸ªå‡½æ•°èƒ½å¤Ÿè§£å†³ç¬¬äºŒåŸåƒé—®é¢˜,åˆ™å¯ä»¥åˆ©ç”¨è¿™ä¸ªå‡½æ•°å»è§£å†³ç¢°æ’é—®é¢˜\né‚£ä¹ˆå¦‚æœä¸€ä¸ªå‡½æ•°çš„ç¢°æ’é—®é¢˜ä¸å¯è¢«è§£å†³(å³ç¢°æ’ç¨³å›º),é‚£ä¹ˆå®ƒçš„ç¬¬äºŒåŸåƒé—®é¢˜ä¹Ÿä¸å¯è¢«è§£å†³(ä¹Ÿæ˜¯ç¬¬äºŒåŸåƒç¨³å›ºçš„).\n\næ³¨æ„: \"è§£å†³ç¢°æ’é—®é¢˜\"çš„å«ä¹‰æ˜¯ **\"å¯ä»¥æ‰¾åˆ°ç¢°æ’å¯¹\"** è€Œä¸æ˜¯ **\"ä¸ä¼šæœ‰ç¢°æ’äº†\"**\n\n### ç¢°æ’ç¨³å›ºä¸åŸåƒç¨³å›º\n\n![img_2022-10-15-14](notes/2021/2021.6/assets/img_2022-10-15-14.png)\n\n- ~~å‰æ: $\\bcancel{|\\mathcal{X}|\\geq 2|\\mathcal{Y}|}$~~\n- ~~å¦‚æœ **ç¢°æ’ç¨³å›º** åˆ™ **åŸåƒç¨³å›º**--~~\n\n**æ³¨æ„ï¼š** ä¸èƒ½è¿™æ ·è¯´ï¼ä¹¦ä¸Šåªè¯´æ˜äº†å¦‚æœæˆ‘ä»¬æœ‰100%çš„æŠŠæ¡è§£å†³åŸåƒé—®é¢˜ï¼Œåˆ™æœ‰\n$$\n\\mathcal{\\frac{|X|-|Y|}{|X|}}\n$$\nçš„æŠŠæ¡è§£å†³ç¢°æ’é—®é¢˜\n\nè€Œç¢°æ’ç¨³å›ºï¼ˆä¸èƒ½è§£å†³ç¢°æ’é—®é¢˜ï¼‰å¹¶ä¸èƒ½æ¨å‡ºåŸåƒç¨³å›ºï¼ˆä¸èƒ½è§£å†³åŸåƒé—®é¢˜ï¼‰\nï¼ˆé™¤é$\\mathcal{X\u003e\u003eY}$, å³æ˜æ–‡ç©ºé—´æå¤§äºå¯†æ–‡ç©ºé—´)\n\n\u0026emsp; **è¯æ˜æ–¹æ³•:**\nè¯æ˜çš„æ˜¯å¦‚æœå­˜åœ¨ä¸€ä¸ªå¯ä»¥100%è§£å†³åŸåƒé—®é¢˜çš„Las Vegasç®—æ³•ï¼Œé‚£ä¹ˆå¯ä»¥åˆ©ç”¨è¿™ä¸ªç®—æ³•æ„é€ ä¸€ä¸ªè§£å†³ç¢°æ’é—®é¢˜æˆåŠŸç‡æ˜¯\n$$\n\\mathcal{\\frac{|X|-|Y|}{|X|}}\n$$\nçš„ç®—æ³•(åœ¨$|\\mathcal{X}|\\geq 2|\\mathcal{Y}|$çš„æ—¶å€™æŠŠæ¡æ˜¯50%,å¦‚æœ$|\\mathcal{X}|=|\\mathcal{Y}|$åˆ™å®Œå…¨ä¸å¯èƒ½æ‰¾åˆ°ç¢°æ’\n\n(ä¸ºä»€ä¹ˆå‘¢? æŒ‰ç†è¯´å¦‚æœæœ‰ä¸¤ä¸ªxæŒ‡å‘åŒä¸€ä¸ªy,è¿˜æ˜¯å¯ä»¥æ‰¾åˆ°ç¢°æ’çš„å•Š?\n\n![|200](notes/2021/2021.6/assets/img_2022-10-15-15.png)\n\n--\u003eåŸå› æ˜¯åœ¨ä¹¦ä¸­æœ‰è¿™ä¹ˆä¸€å¥è¯:\n\n![å¯†ç å­¦åŸç†ä¸å®è·µ page99](notes/2021/2021.6/assets/img_2022-10-15-16.png)\n\næ‰€ä»¥å½“$|\\mathcal{X}|=|\\mathcal{Y}|$çš„æ—¶å€™, xå’Œyä¸€å®šæ˜¯ä¸€ä¸€å¯¹åº”çš„))\n\n![img_2022-10-15-17](notes/2021/2021.6/assets/img_2022-10-15-17.png)\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/Hash%E5%87%BD%E6%95%B0_Pt.3_%E8%BF%AD%E4%BB%A3Hash%E5%87%BD%E6%95%B0":{"title":"Hashå‡½æ•°_Pt.3_è¿­ä»£Hashå‡½æ•°","content":"# è¿­ä»£Hashå‡½æ•°\n\n## è¿­ä»£Hashå‡½æ•°çš„åŸºæœ¬ç»“æ„\n\nè¿­ä»£Hashå‡½æ•°æ˜¯ä¸€ç§ç”¨**æœ‰é™é•¿åº¦Hashå‡½æ•°**æ¥å¤„ç†**æ— é™é•¿åº¦çš„æ•°æ®**çš„æ–¹æ³•\n\nä¸‹é¢è¿™å¼ å›¾å½¢è±¡åœ°è¡¨ç¤ºäº†è¿­ä»£Hashå‡½æ•°åœ°åŠ å¯†æ­¥éª¤:\n![img_2022-10-15-18](notes/2021/2021.6/assets/img_2022-10-15-18.png)\n\nè¿™æ ·çš„æ„é€ æ–¹æ³•å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹çš„ä¸‰ä¸ªæ­¥éª¤:\n\næˆ‘ä»¬ä»¥æœ‰é™çš„Hashå‡½æ•°$compress$ä¸ºåŸºç¡€\n$$\n\\{0,1\\}^{m+t}\\longrightarrow \\{0,1\\}^{m}\n$$\nè¿™æ˜¯ä¸€ä¸ªå°†é•¿åº¦ä»$m+t$ç¼©å‡åˆ°$m$çš„æœ‰é™é•¿åº¦hashå‡½æ•°\n\n1. **é¢„å¤„ç†**\nè¿™ä¸€æ­¥å°†æ˜æ–‡åˆ‡åˆ†æˆé•¿åº¦ä¸º**t**çš„å°æ®µ.\n\n--\u003eæœ€åå‰©ä½™çš„æ€ä¹ˆåŠ?\n\n1. åœ¨æœ«å°¾æ·»åŠ æ•´ä¸ªå­—ç¬¦ä¸²çš„é•¿åº¦\n2. å¦‚æœè¿˜ä¸å¤Ÿ,ç”¨0è¡¥è¶³\n--\u003eä¸ºä»€ä¹ˆè¦æ·»åŠ å­—ç¬¦ä¸²çš„é•¿åº¦?\nè¿™æ˜¯ä¸ºäº†ä½¿é¢„å¤„ç†å‡½æ•°$x\\mapsto y$ä¸ºå•å°„, ä¿è¯æ•´ä½“çš„æŠ—ç¢°æ’æ€§è´¨\nåä¾‹:åªæ·»åŠ 0\n1001_0       -\u003e 1001_0000\n1001_000  -\u003e 1001_0000\nè¿™ä¸¤ä¸ªä¸²æ„æˆäº†ä¸€ä¸ªç¢°æ’å¯¹\n\n2. **å¤„ç†**\nè¿™ä¸€æ­¥é€æ­¥å¾ªç¯è°ƒç”¨$compress$, çŸ¥é“å¾—åˆ°æœ€åçš„ç»“æœ$z_r$,å®ƒçš„é•¿åº¦ä¸º$m$.\n\næ³¨æ„:\n\n- ä¸€å¼€å§‹æœ‰ä¸€ä¸ªå…¬å¼€çš„åˆå§‹å€¼æ¯”ç‰¹ä¸² $IV$, ä¸$y_1$ä¸€åŒæ„æˆ$compress$çš„ç¬¬ä¸€æ¬¡è¾“å…¥\n- æˆ‘ä»¬æ¯æ¬¡ç¼©å‡é•¿åº¦ä¸ºtçš„ä¸², ä¸€å…±è¿›è¡Œ$$r\\times t=\\Big\\lceil \\frac{x}{t}\\Big\\rceil$$æ¬¡,å…¶ä¸­ræ˜¯yçš„ä¸ªæ•°\n\n3. **è¾“å‡ºå˜æ¢**\nè¿™ä¸€æ­¥æŠŠé•¿åº¦ä¸º$m$çš„ç»“æœæ˜ å°„åˆ°$l$, ä½¿å¾—æœ€åçš„è¿­ä»£Hashå‡½æ•°æ˜¯ä¸€ä¸ªé•¿åº¦ä¸Š$i\\mapsto l$çš„æ˜ å°„, iä¸ºä»»æ„è‡ªç„¶æ•°\n\n- è¿™ä¸€æ­¥æ˜¯å¯é€‰çš„\n\n## è¿­ä»£Hashå‡½æ•°çš„å®ä¾‹\n\n### Merkle-Damgardç»“æ„\n\næ ¹æ®æœ‰é™hashå‡½æ•°Compressä¸­tçš„å¤§å°è¿›è¡Œåˆ†ç±», Merkle-Damgardç»“æ„çš„å‡½æ•°æœ‰ä¸¤ç§å½¢å¼ï¼š\n\n#### Compressä¸­ $t\\geqslant2$ çš„Merkle-Damgardç»“æ„\n\nå¯¹æ¯”è§‚å¯Ÿç®—æ³•ä¼ªä»£ç å’Œå›¾è§£å³å¯ï¼ˆæ”¾å¤§çœ‹ï¼‰\n![ä¼ªä»£ç ](notes/2021/2021.6/assets/img_2022-10-15-19.png)\n![æ‰‹ç»˜å›¾è§£](notes/2021/2021.6/assets/img_2022-10-15.jpg)\n\næ¯”è¾ƒMerkle-Damgardç»“æ„å’Œè¿­ä»£Hashçš„ä¸€èˆ¬ç»“æ„ï¼š\n\n1. é¢„å¤„ç†\n 1. MDç»“æ„æŠŠxæ‹†æˆäº†å¤§å°ä¸ºt-1çš„å°æ®µï¼ˆè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆè¦å•ç‹¬è®¨è®º$t=1$ çš„æƒ…å½¢ï¼‰ï¼Œå¦åˆ™$t-1=0ï¼Œy$å‹æ ¹æ²¡æ³•åˆ†\n 2. åœ¨æœ€åè¡¥é½çš„æ—¶å€™æ˜¯åœ¨æœ«å°¾æ·»ä¸Šç©ºç¼ºä½ä¸ªæ•°çš„äºŒè¿›åˆ¶ï¼Œåœ¨ä¸­é—´è¡¥é›¶\n  \n  ![æ‰‹ç»˜å›¾è§£â€”â€”é¢„å¤„ç†](notes/2021/2021.6/assets/img_2022-10-15-20.png)\n  \n2. å¤„ç†\n 1. åœ¨æ¯æ¬¡è°ƒç”¨Compressçš„æ—¶å€™åœ¨æœ€ä¸­é—´æ’å…¥äº†ä¸€ä¸ª1ï¼ˆæ³¨æ„æ˜¯1ä¸ª1ä¸æ˜¯0ï¼ï¼‰\nå¯¹åº”t-1é•¿åº¦çš„yï¼Œæ¯æ¬¡Compressè¾“å…¥çš„é•¿åº¦ä¾ç„¶æ˜¯$m+t$\n\n   ![æ‰‹ç»˜å›¾è§£_è¾“å…¥é•¿åº¦](notes/2021/2021.6/assets/img_2022-10-15-21.png)\n\n#### Compressä¸­ $t=1$ çš„Merkle-Damgardç»“æ„\n\næ²¡æ³•æŠŠxåˆ†æˆt-1é•¿çš„å°æ®µäº†ï¼Œæˆ‘ä»¬æ€ä¹ˆå¯¹xè¿›è¡Œåˆç†çš„æ‹†åˆ†ï¼Œæ–¹ä¾¿æˆ‘ä»¬åˆ©ç”¨Compresså‡½æ•°å‘¢ï¼Ÿ\næˆ‘ä»¬å¯ä»¥é€ä½å¯¹xè¿›è¡ŒæŸç§ä»£æ¢ï¼Œ\n\n## è®ºè¯è¿­ä»£Hashå‡½æ•°çš„å®‰å…¨æ€§\n\n[Hashå‡½æ•°çš„æ”»å‡»æ–¹æ³• å®‰å…¨æ€§](notes/2021/2021.6/Hashå‡½æ•°_Pt.2_æ”»å‡»æ–¹æ³•_å®‰å…¨æ€§.md#Hashå‡½æ•°çš„æ”»å‡»æ–¹æ³•%20å®‰å…¨æ€§)\n\næˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„å®‰å…¨æ€§åªæ˜¯é’ˆå¯¹äºæœ‰é™çš„Hashå‡½æ•°Compressçš„ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥å°†ä»è¿™ç»§ç»­æ¨å¹¿ï¼Œå¾—åˆ°è¿­ä»£Hashå‡½æ•°å®‰å…¨æ€§çš„ä¸€äº›ç»“è®º\n\nä¸æ˜¯æ‰€æœ‰è¿­ä»£Hashå‡½æ•°éƒ½æœ‰Merkle-Damgardç»“æ„çš„ä¼˜ç§€æ€§è´¨:\n\u003e æ¨ç¤¼çè€å¸ˆè¯¾ä»¶ ç¬¬ 4 ç«  Hash å‡½æ•°.Pdf#page=28\n\n### Merkle-Damgardç»“æ„çš„å®‰å…¨æ€§\n\n#### ç¢°æ’ç¨³å›º\n\n- å¦‚æœCompressæ˜¯ç¢°æ’ç¨³å›ºçš„ï¼Œé‚£ä¹ˆMerkle-Damgardå‡½æ•°ä¹Ÿæ˜¯ç¢°æ’ç¨³å›ºçš„\n\n**è¯æ˜ï¼š**\nå› ä¸ºMerkle-Damgardç»“æ„æœ‰ä¸¤ç§æƒ…å½¢ï¼Œæ‰€ä»¥ä¹Ÿè¦åˆ†ç±»è®¨è®º\næˆ‘ä»¬è¯æ˜çš„æ€è·¯ä¾ç„¶æ˜¯â€é€†å¦è¯æ³•â€œï¼Œå³æˆ‘ä»¬éœ€è¦è¯æ˜å¦‚æœMerkle-Damgardç»“æ„ä¸­å­˜åœ¨ä¸€ä¸ªç¢°æ’ï¼Œé‚£ä¹ˆCompresså‡½æ•°é‡Œé¢ä¹Ÿä¸€å®šå¯ä»¥æ‰¾åˆ°ä¸€ä¸ªç¢°æ’\n\n##### $t\\geq 2$çš„Merkle-Damgardç»“æ„\n\nå› ä¸ºCompressæ˜¯æŠŠåŸå­—ç¬¦ä¸²åˆ†æˆè®¸å¤šå°å—è¿›è¡ŒHashçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸»è¦å°±æ˜¯ç¡®å®šæ˜¯åœ¨åŸå­—ç¬¦ä¸²ä¸­çš„å“ªä¸€éƒ¨åˆ†èƒ½å¤Ÿæ‰¾åˆ°ä¸€ä¸ªâ€ä¸ä¸€è‡´â€œï¼ˆç¢°æ’ï¼‰\n$$\n\\begin{array}{l}\ny(x)=y_{1}\\left\\|y_{2}\\right\\| \\cdots \\| y_{k+1} \\\\\ny\\left(x^{\\prime}\\right)=y_{1}^{\\prime}\\left\\|y_{2}^{\\prime}\\right\\| \\cdots \\| y_{\\ell+1}^{\\prime}\n\\end{array}\n$$\n**åˆ†ç±»è®¨è®ºï¼š**\n\n1. åœ¨ä¸¤ä¸ªå­—ç¬¦ä¸²é•¿åº¦æ¨¡$t-1$ç»“æœä¸ä¸€æ ·æ—¶, å¾ˆå®¹æ˜“æƒ³åˆ°åœ¨æœ€åæ·»åŠ çš„$y_{k+1}$ä¸€å®šä¸ä¸€æ ·,è¿™æ ·Compressåœ¨æœ€åä¸€æ­¥ä¸€å®šæœ‰ç¢°æ’\n\n\u003e æƒ…å†µ 1: $|x| \\equiv\\left|x^{\\prime}\\right|(\\bmod t-1)$ ã€‚\n\u003e\n\u003e è¿™é‡Œ $d \\neq d^{\\prime}$ ä¸” $y_{k+1} \\neq y_{l+1}^{\\prime}$, æˆ‘ä»¬æœ‰\n\u003e\n\n$$\\begin{aligned}\n\\operatorname{compress}\\left(g_{k}\\|1\\| y_{k+1}\\right) \u0026=g_{k+1} \\\\\n\u0026=h(x) \\\\\n\u0026=h\\left(x^{\\prime}\\right) \\\\\n\u0026=g_{\\ell+1}^{\\prime} \\\\\n\u0026=\\operatorname{compress}\\left(g^{\\prime}_l\\|1\\| y^{\\prime}_{\\ell+1} \\right)\n\\end{aligned}$$\n\n\u003e\n\u003e å› ä¸º $y_{k+1} \\neq y_{\\ell+1}^{\\prime}$, æ‰€ä»¥æ‰¾åˆ°äº† $h$ çš„ä¸€ä¸ªç¢°æ’ã€‚\n\n2. åœ¨æœ€åæ‰¾ä¸åˆ°ä¸ä¸€è‡´, å°±åªæœ‰å‘å‰å›æº¯. ç°åœ¨ä¸¤ä¸ªå­—ç¬¦ä¸²æœ«å°¾ä¸€æ ·(æ¨¡$t-1$ç»“æœç›¸åŒ), æ‰€ä»¥åªæœ‰ä¸¤ç§æƒ…å½¢:\n \u003e æƒ…å†µ 2: $|x| \\equiv\\left|x^{\\prime}\\right|(\\bmod t-1)$ ã€‚\n \u003e ä¸ºäº†ä¾¿äºè®¨è®ºï¼Œåˆ†æˆä¸¤ç§æ›´ç»†çš„æƒ…å†µ:\n - ä¸¤ä¸ªå­—ç¬¦ä¸²é•¿åº¦ä¸€æ¨¡ä¸€æ ·\n - ä¸¤ä¸ªå­—ç¬¦ä¸²é•¿åº¦ç›¸å·®$t-1$çš„æ•´æ•°å€\n\n 1. **å¯¹äºç¬¬1ç§æƒ…å½¢:**\n å› ä¸º$z_1$åœ¨ä¸­é—´è¿æ¥ä¸¤ä¸ªéƒ¨åˆ†ç”¨çš„æ˜¯0, è€Œå‰©ä¸‹çš„$z$éƒ½ç”¨çš„æ˜¯1, æ‰€ä»¥åœ¨å¼€å¤´ä¸€å®šèƒ½æ‰¾åˆ°ä¸€ä¸ªç¢°æ’.\n \n \u003e æƒ…å†µ 2a: $|x| \\neq\\left|x^{\\prime}\\right|$ ã€‚\n \u003e ä¸å¤±ä¸€èˆ¬æ€§ï¼Œè®¾ $\\left|x^{\\prime}\\right|\u003e|x|$, å› æ­¤ $\\ell\u003ek$ ã€‚æŒ‰ç…§æƒ…å†µ $2 \\mathrm{a}$ ç±»ä¼¼çš„è¿‡ç¨‹ï¼Œå‡å®šæ²¡æœ‰æ‰¾åˆ° compress çš„ç¢°æ’ï¼Œæœ€åæ€»æœ‰\n \u003e $$\n \u003e \\begin{aligned}\n \u003e \\operatorname{compress}\\left(0^{m+1} \\| y_{1}\\right) \u0026=g_{1} \\\\\n \u003e \u0026=g_{\\ell-k+1}^{\\prime} \\\\\n \u003e \u0026=\\operatorname{compress}\\left(g_{\\ell-k}^{\\prime}\\|1\\| y_{\\ell-k+1}^{\\prime}\\right)\n \u003e \\end{aligned}\n \u003e $$\n \u003e ä½†\n \u003e $$\n \u003e 0^{m+1} \\| y_{1}\n \u003e $$\n \u003e çš„ç¬¬ $(m+1)$ æ¯”ç‰¹æ˜¯ 0, è€Œ\n \u003e $$\n \u003e g_{\\ell-k}^{\\prime}\\|1\\| y_{\\ell-k+1}^{\\prime}\n \u003e $$\n \u003e çš„ç¬¬ $(m+1)$ æ¯”ç‰¹æ˜¯ 1 ã€‚å› æ­¤å¿…ç„¶ä¼šæ‰¾åˆ° compress çš„ä¸€ä¸ªç¢°æ’ã€‚\n\n 2. **å¯¹äºç¬¬2ç§æƒ…å½¢,**\n  æˆ‘ä»¬é€æ­¥å€’æ¨, è¦ä¹ˆåœ¨æŸä¸€æ­¥æ‰¾åˆ°ä¸€ä¸ªä¸ä¸€æ ·, è¦ä¹ˆæ²¡æœ‰ä¸ä¸€æ ·(è€Œè¿™ä¸å‡è®¾$y(x)\\neq y(x^\\prime)$ ç›¸çŸ›ç›¾)\n\n \u003e æƒ…å†µ 2b : $|x|=\\left|x^{\\prime}\\right|$ ã€‚\n \u003e æ­¤æ—¶æœ‰ $k=\\ell$ å’Œ $y_{k+1}=y_{k+1}^{\\prime}$, åƒæƒ…å†µ 1 ä¸­ä¸€æ ·ï¼Œæˆ‘ä»¬æœ‰:\n \u003e $$\n \u003e \\begin{aligned}\n \u003e \\operatorname{compress}\\left(g_{k}\\|1\\| y_{k+1}\\right) \u0026=g_{k+1} \\\\\n \u003e \u0026=h(x) \\\\\n \u003e \u0026=h\\left(x^{\\prime}\\right) \\\\\n \u003e \u0026=g_{k+1}^{\\prime} \\\\\n \u003e \u0026=\\operatorname{compress}\\left(g_{k}^{\\prime}\\|1\\| y_{k+1}^{\\prime}\\right)\n \u003e \\end{aligned}\n \u003e $$\n \u003e å¦‚æœ $g_{k} \\neq g_{k}^{\\prime}$, åˆ™æ‰¾åˆ°äº† compress çš„ç¢°æ’ï¼Œæ‰€ä»¥å¯å‡å®š $g_{k}=g_{k}^{\\prime}$ ã€‚åˆ™æœ‰\n \u003e $$\n \u003e \\begin{aligned}\n \u003e \\operatorname{compress}\\left(g_{k-1}\\|1\\| y_{k}\\right) \u0026=g_{k} \\\\\n \u003e \u0026=g_{k}^{\\prime} \\\\\n \u003e \u0026=\\operatorname{compress}\\left(g_{k-1}^{\\prime}\\|1\\| y_{k}^{\\prime}\\right)\n \u003e \\end{aligned}\n \u003e $$\n \u003e æˆ–è€…æ‰¾åˆ° compress çš„ä¸€ä¸ªç¢°æ’ï¼Œæˆ–è€… $g_{k-1}=g_{k-1}^{\\prime}$ å¹¶ä¸” $y_{k}=y_{k}^{\\prime}$ ã€‚å‡å®šæ²¡æœ‰æ‰¾åˆ°ç¢°æ’ï¼Œé‡å¤æ­¢ è¿°è¿‡ç¨‹ï¼Œæœ€åå¾—åˆ°\n \u003e $$\n \u003e \\begin{aligned}\n \u003e \\operatorname{compress}\\left(0^{m+1} \\| y_{1}\\right) \u0026=g_{1} \\\\\n \u003e \u0026=g_{1}^{\\prime} \\\\\n \u003e \u0026=\\operatorname{compress}\\left(0^{m+1} \\| y_{1}^{\\prime}\\right)\n \u003e \\end{aligned}\n \u003e $$\n \u003e å¦‚æœ $y_{1} \\neq y_{1}^{\\prime}$, åˆ™æ‰¾åˆ°äº† compress çš„ä¸€ä¸ªç¢°æ’ï¼Œå› æ­¤å¯å‡å®š $y_{1}=y_{1}^{\\prime}$ ã€‚è¿™æ ·å¯¹ $1 \\leqslant i \\leqslant k+1$ éƒ½æœ‰ $y_{i}=y_{i}^{\\prime}$, æ‰€ä»¥ $y(x)=y\\left(x^{\\prime}\\right)$ ã€‚ä½†å› ä¸ºæ˜ å°„ $x \\mapsto y(x)$ æ˜¯å•å°„ï¼Œè¿™æ„å‘³ç€ $x=x^{\\prime}$ ã€‚è€Œæˆ‘ä»¬å‡å®šäº† $x \\neq x^{\\prime}$, è¿™å°±äº§ç”Ÿäº†çŸ›ç›¾ã€‚\n\nå› ä¸ºè®¨è®ºäº†æ‰€æœ‰çš„æƒ…å†µï¼Œä¹Ÿå°±è¯æ˜äº†æ‰€æœŸæœ›çš„ç»“è®ºã€‚\n\n\u003e å…¶å®è¿™é‡Œä¸åº”è¯¥æŠŠä¹¦ä¸Šçš„è¯æ˜æŠ„ä¸‹æ¥çš„, è¿™æ ·é™ä½äº†æˆ‘çš„æ€è€ƒçš„æµ“åº¦,è®©è¿™ç¯‡ç¬”è®°å˜å¾—é™Œç”Ÿäº†, å¦‚æœæ‹…å¿ƒä¸å¤Ÿè¯¦ç»†, å¯ä»¥åˆ—å‡ºä¹¦ä¸Šçš„é¡µç , åœ¨å°†æ¥å¦‚æœéœ€è¦æ•´ç†æˆæ–‡ç« ,ä¹Ÿå¯ä»¥åˆ°æ—¶å€™å†æ¥æ’ç‰ˆ\n\n##### $t = 1$çš„Merkle-Damgardç»“æ„\n\n**å…³é”®:**\n\n- é€æ¯”ç‰¹é¢„å¤„ç†\n é¢„å¤„ç†çš„å…³é”®ä¾¿æ˜¯å¦‚ä½•åœ¨æŠŠé•¿åº¦å˜å¾—è§„æ•´çš„åŒæ—¶æ„é€ ä¸€ä¸ª**å•å°„**\n å…ˆåˆ©ç”¨è¿™ä¸ªå‡½æ•°é€æ¯”ç‰¹é¢„å¤„ç†:\n $$\n \\begin{align}\n f(0)\u0026=0\\\\\n f(1)\u0026=01\\\\\n \\end{align}\n $$\n ç„¶ååœ¨å¼€å¤´æ·»åŠ 11:\n $y\\leftarrow 11||f(x_1)||f(x_2)||\\cdots||f(x_n)$\n (è¿™æ˜¯ä¸ºäº†ä¿è¯æ— ç¢°æ’æ€§è´¨, (æ„é€ æ— åç¼€æ€§è´¨ä¿è¯æ— ç¢°æ’æ€§è´¨))\n- é€æ¯”ç‰¹å‹ç¼©\n åˆ©ç”¨ $compress: \\{0,1\\}^{m+1}\\rightarrow \\{0,1\\}^m$\n è¢«å‹ç¼©çš„ç¬¬ä¸€ä¸ªä¸²æ˜¯$0^m||y_1$\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/Hash%E5%87%BD%E6%95%B0_Pt.4_%E5%AE%89%E5%85%A8Hash%E7%AE%97%E6%B3%95_SHA-1":{"title":"Hashå‡½æ•°_Pt.4_å®‰å…¨Hashç®—æ³•_SHA-1","content":"# SHA-1\n\nTags: #Cryptography  #Math  #Course #Hash \n\n**SHA-1æ˜¯ä¸€ä¸ªå…·æœ‰160bitæ¶ˆæ¯æ‘˜è¦çš„è¿­ä»£Hashå‡½æ•°**\n\n## ä¸»è¦æ€æƒ³\nSHA-1 çš„åˆ†ç»„å¤§å°æ˜¯ 512bit, æ„å‘³ç€æ¯ä¸€æ¬¡è¿­ä»£å¤„ç† 512bit çš„æ•°æ®\n\nSHA-1å»ºç«‹åœ¨å¯¹æ¯”ç‰¹ä¸²é¢å‘**å­—**çš„æ“ä½œä¸Š, æ„å‘³ç€åœ¨å¤„ç†512bitçš„æ—¶å€™æ˜¯æ¯æ¬¡32bit, ~~ä¸€å…±16æ¬¡~~, ä¸€å…±80æ¬¡. (ä¸ºä»€ä¹ˆå˜å¤šäº†? å› ä¸ºåœ¨å¾ªç¯é‡Œé¢éœ€è¦å°†16ä¸ªå­—æ‰©å……åˆ°80ä¸ªå­—, å¦‚ä¸‹å›¾)\n\n![](notes/2021/2021.6/assets/img_2022-10-15-22.png)\n\n(åˆšå¼€å§‹æˆ‘ä¸€ç›´çœ‹ä¸æ‡‚è¿™é‡Œ, è§‰å¾—æ•°ç»„ä¸‹æ ‡è¶…é™äº†, ä½†ä»”ç»†çœ‹, æ„æ€å…¶å®æ˜¯æ ¹æ®åŸæ¥çš„16ä¸ªå­—åˆ©ç”¨å¼‚æˆ–ä¸å¾ªç¯å·¦ç§»æ„å»ºæ–°çš„å­—)\n\nSHA-1åœ¨å¾ªç¯çš„æ—¶å€™ä½¿ç”¨äº†5ä¸ªä¸­é—´å˜é‡$A,B,C,D,E$, å¤§å°ä¸ºä¸€ä¸ªå­—, ä¸é€šè¿‡æ–­æ›´æ–°å®ƒä»¬çš„å€¼æ¥è¿›è¡Œå¤„ç†\n\n[Youtube - An Intuitive Introduction](https://www.youtube.com/watch?v=DMtFhACPnTY)\n![](notes/2021/2021.6/assets/img_2022-10-15-23.png)\nåŒæ—¶è¿™ä¸ªè§†é¢‘é‡Œé¢è¿˜æŒ‡å‡ºäº†å…¶ä»–åœ°æ–¹éƒ½æ²¡æœ‰æåˆ°çš„ä¸€ç‚¹: SHA-1 é‡Œé¢çš„æ‰€æœ‰åŠ æ³•éƒ½æ˜¯å¾ªç¯åŠ æ³•(æº¢å‡ºä½å˜æˆæœ€ä½ä½), è¿™æ ·ä¼šæŸå¤±ä¿¡æ¯, è®© Hash å˜å¾—æ›´å®‰å…¨.\n\n**(ä½†æ˜¯è¿™ä¸€ç‚¹å…¶ä»–åœ°æ–¹éƒ½æ²¡æœ‰æåˆ°, å¾…éªŒè¯!)**\n#todo\n\nè€å¸ˆçš„è¯¾ä»¶ä¸­æŠŠSHA-1ä¸Merkle-Damgardç»“æ„çš„å¯¹åº”å…³ç³»å†™çš„å¾ˆæ¸…æ™°\n\n[Merkle-Damgardç»“æ„](notes/2021/2021.6/Hashå‡½æ•°_Pt.3_è¿­ä»£Hashå‡½æ•°.md#Merkle-Damgardç»“æ„)\n\n![](notes/2021/2021.6/assets/img_2022-10-15-24.png)\n![](notes/2021/2021.6/assets/img_2022-10-15-25.png)\n\n\n\nçº¢è‰²\"do\"é‡Œé¢çš„éƒ¨åˆ†å¦‚ä¸‹å›¾ä¾‹:\n\n![File:SHA-1.svg](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/SHA-1.svg/365px-SHA-1.svg.png)\n\n\n## é¢„å¤„ç†:\næ³¨æ„çš„ä¸€ç‚¹æ˜¯SHA-1èƒ½å¤„ç†çš„ä¸²æ˜¯æœ‰æœ€å¤§é•¿åº¦çš„, ä¸º$2^{64}-1$\n\nåŒæ—¶å› ä¸ºåœ¨é¢„å¤„ç†çš„æ—¶å€™éœ€è¦å¡«å……xçš„é•¿åº¦$l$, ä»ä¸Šé¢å¯ä»¥çŸ¥é“$|l|\\leq 64\\space bits$, å¦‚æœ$l$é•¿åº¦ä¸å¤Ÿ, åœ¨å·¦è¾¹åŠ 0, (åœ¨å·¦è¾¹åŠ 0ä¹Ÿç¬¦åˆæ­£å¸¸çš„å¤§å°è¡¨ç¤ºæ–¹æ³•(ç”¨0\nå¡«å……æ²¡æœ‰ç”¨åˆ°çš„é«˜ä½))\n\né¢„å¤„ç†æ–¹æ³•:\n$$y\\leftarrow x||ä¸€ä¸ª1||è®¸å¤š0||l$$\n0 æœ‰å¤šå°‘ä¸ªå‘¢? è®© y çš„é•¿åº¦ mod 512=0 å³å¯\n\næ›´æ¸…æ™°ä¸€ç‚¹çš„è¯, æ˜¯:\n\n![|480](notes/2021/2021.6/assets/img_2022-10-15-26.png)\n\n## å¤„ç†\nç›´è§‰ç†è§£ä¸Šé¢å·²ç»è°ˆè¿‡äº†, è¯¦ç»†çš„è¯å¯ä»¥çœ‹\u003cå¯†ç å­¦åŸç†ä¸å®è·µ page118\u003eæˆ–è€…å®˜æ–¹æ–‡æ¡£:[RFC3174](https://datatracker.ietf.org/doc/html/rfc3174#section-6)\n\n## ç»“æœå˜æ¢\nä¸éœ€è¦å˜æ¢, æœ€åçš„$H_0||H_1||H_2||H_3||H_4$è¿èµ·æ¥, ä¾¿æ˜¯ä¸€ä¸ª$32bits\\cdot 5=160\\space bits$çš„æ¶ˆæ¯æ‘˜è¦.\n\n\n## Further Questions\n- SHA-1çš„è¿™ç§è¿­ä»£ç»“æ„ä¸Merkel-Damgardç»“æ„çš„å…³ç³»æ˜¯ä»€ä¹ˆ?(History, æ˜¯Merkelé¦–åˆ›äº†è¿™ç§ç»“æ„å—?)\n\n[SHA-1çš„Wikipediaå†™çš„è›®å¥½](https://en.wikipedia.org/wiki/SHA-1)\n\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.6/Hash%E5%87%BD%E6%95%B0_Pt.5_%E6%B6%88%E6%81%AF%E8%AE%A4%E8%AF%81%E7%A0%81_MAC":{"title":"Hashå‡½æ•°_Pt.5_æ¶ˆæ¯è®¤è¯ç _MAC","content":"# æ¶ˆæ¯è®¤è¯ç  MAC Message Authentication Code\n\n\n## æ¶ˆæ¯è®¤è¯ç æ˜¯ä»€ä¹ˆ\n\nç”Ÿæˆæ–¹å¼: å¸¦å¯†é’¥çš„Hashå‡½æ•°, Hashå€¼å¯ä»¥ä¸ç”¨åœ¨å®‰å…¨çš„ä¿¡é“ä¸Šä¼ è¾“, åªéœ€è¦å¼€å§‹çš„æ—¶å€™åå•†ä¸€ä¸ªå¯†é’¥$K$å°±å¯ä»¥äº†\n\nç”¨äºæ ¸éªŒåœ¨**ä¸å®‰å…¨ä¿¡é“ä¸Šä¼ è¾“çš„æ¶ˆæ¯**æœ‰æ²¡æœ‰è¢«ä¿®æ”¹\n\n## ä¸å®‰å…¨çš„æ„é€ æ–¹å¼\nä¸€ä¸ªå¾ˆç›´è§‚çš„æ–¹å¼ä¾¿æ˜¯æŠŠå¯†é’¥$K$åŠ åˆ°æ˜æ–‡xé‡Œé¢,ä¸€èµ·Hash, æ—¢ç„¶æ”»å‡»è€…ä¸çŸ¥é“$K$æ˜¯ä»€ä¹ˆ, ä»–ä¹Ÿåº”è¯¥æ— æ³•è®¡ç®—$h_K(x)=h(x_K). (x_K$ä¸ºåŠ å…¥äº†Kçš„x)\n\nä½†æ˜¯ä»¥ä¸‹è®ºè¯å‘Šè¯‰æˆ‘ä»¬ä¸€äº›ç®€å•çš„æ„é€ æ–¹å¼å¹¶ä¸å®‰å…¨, æ”»å‡»è€…å³ä½¿ä¸çŸ¥é“Kæ˜¯ä»€ä¹ˆ, ä¹Ÿå¯ä»¥åˆ©ç”¨ä¸€ä¸ªæœ‰æ•ˆå¯¹$(x,h_K(x))$è®¡ç®—æ–°çš„æœ‰æ•ˆå¯¹$(x^\\prime,h_K(x^\\prime)$\n\n### ç›´æ¥æŠŠKä½œä¸º$IV$\n(IV å³ Compress çš„åˆå§‹è¾“å…¥ [è§è¿­ä»£Hashå‡½æ•°çš„åŸºæœ¬ç»“æ„](notes/2021/2021.6/Hashå‡½æ•°_Pt.3_è¿­ä»£Hashå‡½æ•°.md#è¿­ä»£Hashå‡½æ•°çš„åŸºæœ¬ç»“æ„))\n\n#### æ— é¢„å¤„ç†\nå‡è®¾$x^{\\prime}=x||w$, åˆ™å¯ä»¥è¿™æ ·è®¡ç®—æ–°çš„$h_K(x^\\prime)$\n$$h_{K}\\left(x \\| w\\right)=\\operatorname{compress}\\left(h_{K}(x) \\| w\\right)=\\operatorname{compress}\\left(y\\| w\\right)$$\n\n**ç›´è§‰ç†è§£:**\nä¸ºä»€ä¹ˆè¿˜æ˜¯èƒ½å¤Ÿç®—å‡ºæ–°çš„æœ‰æ•ˆå¯¹, å³ä½¿æˆ‘ä»¬å¹¶ä¸çŸ¥é“K? è¿™è¯´æ˜è¿™ç§æ„é€ æ–¹å¼æ²¡æœ‰å¾ˆå¥½çš„éšè—K, æˆ‘ä»¬ä»¥ä¸ºK,æ²¡æœ‰æ³„éœ², å…¶å®Kæ˜¯éšè—åœ¨$h_K(x)$é‡Œé¢çš„\n\n#### æœ‰é¢„å¤„ç†(padding)\næˆ‘ä»¬è¿˜æ˜¯èƒ½å¤Ÿè®¡ç®—$h_K(x||pad(x)||w||(pad(x^\\prime))$æ­¤æ—¶$x^\\prime=x||pad(x)|w$\n\n\n### åµŒå¥—MACå’ŒHMAC\nåµŒå¥— MAC å³åˆæˆä¸¤ä¸ªå¸¦å¯†é’¥çš„ Hash æ—æ¥å»ºç«‹ä¸€ä¸ª MAC ç®—æ³•\n\n$$(g \\circ h)_{(K, L)}(x)=h_{L} \\left(g_{K}(x)\\right)$$\n\nå¤–é¢çš„$h_L$æ˜¯ä¸€ä¸ªå®‰å…¨çš„\"å°MAC\", é‡Œé¢çš„$g_K$æ˜¯ä¸€ä¸ªç¢°æ’ç¨³å›ºçš„å¸¦å¯†é’¥çš„Hashæ—, å®ƒä»¬å…±åŒæ„å»ºäº†ä¸€ä¸ªå®‰å…¨çš„\"å¤§MAC\" \n$\\Rightarrow$ **\"å¤§ MAC\"=å…ˆå¸¦å¯†é’¥ Hash, å†ç”Ÿæˆ MAC**\n\n#### å¯¹åµŒå¥—MACçš„æ”»å‡»\næœ‰ä¸‰ç§æ”»å‡»æ–¹å¼ , åˆ†åˆ«æ˜¯:\n- å¯¹åµŒå¥—MACçš„å‡å†’è€…ï¼ˆâ€œå¤§MACæ”»å‡»â€ï¼‰$\\longrightarrow$(ç›´æ¥æ”»å‡»æ•´ä¸ª, ä¼å›¾æ‰¾åˆ°$x^\\prime$ çš„$h_{L}(g_{K}(x^\\prime))$)\n- å¯¹å°MACçš„å‡å†’è€…ï¼ˆâ€œå°MACæ”»å‡»â€ï¼‰$\\longrightarrow$(æ”»å‡»$h_L$, å³æ”»å‡»å¤–å±‚çš„MAC, å¯¹äº$x^\\prime$ ,ä¼å›¾æ‰¾åˆ°$h_{L}(x^\\prime)$\n- å½“å¯†é’¥æ˜¯ä¿å¯†çš„ï¼Œå¯¹Hashæ—çš„ç¢°æ’-æ¢æµ‹è€…ï¼ˆâ€œæœªçŸ¥-å¯†é’¥ç¢°æ’æ”»å‡»â€ï¼‰$\\longrightarrow$(æ”»å‡»$g_K$, å³æ”»å‡»å†…å±‚çš„çš„MAC, å¯¹äº$x^\\prime$ ,ä¼å›¾æ‰¾åˆ°$h_{L}(x^\\prime)$([ä¹‹å‰è®¨è®ºè¿‡çš„ç¢°æ’é—®é¢˜](notes/2021/2021.6/Hashå‡½æ•°_Pt.2_æ”»å‡»æ–¹æ³•_å®‰å…¨æ€§.md#ç¢°æ’é—®é¢˜))\n\nä¹¦ä¸Šè¯æ˜äº†ä¸€ä¸ªç»“è®º, è¿™ä¸ªç»“è®ºè¯´æ˜: \n\nå¦‚æœå¯¹å°MACçš„æ”»å‡»è‡³å¤šæœ‰$\\epsilon_2$çš„æˆåŠŸç‡, å¯¹Hashå‡½æ•°çš„(ä¸çŸ¥é“å¯†é’¥çš„)ç¢°æ’æ”»å‡»æœ€å¤šæœ‰$\\epsilon_1$çš„æˆåŠŸç‡, é‚£ä¹ˆå¯¹æ€»çš„åµŒå¥—MACçš„æ”»å‡»è‡³å¤šæœ‰$\\epsilon_1+\\epsilon_2$çš„æˆåŠŸç‡\n\n(å³$\\epsilon\\leqslant \\epsilon_1+\\epsilon_2$)\n\n#### HMAC\nHMACæ˜¯åˆ©ç”¨ä¸å¸¦å¯†é’¥çš„Hashå‡½æ•°æ„é€ çš„åµŒå¥—MAC\nä¸‹é¢æ˜¯åˆ©ç”¨[SHA-1](notes/2021/2021.6/Hashå‡½æ•°_Pt.4_å®‰å…¨Hashç®—æ³•_SHA-1.md)æ„é€ çš„HMAC:\n$$\n\\operatorname{HMAC}_{K}(x)=\\mathrm{SHA}-1((K \\oplus \\text { opad }) \\| \\mathrm{SHA}-1((K \\oplus \\text { ipad }) \\| x))\n$$\nå…¶ä¸­, å¯†é’¥Kçš„é•¿åº¦æ˜¯512bits, \n![](notes/2021/2021.6/assets/img_2022-10-15-27.png)\n\n![image-20210620164647868](notes/2021/2021.6/assets/img_2022-10-15-28.png)\n\næ€»ä½“ä¸Šæ¥çœ‹, HMACæŠŠå¯†é’¥ä¸ä¸¤ä¸ªå¸¸æ•°å¼‚æˆ–æ„æˆä¸¤ä¸ªæ–°çš„å¯†é’¥ , ç„¶ååˆ†åˆ«æ”¾å…¥åµŒå¥—çš„SHA-1ä¸­ä¸æ˜æ–‡ä¸€èµ·è¿›è¡ŒåŠ å¯†, (å¤„ç†åçš„å¯†é’¥æ”¾åœ¨å‰é¢)\n\næ³¨æ„ç¬¬äºŒæ¬¡è®¡ç®—ä»…ä»…éœ€è¦åˆ©ç”¨ä¸€æ¬¡Compress, æ‰€ä»¥HMACä¹Ÿç›¸å½“äº\n\n![image-20210620165121073](notes/2021/2021.6/assets/img_2022-10-15-29.png)\n\n### CBC-MAC\n\nCBC-MACå’ŒDES/AESçš„CBCå·¥ä½œæ¨¡å¼éå¸¸ç›¸ä¼¼, è¿™æ˜¯ä¸€ç§ç”±åˆ†ç»„å¯†ç æ„é€ MACçš„æ–¹å¼.\n\n\u003e æ¨ç¤¼çè€å¸ˆè¯¾ä»¶ ç¬¬ 4 ç«  Hash å‡½æ•°.pdf#page=47\n![](notes/2021/2021.6/assets/img_2022-10-15-30.png)\nå…¶å®IVç›¸å½“äºæ²¡æœ‰, å› ä¸º$0^t\\oplus x_1=x_1$\n\n\n[Nice Youtube Video](https://www.youtube.com/watch?v=BsWsJfIisvY)\n![](notes/2021/2021.6/assets/img_2022-10-15-31.png)\n![](notes/2021/2021.6/assets/img_2022-10-15-32.png)\nåœ¨è§†é¢‘é‡Œé¢å¼ºè°ƒäº†, å¦‚æœä½ å¼•å…¥äº†IV, åè€Œä¼šæŸå¤±å®‰å…¨æ€§\n\nè¿™ä¸ªå¸¦é•¿åº¦çš„æ²¡çœ‹æ‡‚ #æ²¡çœ‹æ‡‚\n![](notes/2021/2021.6/assets/img_2022-10-15-33.png)\nç”Ÿæ—¥æ”»å‡»æ²¡çœ‹æ‡‚\n\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:33.926464104Z","tags":null},"/notes/2021/2021.7/Difference_between_Git-Bash_Git_CMD":{"title":"Difference_between_Git Bash_Git_CMD","content":"# Git Bash or Git Cmd?\n\n\u003cdiv align=\"right\"\u003e 2021-07-27\u003c/div\u003e\n\nTags: #Git \n\n## å®ƒä»¬æ˜¯ä»€ä¹ˆ?\nåœ¨ä¸ºWindows Terminalè®¾ç½®Gitç•Œé¢çš„æ—¶å€™é‡åˆ°äº†è¿™ä¸ªé—®é¢˜, Gitæä¾›äº†ä¸‰ç§æ“æ§æ–¹å¼: Git GUI, Git Bashå’ŒGit Cmd, ç¬¬ä¸€ä¸ªæ˜¯å›¾å½¢ç•Œé¢, é‚£ä¹ˆåé¢ä¸¤ä¸ªå‘½ä»¤è¡Œç•Œé¢æœ‰ä»€ä¹ˆåŒºåˆ«å‘¢?\n\nBashæ˜¯Unix Shellçš„ä¸€ç§\nUnixï¼Œä¸€ç§æ“ä½œç³»ç»Ÿï¼ŒLinuxæ˜¯Unixçš„ä¸€ç§\nShellï¼Œâ€œä¸ºç”¨æˆ·æä¾›ç”¨æˆ·ç•Œé¢â€çš„è½¯ä»¶ï¼Œæ¯”å¦‚Windowsé‡Œé¢çš„Cmd\n\n\u003eCLIä¸GUI:\n\u003e é€šå¸¸å°†shellåˆ†ä¸ºä¸¤ç±»ï¼šå‘½ä»¤è¡Œä¸å›¾å½¢ç•Œé¢ã€‚å‘½ä»¤è¡Œå£³å±‚æä¾›ä¸€ä¸ª[å‘½ä»¤è¡Œç•Œé¢](https://zh.wikipedia.org/wiki/%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%95%8C%E9%9D%A2 \"å‘½ä»¤è¡Œç•Œé¢\")ï¼ˆCLIï¼‰ï¼›è€Œå›¾å½¢å£³å±‚æä¾›ä¸€ä¸ª[å›¾å½¢ç”¨æˆ·ç•Œé¢](https://zh.wikipedia.org/wiki/%E5%9C%96%E5%BD%A2%E4%BD%BF%E7%94%A8%E8%80%85%E4%BB%8B%E9%9D%A2)ï¼ˆGUIï¼‰ã€‚[^2]\n\n## å¦‚ä½•é€‰æ‹©?\n\n\u003e **Git CMD** is just like regular Windows command prompt with the `git` command. It lets you use all of Git features through command line. Useful if you are already familiar with Windows cmd and you only work on Windows.\n\u003e \n\u003e **Git Bash** emulates a [bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)) environment on windows. It lets you use all git features in command line plus most of [standard unix commands](https://ss64.com/bash/). Useful if you are used to Linux and want to keep the same habits.\n\u003e \n\u003e **Git GUI** is a **G**raphical **U**ser **I**nterface letting you use Git without touching command line. It is an alternative among other Git clients. Since Git GUI is very minimal, you could also look at [other alternatives](https://git-scm.com/download/gui/windows) if GUIs interest you.\n\u003e \n\u003e It is up to you to decide which you want to use. As many others, I recommend you to learn Git with command line before switching to a graphical interface. If you don't know which to choose between Git Bash and Git CMD, I'd go for Git Bash since bash is a really useful tool to learn.[^1]\n\n\n\n[^1]: https://stackoverflow.com/questions/45034549/difference-between-git-gui-git-bash-git-cmd\n[^2]: https://zh.wikipedia.org/wiki/%E6%AE%BC%E5%B1%A4","lastmodified":"2023-11-19T19:19:33.942464365Z","tags":null},"/notes/2021/2021.8/%E5%87%B8%E4%BC%98%E5%8C%96%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98":{"title":"å‡¸ä¼˜åŒ–ä¸çº¿æ€§å›å½’é—®é¢˜","content":"# Gradient Descent \u0026 Convex Optimization / å‡¸ä¼˜åŒ–\n\n\u003cdiv align=\"right\"\u003e 2021-08-02\u003c/div\u003e\n\nTags: #MachineLearning #ConvexOptimization #Math \n\nåœ¨[è¿™é‡Œ(å’Œä¸‹é¢çš„å¼•ç”¨é‡Œé¢)](notes/2021/2021.8/Part.5_Gradient_Descent(ML_Andrew.Ng.).md), æˆ‘ä»¬ç‰¹æ®Šçš„çº¿æ€§è§„åˆ’çš„æŸå¤±å‡½æ•°ä¸€å®šæ˜¯ä¸€ä¸ªå‡¸å‡½æ•°, é‚£ä¹ˆåœ¨å…¶ä»–æƒ…å†µä¸‹, çº¿æ€§è§„åˆ’è¿˜æ˜¯å‡¸å‡½æ•°å—, çº¿æ€§è§„åˆ’é—®é¢˜ä¼šé™·å…¥å±€éƒ¨æœ€ä¼˜çš„é—®é¢˜ä¸­å»å—?\n\n\u003e Note that, while gradient descent can be susceptible to local minima in general, the optimization problem we have posed here for linear regression has only one global, and no other local, optima; thus gradient descent always converges (assuming the learning rate Î± is not too large) to the global minimum. Indeed, J is a convex quadratic function. Here is an example of gradient descent as it is run to minimize a quadratic function.\n\u003e \n\u003e ![](notes/2021/2021.8/assets/img_2022-10-15.png)\n\u003e \n\u003e The ellipses shown above are the contours of a quadratic function.[^1]\n\t\n- å‡¸ä¼˜åŒ–é—®é¢˜ä¸æœºå™¨å­¦ä¹ æœ‰ç€å¾ˆå¯†åˆ‡çš„è”ç³», éœ€è¦è¿›ä¸€æ­¥äº†è§£\n\n\n[^1]: https://www.coursera.org/learn/machine-learning/supplement/U90DX/gradient-descent-for-linear-regression","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.8/%E5%A6%82%E4%BD%95%E5%8A%AA%E5%8A%9B%E5%B7%A5%E4%BD%9C_Paul_Graham":{"title":"å¦‚ä½•åŠªåŠ›å·¥ä½œ_Paul_Graham","content":"# å¦‚ä½•å‹¤å¥‹å·¥ä½œ\n\n\u003cdiv align=\"right\"\u003e 2021-08-16\u003c/div\u003e\n\nTags: #Essay #PaulGraham #Translation \n\n\u003cdiv align=\"right\"\u003e 2021.6\u003c/div\u003e\n\nå…³äºå¦‚ä½•å‹¤å¥‹å·¥ä½œä¼¼ä¹æ²¡ä»€ä¹ˆå¥½å­¦çš„. ä»»ä½•ä¸Šè¿‡å­¦çš„äººéƒ½çŸ¥é“å‹¤å¥‹å·¥ä½œéœ€è¦ä»˜å‡ºäº›ä»€ä¹ˆ, å³ä½¿ä»–ä»¬é€‰æ‹©ä¸å»è¿™ä¹ˆåš. è¦çŸ¥é“æœ‰äº›12å²çš„å°å­©ä¹Ÿå·¥ä½œå¾—éå¸¸å‹¤å¥‹. å¦‚ä»Šï¼Œ æ¯å½“æ€è€ƒè¿™ä¸ªé—®é¢˜çš„æ—¶å€™, æˆ‘æ€»ä¼šå‘ç°è‡ªå·±ç›¸æ¯”å­¦ç”Ÿæ—¶æœŸæœ‰äº†æ›´å¤šçš„æ„Ÿæ‚Ÿ.\n\næˆ‘çš„æ„Ÿæ‚Ÿä¹‹ä¸€æ˜¯: å¦‚æœä½ æƒ³è¦åšç‚¹äº†ä¸èµ·çš„äº‹æƒ…, é‚£ä¹ˆåŠªåŠ›å·¥ä½œæ˜¯å¿…é¡»çš„. åœ¨ç«¥å¹´çš„æ—¶å€™, æˆ‘è¿˜å¯¹æ­¤ä¸å¤ªç¡®å®š: é‚£æ—¶å­¦æ ¡é‡Œä¸åŒåŠŸè¯¾çš„éš¾åº¦å¹¶ä¸ç›¸åŒ, æœ‰çš„åŠŸè¯¾ä¸è´¹ä»€ä¹ˆåŠ›æ°”å°±èƒ½åšå¥½. è€Œä¸”æˆ‘çœ‹é‚£äº›å‡ºè‰²çš„å¤§äººä»¬å·¥ä½œçš„æ—¶å€™, ä»–ä»¬ä¼¼ä¹æ¯«ä¸è´¹åŠ›å°±èƒ½åšå¥½. ä¹Ÿè®¸, åªè¦ä½ è¶³å¤Ÿèªæ˜, å°±æœ‰æ–¹æ³•èº²è¿‡ç¹é‡çš„å·¥ä½œ? ç°åœ¨, æˆ‘æ˜ç™½äº†å…¶å®å¹¶æ²¡æœ‰è¿™æ ·çš„æ–¹æ³•.\n\nä¹‹æ‰€ä»¥å­¦æ ¡é‡Œé¢æœ‰äº›å­¦ç§‘ç®€å•å¾ˆå¤šï¼Œæ˜¯å› ä¸ºå­¦æ ¡å¯¹å®ƒä»¬çš„è¦æ±‚ä¸é«˜. è€Œä¹‹æ‰€ä»¥é‚£äº›å¤§äººä»¬å·¥ä½œçœ‹èµ·æ¥æ¯«ä¸è´¹åŠ›æ˜¯å› ä¸ºä»–ä»¬å·²ç»ç»ƒä¹ äº†è®¸å¤šå¹´, ä»–ä»¬è®©è‡ªå·±çš„å·¥ä½œå˜å¾—çœ‹èµ·æ¥å¾ˆç®€å•.\n\nå½“ç„¶, é‚£äº›å·¥ä½œå‡ºè‰²çš„äººå¸¸å¸¸çš„ç¡®æœ‰è®¸å¤šå¤©èµ‹. å‹¤å¥‹å·¥ä½œæœ‰ä¸‰ä¸ªè¦ç´ : å¤©èµ‹, ç»ƒä¹ , å’ŒåŠªåŠ›. åªå…·å¤‡å…¶ä¸­ä¸¤é¡¹çš„è¯, ä½ ä¸€æ ·ä¹Ÿèƒ½åšå¾—å¾ˆå¥½, ä½†æ˜¯è¦æˆä¸ºä½¼ä½¼è€…, ä½ å¿…é¡»åŒæ—¶å…·å¤‡è¿™ä¸‰ä¸ªè¦ç´ : ä½ éœ€è¦æœ‰æ‰å, å‹¤åŠ ç»ƒä¹ å¹¶ä¸”ååˆ†åŠªåŠ›. [^3]\n\næ¯”å°”Â·ç›–èŒ¨å¯ä»¥è¯´æ˜¯ä»–åŒæ—¶ä»£é‡Œé¢æœ€èªæ˜çš„å•†äººä¹‹ä¸€, ä½†åŒæ—¶ä»–ä¹Ÿæ˜¯é‡Œé¢æœ€å‹¤å¥‹çš„ä¹‹ä¸€. \"æˆ‘åœ¨äºŒåå‡ å²çš„æ—¶å€™ä»æ¥æ²¡æœ‰ä¼‘æ¯è¿‡ä¸€å¤©, \" ä»–è¯´, \"ä¸€å¤©ä¹Ÿæ²¡æœ‰. \" åˆ©æ˜‚å†…å°”Â·æ¢…è¥¿(Lionel Messi)ä¹Ÿæ˜¯è¿™æ ·, ä»–å¤©èµ‹å¼‚ç¦€, ä½†æ˜¯å½“ä»–å¹´è½»æ—¶å€™çš„æ•™ç»ƒä»¬è°ˆåˆ°ä»–çš„æ—¶å€™, ä»–ä»¬è®°ä½çš„æ˜¯æ¢…è¥¿çš„ä»˜å‡ºå’Œå¿…èƒœçš„å†³å¿ƒ. å¦‚æœæˆ‘ä¸€å®šè¦é€‰ä¸€ä¸ªè¯, PÂ·GÂ·ä¼å¾·è±ªæ–¯(P. G. Wodehouse)æ˜¯æˆ‘å¿ƒç›®ä¸­äºŒåä¸–çºªæœ€ä¼Ÿå¤§çš„è‹±å›½ä½œå®¶. å†™ä½œå¯¹äºä»–æ¥è¯´å½“ç„¶æ¯”ä»»ä½•äººéƒ½æ›´å¾—å¿ƒåº”æ‰‹, ä½†ä¹Ÿæ²¡æœ‰äººå·¥ä½œå¾—æ¯”ä»–æ›´åŠªåŠ›. åœ¨74å²çš„æ—¶å€™, ä»–è¿™æ ·è¯´:\n\n\u003e æ­£å¦‚æˆ‘æ‰€è¯´çš„é‚£æ ·, æˆ‘å¯¹è‡ªå·±çš„æ¯ä¸€æœ¬æ–°ä¹¦, éƒ½æœ‰ \"è¿™æ¬¡åˆåœ¨æ–‡å­¦èŠ±å›­é‡Œé¢æ‘˜åˆ°äº†ä¸€é¢—æŸ æª¬ \" çš„æ„Ÿè§‰. ä½†æˆ‘è§‰å¾—è¿™æ˜¯ä¸€ä»¶å¥½äº‹: è¿™è®©æˆ‘å§‹ç»ˆä¿æŒæ´»åŠ›, ä¹¦é‡Œæ¯ä¸€å¥è¯æˆ‘éƒ½è¦é‡å†™åé, æœ‰æ—¶ç”šè‡³äºŒåé.\n\nå¯¹ä½ æ¥è¯´, è¿™å¯èƒ½å¬èµ·æ¥æœ‰ç‚¹æç«¯. ä½†æ¯”å°”ç›–èŒ¨å¥½åƒå¬èµ·æ¥æ›´æç«¯: è°èƒ½åå¹´é‡Œä¸€å¤©ä¹Ÿä¸ä¼‘æ¯? ä»–ä»¬ä¸¤ä¸ªæœ‰ç€æ¯”ä»»ä½•äººéƒ½å¤šçš„å¤©èµ‹, å´ä¹Ÿå·¥ä½œçš„æ¯”ä»»ä½•äººéƒ½å‹¤å¥‹. è¿™ä¸¤ä¸ªç‰¹è´¨æ­£æ˜¯ä½ éœ€è¦åŒæ—¶å…·å¤‡çš„.\n\nå¬èµ·æ¥, è¿™æ˜¯å¤ªæ˜¾ç„¶ä¸è¿‡çš„äº†, ä½†å®é™…ä¸Šå´å¾ˆéš¾å®Œå…¨åšåˆ°. â€œæ‰åå’Œå‹¤å¥‹çš„åŒºåˆ«å¹¶ä¸å¤§.[^1]â€, è¿™ä¸ªè§‚ç‚¹ä¸€éƒ¨åˆ†æ¥è‡ªäºä¸»æµæ–‡åŒ–(è¿™åœ¨ä¸»æµæ–‡åŒ–é‡Œé¢æ ¹æ·±è’‚å›º), ä¸€éƒ¨åˆ†ä¹Ÿæ˜¯å› ä¸ºæ‰åå’Œå‹¤å¥‹ä¸¤è€…éƒ½æœ‰çš„\"ç¦»ç¾¤è€…\"å¤ªå°‘è§äº†. å¦‚æœè¯´å¤©èµ‹å’ŒåšæŒåŠªåŠ›çš„åŠ¨åŠ›éƒ½å¾ˆå°‘è§çš„è¯, é‚£ä¹ˆä¸¤è€…éƒ½å…·å¤‡çš„äººå¯ä»¥è¯´æ˜¯\"å¹³æ–¹å°‘è§(rare squared)\", ä¸€èˆ¬æ¥è¯´, æœ‰å…¶ä¸­ä¸€ç‚¹çš„äººå¸¸å¸¸ç¼ºä¹å¦ä¸€ç‚¹. ä½†æ˜¯æƒ³è¦å‡ºä¼—çš„è¯, ä½ éœ€è¦åŒæ—¶å…·å¤‡ä¸¤ç‚¹. æ—¢ç„¶ä½ ä¸èƒ½æ”¹å˜è‡ªå·±çš„å¤©èµ„, é‚£ä¹ˆå°½è‡ªå·±æ‰€èƒ½åœ°å‹¤å¥‹å·¥ä½œ, ä¾¿æ˜¯æˆå°±ä¼Ÿå¤§äº‹ä¸šçš„å”¯ä¸€é€‰æ‹©äº†.\n\nå¦‚æœä½ é¢å‰æœ‰å¤–åŠ ç»™ä½ çš„, å®šä¹‰æ˜ç¡®çš„ç›®æ ‡(å°±åƒåœ¨å­¦æ ¡é‡Œé¢é‚£æ ·), é‚£ä¹ˆè¦åšåˆ°å‹¤å¥‹å·¥ä½œå…¶å®å¾ˆç®€å•. åœ¨è¿™ç§æƒ…å†µä¸‹, æœ‰ä¸€äº›æŠ€å·§: ä¸æ¬ºéª—è‡ªå·±, ä¸è¦æ‹–å»¶(è¿™ä¹Ÿæ˜¯æ¬ºéª—è‡ªå·±çš„ä¸€ç§å½¢å¼), ä¸è¦åˆ†å¿ƒ, é‡åˆ°æŒ«æŠ˜ä¸è¦æ”¾å¼ƒ. ä½†æ˜¯è¿™äº›åŸåˆ™å¾ˆå°çš„å­©å­ä¹Ÿèƒ½åšåˆ°, åªè¦ä»–ä»¬æ„¿æ„.\n\næˆ‘åœ¨è¿˜æ˜¯å­©å­çš„æ—¶å€™å­¦åˆ°çš„æ˜¯: å¦‚ä½•å®ç°é‚£äº›æ²¡æœ‰æ˜ç¡®å®šä¹‰, ä¹Ÿä¸æ˜¯å¤–åŠ ç»™è‡ªå·±çš„ç›®æ ‡. å¦‚æœä½ æƒ³è¦æœ‰æ‰€æˆå°±, ä½ å¾—é€‚åº”ä»¥ä¸Šä¸¤ç§æƒ…å†µ.\n\næœ€åŸºæœ¬çš„æ˜¯: ä½ éœ€è¦è‡ªå·±æƒ³è¦å·¥ä½œ, è€Œä¸æ˜¯è®©åˆ«äººå‚¬ä¿ƒä½ . ç°åœ¨, å¦‚æœæˆ‘æ²¡æœ‰åœ¨åŠªåŠ›å·¥ä½œ, å¿ƒé‡Œçš„è­¦é’Ÿå°±ä¼šå“èµ·. å½“æˆ‘åŠªåŠ›å·¥ä½œçš„æ—¶å€™, å¹¶ä¸ä¸€å®šä¼šæœ‰æ‰€æ”¶è·, ä½†æ˜¯å¦‚æœæˆ‘æ²¡æœ‰åŠªåŠ›å·¥ä½œ, æˆ‘ä¸€å®šä»€ä¹ˆä¹Ÿå¾—ä¸åˆ°, è¿™ä¼šè®©æˆ‘æ„Ÿè§‰å¾ˆç³Ÿ.[^2]\n\næˆ‘å°æ—¶å€™å¹¶æ²¡æœ‰çªç„¶é¢†æ‚Ÿåˆ°è¿™ä¸€ç‚¹. åƒå…¶ä»–å°å­©å­ä¸€æ ·, æˆ‘å–œæ¬¢å­¦ä¹ æˆ–è€…å®ŒæˆæŸæ ·æ–°ä¸œè¥¿æ—¶å€™çš„æˆå°±æ„Ÿ. éšç€å¹´é¾„çš„å¢é•¿, è¿™æ…¢æ…¢å˜æˆäº†åœ¨è‡ªå·±æ— æ‰€äº‹äº‹çš„æ—¶å€™çš„ä¸€ç§åŒæ¶æ„Ÿ. ä¸€ä¸ªæˆ‘è®°å¾—å¾ˆæ¸…æ¥šçš„æ—¶é—´æ˜¯, æˆ‘ä»13å²èµ·ä¾¿ä¸å†çœ‹ç”µè§†äº†. \n\næˆ‘æ¥è§¦çš„ä¸€äº›äººä¹Ÿæ˜¯åœ¨å¤§çº¦è¿™ä¸ªå¹´çºªå†³å®šå¼€å§‹è®¤çœŸåšäº‹çš„. å½“æˆ‘é—®Patrick Collisonä»–æ˜¯ä»€ä¹ˆæ—¶å€™å¼€å§‹å—ä¸äº†æ— æ‰€äº‹äº‹çš„, ä»–è¯´:\n\n\u003e æˆ‘è§‰å¾—æ˜¯13, 14å²å·¦å³. æˆ‘æ¸…æ¥šçš„è®°ç€æˆ‘ååœ¨å®¢å…é‡Œé¢, æœ›ç€å¤–é¢, å¯»æ€è‡ªå·±ä¸ºä»€ä¹ˆåœ¨æµªè´¹è‡ªå·±çš„æš‘å‡. \n\nä¹Ÿè®¸æ˜¯é’æ˜¥æœŸä¼šå‘ç”Ÿä¸€äº›å˜åŒ–å§. è¿™å°±è§£é‡Šçš„é€šäº†.\n\nå¥‡æ€ªçš„æ˜¯, \"å¼€å§‹è®¤çœŸåšäº‹\"å‰é¢æœ€å¤§çš„é˜»ç¢å¾ˆå¯èƒ½æ˜¯å­¦æ ¡. å­¦æ ¡è®©å·¥ä½œ(å­¦ä¹ , è‡³å°‘ä»–ä»¬æ‰€æŒ‡çš„æ‰€è°“çš„\"å­¦ä¹ \")å˜å¾—æ— æ„ä¹‰åˆä¹å‘³. åœ¨æˆ‘å…¨èº«å¿ƒæŠ•å…¥ä¸€ä»¶äº‹ä¹‹å‰, æˆ‘å¿…é¡»è¦çŸ¥é“ä»€ä¹ˆæ‰æ˜¯\"çœŸæ­£çš„å·¥ä½œ\", æˆ‘èŠ±äº†ä¸€äº›æ—¶é—´æ‰å­¦åˆ°è¿™ä¸€ç‚¹, å› ä¸ºå³ä½¿æ˜¯åœ¨å¤§å­¦é‡Œé¢, è®¸å¤šå·¥ä½œä¹Ÿæ˜¯æ²¡æœ‰æ„ä¹‰çš„, ç”šè‡³æœ‰æ—¶ä¸€æ•´ä¸ªéƒ¨é—¨éƒ½æ˜¯æ²¡ç”¨çš„. ä½†æ˜¯åœ¨æˆ‘ç»ˆäºçŸ¥é“çœŸæ­£çš„å·¥ä½œæ˜¯ä»€ä¹ˆä¹‹å, æˆ‘å‘ç°è‡ªå·±æƒ³è¦å®Œæˆå·¥ä½œçš„æ¬²æœ›ä¸å·¥ä½œæœ¬èº«è¾¾åˆ°äº†å®Œç¾çš„å¥‘åˆ.\n\næˆ‘çŒœæƒ³å¤§å¤šæ•°äººéƒ½å¾—å…ˆè®¤æ¸…ä»€ä¹ˆæ‰æ˜¯\"çœŸæ­£çš„å·¥ä½œ\", ç„¶åæ‰æœ‰æœºä¼šçˆ±ä¸Šå·¥ä½œ. åœ¨_ã€Šä¸€ä¸ªæ•°å­¦å®¶çš„è¾©ç™½ã€‹(A Mathematician's Apology)_ é‡Œé¢å¯¹è¿™æœ‰ä¸€å¥å°‘æœ‰çš„ç²¾è¾Ÿæè¿°:\n\n\u003e æˆ‘ä¸è®°å¾—æˆ‘åœ¨å„¿æ—¶å¯¹æ•°å­¦æœ‰ä»€ä¹ˆçƒ­æƒ…, è¿™å¯¹äºä¸€ä¸ªæ•°å­¦å®¶æ¥è¯´å¹¶ä¸æ˜¯ä¸€ä¸ªå…‰å½©çš„æƒ³æ³•. æˆ‘å½“æ—¶ä»¥ä¸ºæ•°å­¦å°±æ˜¯è€ƒè¯•å’Œå¥–å­¦é‡‘, æˆ‘æƒ³è¦æ‰“è´¥å…¶ä»–åŒé¾„äºº, è€Œæ•°å­¦æˆä¸ºäº†æˆ‘æ‰“è´¥ä»–ä»¬æœ€å¹²è„†çš„æ–¹å¼.\n\nä»–ç›´åˆ°å¤§å­¦æ‰äº†è§£åˆ°æ•°å­¦çš„çœŸæ­£å†…æ¶µ, å½“æ—¶ä»–åœ¨é˜…è¯»Jordançš„ _Cours d'analyse_:\n\n\u003e æˆ‘æ°¸è¿œä¹Ÿå¿˜ä¸äº†æˆ‘åœ¨é˜…è¯»é‚£éƒ¨æ°ä½œæ—¶å€™çš„æƒŠå¼‚å¿ƒæƒ…, äº†è§£åˆ°æˆ‘è¿™ä¸€ä»£æ•°å­¦å®¶æœ€åˆçš„çµæ„Ÿæ¥æº, æˆ‘ç¬¬ä¸€æ¬¡æ‡‚å¾—äº†æ•°å­¦çš„çœŸæ­£å«ä¹‰.\n\nä¸ºäº†ç†è§£ä»€ä¹ˆæ˜¯\"çœŸæ­£çš„å·¥ä½œ\", ä½ éœ€è¦ç ´é™¤ä¸¤ç§è™šå‡çš„è§‚å¿µ. ç¬¬ä¸€ç§æ­£æ˜¯å“ˆä»£(Hardy[^4])åœ¨å­¦æ ¡é‡Œé‡åˆ°çš„é‚£ç§. ä¸ºäº†ä¾¿äºæ•™æˆ, å­¦ç§‘çŸ¥è¯†ä¼šè¢«æ‰­æ›², è€Œæ‰­æ›²ç¨‹åº¦å¸¸å¸¸å¦‚æ­¤ä¹‹å¤§ä»¥è‡³äºä½¿å®ƒä»¬å˜å¾—é¢ç›®å…¨é.[^5] å¦ä¸€ç§è§‚å¿µæ˜¯æŸäº›å·¥ä½œæœ¬è´¨ä¸Šçš„é—®é¢˜: æœ‰äº›å·¥ä½œæœ¬èº«å°±æ˜¯è™šä¼ªçš„, æˆ–è€…åªæ˜¯çº¯ç²¹çš„çäº‹.\n\nçœŸæ­£çš„å·¥ä½œæœ‰ç€æŸç§å®åœ¨çš„ä¸œè¥¿. æˆ‘å¹¶ä¸æ˜¯è¯´æ¯ä¸ªäººéƒ½è¦å»å†™ç‰›é¡¿çš„ã€ŠåŸç†ã€‹, è€Œæ˜¯è¯´çœŸæ­£çš„å·¥ä½œä¼šè®©ä½ æ„Ÿè§‰åˆ°å®ƒçš„é‡è¦æ€§. è¿™çš„ç¡®æ˜¯ä¸€ä¸ªæ¨¡ç³Šçš„æ ‡å‡†, ä½†æ˜¯æˆ‘æ˜¯æœ‰æ„è¯´çš„è¿™ä¹ˆæ¨¡ç³Šçš„, æˆ‘ä»¬éœ€è¦æ¶µç›–å¾ˆå¹¿çš„èŒƒå›´.[^6]\n\nä¸€æ—¦ä½ å¼„æ¸…äº†ä»€ä¹ˆæ˜¯çœŸæ­£çš„å·¥ä½œ, ä½ æ¥ä¸‹æ¥éœ€è¦å¼„æ¸…æ¥šè‡ªå·±æ¯å¤©è¦èŠ±å¤šå°‘æ—¶é—´åœ¨å®ƒä¸Šé¢. ä½ ä¸å¯èƒ½æŠŠæ¸…é†’çš„æ¯ä¸€åˆ†é’Ÿéƒ½èŠ±åœ¨è¿™ä»¶äº‹ä¸Šé¢, å› ä¸ºå¯¹äºè®¸å¤šå·¥ä½œè€Œè¨€, æŠ•å…¥åˆ°ç²¾åŠ›è¶…å‡ºäº†ä¸€å®šé™åº¦, ç»“æœä¼šè¶Šæ¥è¶Šç³Ÿç³•.\n\nè¿™ä¸ªé™åº¦å–å†³äºäººå’Œå·¥ä½œæœ¬èº«. æˆ‘åšè¿‡å¥½å‡ ç§ä¸åŒçš„å·¥ä½œ, æ¯ä¸€ä¸ªå·¥ä½œçš„é™åº¦éƒ½æ˜¯ä¸ä¸€æ ·çš„. å¯¹äºéš¾ä¸€ç‚¹çš„å†™ä½œæˆ–è€…ç¼–ç¨‹ä»»åŠ¡, æˆ‘çš„é™åº¦æ˜¯ä¸€å¤©5ä¸ªå°æ—¶. ç„¶è€Œå½“æˆ‘ç»è¥ä¸€å®¶åˆåˆ›å…¬å¸çš„æ—¶å€™, æˆ‘å¯ä»¥ä¸é—´æ–­åœ°å·¥ä½œ, è‡³å°‘å‰ä¸‰å¹´æ˜¯è¿™æ ·, å¦‚æœæˆ‘å†åšä¹…ä¸€ç‚¹çš„è¯, æˆ‘å¯èƒ½å°±éœ€è¦å¶å°”æ”¾æ”¾å‡äº†.[^7]\n\næ‰¾åˆ°é™åº¦çš„å”¯ä¸€æ–¹æ³•æ˜¯è¶…è¶Šé™åº¦. è¦åŸ¹å…»è‡ªå·±å¯¹å·¥ä½œç»“æœå¥½åçš„æ•æ„Ÿåº¦, è¿™æ ·ä½ å°±èƒ½å¤Ÿé€šè¿‡å·¥ä½œæˆæœçš„å¥½åæ¥åˆ¤æ–­è‡ªå·±æ˜¯ä¸æ˜¯å·¥ä½œå¾—å¤ªç‹ äº†. è¿™æ—¶, å¯¹è‡ªå·±è¯šå®éå¸¸é‡è¦: ä¸€æ–¹é¢, ä½ å¯ä»¥æ³¨æ„åˆ°è‡ªå·±æ˜¯ä¸æ˜¯æ‡ˆæ€ äº†, å¦ä¸€æ–¹é¢, ä½ ä¹Ÿå¯ä»¥æ³¨æ„åˆ°è‡ªå·±æ˜¯ä¸æ˜¯å·¥ä½œå¾—å¤ªå¤šäº†. å¦‚æœä½ è§‰å¾—æ‹¼å‘½åœ°å·¥ä½œæ˜¯ä¸€ä»¶å…‰è£çš„äº‹, èµ¶ç´§ä¸¢æ‰è¿™ä¸ªæƒ³æ³•, å› ä¸ºä½ åªä¸è¿‡æ˜¯åœ¨å¾—åˆ°æ›´å·®çš„ç»“æœç½¢äº†, ä½ è¿™æ ·åšä»…ä»…æ˜¯ä¸ºäº†è£èª‰æ„Ÿ, å¦‚æœä¸æ˜¯ä¸ºäº†ç»™åˆ«äººçœ‹, é‚£ä¹ˆå°±æ˜¯ä¸ºäº†ç»™ä½ è‡ªå·±çœ‹.[^8]\n\næ‰¾åˆ°åˆ»è‹¦å·¥ä½œçš„é™åº¦æ˜¯ä¸€ä¸ªé•¿æœŸçš„, æŒç»­çš„è¿‡ç¨‹, ä¸æ˜¯ä¸€è¹´è€Œå°±çš„. å·¥ä½œæœ¬èº«çš„éš¾åº¦å’Œä½ è‡ªå·±çš„ç²¾åŠ›æ¯ä¸ªå°æ—¶éƒ½åœ¨å‘ç”Ÿå˜åŒ–, æ‰€ä»¥ä½ éœ€è¦æŒç»­è¯„ä»·è‡ªå·±çš„å·¥ä½œå¼ºåº¦å’Œå·¥ä½œæ•ˆæœ.\n\nåŠªåŠ›ä¹Ÿå¹¶ä¸æ„å‘³ç€è¦ä¸€ç›´å¼ºè¿«è‡ªå·±å»å·¥ä½œ. æœ‰äº›äººå¯èƒ½çš„ç¡®æ˜¯è¿™æ ·åšçš„, ä½†æ˜¯æˆ‘è§‰å¾—æˆ‘çš„ç»éªŒé€‚ç”¨äºå¤§å¤šæ•°äºº: æˆ‘åªéœ€è¦å¶å°”åœ¨å¼€å§‹ä¸€ä¸ªé¡¹ç›®çš„æ—¶å€™æˆ–è€…ä¸´è¿‘æŸä¸ªæ£€æŸ¥çš„æ—¶å€™å‚¬ä¿ƒè‡ªå·±, é‚£ä¸ªæ—¶å€™æˆ‘å¾ˆå®¹æ˜“æ‹–å»¶. ä½†æ˜¯åªè¦æˆ‘å¼€å§‹åšäº‹äº†, æˆ‘å°±ä¼šä¸€ç›´åšä¸‹å».\n\næˆ‘åšæŒçš„åŠ¨åŠ›å–å†³äºæˆ‘åšçš„å·¥ä½œ. å½“æˆ‘åœ¨Viawebå·¥ä½œçš„æ—¶å€™, æˆ‘çš„åŠ¨åŠ›æ˜¯å¯¹å¤±è´¥çš„ææƒ§. æˆ‘å½“æ—¶å‡ ä¹ä¸ä¼šæ‹–å»¶, å› ä¸ºæ€»æœ‰äº‹æƒ…è¦åš, å¦‚æœæˆ‘èƒ½å¤Ÿåšç‚¹ä»€ä¹ˆæ¥æ‹‰å¼€æˆ‘å’Œè¿½èµ¶æˆ‘çš„çŒ›å…½çš„è·ç¦», ä¸ºä»€ä¹ˆè¦æ‹–å»¶å‘¢?[^9] ç„¶è€Œç°åœ¨é©±ä½¿æˆ‘å†™æ–‡ç« çš„åŠ¨åŠ›æ˜¯æ–‡ç« é‡Œé¢ä¸å®Œç¾çš„åœ°æ–¹. åœ¨åŠ¨ç¬”ä¹‹å‰æˆ‘ä¼šæŠ˜è…¾å‡ å¤©, åƒä¸€åªç‹—åœ¨è¶´ä¸‹ä¹‹å‰éƒ½ä¼šè½¬å‡ åœˆ, æ€è€ƒè¶´åœ¨å“ªé‡Œ. ä½†æ˜¯åªè¦æˆ‘å¼€å§‹å†™äº†, æˆ‘å¹¶ä¸éœ€è¦åˆ»æ„ç£ä¿ƒè‡ªå·±å»å·¥ä½œ, å› ä¸ºæ€»æœ‰ä¸€äº›é”™è¯¯æˆ–è€…ç¼ºæ¼åœ¨ç£ä¿ƒæˆ‘. \n\næˆ‘çš„ç¡®ä¼šèŠ±ä¸€äº›ç²¾åŠ›è®©è‡ªå·±ç€çœ¼äºé‡è¦çš„éƒ¨åˆ†. è®¸å¤šé—®é¢˜éƒ½æœ‰ä¸€ä¸ªæœ€éš¾çš„æ ¸å¿ƒ, å‘¨å›´ç¯ç»•çš„æ˜¯ä¸€äº›ç›¸å¯¹ç®€å•çš„éƒ¨åˆ†. åŠªåŠ›å·¥ä½œæ„å‘³ç€å°½è‡ªå·±æ‰€èƒ½åœ°ç€çœ¼äºæ ¸å¿ƒ, æœ‰äº›æ—¶å€™ä½ å¯èƒ½ä¼šæ„Ÿåˆ°åŠ›ä¸ä»å¿ƒ, æœ‰äº›æ—¥å­ä½ å¯èƒ½åªèƒ½åšäº›ç®€å•çš„, å¤–å›´çš„å·¥ä½œ. ä½†æ˜¯ä½ å§‹ç»ˆåº”è¯¥åŠªåŠ›ç€çœ¼äºæ ¸å¿ƒ, åŠªåŠ›ä¸æ‹–å»¶. \n\nä½ åº”è¯¥æ€ä¹ˆç”Ÿæ´»ä¹Ÿæ˜¯è¿™äº›\"ç¡¬æ ¸é—®é¢˜\"ä¹‹ä¸€. åœ¨æ ¸å¿ƒçš„éƒ¨åˆ†æœ‰æ›´é‡è¦æ›´è‰°éš¾çš„é—®é¢˜, è€Œä¸é‚£ä¹ˆé‡è¦çš„é—®é¢˜åˆ™åœ¨è¾¹ç¼˜. æ‰€ä»¥ä½ ä¸ä»…åœ¨ä»äº‹å…·ä½“å·¥ä½œçš„æ—¶å€™éœ€è¦å¶å°”åšå‡ºæ”¹å˜,  ä½ ä¸æ—¶ä¹Ÿéœ€è¦è¿›è¡Œä¸€äº›é‡å¤§çš„, è½¬å˜ç”Ÿæ´»è½¨è¿¹çš„è°ƒæ•´, æ¥ç¡®ä¿è‡ªå·±å§‹ç»ˆåœ¨åšé‡è¦çš„äº‹. åŸåˆ™è¿˜æ˜¯ä¸€æ ·çš„, å‹¤å¥‹å·¥ä½œæ„å‘³ç€æŠ“ä½æ ¸å¿ƒ, æŠ“ä½æœ€å›°éš¾çš„é—®é¢˜. \n\næˆ‘è¯´çš„\"æ ¸å¿ƒ\"æŒ‡çš„æ˜¯çœŸæ­£çš„æ ¸å¿ƒ, è€Œä¸æ˜¯å¤§å®¶è®¤ä¸ºçš„çš„æ ¸å¿ƒ. å¤§å®¶å…¬è®¤çš„æœ€é‡è¦çš„é—®é¢˜å¸¸å¸¸æ˜¯é”™è¯¯çš„, æ— è®ºæ˜¯æ•´ä½“ä¸Šè¿˜æ˜¯å…·ä½“çš„é¢†åŸŸä¸­. å¦‚æœä½ çš„æ„è§å’Œå¤§å®¶ç›¸å¼‚, è€Œä¸”ä½ å¯¹äº†, é‚£å°†æ˜¯ä¸€ä¸ªåˆ›é€ æ–°äº‹ç‰©çš„å®è´µæ—¶æœº.\n\næ›´æœ‰é‡å¿ƒçš„å·¥ä½œå¸¸å¸¸æ˜¯æ›´å›°éš¾çš„, å°½ç®¡åº”è¯¥æ‰¿è®¤è¿™ä¸€ç‚¹, ä½†æ˜¯ä½ ä¹Ÿä¸åº”è¯¥åªæ ¹æ®é—®é¢˜çš„å›°éš¾åº¦æ¥å†³å®šåšä»€ä¹ˆ. å¦‚æœä½ å‘ç°æŸä¸ªé‡è¦çš„å·¥ä½œå¯¹ä½ æ¥è¯´æ¯”å…¶ä»–äººæ›´å®¹æ˜“, è¦ä¹ˆæ˜¯å› ä¸ºä½ ç¢°å·§å¾ˆæ“…é•¿è¿™ä»¶äº‹, ä½ æœ‰å¤©èµ‹, è¦ä¹ˆæ˜¯å› ä¸ºä½ æ‰¾åˆ°äº†ä¸€ä¸ªæ–°æ–¹æ³•, æˆ–è€…åªæ˜¯å› ä¸ºä½ åšè¿™ä»¶äº‹æ›´æœ‰åŠ¨åŠ›.æ— è®ºå¦‚ä½•éƒ½è¦å®Œæˆå®ƒ. æœ‰äº›æœ€æ£’çš„å·¥ä½œæ˜¯ç”±é‚£äº›æ‰¾åˆ°å›°éš¾é—®é¢˜çš„ç®€å•ç­–ç•¥çš„äººå®Œæˆçš„.\n\né™¤äº†å­¦ä¹ ä»€ä¹ˆæ˜¯çœŸæ­£çš„å·¥ä½œä¹‹å¤–, ä½ è¿˜éœ€è¦å¼„æ¸…æ¥šä½ é€‚åˆä»€ä¹ˆå·¥ä½œ. è¿™ä¹Ÿä¸æ˜¯è¯´ä½ ä¸€å®šè¦æ‰¾åˆ°æœ€ç¬¦åˆä½ å¤©èµ‹çš„å·¥ä½œ, å¦‚æœä½ 7è‹±å°ºé«˜, ä½ ä¹Ÿä¸ä¸€å®šè¦å»æ‰“ç¯®çƒ. ä½ é€‚åˆä»€ä¹ˆå·¥ä½œä¸ä»…ä»…å–å†³äºä½ çš„å¤©èµ‹, ä¹Ÿå–å†³äºä½ çš„å…´è¶£, ç”šè‡³å…´è¶£è¿˜è¦æ›´é‡è¦ä¸€ç‚¹. [å¯¹äºä¸€ä¸ªé¢†åŸŸçš„å¼ºçƒˆå…´è¶£](http://www.paulgraham.com/genius.html)æ¯”ä»»ä½•çº¦æŸéƒ½æ›´èƒ½æ¿€å‘ä½ å·¥ä½œçš„çƒ­æƒ….\n\nå‘ç°ä½ çš„å…´è¶£å¯èƒ½æ¯”å‘ç°ä½ çš„å¤©èµ‹æ›´éš¾. å¤©èµ‹çš„ç§ç±»æ¯”å…´è¶£è¦å°‘, å¹¶ä¸”ä½ å¾€å¾€ä»ç«¥å¹´å°±å¼€å§‹å‘æ˜è‡ªå·±çš„å¤©èµ‹äº†, ç›¸æ¯”ä¹‹ä¸‹, å…´è¶£æ›´ä¸ºå¾®å¦™, ä½ å¯èƒ½åˆ°äºŒåå¤šå²æ‰å‘ç°è‡ªå·±çš„å…´è¶£, ç”šè‡³æ›´è¿Ÿ. ä½ æ„Ÿå…´è¶£çš„ä¸œè¥¿æœ‰å¯èƒ½è¿˜ä¸å­˜åœ¨. å¹¶ä¸”ä½ è¿˜è¦æ’é™¤ä¸€åˆ‡æ›´ä¸ºå¼ºå¤§çš„å¹²æ‰°: ä½ çœŸçš„å¯¹$x$æ„Ÿå…´è¶£å—? ä¼šä¸ä¼šåªæ˜¯å› ä¸º$x$èƒ½èµšå¾ˆå¤šé’±?æˆ–è€…æ˜¯å› ä¸º$x$æ˜¯ä¸€ä¸ªå¾ˆé£å…‰çš„å·¥ä½œ?æˆ–è€…æ˜¯å› ä¸ºä½ çˆ¶æ¯æƒ³è®©ä½ ä»äº‹$x$?[^10]\n\nå¼„æ¸…æ¥šè¦åšä»€ä¹ˆå·¥ä½œçš„å›°éš¾ç¨‹åº¦å¯¹æ¯ä¸ªäººæ¥è¯´å·®åˆ«éå¸¸å¤§. è¿™æ˜¯æˆ‘è‡ªç«¥å¹´ä»¥æ¥å­¦åˆ°çš„å…³äºå·¥ä½œæœ€é‡è¦çš„äº‹æƒ…ä¹‹ä¸€. è¿˜æ˜¯ä¸€ä¸ªå­©å­çš„æ—¶å€™, ä½ ä¼šä»¥ä¸ºæ¯ä¸ªäººéƒ½æœ‰ä¸€ä¸ªä½¿å‘½, æ¯ä¸ªäººéœ€è¦åšçš„å°±æ˜¯å¼„æ¸…æ¥šå®ƒæ˜¯ä»€ä¹ˆ. åœ¨ç”µå½±é‡Œçš„ç¡®æ˜¯è¿™æ ·, åœ¨é‚£äº›è®²ç»™å­©å­ä»¬å¬çš„çº¿æ€§çš„åäººä¼ è®°é‡Œé¢ä¹Ÿæ˜¯è¿™æ ·. æœ‰æ—¶å€™ç”Ÿæ´»çš„ç¡®æ˜¯è¿™æ ·çš„, æœ‰çš„äººåœ¨ç«¥å¹´æ—¶å°±å‘ç°äº†è‡ªå·±æƒ³å¹²ä»€ä¹ˆ, ä»–ä»¬åªéœ€è¦åšæŒåšå°±è¡Œäº†, æ¯”å¦‚è«æ‰ç‰¹. ä½†æ˜¯å¦ä¸€äº›äºº, æ¯”å¦‚ç‰›é¡¿, æ¢äº†ä¸€ç§åˆä¸€ç§å·¥ä½œ. ä¹Ÿè®¸æˆ‘ä»¬ä½œä¸ºåæ¥äººèƒ½ä»ä¸­æ‰¾å‡ºä¸€ä¸ªå·¥ä½œå½“ä½œä»–ä»¬çš„ä½¿å‘½â€”â€”æˆ‘ä»¬ä¼šå¸Œæœ›ç‰›é¡¿å¤šèŠ±ç‚¹æ—¶é—´åœ¨æ•°å­¦å’Œç‰©ç†ä¸Šé¢, å°‘èŠ±ç‚¹æ—¶é—´åœ¨ç‚¼é‡‘æœ¯å’Œç¥å­¦ä¸Šé¢â€”â€”ä½†æ˜¯è¿™ä»…ä»…æ˜¯åè§ä¹‹æ˜å¸¦æ¥çš„é”™è§‰. å¯¹äºç‰›é¡¿æ¥è¯´, æ²¡æœ‰ä»»ä½•å£°éŸ³åœ¨æŒ‡å¼•ä»–.\n\næ‰€ä»¥è™½ç„¶æœ‰ä¸€éƒ¨åˆ†äººçš„ç”Ÿæ´»å¾ˆå¿«å°±èƒ½ç¡®å®šä¸‹æ¥, å¦å¤–ä¹Ÿæœ‰ä¸€éƒ¨åˆ†äººçš„ç”Ÿæ´»æ°¸è¿œä¹Ÿä¸ä¼šç¡®å®šä¸‹æ¥. å¯¹äºåé¢è¿™éƒ¨åˆ†äºº, ç¡®å®šè¦åšä»€ä¹ˆä¸æ˜¯å‹¤å¥‹å·¥ä½œçš„\"åºæ›²\", è€Œæ˜¯å‹¤å¥‹å·¥ä½œæœ¬èº«çš„ä¸€éƒ¨åˆ†, ä¸¤è€…å°±åƒä¸€ç»„è”ç«‹æ–¹ç¨‹å¼ä¸€æ ·. å¯¹äºè¿™éƒ¨åˆ†äºº, æˆ‘å‰é¢æåˆ°çš„è¿‡ç¨‹æœ‰äº†ç¬¬ä¸‰ä¸ªéƒ¨åˆ†: é™¤äº†è®¤è¯†åˆ°è‡ªå·±çš„å·¥ä½œå¼ºåº¦å’Œå·¥ä½œçš„æ•ˆæœ, ä½ è¿˜éœ€è¦æ€è€ƒè‡ªå·±æ˜¯è¯¥ç»§ç»­ç°åœ¨çš„å·¥ä½œè¿˜æ˜¯æ¢ä¸€ä¸ªæ–°çš„é¢†åŸŸ. å¦‚æœä½ å·¥ä½œå¾—å¾ˆåŠªåŠ›ä½†æ˜¯æ•ˆæœä¸å¤Ÿå¥½, ä½ å°±è¯¥æ¢ä¸€ä¸ªå·¥ä½œäº†. è¿™å¬èµ·æ¥å¾ˆç®€å•, ä½†æ˜¯åšèµ·æ¥å¾ˆéš¾. å¦‚æœä½ åœ¨å·¥ä½œç¬¬ä¸€å¤©éå¸¸åŠªåŠ›ä½†æ˜¯æ•ˆæœä¸ç†æƒ³, ä½ å½“ç„¶ä¸åº”è¯¥æ”¾å¼ƒ, ä¸Šæ‰‹éœ€è¦æ—¶é—´. ä½†æ˜¯å¤šå°‘æ—¶é—´åˆæ˜¯åˆé€‚çš„å‘¢? å¦‚æœä½ ä¹‹å‰å¾—å¿ƒåº”æ‰‹çš„å·¥ä½œä¸å†é¡ºæ‰‹, ä½ åˆåº”è¯¥æ€ä¹ˆåŠ? ä½ è¿™æ—¶åˆè¯¥ç»™è‡ªå·±å¤šå°‘æ—¶é—´? [^11]\n\nç©¶ç«Ÿä»€ä¹ˆæ ·çš„ç»“æœæ‰èƒ½ç§°å¾—ä¸Šå¥½ç»“æœ? è¿™å¾ˆéš¾è¯„åˆ¤. å¦‚æœä½ æ˜¯åœ¨å‡ ä¹æ²¡æœ‰å‰æœŸå·¥ä½œçš„é¢†åŸŸé‡Œé¢æ‘¸ç´¢, é‚£ä¹ˆä½ ç”šè‡³ä¸çŸ¥é“å¥½çš„ç»“æœé•¿ä»€ä¹ˆæ ·å­. åœ¨å†å²ä¸Š, é”™è¯¯åœ°è¯„ä¼°è‡ªå·±å·¥ä½œé‡è¦æ€§çš„ä¾‹å­æ¯”æ¯”çš†æ˜¯.\n\nè¯„åˆ¤ä¸€é¡¹å·¥ä½œæ˜¯å¦æœ‰ä»·å€¼çš„æœ€å¯é æ ‡å‡†æ˜¯ä½ æ˜¯å¦è§‰å¾—å®ƒæœ‰æ„æ€. è¿™å¬èµ·æ¥è¿‡åˆ†ä¸»è§‚äº†, ç”šè‡³ä¸»è§‚å¾—æœ‰ç‚¹å±é™©. ä½†æ˜¯è¿™å¤§æ¦‚æ˜¯ä½ èƒ½å¤Ÿå¾—åˆ°çš„æœ€ç²¾ç¡®çš„ç»“æœäº†. åšè¿™é¡¹å·¥ä½œçš„äººæ˜¯ä½ è‡ªå·±. è°è¿˜èƒ½æ¯”ä½ è‡ªå·±æ›´æœ‰èµ„æ ¼è¯„åˆ¤è¿™é¡¹å·¥ä½œçš„é‡è¦æ€§å‘¢? åˆèƒ½æœ‰ä»€ä¹ˆæ ‡å‡†æ¯”\"æ˜¯ä¸æ˜¯æœ‰è¶£\"æ›´å¥½å‘¢?\n\nä½†æ˜¯è¦æƒ³å®è·µè¿™ä¸ªæ ‡å‡†, ä½ éœ€è¦å¯¹è‡ªå·±å®Œå…¨è¯šå®. çš„ç¡®, è¿™æ˜¯å¦‚ä½•å‹¤å¥‹å·¥ä½œè¿™ä¸ªé—®é¢˜é‡Œæœ€çªå‡ºçš„ä¸€ç‚¹, è¿™é‡Œé¢æ¯ä¸€ä¸ªç¯èŠ‚éƒ½å–å†³äºä½ å¯¹è‡ªå·±çš„è¯šå®ç¨‹åº¦.\n\nå‹¤å¥‹å·¥ä½œå¹¶ä¸æ˜¯æ¦¨å¹²è‡ªå·±çš„æ¯ä¸€ä»½ç²¾åŠ›. è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„ä¸»é¢˜, å®ƒæ˜¯ä¸€ä¸ªéœ€è¦æ¯ä¸€ç‚¹éƒ½æ°åˆ°å¥½å¤„çš„åŠ¨æ€ç³»ç»Ÿ: ä½ éœ€è¦è®¤æ¸…\"çœŸæ­£çš„å·¥ä½œ\"æ˜¯ä»€ä¹ˆ, å¼„æ¸…è‡ªå·±é€‚åˆåšä»€ä¹ˆ, å°½ä½ æ‰€èƒ½æŠ“ä½é—®é¢˜çš„æ ¸å¿ƒ, åœ¨æ¯ä¸€åˆ»éƒ½æ¸…æ¥šçš„è®¤è¯†è‡ªå·±çš„ç°çŠ¶ä¸æ½œåŠ›, å¹¶ä¸”ç¡®ä¿æŠ•å…¥æ°åˆ°å¥½å¤„çš„ç²¾åŠ›æ¥ä¿è¯æœ€å¥½çš„ç»“æœ. è¿™è™½ç„¶æ˜¯ä¸€ä¸ªå¤æ‚çš„ç½‘ç»œ, ä½†åªè¦ä½ å§‹ç»ˆä¿æŒè¯šå®ä¸æ¸…é†’, å®ƒä¾¿ä¼šè‡ªåŠ¨è¾¾åˆ°æœ€ä¼˜, è€Œä½ ä¹Ÿå°†ä¼šå¼‚ä¹å¸¸äººçš„é«˜æ•ˆ.\n\n## è‹±è¯­åŸæ–‡\n[å¦‚ä½•åŠªåŠ›å·¥ä½œ_Paul_Graham](notes/2021/2021.8/å¦‚ä½•åŠªåŠ›å·¥ä½œ_Paul_Graham.md)\n\n\n\n[^3]: åœ¨\"å…³äºå¤©æ‰çš„å…¬äº¤è½¦ç¥¨ç†è®º\"ä¸€æ–‡ä¸­, æˆ‘æåˆ°ä¼Ÿå¤§äº‹ä¸šçš„ä¸‰ä¸ªè¦ç´ æ˜¯å¤©èµ‹, å†³å¿ƒå’Œå…´è¶£. é‚£æ˜¯å‰ä¸€é˜¶æ®µçš„è¦ç´ : å› ä¸ºå†³å¿ƒå’Œå…´è¶£å‚¬ç”Ÿäº†ç»ƒä¹ å’ŒåŠªåŠ›.\n[^1]:  åŸæ–‡: here's a faint xor between talent and hard work.æ½œåœ¨çš„æ„æ€æ˜¯åªè¦æœ‰ä¸€ä¸ªå°±è¡Œäº† [è¯‘æ³¨]\n[^2]: è¿™é‡Œçš„\"åˆ†è¾¨ç‡\"æ˜¯ä¸€å¤©, è€Œä¸æ˜¯ä¸€å°æ—¶. ä½ å¯èƒ½åœ¨æ´—æ¾¡çš„æ—¶å€™, ç”šè‡³ç¡è§‰çš„æ—¶å€™æƒ³åˆ°ä¸€ä¸ªé—®é¢˜çš„ç­”æ¡ˆ, ä½†æ˜¯è¿™çš„å‰ææ˜¯ä½ å‰ä¸€å¤©ä¸€å®šåœ¨åŠªåŠ›è§£å†³é‚£ä¸ªé—®é¢˜.å¶å°”ä¼‘å‡æ˜¯ä»¶å¥½äº‹, æˆ‘å–œæ¬¢å­¦ä¹ æ–°ä¸œè¥¿, è€Œä¸æ˜¯çŸ¥è¯†èººåœ¨æ²™æ»©ä¸Š.\n[^4]: ä¸Šæ–‡ã€Šä¸€ä¸ªæ•°å­¦å®¶çš„è¾©ç™½ã€‹çš„ä½œè€… [è¯‘æ³¨]\n[^5]: å­©å­åœ¨å­¦æ ¡é‡Œé¢å­¦åˆ°çš„æœ€\"åŸæ±åŸå‘³\"çš„ä¸œè¥¿æ˜¯ä½“è‚², è¿™è¯šç„¶æ˜¯å› ä¸ºè®¸å¤šè¿åŠ¨é¡¹ç›®éƒ½æ˜¯èµ·æºäºå­¦æ ¡é‡Œé¢çš„æ¸¸æˆ, ä½†æ˜¯è‡³å°‘åœ¨è¿™ä¸€éƒ¨åˆ†, å­©å­ä»¬åœ¨åšå’Œæˆå¹´äººä¸€æ ·çš„äº‹. åœ¨æ™®é€šçš„ç¾å›½é«˜ä¸­é‡Œ, ä½ å¯ä»¥é€‰æ‹©å‡è£…åšæ­£ç»äº‹, æˆ–è€…æ­£ç»åœ°åšäº›æ¨¡ä»¿çš„äº‹, è€å®è¯´, åè€…å¹¶ä¸å·®.\n[^6]: çŸ¥é“ä½ æƒ³è¦åšä»€ä¹ˆå¹¶ä¸æ„å‘³ç€ä½ æœ‰èƒ½åŠ›åšè¿™ä»¶äº‹. è®¸å¤šäººèŠ±äº†å¾ˆå¤šæ—¶é—´åšä»–ä»¬ä¸æƒ³åšçš„å·¥ä½œ, å°¤å…¶æ˜¯æ—©å¹´çš„æ—¶å€™, ä½†æ˜¯å¦‚æœä½ æ¸…æ¥šè‡ªå·±æƒ³è¦åšä»€ä¹ˆ, ä½ è‡³å°‘çŸ¥é“åº”è¯¥å¾€å“ªè¾¹åŠªåŠ›.\n[^7]: é«˜å¼ºåº¦å·¥ä½œæœ‰ç€æ›´çŸ­çš„æœ‰æ•ˆå·¥ä½œæ—¶é—´, è¿™å¯èƒ½æ˜¯å½“ä½ æœ‰äº†å­©å­ä»¥åçš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆ: åšæ›´éš¾çš„äº‹. æˆ‘å®é™…ä¸Šå°±æ˜¯è¿™ä¹ˆå¹²çš„, å°½ç®¡ä¸æ˜¯æ•…æ„çš„.\n[^8]: åœ¨æœ‰äº›æ–‡åŒ–é‡Œé¢æå€¡è¡¨æ¼”æ€§è´¨çš„åˆ»è‹¦å·¥ä½œ, æˆ‘ä¸ªäººå¹¶ä¸å–œæ¬¢è¿™ä¸ªä¸»æ„, å› ä¸º: 1. è¿™åªä¸è¿‡æ˜¯å¯¹é‡è¦çš„äº‹çš„æ¨¡ä»¿è€Œå·², 2. è¿™æ˜¯å¯¹äººä»¬ç²¾åŠ›æ— æ„ä¹‰çš„æ¶ˆè€—. æˆ‘æ‡‚å¾—ä¸å¤š, æ²¡æœ‰èµ„æ ¼è¯„ä»·è¿™ä¸ªç°è±¡çš„å¥½å, ä½†æ˜¯æˆ‘çŒœæµ‹è¿™ä¸ªç°è±¡å¹¶ä¸å¥½.\n[^9]: åˆåˆ›ä¼ä¸šçš„äººä»¬æ‹¼å‘½å·¥ä½œçš„åŸå› ä¹‹ä¸€å°±æ˜¯åˆåˆ›ä¼ä¸šä¼šå€’é—­, å¹¶ä¸”å¦‚æœä»–ä»¬å€’é—­äº†, è¿™ä¸ªå¤±è´¥å°†ä¼šæ˜¯å†³å®šæ€§ä¸”éå¸¸æ˜¾çœ¼çš„\n[^10]: æƒ³è¦èµšå¾ˆå¤šé’±æ²¡ä»€ä¹ˆä¸å¥½æ„æ€çš„. ä½ æ€»æ˜¯éœ€è¦è§£å†³ç”Ÿè®¡é—®é¢˜çš„, å¹¶ä¸”æƒ³è¦ä¸€æ¬¡æ€§èµšå¾ˆå¤šé’±çš„æƒ³æ³•ä¹Ÿæ²¡ä»€ä¹ˆä¸å¯¹. æˆ‘è®¤ä¸ºå¯¹é‡‘é’±æœ¬èº«æ„Ÿå…´è¶£ä¹Ÿæ˜¯å¯ä»¥çš„, éšä½ ä¾¿. åªè¦ä½ çŸ¥é“è‡ªå·±çš„åˆå¿ƒ. ä¸è¦æ— æ„é—´è®©å¯¹é‡‘é’±çš„æ¸´æœ›æ©ç›–äº†ä½ çœŸæ­£æ„Ÿå…´è¶£çš„ä¸œè¥¿.\n[^11]: è®¸å¤šäººåœ¨ä¸ªäººçš„å°é¡¹ç›®é‡Œé¢é‡åˆ°è¿‡è¿™ä¸ªé—®é¢˜. ä½†æ˜¯èˆå¼ƒä¸€ä¸ªå°é¡¹ç›®è¿˜æ˜¯è¦æ¯”æ”¾å¼ƒä¸€æ•´ä¸ªå·¥ä½œè¦å®¹æ˜“è®¸å¤š. ä½ è¶Šåšå®š, æ”¾å¼ƒå°±è¶Šå›°éš¾. è¿™æ—¶çš„ä½ å°±åƒè¥¿ç­ç‰™æµæ„Ÿç—…äºº, åœ¨å¯¹æŠ—è‡ªå·±çš„å…ç–«ç³»ç»Ÿ: ä½ å‘Šè¯‰è‡ªå·±ä¸èƒ½æ”¾å¼ƒ, åº”è¯¥å†åŠªåŠ›ä¸€ç‚¹. è¿™æ—¶, è°åˆèƒ½è¯´ä½ åšçš„ä¸å¯¹å‘¢?","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.8/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83%E4%B8%8E%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%9A%84%E8%81%94%E7%B3%BB_Relation_of_Laplace_distribution-_and_Gaussian_distribution":{"title":"æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒä¸é«˜æ–¯åˆ†å¸ƒçš„è”ç³»_Relation_of_Laplace_distribution _and_Gaussian_distribution","content":"# Gaussian distribution, Laplace distribution: The Relation\n\n\u003cdiv align=\"right\"\u003e 2021-07-31\u003c/div\u003e\n\nTags: #Math/Statistics #GaussianDistribution #LaplaceDistribution\n\næ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒ, æ¦‚ç‡å¯†åº¦å‡½æ•°:\n![](notes/2021/2021.7/assets/img_2022-10-15-1.png)\n![](notes/2021/2021.7/assets/img_2022-10-15-2.png)\n\n![æ¦‚ç‡å¯†åº¦å‡½æ•°](notes/2021/2021.9/æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution.md#æ¦‚ç‡å¯†åº¦å‡½æ•°)\n\n- Look at the formula for the PDF in the infobox -- it's just the Gaussian with  $|\\boldsymbol{x}-\\boldsymbol{\\mu}|$ instead of $(\\boldsymbol{x}-\\boldsymbol{\\mu})^{2}$)[^2]\n\n- æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°è®©æˆ‘ä»¬è”æƒ³åˆ°[æ­£æ€åˆ†å¸ƒ](https://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83 \"æ­£æ€åˆ†å¸ƒ\")ï¼Œä½†æ˜¯ï¼Œ**æ­£æ€åˆ†å¸ƒ**æ˜¯ç”¨ç›¸å¯¹äº _Î¼_ **[å¹³å‡å€¼](https://zh.wikipedia.org/wiki/%E5%B9%B3%E5%9D%87%E5%80%BC)çš„å·®çš„å¹³æ–¹**æ¥è¡¨ç¤ºï¼Œè€Œ**æ‹‰æ™®æ‹‰æ–¯æ¦‚ç‡å¯†åº¦**ç”¨ç›¸å¯¹äº**å¹³å‡å€¼çš„å·®çš„[ç»å¯¹å€¼](https://zh.wikipedia.org/wiki/%E7%BB%9D%E5%AF%B9%E5%80%BC \"ç»å¯¹å€¼\")** æ¥è¡¨ç¤ºã€‚å› æ­¤ï¼Œæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒçš„å°¾éƒ¨æ¯”æ­£æ€åˆ†å¸ƒæ›´åŠ å¹³å¦ã€‚[^1]\n[^1]: https://zh.wikipedia.org/zh-hans/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83\n[^2]: [Why_do_cost_functions_use_the_square_error](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md#^b7e1c9)","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.8/%E7%9F%A9%E9%98%B5%E7%9A%84%E6%B1%82%E5%AF%BC":{"title":"çŸ©é˜µçš„æ±‚å¯¼","content":"# å¯¹çŸ©é˜µçš„æ±‚å¯¼_Matrix_Derivative\n\n\u003cdiv align=\"right\"\u003e 2021-08-16\u003c/div\u003e\n\nTags: #Matrix #Derivative #Calculus #MachineLearning \n\n- åœ¨å­¦ä¹ å´æ©è¾¾æœºå™¨å­¦ä¹ CS229çš„æ—¶å€™ä¸ºäº†æ¨å¯¼Normal Equationçš„å…¬å¼, æ¥è§¦åˆ°äº†å‡½æ•°å¯¹äºçŸ©é˜µçš„æ±‚å¯¼, å› ä¸ºè®¸ä¹…æ²¡æœ‰æ¥è§¦å¾®ç§¯åˆ†, å¹¶ä¸”çŸ¥è¯†è·¨åº¦å¤ªå¤§, è®¸ä¹…æ²¡æœ‰çœ‹æ‡‚, æ•…åœ¨æ­¤ç¬”è®°ä¸­æ…¢æ…¢æ¢³ç†.\n- Learning Materials:\n\t- Pili HU, Matrix Calculus, https://github.com/hupili/tutorial/tree/master/matrix-calculus\n\t- A Matrix Algebra Approach to Artificial Intelligence by Xian-Da Zhang\n\t- [çŸ©é˜µæ±‚å¯¼æœ¯](https://zhuanlan.zhihu.com/p/24709748)\n\t- [çŸ©é˜µå¯¼æ•°è®¡ç®—å™¨](http://www.matrixcalculus.org/)\n\t- \n---\n## ä¸åŒçš„æƒ…å†µ\næ¶‰åŠåˆ°çŸ©é˜µçš„å¯¼æ•°è¿ç®—æœ‰ä»¥ä¸‹æƒ…å†µ:\n- æ ‡é‡å‡½æ•°(Scalar Function) : å°†å˜é‡(å¯èƒ½æ˜¯çŸ©é˜µæˆ–è€…å‘é‡)æ˜ å°„åˆ° $\\rightarrow\\mathbb{R}_{}$\n- å‘é‡å‡½æ•°(Vector Function):  å˜é‡$\\rightarrow\\mathbb{R}_{n}$\n- çŸ©é˜µå‡½æ•°(Matrix Function): å˜é‡$\\rightarrow\\mathbb{R}_{m\\times n}$\n\nå…·ä½“çš„æ˜ å°„è¡¨ç¤ºå¦‚ä¸‹:[^1]\n![](notes/2021/2021.7/assets/img_2022-10-15.png)\n\n## A Walk Through\n[Link to File](https://project.hupili.net/tutorial/hu2012-matrix-calculus/hu2012matrix-calculus.pdf)\n### Highlights\nçŸ©é˜µå¯¼æ•°ä¸å¾®åˆ†çš„è”ç³» \n$$d f=\\operatorname{tr}\\left(\\left(\\frac{\\partial f}{\\partial X}\\right)^{T} d X\\right)$$ ^e0894d\n\n\n## ä¸æ¢¯åº¦çš„å…³ç³»[^2]\nä»ä¸‹é¢çš„å™è¿°å¯ä»¥çœ‹å‡º, ä¸€ä¸ª$\\mathbb R_{m\\times n}\\mapsto \\mathbb R_{n}$å‡½æ•°$f(A)$, å…¶å¯¹äº$A$æ¢¯åº¦ä¾¿æ˜¯å¯¹äºè‡ªå˜é‡$A$çš„å¯¼æ•°çŸ©é˜µ.\n\næ‰€ä»¥åœ¨å´æ©è¾¾çš„è®²ä¹‰é‡Œé¢çš„$\\nabla$ç¬¦å·æ˜¯æ¢¯åº¦, ä½†æ˜¯ä¸¥æ ¼çš„æ¥è¯´åº”è¯¥æ˜¯å¯¼æ•°$\\large \\frac {\\partial f} {\\partial x}$\n[Normal_Equation_Proof_2_Matrix_Method](notes/2021/2021.8/Normal_Equation_Proof_2_Matrix_Method.md)\n\n### å®å€¼å‡½æ•°ç›¸å¯¹äºå‘é‡å’ŒçŸ©é˜µçš„æ¢¯åº¦\nç›¸å¯¹äº $\\mathrm{n} \\times 1$ å‘é‡ $\\mathrm{x}$ çš„æ¢¯åº¦ç®—å­è®°ä½œ $\\nabla_{\\boldsymbol{x}}$, å®šä¹‰ä¸º\n$$\n\\nabla_{\\boldsymbol{x}} \\stackrel{\\text { def }}{=}\\left[\\frac{\\partial}{\\partial x_{1}}, \\frac{\\partial}{\\partial x_{2}}, \\cdots, \\frac{\\partial}{\\partial x_{n}}\\right]^{T}=\\frac{\\partial}{\\partial \\boldsymbol{x}}\n$$\n\n#### å¯¹å‘é‡çš„æ¢¯åº¦\n\nä»¥ $\\mathrm{n} \\times 1$ å®å‘é‡ $\\mathrm{x}$ ä¸ºå˜å…ƒçš„å®æ ‡é‡å‡½æ•° $\\mathrm{f}(\\mathrm{x})$ ç›¸å¯¹äº $\\mathrm{x}$ çš„æ¢¯åº¦ä¸º $\\mathrm{n} \\times 1$ åˆ—å‘é‡ $\\mathbf{x}$, å®šä¹‰ä¸º\n$$\n\\nabla_{\\boldsymbol{x}} f(\\boldsymbol{x}) \\stackrel{\\text { def }}{=}\\left[\\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{1}}, \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{2}}, \\cdots, \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{n}}\\right]^{T}=\\frac{\\partial f(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}\n$$\nmç»´è¡Œå‘é‡å‡½æ•° $\\boldsymbol{f}(\\boldsymbol{x})=\\left[f_{1}(\\boldsymbol{x}), f_{2}(\\boldsymbol{x}), \\cdots, f_{m}(\\boldsymbol{x})\\right]$ ç›¸å¯¹äºnç»´å®å‘é‡ $\\mathbf{x}$ çš„æ¢¯åº¦ä¸º $\\mathrm{n} \\times \\mathrm{m}$ çŸ©é˜µ, å®šä¹‰ä¸º\n$$\n\\nabla_{\\boldsymbol{x}} \\boldsymbol{f}(\\boldsymbol{x}) \\stackrel{\\operatorname{def}}{=}\\left[\\begin{array}{cccc}\n\\frac{\\partial f_{1}(\\boldsymbol{x})}{\\partial x_{1}} \u0026 \\frac{\\partial f_{2}(\\boldsymbol{x})}{\\partial x_{1}} \u0026 \\cdots \u0026 \\frac{\\partial f_{m}(\\boldsymbol{x})}{\\partial x_{1}} \\\\\n\\frac{\\partial f_{1}(\\boldsymbol{x})}{\\partial x_{2}} \u0026 \\frac{\\partial f_{2}(\\boldsymbol{x})}{\\partial x_{2}} \u0026 \\cdots \u0026 \\frac{\\partial f_{m}(\\boldsymbol{x})}{\\partial x_{2}} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n\\frac{\\partial f_{1}(\\boldsymbol{x})}{\\partial x_{n}} \u0026 \\frac{\\partial f_{2}(\\boldsymbol{x})}{\\partial x_{n}} \u0026 \\cdots \u0026 \\frac{\\partial f_{m}(\\boldsymbol{x})}{\\partial x_{n}}\n\\end{array}\\right]=\\frac{\\partial \\boldsymbol{f}(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}\n$$\n#### å¯¹çŸ©é˜µçš„æ¢¯åº¦\n\næ ‡é‡å‡½æ•° $f(\\boldsymbol{A})$ ç›¸å¯¹äº $\\mathrm{m} \\times \\mathrm{n}$ å®çŸ©é˜µ $\\mathrm{A}$ çš„æ¢¯åº¦ä¸º $\\mathrm{m} \\times \\mathrm{n}$ çŸ©é˜µ, ç®€ç§°æ¢¯åº¦çŸ©é˜µ, å®šä¹‰ä¸º\n$$\n\\nabla_{A} f(\\boldsymbol{A})\\stackrel{\\text { def }}{=}\\left[\\begin{array}{cccc}\n\\frac{\\partial f(A)}{\\partial a_{11}} \u0026 \\frac{\\partial f(A)}{\\partial a_{12}} \u0026 \\cdots \u0026 \\frac{\\partial f(A)}{\\partial a_{1 n}} \\\\\n\\frac{\\partial f(A)}{\\partial a_{21}} \u0026 \\frac{\\partial f(A)}{\\partial a_{22}} \u0026 \\cdots \u0026 \\frac{\\partial f(A)}{\\partial a_{2 n}} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n\\frac{\\partial f(A)}{\\partial a_{m 1}} \u0026 \\frac{\\partial f(A)}{\\partial a_{m 2}} \u0026 \\cdots \u0026 \\frac{\\partial f(A)}{\\partial a_{m n}}\n\\end{array}\\right]=\\frac{\\partial f(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}\n$$\n\n\n\n#### æ³•åˆ™\n\nä»¥ä¸‹æ³•åˆ™é€‚ç”¨äºå®æ ‡é‡å‡½æ•°å¯¹å‘é‡çš„æ¢¯åº¦ä»¥åŠå¯¹çŸ©é˜µçš„æ¢¯åº¦.\n\n- çº¿æ€§æ³•åˆ™: è‹¥ $f(\\boldsymbol{A})$ å’Œ $g(\\boldsymbol{A})$ åˆ†åˆ«æ˜¯çŸ©é˜µAçš„å®æ ‡é‡å‡½æ•°, $\\mathrm{c}_{1}$ å’Œ $\\mathrm{c}_{2}$ ä¸ºå®å¸¸æ•°, åˆ™\n\n$$\n\\frac{\\partial\\left[c_{1} f(\\boldsymbol{A})+c_{2} g(\\boldsymbol{A})\\right]}{\\partial \\boldsymbol{A}}=c_{1} \\frac{\\partial f(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}+c_{2} \\frac{\\partial g(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}\n$$\n- ä¹˜ç§¯æ³•åˆ™: è‹¥ $f(\\boldsymbol{A}), g(\\boldsymbol{A})$ å’Œ $h(\\boldsymbol{A})$ åˆ†åˆ«æ˜¯çŸ©é˜µAçš„å®æ ‡é‡å‡½æ•°, åˆ™\n\n$$\n\\begin{aligned}\n\u0026\\frac{\\partial f(\\boldsymbol{A}) g(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}=g(\\boldsymbol{A}) \\frac{\\partial f(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}+f(\\boldsymbol{A}) \\frac{\\partial g(\\boldsymbol{A})}{\\partial \\boldsymbol{A}} \\\\\n\u0026\\frac{\\partial f(\\boldsymbol{A}) g(\\boldsymbol{A}) h(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}=g(\\boldsymbol{A}) h(\\boldsymbol{A}) \\frac{\\partial f(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}+f(\\boldsymbol{A}) h(\\boldsymbol{A}) \\frac{\\partial g(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}+f(\\boldsymbol{A}) g(\\boldsymbol{A}) \\frac{\\partial h(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}\n\\end{aligned}\n$$\n- å•†æ³•åˆ™: è‹¥ $g(\\boldsymbol{A}) \\neq 0$, åˆ™\n\n$$\n\\frac{\\partial f(\\boldsymbol{A}) / g(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}=\\frac{1}{g(\\boldsymbol{A})^{2}}\\left[g(\\boldsymbol{A}) \\frac{\\partial f(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}-f(\\boldsymbol{A}) \\frac{\\partial g(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}\\right]\n$$\n- é“¾å¼æ³•åˆ™ï¼šè‹¥Aä¸º $m \\times n$ çŸ©é˜µï¼Œä¸” $y=f(\\boldsymbol{A})$ å’Œ $g(y)$ åˆ†åˆ«æ˜¯ä»¥çŸ©é˜µ $\\mathbf{A}$ å’Œæ ‡é‡ $y$ ä¸ºå˜å…ƒçš„å®æ ‡é‡å‡½æ•°, åˆ™\n\n$$\n\\frac{\\partial g(f(\\boldsymbol{A}))}{\\partial \\boldsymbol{A}}=\\frac{d g(y)}{d y} \\frac{\\partial f(\\boldsymbol{A})}{\\partial \\boldsymbol{A}}\n$$\n\n\n\n\n\n\n\n\n\n\n[^1]:A Matrix Algebra Approach to Artificial Intelligence\n[^2]: https://zh.wikipedia.org/zh-sg/%E6%A2%AF%E5%BA%A6 ","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.8/%E7%9F%A9%E9%98%B5%E8%BF%B9%E7%9A%84%E6%80%A7%E8%B4%A8":{"title":"çŸ©é˜µè¿¹çš„æ€§è´¨","content":"# çŸ©é˜µè¿¹çš„æ€§è´¨\n\n\u003cdiv align=\"right\"\u003e 2021-08-16\u003c/div\u003e\n\nTags: #Trace #Matrix #Math\n\n- æ ‡é‡å¯ä»¥ç›´æ¥å¥—ä¸Šè¿¹ï¼š $a=\\operatorname{tr}(a)$\n\n- $\\mathrm{tr}AB = \\mathrm{tr}BA$  ^tracecommutative\n\n![](notes/2021/2021.7/assets/tr1.drawio.svg)\nå·¦è¾¹: \n$$\n\\begin{align}\n\u0026\\sum^n_i a_{1i}b_{i1}+\\sum^n_i a_{2i}b_{i2}+\\cdots+\\sum^n_i a_{mi}b_{im} \\\\ = \u0026\\sum^m_j\\sum^n_ia_{ji}b_{ij}\n\\\\ = \u0026\\sum^m_i\\sum^n_j a_{ij}b_{ji}\n\\end{align}\n$$\nå³è¾¹:\n$$\n\\begin{align}\n\u0026\\sum^m_i b_{1i}a_{i1}+\\sum^m_i b_{2i}a_{i2}+\\cdots+\\sum^m_i b_{ni}a_{in} \\\\ = \u0026\\sum^n_j\\sum^m_i b_{ji}a_{ij}\n\\\\ = \u0026\\sum^m_i\\sum^n_j a_{ij}b_{ji}\n\\end{align}\n$$\n\nå·¦è¾¹=å³è¾¹\n\nä¸Šé¢çš„å¼å­å…¶å®å°±ç›¸å½“äºæŠŠA,Bå…¶ä¸­ä¸€ä¸ªç¿»è¿‡æ¥, å’Œå¦ä¸€ä¸ªå åœ¨ä¸€èµ·, å¯¹åº”ä½ç½®ä¹˜èµ·æ¥, å†åŠ èµ·æ¥:\n![](notes/2021/2021.7/assets/tr2.drawio.svg)\n\næ¨å¹¿:\nåªè¦\"ç¯å½¢çš„\"é¡ºåºä¸å˜, çŸ©é˜µç›¸ä¹˜çš„è¿¹å°±ä¸å˜ \n$$\\mathrm{tr}ABC = \\mathrm{tr}CAB = \\mathrm{tr}BCA$$\n$$\\mathrm{tr}ABCD = \\mathrm{tr}DABC = \\mathrm{tr}CDAB = \\mathrm{tr}BCDA$$\n\n\n- å¯¹äºæ–¹é˜µ, è¿˜æœ‰ä»¥ä¸‹æ€§è´¨:\n\t- $\\mathrm{tr}A=\\mathrm{tr}A^T \\Rightarrow$ å› ä¸ºæ—‹è½¬è½´ä¸å˜\n\t\t- flip the matrix around its rotary line, which is the \"trace line\", and the \"trace line\" is the only thing that doesn't change when flipping the matrix.\n\t- $\\mathrm{tr}(A+B)=\\mathrm{tr}A+\\mathrm{tr}B$\n\t- $\\mathrm{tr}(aA)=a\\mathrm{tr}A$\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.8/Different_Gradient_Descent_Methods":{"title":"Different_Gradient_Descent_Methods","content":"## Batch Gradient Descent, æ‰¹æ¢¯åº¦ä¸‹é™, BGD\n\næ¯ä¸€æ¬¡æŠŠæ‰€æœ‰æ•°æ®éƒ½ç”¨æ¥æ›´æ–°å‚æ•°, Use ALL the training examples.\n$$\n\\begin{array}{l}\n\\text { repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\u0026\\theta_{j}:=\\theta_{j}-\\alpha \\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) x_j^{(i)}\n\\end{array}\\\\\n\\text { \\} }\n\\\\\\\\ \\text { (simultaneously update }\nj=0, \\cdots ,j=n)\n\\end{array}\n$$\n\n## Stochastic/Incremental Gradient Descent, éšæœºæ¢¯åº¦ä¸‹é™ SGD\n\n$$\n\\begin{aligned}\nLoop \u0026\\quad \\{\\qquad\\\\\n\u0026\\text { for } \\mathrm{i}=1 \\text { to } \\mathrm{m},\\{ \\\\\n\u0026\\qquad \\theta_{j}:=\\theta_{j}+\\alpha\\left(y^{(i)}-h_{\\theta}\\left(x^{(i)}\\right)\\right) x_{j}^{(i)} \\qquad\\quad(\\text { for every j} \\space )\\\\\n\\quad\u0026\\qquad\\quad\\}\\\\\n\u0026\\quad\\}\n\\end{aligned}\n$$\nä¸Šé¢è¿™ä¸ªå¼å­æœ€å¤§çš„ä¸åŒæ˜¯: æ²¡æœ‰äº†æ±‚å’Œç¬¦å·, å–è€Œä»£ä¹‹çš„æ˜¯ä¸€ä¸ªforå¾ªç¯. è¿™æ„å‘³ç€éšæœºæ¢¯åº¦ä¸‹é™æ¯ä¸€æ¬¡åªæ ¹æ®ä¸€ä¸ªæ ·æœ¬è¿›è¡Œå‚æ•°æ›´æ–°.(each time we encounter a training example, we update the parameters according to the gradient of the error with respect to that single training example only.)\n\nè¿™æ ·çš„å¥½å¤„æ˜¯é€Ÿåº¦å¿«, æ¯ä¸€æ¬¡è®¡ç®—éƒ½åœ¨æ›´æ–°å‚æ•°, è€Œä¸åƒBGDé‚£æ ·æŠŠæ‰€æœ‰æ ·æœ¬éƒ½ç®—ä¸€éæ‰èƒ½æ›´æ–°ä¸€æ¬¡å‚æ•°.\nåå¤„æ˜¯å¯èƒ½ä¸ä¼šConverge, æœ€ç»ˆå¾—åˆ°çš„ç»“æœå¯èƒ½åªæ˜¯ä¸€ä¸ªè¿‘ä¼¼è§£, æœ€åå¾—åˆ°ä¸€ç§éœ‡è¡çš„çŠ¶æ€.\nä¸€ç§è§£å†³æ–¹æ³•æ˜¯éšç€è®­ç»ƒçš„è¿›è¡Œä¸æ–­å‡å°å­¦ä¹ ç‡, è¿™æ ·ä¾¿å¯ä»¥å¢å¤§æ”¶æ•›çš„å‡ ç‡.\n\n## Mini-batch Gradient Descent\n\nè¿™ç§æ–¹æ³•ç»¼åˆäº†ä¸Šé¢ä¸¤ç§æ–¹æ³•çš„ä¼˜ç¼ºç‚¹, æ¯æ¬¡é€‰ä¸€ä¸ªå°æ ·æœ¬æ¥æ›´æ–°å‚æ•°, è¾¾åˆ°äº†ä¸€ä¸ªå¾ˆå¥½çš„æŠ˜ä¸­.\n\n![](notes/2021/2021.7/assets/img_2022-10-15-3.png)\n\n## Other Methods\n\nå…¶å®è¿˜æœ‰å¾ˆå¤šæ–¹æ³•, [è¿™ç¯‡æ–‡ç« ](https://ruder.io/optimizing-gradient-descent/)æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ€»ç»“.\n\nå´æ©è¾¾çš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹é‡Œé¢æœ‰ä¸€èŠ‚ä¸“é—¨è®²ä¼˜åŒ–æ–¹æ³•: #todo\n\u003chttps://www.coursera.org/lecture/deep-neural-network/mini-batch-gradient-descent-qcogH\u003e ^06f99c\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Here_goes_nothing_meaningetymology":{"title":"Here_goes_nothing!_meaning\u0026etymology","content":"# Here goes nothing!\n\n\u003cdiv align=\"right\"\u003e 2021-08-02\u003c/div\u003e\n\nTags: #English \n\n![](notes/2021/2021.7/assets/img_2022-10-15.gif)\n\n## ref.1\nIndicates a lack of confidence or certainty about the activity about to be tried.\n\n    Well, I checked everything and I think it's wired up correctly, so I guess all that's left is to turn it on. Here goes nothing!\n[^1]\n## ref.2\nWhen we are certain the outcome of an/a activity/task will be a failure or when we know we are going to be unsuccessful but we still do it.\n\n\tWhen going to give a speech on feminism , for which she wasn't prepared for, Brooklyn whispered to herself: Here goes nothing.\n[^2]\n\n## ref.3\nI'm going to attempt this, even though I doubt that I'll be successful, do well, or enjoy it. Often used somewhat ironically, in a way that indicates optimism despite the possibility of failure. \n\n\t- \"Here goes nothing,\" he muttered, as he began the final exam. \n\t\n\t- My rocket is ready for launch! Here goes nothing!\n[^3]\n\n[^1]: https://en.wiktionary.org/wiki/here_goes_nothing\n[^2]: https://www.urbandictionary.com/define.php?term=Here%20Goes%20Nothing\n[^3]: https://idioms.thefreedictionary.com/here+goes+nothing","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/How_to_Work_Hard-Paul_Graham":{"title":"How_to_Work_Hard-Paul_Graham","content":"# How to Work Hard\n\n\u003cdiv align=\"right\"\u003e 2021-08-16\u003c/div\u003e\n\nTags: #Essay #PaulGraham #Translation\n\n## Chinese Translation\n[[notes/2021/2021.8/å¦‚ä½•åŠªåŠ›å·¥ä½œ_Paul_Graham]]\n\n## English Version\nJune 2021  \n  \nIt might not seem there's much to learn about how to work hard. Anyone who's been to school knows what it entails, even if they chose not to. There are 12 year olds who work amazingly hard. And yet when I ask if I know more about working hard now than when I was in school, the answer is definitely yes.  \n  \nOne thing I know is that if you want to do great things, you'll have to work very hard. I wasn't sure of that as a kid. Schoolwork varied in difficulty; one didn't always have to work super hard to do well. And some of the things famous adults did, they seemed to do almost effortlessly. Was there, perhaps, some way to evade hard work through sheer brilliance? Now I know the answer to that question. There isn't.  \n  \nThe reason some subjects seemed easy was that my school had low standards. And the reason famous adults seemed to do things effortlessly was years of practice; they made it look easy.  \n  \nOf course, those famous adults usually had a lot of natural ability too. There are three ingredients in great work: natural ability, practice, and effort. You can do pretty well with just two, but to do the best work you need all three: you need great natural ability _and_ to have practiced a lot _and_ to be trying very hard. [[1](http://www.paulgraham.com/hwh.html#f1n)]  \n  \nBill Gates, for example, was among the smartest people in business in his era, but he was also among the hardest working. \"I never took a day off in my twenties,\" he said. \"Not one.\" It was similar with Lionel Messi. He had great natural ability, but when his youth coaches talk about him, what they remember is not his talent but his dedication and his desire to win. P. G. Wodehouse would probably get my vote for best English writer of the 20th century, if I had to choose. Certainly no one ever made it look easier. But no one ever worked harder. At 74, he wrote\n\n\u003e with each new book of mine I have, as I say, the feeling that this time I have picked a lemon in the garden of literature. A good thing, really, I suppose. Keeps one up on one's toes and makes one rewrite every sentence ten times. Or in many cases twenty times.\n\nSounds a bit extreme, you think. And yet Bill Gates sounds even more extreme. Not one day off in ten years? These two had about as much natural ability as anyone could have, and yet they also worked about as hard as anyone could work. You need both.  \n  \nThat seems so obvious, and yet in practice we find it slightly hard to grasp. There's a faint xor between talent and hard work. It comes partly from popular culture, where it seems to run very deep, and partly from the fact that the outliers are so rare. If great talent and great drive are both rare, then people with both are rare squared. Most people you meet who have a lot of one will have less of the other. But you'll need both if you want to be an outlier yourself. And since you can't really change how much natural talent you have, in practice doing great work, insofar as you can, reduces to working very hard.  \n  \nIt's straightforward to work hard if you have clearly defined, externally imposed goals, as you do in school. There is some technique to it: you have to learn not to lie to yourself, not to procrastinate (which is a form of lying to yourself), not to get distracted, and not to give up when things go wrong. But this level of discipline seems to be within the reach of quite young children, if they want it.  \n  \nWhat I've learned since I was a kid is how to work toward goals that are neither clearly defined nor externally imposed. You'll probably have to learn both if you want to do really great things.  \n  \nThe most basic level of which is simply to feel you should be working without anyone telling you to. Now, when I'm not working hard, alarm bells go off. I can't be sure I'm getting anywhere when I'm working hard, but I can be sure I'm getting nowhere when I'm not, and it feels awful. [[2](http://www.paulgraham.com/hwh.html#f2n)]  \n  \nThere wasn't a single point when I learned this. Like most little kids, I enjoyed the feeling of achievement when I learned or did something new. As I grew older, this morphed into a feeling of disgust when I wasn't achieving anything. The one precisely dateable landmark I have is when I stopped watching TV, at ageÂ 13.  \n  \nSeveral people I've talked to remember getting serious about work around this age. When I asked Patrick Collison when he started to find idleness distasteful, he said\n\n\u003e I think around age 13 or 14. I have a clear memory from around then of sitting in the sitting room, staring outside, and wondering why I was wasting my summer holiday.\n\nPerhaps something changes at adolescence. That would make sense.  \n  \nStrangely enough, the biggest obstacle to getting serious about work was probably school, which made work (what they called work) seem boring and pointless. I had to learn what real work was before I could wholeheartedly desire to do it. That took a while, because even in college a lot of the work is pointless; there are entire departments that are pointless. But as I learned the shape of real work, I found that my desire to do it slotted into it as if they'd been made for each other.  \n  \nI suspect most people have to learn what work is before they can love it. Hardy wrote eloquently about this in _A Mathematician's Apology_:\n\n\u003e I do not remember having felt, as a boy, any _passion_ for mathematics, and such notions as I may have had of the career of a mathematician were far from noble. I thought of mathematics in terms of examinations and scholarships: I wanted to beat other boys, and this seemed to be the way in which I could do so most decisively.\n\nHe didn't learn what math was really about till part way through college, when he read Jordan's _Cours d'analyse_.\n\n\u003e I shall never forget the astonishment with which I read that remarkable work, the first inspiration for so many mathematicians of my generation, and learnt for the first time as I read it what mathematics really meant.\n\nThere are two separate kinds of fakeness you need to learn to discount in order to understand what real work is. One is the kind Hardy encountered in school. Subjects get distorted when they're adapted to be taught to kids â€” often so distorted that they're nothing like the work done by actual practitioners. [[3](http://www.paulgraham.com/hwh.html#f3n)] The other kind of fakeness is intrinsic to certain types of work. Some types of work are inherently bogus, or at best mere busywork.  \n  \nThere's a kind of solidity to real work. It's not all writing the _Principia_, but it all feels necessary. That's a vague criterion, but it's deliberately vague, because it has to cover a lot of different types. [[4](http://www.paulgraham.com/hwh.html#f4n)]  \n  \nOnce you know the shape of real work, you have to learn how many hours a day to spend on it. You can't solve this problem by simply working every waking hour, because in many kinds of work there's a point beyond which the quality of the result will start to decline.  \n  \nThat limit varies depending on the type of work and the person. I've done several different kinds of work, and the limits were different for each. My limit for the harder types of writing or programming is about five hours a day. Whereas when I was running a startup, I could work all the time. At least for the three years I did it; if I'd kept going much longer, I'd probably have needed to take occasional vacations. [[5](http://www.paulgraham.com/hwh.html#f5n)]  \n  \nThe only way to find the limit is by crossing it. Cultivate a sensitivity to the quality of the work you're doing, and then you'll notice if it decreases because you're working too hard. Honesty is critical here, in both directions: you have to notice when you're being lazy, but also when you're working too hard. And if you think there's something admirable about working too hard, get that idea out of your head. You're not merely getting worse results, but getting them because you're showing off â€” if not to other people, then to yourself. [[6](http://www.paulgraham.com/hwh.html#f6n)]  \n  \nFinding the limit of working hard is a constant, ongoing process, not something you do just once. Both the difficulty of the work and your ability to do it can vary hour to hour, so you need to be constantly judging both how hard you're trying and how well you're doing.  \n  \nTrying hard doesn't mean constantly pushing yourself to work, though. There may be some people who do, but I think my experience is fairly typical, and I only have to push myself occasionally when I'm starting a project or when I encounter some sort of check. That's when I'm in danger of procrastinating. But once I get rolling, I tend to keep going.  \n  \nWhat keeps me going depends on the type of work. When I was working on Viaweb, I was driven by fear of failure. I barely procrastinated at all then, because there was always something that needed doing, and if I could put more distance between me and the pursuing beast by doing it, why wait? [[7](http://www.paulgraham.com/hwh.html#f7n)] Whereas what drives me now, writing essays, is the flaws in them. Between essays I fuss for a few days, like a dog circling while it decides exactly where to lie down. But once I get started on one, I don't have to push myself to work, because there's always some error or omission already pushing me.  \n  \nI do make some amount of effort to focus on important topics. Many problems have a hard core at the center, surrounded by easier stuff at the edges. Working hard means aiming toward the center to the extent you can. Some days you may not be able to; some days you'll only be able to work on the easier, peripheral stuff. But you should always be aiming as close to the center as you can without stalling.  \n  \nThe bigger question of what to do with your life is one of these problems with a hard core. There are important problems at the center, which tend to be hard, and less important, easier ones at the edges. So as well as the small, daily adjustments involved in working on a specific problem, you'll occasionally have to make big, lifetime-scale adjustments about which type of work to do. And the rule is the same: working hard means aiming toward the center â€” toward the most ambitious problems.  \n  \nBy center, though, I mean the actual center, not merely the current consensus about the center. The consensus about which problems are most important is often mistaken, both in general and within specific fields. If you disagree with it, and you're right, that could represent a valuable opportunity to do something new.  \n  \nThe more ambitious types of work will usually be harder, but although you should not be in denial about this, neither should you treat difficulty as an infallible guide in deciding what to do. If you discover some ambitious type of work that's a bargain in the sense of being easier for you than other people, either because of the abilities you happen to have, or because of some new way you've found to approach it, or simply because you're more excited about it, by all means work on that. Some of the best work is done by people who find an easy way to do something hard.  \n  \nAs well as learning the shape of real work, you need to figure out which kind you're suited for. And that doesn't just mean figuring out which kind your natural abilities match the best; it doesn't mean that if you're 7 feet tall, you have to play basketball. What you're suited for depends not just on your talents but perhaps even more on your interests. A [deep interest](http://www.paulgraham.com/genius.html) in a topic makes people work harder than any amount of discipline can.  \n  \nIt can be harder to discover your interests than your talents. There are fewer types of talent than interest, and they start to be judged early in childhood, whereas interest in a topic is a subtle thing that may not mature till your twenties, or even later. The topic may not even exist earlier. Plus there are some powerful sources of error you need to learn to discount. Are you really interested in x, or do you want to work on it because you'll make a lot of money, or because other people will be impressed with you, or because your parents want you to? [[8](http://www.paulgraham.com/hwh.html#f8n)]  \n  \nThe difficulty of figuring out what to work on varies enormously from one person to another. That's one of the most important things I've learned about work since I was a kid. As a kid, you get the impression that everyone has a calling, and all they have to do is figure out what it is. That's how it works in movies, and in the streamlined biographies fed to kids. Sometimes it works that way in real life. Some people figure out what to do as children and just do it, like Mozart. But others, like Newton, turn restlessly from one kind of work to another. Maybe in retrospect we can identify one as their calling â€” we can wish Newton spent more time on math and physics and less on alchemy and theology â€” but this is an [illusion](http://www.paulgraham.com/disc.html) induced by hindsight bias. There was no voice calling to him that he could have heard.  \n  \nSo while some people's lives converge fast, there will be others whose lives never converge. And for these people, figuring out what to work on is not so much a prelude to working hard as an ongoing part of it, like one of a set of simultaneous equations. For these people, the process I described earlier has a third component: along with measuring both how hard you're working and how well you're doing, you have to think about whether you should keep working in this field or switch to another. If you're working hard but not getting good enough results, you should switch. It sounds simple expressed that way, but in practice it's very difficult. You shouldn't give up on the first day just because you work hard and don't get anywhere. You need to give yourself time to get going. But how much time? And what should you do if work that was going well stops going well? How much time do you give yourself then? [[9](http://www.paulgraham.com/hwh.html#f9n)]  \n  \nWhat even counts as good results? That can be really hard to decide. If you're exploring an area few others have worked in, you may not even know what good results look like. History is full of examples of people who misjudged the importance of what they were working on.  \n  \nThe best test of whether it's worthwhile to work on something is whether you find it interesting. That may sound like a dangerously subjective measure, but it's probably the most accurate one you're going to get. You're the one working on the stuff. Who's in a better position than you to judge whether it's important, and what's a better predictor of its importance than whether it's interesting?  \n  \nFor this test to work, though, you have to be honest with yourself. Indeed, that's the most striking thing about the whole question of working hard: how at each point it depends on being honest with yourself.  \n  \nWorking hard is not just a dial you turn up to 11. It's a complicated, dynamic system that has to be tuned just right at each point. You have to understand the shape of real work, see clearly what kind you're best suited for, aim as close to the true core of it as you can, accurately judge at each moment both what you're capable of and how you're doing, and put in as many hours each day as you can without harming the quality of the result. This network is too complicated to trick. But if you're consistently honest and clear-sighted, it will automatically assume an optimal shape, and you'll be productive in a way few people are.  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n**Notes**  \n  \n[1] In \"The Bus Ticket Theory of Genius\" I said the three ingredients in great work were natural ability, determination, and interest. That's the formula in the preceding stage; determination and interest yield practice and effort.  \n  \n[2] I mean this at a resolution of days, not hours. You'll often get somewhere while not working in the sense that the solution to a problem comes to you while taking a [shower](http://www.paulgraham.com/top.html), or even in your sleep, but only because you were working hard on it the day before.  \n  \nIt's good to go on vacation occasionally, but when I go on vacation, I like to learn new things. I wouldn't like just sitting on a beach.  \n  \n[3] The thing kids do in school that's most like the real version is sports. Admittedly because many sports originated as games played in schools. But in this one area, at least, kids are doing exactly what adults do.  \n  \nIn the average American high school, you have a choice of pretending to do something serious, or seriously doing something pretend. Arguably the latter is no worse.  \n  \n[4] Knowing what you want to work on doesn't mean you'll be able to. Most people have to spend a lot of their time working on things they don't want to, especially early on. But if you know what you want to do, you at least know what direction to nudge your life in.  \n  \n[5] The lower time limits for intense work suggest a solution to the problem of having less time to work after you have kids: switch to harder problems. In effect I did that, though not deliberately.  \n  \n[6] Some cultures have a tradition of performative hard work. I don't love this idea, because (a) it makes a parody of something important and (b) it causes people to wear themselves out doing things that don't matter. I don't know enough to say for sure whether it's net good or bad, but my guess is bad.  \n  \n[7] One of the reasons people work so hard on startups is that startups can fail, and when they do, that failure tends to be both decisive and conspicuous.  \n  \n[8] It's ok to work on something to make a lot of money. You need to solve the money problem somehow, and there's nothing wrong with doing that efficiently by trying to make a lot at once. I suppose it would even be ok to be interested in money for its own sake; whatever floats your boat. Just so long as you're conscious of your motivations. The thing to avoid is _unconsciously_ letting the need for money warp your ideas about what kind of work you find most interesting.  \n  \n[9] Many people face this question on a smaller scale with individual projects. But it's easier both to recognize and to accept a dead end in a single project than to abandon some type of work entirely. The more determined you are, the harder it gets. Like a Spanish Flu victim, you're fighting your own immune system: Instead of giving up, you tell yourself, I should just try harder. And who can say you're not right?  \n  \n  \n  \n**Thanks** to Trevor Blackwell, John Carmack, John Collison, Patrick Collison, Robert Morris, Geoff Ralston, and Harj Taggar for reading drafts of this.  \n  \n\n  \n\n![](https://sep.yimg.com/ca/Img/trans_1x1.gif)\n\n![](https://sep.yimg.com/ca/I/paulgraham_2272_1423)[Arabic Translation](https://world.hey.com/amna/post-09ff9372)![](https://sep.yimg.com/ca/Img/trans_1x1.gif)  \n\n![](https://sep.yimg.com/ca/Img/trans_1x1.gif)\n\n  \n\n  \n  \n\n---","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Linear_RegressionGradient_Descent":{"title":"Linear_Regression\u0026Gradient_Descent","content":"%%ä¸‹é¢è¿™é‡Œæˆ‘ä¸€æ¥å°±æƒ³è¦å†™ä¸€ä¸ªæœ€æ™®é€‚çš„æƒ…å†µ, ä½†æ˜¯å¼„å¾—èƒ½éš¾æ‡‚, å´æ©è¾¾åœ¨è¿™é‡Œæ¯”æˆ‘è®²çš„æ¸…æ™°å¤šäº†%%\n\næŠŠæ¢¯åº¦ä¸‹é™æ–¹æ³•åº”ç”¨åˆ°æˆ‘ä»¬çš„çº¿æ€§å›å½’é—®é¢˜é‡Œé¢, å¯ä»¥å¾—åˆ°æˆ‘ä»¬Hypothesiså‡½æ•°å‚æ•°æ›´æ–°çš„æ–¹æ³•(å¦‚ä½•æ±‚Cost Functionæœ€å°å€¼Minimalçš„æ–¹æ³•):\n $$\\begin{align*}\n \\text{repeat until convergence: }\n\\lbrace \u0026 \\newline \\theta_0 := \u0026 \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)}) \\newline\n\\theta_1 := \u0026 \\theta_1 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}\\left((h_\\theta(x^{(i)}) - y^{(i)}) x^{(i)}_1\\right) \\newline\n \\rbrace\u0026\n \\end{align*}$$\n\nä¸‹é¢æˆ‘ä»¬ç”¨ä¸€ä¸ªä¸€èˆ¬çš„å½¢å¼, è¯¦ç»†è§£é‡Šä¸€ä¸‹åº”ç”¨çš„è¿‡ç¨‹:\n\n- [Algorithm](notes/2021/2021.8/Part.5_Gradient_Descent(ML_Andrew.Ng.).md#Algorithm)\n è¿™æ˜¯ä¸€ä¸ªæœ‰$n$ä¸ªå˜é‡(Feature  $x$), $n+1$ä¸ªå‚æ•°( $\\theta$ )çš„æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¸‹é™ç®—æ³•:\n$$\n\\begin{array}{l}\n\\text { repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\\theta_{j}:=\\theta_{j}-\\alpha \\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}}   J\\left(\\theta_{0},\\cdots ,\\theta_{n}\\right) \u0026 \\text { (simultaneously update }\nj=0, \\cdots ,j=n)\n\\end{array}\\\\\n\\text { \\} }\n\\end{array}\n$$\n\n- [Cost Function](notes/2021/2021.8/Part.3_Linear_Regression(ML_Andrew.Ng.).md#Cost%20Function)\n è¿™æ˜¯ä¸€ä¸ªå¹³æ–¹æŸå¤±å‡½æ•°\n$$J\\left(\\theta_{0},\\cdots ,\\theta_{n}\\right)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(\\hat{y}^{(i)}-y^{(i)}\\right)^{2}=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$$\n\nå…¶ä¸­ $\\mathrm{m}$ æ˜¯æ•°æ®ç‚¹çš„ä¸ªæ•°, $x^{(i)}, y^{(i)}$ æ˜¯å•ä¸ªæ•°æ®ç‚¹, è¿™é‡Œ$x^{(i)}$åº”å½“æ˜¯ä¸€ä¸ªçŸ¢é‡. $\\theta_{0}, \\cdots ,\\theta_{n}$ æ˜¯Hypothesisé‡Œé¢çš„å‚æ•°, ä¹Ÿæ˜¯Cost Functioné‡Œé¢çš„å˜é‡.\n\n- æˆ‘ä»¬çš„Hypothesisæ˜¯$h_\\theta$, å…·ä½“çš„è¡¨è¾¾å¼æœªæŒ‡æ˜, æš‚å®šä¸º\n $$\\begin{align}\n \u0026h_\\theta= \\theta_n {\\large f_{\\normalsize n}}(x^{(i)})+\\cdots , +\\theta_1 {\\large f_{\\normalsize 1}}(x^{(i)})+\\theta_0\\quad  \\\\\u0026and\\quad ( { f_{\\normalsize 0}}(x^{(i)})=1)\n \\end{align}\n $$\n å¯¹äºæˆ‘ä»¬çš„çº¿æ€§å›å½’é—®é¢˜, $f_j(x^{(i)})=x_j^{(i)}$\n \nä¸‹é¢æŠŠCost Function$:J\\left(\\theta_{0},\\cdots ,\\theta_{n}\\right)$å¸¦å…¥ä¸Šé¢çš„æ¢¯åº¦ä¸‹é™å…¬å¼, å¾—å‡ºå…·ä½“çš„æ¢¯åº¦ä¸‹é™è¡¨è¾¾å¼.\n\né¦–å…ˆæ˜¯å¯¹äº$\\theta_j$çš„åå¯¼æ•°è®¡ç®—, å³ $\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}} J(\\theta)$ .\nä¸ºäº†ä½¿æ€è·¯æ¸…æ™°, æˆ‘ä»¬å…ˆè®¡ç®—å¯¹äºä¸€ä¸ªæ•°æ®ç‚¹çš„å¹³æ–¹è¯¯å·®çš„åå¯¼æ•°$\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}}  K(\\theta)$, æ ¹æ®å¯¼æ•°çš„æ€§è´¨, æœ‰$\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}} J(\\theta)=\\frac{\\Large1}{\\Large2 m} \\sum_{i=1}^{m} \\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}}  K(\\theta)$ :\n\n$$\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} K(\\theta)\n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}\\left(\\hat{y}-y\\right)^{2}\\\\\n\n\u0026=\\frac{\\partial}{\\partial \\theta_{j}} \\left(h_{\\theta}(x)-y\\right)^{2} \\\\\n\n\u0026= 2 \\left(h_{\\theta}(x)-y\\right) \\cdot \\frac{\\partial}{\\partial \\theta_{j}}\\left(h_{\\theta}(x)-y\\right) \\\\\n\n\u0026=2\\left(h_{\\theta}(x)-y\\right) \\cdot \\frac{\\partial}{\\partial \\theta_{j}}\\left(\\sum_{i=0}^{n} \\theta_{i} f_i(x)-y\\right) \\\\\n\n\u0026=2\\left(h_{\\theta}(x)-y\\right) f_{j}(x)\n\n\\end{aligned}\n$$\nå¸¦å…¥æ‰€æœ‰æ ·æœ¬ç‚¹, è®¡ç®—$\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}} J(\\theta)$:\n$$\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta)\n\u0026=\\frac{1}{2 m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial \\theta_{j}}  K(\\theta)\\\\\n\n\u0026=\\frac{1}{2 m} \\sum_{i=1}^{m} 2\\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) f_{j}(x^{(i)}) \\\\\n\n\u0026=2\\cdot\\frac{1}{2}\\cdot \\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) f_{j}(x^{(i)}) \\\\\n\n\u0026=\\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) f_{j}(x^{(i)}) \\\\\n\n\\end{aligned}\n$$\n\n- æ³¨æ„åœ¨ç¬¬ä¸‰è¡Œçš„$2\\cdot{\\Large\\frac1 2}$, [è¿™é‡Œå°±æ˜¯ä¸ºä»€ä¹ˆCost Functioné‡Œé¢è¦åŠ å…¥ä¸€ä¸ª$\\frac1 2$, å¯ä»¥è®©Gradientçš„å½¢å¼æ›´å¥½çœ‹](notes/2021/2021.8/Part.3_Linear_Regression(ML_Andrew.Ng.).md#Cost%20Function)      ([Regarding the $\\frac1 2$ term](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md#Regarding%20the%20frac1%202%20term)) ^021e6f\n\nå¯¹äºæˆ‘ä»¬çš„çº¿æ€§å›å½’é—®é¢˜, :\n$$\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta) =\\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right)x_j^{(i)} $$\nå†ä¹˜ä¸Šå­¦ä¹ ç‡$\\alpha$, å³æ˜¯æ¯ä¸€æ¬¡å‚æ•°$\\theta$å˜åŒ–çš„å¤§å°, ä¸æ—§å‚æ•°ç›¸å‡å³å¾—åˆ°æ–°çš„å‚æ•°.\n\n- [Batch Gradient Descent æ‰¹æ¢¯åº¦ä¸‹é™ BGD](notes/2021/2021.8/Different_Gradient_Descent_Methods.md#Batch%20Gradient%20Descent%20æ‰¹æ¢¯åº¦ä¸‹é™%20BGD):è¿™é‡Œ$i$çš„æ±‚å’ŒèŒƒå›´æ˜¯$1$~$m$, ä»£è¡¨æ¯ä¸€æ¬¡éƒ½åˆ©ç”¨æ‰€æœ‰æ ·æœ¬ç‚¹æ¥æ›´æ–°å‚æ•°.\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Mean_Squared_Error_%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE":{"title":"Mean_Squared_Error_å‡æ–¹è¯¯å·®","content":"# Mean Squared Error\n\n\u003cdiv align=\"right\"\u003e 2021-07-31\u003c/div\u003e\n\nTags: #MachineLearning #CostFunction\n\nMean Square Error: å¹³å‡å¹³æ–¹è¯¯å·®, ç®€ç§°å‡æ–¹å·®, MSE, åˆç§° Mean Squared **Deviation** (MSD)\n\nå‡æ–¹å·®çš„å½¢å¼å¾ˆç®€å•, ä½†æ˜¯ä¹Ÿæœ‰è®¸å¤šé—®é¢˜å€¼å¾—æ€è€ƒ\n- ä¸ºä»€ä¹ˆé‡‡ç”¨å¹³æ–¹, è€Œä¸æ˜¯ç»å¯¹å€¼, ä¸‰æ¬¡æ–¹ç­‰ç­‰\n\n## StackExchangeä¸Šé¢ä¸€ä¸ªå¾ˆå¥½çš„è§£é‡Š\n[Why_do_cost_functions_use_the_square_error/ä¸ºä»€ä¹ˆæŸå¤±å‡½æ•°è¦ä½¿ç”¨å‡æ–¹è¯¯å·®](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md)\n\n## ä¸ºä»€ä¹ˆMSEæ˜¯åˆç†çš„\n\n\u003e å‡æ–¹è¯¯å·®æœ‰éå¸¸å¥½çš„å‡ ä½•æ„ä¹‰, å®ƒå¯¹åº”äº†å¸¸ç”¨çš„**æ¬§å‡ é‡Œå¾—è·ç¦»**æˆ–ç®€ç§°\"æ¬§æ°è·ç¦»\" (Euclidean distance). åŸºäºå‡æ–¹è¯¯å·®æœ€å°åŒ–æ¥è¿›è¡Œæ¨¡å‹æ±‚è§£çš„æ–¹æ³•ç§°ä¸º\"æœ€å°äºŒä¹˜æ³•\" (least square method). åœ¨çº¿æ€§å›å½’ä¸­ï¼Œæœ€å°äºŒä¹˜æ³•å°±æ˜¯è¯•å›¾æ‰¾åˆ°ä¸€æ¡ç›´çº¿ï¼Œä½¿æ‰€æœ‰æ ·æœ¬åˆ°ç›´çº¿ä¸Šçš„æ¬§æ°è·ç¦»ä¹‹å’Œæœ€å°.[^1]\n\n^0a7c67\n\n## ä¸ºä»€ä¹ˆå‰é¢æœ‰$\\frac{1}{2m}$\n\n$$J\\left(\\theta_{0}, \\theta_{1}\\right)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(\\hat{y}^{(i)}-y^{(i)}\\right)^{2}=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$$[Cost Function ML_Andrew.Ng.](notes/2021/2021.8/Part.3_Linear_Regression(ML_Andrew.Ng.).md#Cost%20Function)\n\t\nThe mean is halved $\\left(\\frac{1}{2}\\right)$ as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the $\\frac{1}{2}$ term.[^2]\n\nAlso:\n[Regarding the frac1 2 term](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md#Regarding%20the%20frac1%202%20term)\n\n\t\n\t\n[^1]: å‘¨å¿—å, æœºå™¨å­¦ä¹ , ç¬¬ä¸‰ç« , çº¿æ€§æ¨¡\n[^2]: å´æ©è¾¾æœºå™¨å­¦ä¹ çš„è§£é‡Š","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Norm_of_a_Vector-Matrix":{"title":"Norm_of_a_Vector-Matrix","content":"# å‘é‡/çŸ©é˜µçš„èŒƒæ•°\n\n\u003cdiv align=\"right\"\u003e 2021-08-20\u003c/div\u003e\n\nTags: #Norm #Math #MachineLearning #Regularization\n\nhttps://zh.wikipedia.org/wiki/%E8%8C%83%E6%95%B0\n\n![](notes/2021/2021.7/assets/img_2022-10-15-4.png)\n\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Normal_Equation_Proof_2_Matrix_Method":{"title":"Normal_Equation_Proof_2_Matrix_Method","content":"## é¦–å…ˆè¡¥å……ä¸€ç‚¹çŸ©é˜µçš„çŸ¥è¯†:æ±‚å¯¼ã€è¿¹çš„æ€§è´¨\n\nçŸ©é˜µçš„æ±‚å¯¼å’ŒçŸ©é˜µçš„è¿¹æ˜¯å¯†ä¸å¯åˆ†çš„\n\n### çŸ©é˜µçš„æ±‚å¯¼\n\n[çŸ©é˜µçš„æ±‚å¯¼](notes/2021/2021.8/çŸ©é˜µçš„æ±‚å¯¼.md)\n\n### çŸ©é˜µçš„è¿¹\n\n[çŸ©é˜µè¿¹çš„æ€§è´¨](notes/2021/2021.8/çŸ©é˜µè¿¹çš„æ€§è´¨.md)\n\n### è¯æ˜ä¸­éœ€è¦çš„ä¸€äº›å…¶ä»–æ€§è´¨\n\nç»“åˆçŸ©é˜µçš„æ±‚å¯¼, è¿˜æœ‰ä»¥ä¸‹æ€§è´¨:\n\n- $$\\nabla_{A} \\operatorname{tr} A B =B^{T}$$\n  - ç»“åˆ[è¿™é‡Œ](notes/2021/2021.8/çŸ©é˜µè¿¹çš„æ€§è´¨.md#^tracecommutative)å¯¹$\\operatorname{tr} A B$çš„æ¨å¯¼, å¯ä»¥çœ‹å‡ºå¯¹äºçŸ©é˜µ$A$æ¯ä¸€ä¸ªä½ç½®å•ç‹¬æ±‚åå¯¼, éƒ½ä¼šå¾—åˆ°$b_{ji}$, å³$B^T$å¯¹åº”çš„ä½ç½®.\n  - æˆ–è€…å¯ä»¥ä»å¯¼æ•°çš„è§’åº¦æ¥è¯æ˜:\n æ ‡é‡å‡½æ•°$f=\\operatorname{tr}AB$\n $$\\begin{align}  \n df \u0026= d\\space \\operatorname{tr}AB  \\\\\n    \u0026= \\operatorname{tr}d(AB) \\\\\n    \u0026= \\operatorname{tr}BdA \\\\\n    \\end{align}$$\n    è”ç³»:![çŸ©é˜µå¯¼æ•°ä¸å¾®åˆ†çš„è”ç³»](notes/2021/2021.8/çŸ©é˜µçš„æ±‚å¯¼.md#^e0894d)\n æ‰€ä»¥: $$\\frac{\\partial f}{\\partial A}=B^T$$\n è¯æ¯•\n- $$\\nabla_{A^{T}} f(A) =\\left(\\nabla_{A} f(A)\\right)^{T}$$\n\n$$\\begin{align}\n\\nabla_{A^T} f(A)\n\u0026=\\left[\\begin{array}{ccc}\n\\frac{\\partial f}{\\partial A^T_{11}} \u0026 \\cdots \u0026 \\frac{\\partial f}{\\partial A^T_{1 n}} \\\\\n\\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n\\frac{\\partial f}{\\partial A^T_{m 1}} \u0026 \\cdots \u0026 \\frac{\\partial f}{\\partial A^T_{m n}}\n\\end{array}\\right]\\\\\n\u0026=\\left[\\begin{array}{ccc}\n\\frac{\\partial f}{\\partial A_{11}} \u0026 \\cdots \u0026 \\frac{\\partial f}{\\partial A_{1 n}} \\\\\n\\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n\\frac{\\partial f}{\\partial A_{m 1}} \u0026 \\cdots \u0026 \\frac{\\partial f}{\\partial A_{m n}}\n\\end{array}\\right]^T\\\\\n\u0026=\\left(\\nabla_{A} f(A)\\right)^{T}\n\\end{align}$$\n\n- $$\\nabla_{A} \\operatorname{tr} A B A^{T} C =C A B+C^{T} A B^{T} $$\n è¯æ˜:\n æ ‡é‡å‡½æ•°$f=\\operatorname{tr} A B A^{T} C$\n $$\\begin{align}  \n df \u0026= d\\space \\operatorname{tr} (A B A^{T} C)  \\\\\n    \u0026= \\operatorname{tr}(d(A B A^{T} C)) \\\\\n    \u0026= \\operatorname{tr}(dA (B A^{T} C)+A dB (A^{T} C)+(A B) dA^{T} (C)+(A B A^{T}) dC) \\\\\n    \u0026= \\operatorname{tr}(dA (B A^{T} C)+(A B) dA^{T} (C)) \\\\\n    \u0026= \\operatorname{tr}((B A^{T} C)dA)+\\operatorname{tr}( (CA B) dA^{T})) \\\\\n \u0026= \\operatorname{tr}((B A^{T} C)dA)+\\operatorname{tr}( (CAB)^T (dA^{T})^T)) \\\\\n \u0026= \\operatorname{tr}((B A^{T} C)dA)+\\operatorname{tr}( (CAB)^T dA) \\\\\n \u0026= \\operatorname{tr}\\left(\\left(BA^{T}C+ (CAB)^T\\right) dA\\right)\n    \\end{align}$$\n æ‰€ä»¥: $$\\frac{\\partial f}{\\partial A}=\\left(BA^{T}C+ (CAB)^T\\right)^T=C A B+C^{T} A B^{T}$$\n è¯æ¯•\n \n- $$\\nabla_{A}|A| =|A|\\left(A^{-1}\\right)^{T}$$\n å‚è§å´æ©è¾¾è®²ä¹‰é‡Œé¢çš„è¯æ˜:\n ![](notes/2021/2021.7/assets/Pasted%20image%2020210817213317.png)\n \n## ç„¶åæ˜¯è¯æ˜\n\nå†…ç§¯çš„å¦ä¸€ç§è¡¨è¿°:  $z^{T} z=\\sum_{i} z_{i}^{2}$ :\n$$\n\\begin{aligned}\n\\frac{1}{2}(X \\theta-\\vec{y})^{T}(X \\theta-\\vec{y}) \u0026=\\frac{1}{2} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2} \\\\\n\u0026=J(\\theta)\n\\end{aligned}\n$$\nä¸ºäº†æœ€å°åŒ– $J$, æˆ‘ä»¬å¯¹ $\\theta$æ±‚å¯¼. ç»“åˆä¸Šé¢çš„è¡¥å……æ€§è´¨, æˆ‘ä»¬æœ‰:\n$$\n\\nabla_{A^{T} } \\operatorname{tr} A B A^{T} C=B^{T} A^{T} C^{T}+B A^{T} C\n$$\nè¿™ä¸ªåœ¨ä¸‹é¢ä¼šç”¨åˆ°.\næ±‚å¯¼æœ‰:\n$$\\begin{aligned}\n\\nabla_{\\theta} J(\\theta) \u0026=\\nabla_{\\theta} \\frac{1}{2}(X \\theta-\\vec{y})^{T}(X \\theta-\\vec{y}) \\\\\n\\text{(å±•å¼€)}\u0026=\\frac{1}{2} \\nabla_{\\theta}\\left(\\theta^{T} X^{T} X \\theta-\\theta^{T} X^{T} \\vec{y}-\\vec{y}^{T} X \\theta+\\vec{y}^{T} \\vec{y}\\right) \\\\\n\\text{(æ ‡é‡çš„è¿¹å°±æ˜¯å®ƒè‡ªå·±)}\u0026=\\frac{1}{2} \\nabla_{\\theta} \\operatorname{tr}\\left(\\theta^{T} X^{T} X \\theta-\\theta^{T} X^{T} \\vec{y}-\\vec{y}^{T} X \\theta+\\vec{y}^{T} \\vec{y}\\right) \\\\\n\u0026=\\frac{1}{2} \\nabla_{\\theta}\\left(\\operatorname{tr} \\theta^{T} X^{T} X \\theta-2 \\operatorname{tr} \\vec{y}^{T} X \\theta\\right) \\\\\n\\text{(åˆ©ç”¨ä¸Šé¢çš„æ¨è®º)}\u0026=\\frac{1}{2}\\left(X^{T} X \\theta+X^{T} X \\theta-2 X^{T} \\vec{y}\\right) \\\\\n\u0026=X^{T} X \\theta-X^{T} \\vec{y}\n\\end{aligned}$$\n\né›¶å¯¼æ•°ä¸ºé›¶, æœ‰$X^{T} X \\theta=X^{T} \\vec{y}$ , æ‰€ä»¥ $\\theta=(X^{T} X )^{-1}X^{T} \\vec{y}$\nè¯æ¯•.\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.10_Octave_TutorialML_Andrew.Ng.":{"title":"Part.10_Octave_Tutorial(ML_Andrew.Ng.)","content":"# Octave Tutorial\n\n\u003cdiv align=\"right\"\u003e 2021-08-18\u003c/div\u003e\n\nTags: #Octave #MachineLearning \n\n- è¿˜æ˜¯è¦åœ¨å®è·µä¸­å­¦ä¹ Octave\n\n\n## ä¸ºä»€ä¹ˆå´æ©è¾¾è¯´Octaveæ¯”Pythonå¥½å‘¢?  \n- æˆ–è®¸è¿™é‡Œæ¶‰åŠåˆ°ç¼–ç¨‹ä¸å»ºæ¨¡çš„åŒºåˆ«? \n\t\tå»ºæ¨¡çš„ç›®çš„æ˜¯å¿«é€Ÿå®ç°ä¸€ä¸ªæ¨¡å‹, åƒ `Matlab` `Octave` `Labview`ä¹‹ç±»çš„è½¯ä»¶çš„ç›®æ ‡å°±æ˜¯å¿«é€Ÿå»ºæ¨¡, è€Œç¼–ç¨‹è¯­è¨€åƒæ˜¯Pythonä¹‹ç±»çš„, ä»–ä»¬çš„ç›®çš„åå‘äº å»ºç«‹ä¸€ä¸ªæ¨¡å‹çš„å¯é çš„åº”ç”¨å®ä¾‹, ä¸ä»…è¦å®ç°, è¿˜éœ€è¦å¯é , æ€§èƒ½éœ€è¦ä¼˜åŒ–\n\t\tä½†æ˜¯åƒIPython Console, Jupyter Notebookä¹‹ç±»çš„äº¤äº’å¼ç¼–ç¨‹ç•Œé¢æ˜¯å¦å·²ç»æ‰“ç ´äº†è¿™ä¸¤ä¸ªä¹‹é—´çš„éš”é˜‚? \t\n\t\t\n\t\t\n\t- Cousera ä¸Šé¢Machine Learning å¤§æ¦‚å¼€å§‹äº2011\n\t\t\n\t\t\u003eIn October 2011, the \"applied\" version of the Stanford class (CS229a) was hosted on ml-class.org and launched, with over 100,000 students registered for its first edition[^1]\n\t- IPython Notebook \u0026 Jupyter Notebook ä¹Ÿå¤§è‡´è‡ª2011-2015å¹´é—´é€æ¸èµ·æ­¥, åæ¥æ‰é€æ­¥å˜å¾—æµè¡Œèµ·æ¥.\n\t\t \u003e-  IPythonåœ¨0.12ç‰ˆæœ¬ï¼ˆ2011å¹´12æœˆï¼‰ä¸­æ·»åŠ äº†Notebookç•Œé¢ï¼Œ2015å¹´æ›´åä¸ºJupyter Notebook[^2]\n\t\t \u003e - æ®ã€Šå¤§è¥¿æ´‹ã€‹æ‚å¿—æŠ¥é“ï¼Œåœ¨2018å¹´åˆï¼Œç”¨æˆ·å¯¹Jupyterçš„å…´è¶£è¶…è¿‡äº†Mathematica Notebookç•Œé¢çš„æµè¡Œç¨‹åº¦[^2]\n\t- æ•…ä¸€ç§åˆç†çš„çŒœæµ‹æ˜¯åœ¨Andrew Ng çš„è¯¾ç¨‹å½•åˆ¶çš„æ—¶å€™, Python çš„äº¤äº’æ€§è¿˜æ²¡æœ‰å¾—åˆ°å¾ˆå¥½çš„å‘å±•ä¸æ¨å¹¿, æ—¶è‡³ä»Šæ—¥(2021), Pythonä½œä¸ºæœºå™¨å­¦ä¹ å»ºæ¨¡å·¥å…·çš„æ˜“ç”¨æ€§å€¼å¾—å…³æ³¨.\n\n## å®ç”¨æŠ€å·§: å‘é‡åŒ–Vectorization\n\nç›¸æ¯”äºåˆ©ç”¨å¾ªç¯, åœ¨éœ€è¦å¯¹ä¸€ä¸ªçŸ©é˜µé‡Œé¢çš„å…ƒç´ è¿›è¡Œç›¸ä¼¼çš„æ“ä½œçš„æ—¶å€™, æˆ‘ä»¬å¯ä»¥åˆ©ç”¨çŸ©é˜µä¹˜æ³•æ¥è¿›è¡Œç›¸åŒçš„æ“ä½œ, è¿™æ ·æˆ‘ä»¬å¯ä»¥åˆ©ç”¨**æ€§èƒ½ä¼˜åŒ–è¿‡çš„å‡½æ•°**, åŠ å¿«ç¨‹åºæ€§èƒ½. \n\nE.g. $$\\sum x_i^2=\\vec X^T \\vec X$$ \n\n\n[^1]: https://en.wikipedia.org/wiki/Andrew_Ng\n[^2]: https://zh.wikipedia.org/zh-sg/Jupyter#Jupyter_Notebook","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.11_ClassificationML_Andrew.Ng.":{"title":"Part.11_Classification(ML_Andrew.Ng.)","content":"# Classification\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #MachineLearning  #Classification \n\n- åˆ†ç±»é—®é¢˜æœ€ç®€å•çš„æƒ…å†µæ˜¯äºŒåˆ†ç±»é—®é¢˜(Binary Classification), æ›´ä¸€èˆ¬çš„æƒ…å†µæ˜¯å¤šåˆ†ç±»é—®é¢˜.\n\n- åˆ†ç±»é—®é¢˜ä¸å›å½’é—®é¢˜æœ€å¤§çš„ä¸åŒæ˜¯å…¶å¯¹è¾“å‡ºçš„è¦æ±‚æ˜¯ç¦»æ•£çš„, çº¿æ€§å‡½æ•°/å›å½’åœ¨åˆ†ç±»é—®é¢˜ä¸Šé¢ä¸é€‚ç”¨. \n\n\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.12_Logistic_RegressionML_Andrew.Ng.":{"title":"Part.12_Logistic_Regression(ML_Andrew.Ng.)","content":"# Logistic Regression\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #LogisticRegression #MachineLearning #Classification \n\n## Logistic Function\n![Logistic Function](notes/2021/2021.8/Sigmoid_Function.md#Logistic%20Function)\n\n\n## Hypothesis Representation\n- æˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹çº¿æ€§å›å½’çš„æ–¹æ³•è¿›è¡Œä¸€äº›å°æ”¹åŠ¨æ¥åŒ¹é…å›å½’é—®é¢˜, åœ¨çº¿æ€§å›å½’çš„æ—¶å€™, $h(x)$çš„è¾“å‡ºä¸åˆ†ç±»é—®é¢˜çš„\"å€¼åŸŸ\"åå·®è¾ƒå¤§, æ¯”å¦‚åœ¨äºŒåˆ†ç±»é—®é¢˜é‡Œé¢, è¦æ±‚$y=0\\space or\\space 1$, ä½†æ˜¯$h(x)$ä¼šè¾“å‡ºå¤§äºä¸€æˆ–è€…å°äºé›¶çš„æ•°. \n\n- ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜, æˆ‘ä»¬å°†$h(x)$ä½œä¸ºé€»è¾‘æ–¯è’‚å‡½æ•°çš„è¾“å…¥, å°†ä»»æ„è¾“å‡ºåŒ¹é…åˆ°$(0,1)$åŒºé—´é‡Œé¢å», æ–¹ä¾¿åˆ†ç±».\n$$\\begin{aligned}\n\u0026h_{\\theta}(x)=g\\left(\\theta^{T} x\\right) \\\\\n\u0026g(z)=\\frac{1}{1+e^{-z}}\\\\\n\u0026z=\\theta^{T} x \\\\\n\\end{aligned}$$\n\n- Hypothesiså¦‚æ­¤è¡¨è¿°ä¹‹å,  $h(x)$çš„å€¼å°±å¯ä»¥ç†è§£ä¸ºäºŒåˆ†ç±»é—®é¢˜ä¸­, $x$è¢«å½’ä¸º$1$çš„æ¦‚ç‡å¤§å°.\n\tä¸¥è°¨çš„è¡¨è¿°æ˜¯: \n\t$$h_Î¸(x)=P(y=1|x;Î¸)=1âˆ’P(y=0|x;Î¸)$$\n\t$$P(y=0|x;Î¸)+P(y=1|x;Î¸)=1$$\n\tå…¶ä¸­ \" $;Î¸$ \" çš„å«ä¹‰æ˜¯: $Î¸$æ˜¯å‚æ•°(Parameterized by theta).\n\t\n\t\n## Decision Boundary\nå‡å¦‚æˆ‘ä»¬é‡‡ç”¨è¿™æ ·çš„åˆ†ç±»æ–¹æ³•:\n$$\\begin{aligned}\n\u0026h_{\\theta}(x) \\geq 0.5 \\rightarrow y=1 \\\\\n\u0026h_{\\theta}(x)\u003c0.5 \\rightarrow y=0\n\\end{aligned}$$\n\né‚£ä¹ˆåˆ†ç±»ç»“æœæœ€ç»ˆç”±$h(x)$çš„å€¼å†³å®š:\n$$\\begin{aligned}\nÎ¸^Txâ‰¥0â‡’y=1\\\\\nÎ¸^Tx\u003c0â‡’y=0\n\\end{aligned}$$\n\nä¸€ä¸ªä¾‹å­:\n![](notes/2021/2021.7/assets/Pasted%20image%2020210819153316.png)\nå›¾ä¸­åˆ’åˆ†æ•°æ®é›†çš„çº¿ä¾¿æ˜¯è¿™ä¸ª$h(x)$, Decision Boundary, åœ¨æ›²çº¿ä¸Šé¢çš„ç‚¹$h(x)\\geq 0$, åˆ†ç±»ç»“æœä¸º1, åœ¨æ›²çº¿ä¸‹é¢çš„ç‚¹$h(x)\u003c 0$, åˆ†ç±»ç»“æœä¸º0.\n\næ³¨æ„Decision Boundaryæ˜¯$h(x)$çš„æ€§è´¨, å³ä½¿ä¸Šå›¾ä¸ç”»æ•°æ®ç‚¹, Boundaryä¾ç„¶å­˜åœ¨.\n\n## Nonlinearity\n\nå°±åƒçº¿æ€§å›å½’å¯ä»¥æ¨å¹¿ä¸ºå¤šé¡¹å¼å›å½’ä¸€æ ·, Logistic å›å½’ä¹Ÿå¯ä»¥æœ‰éçº¿æ€§çš„å†³ç­–è¾¹ç•Œ:\n![](notes/2021/2021.7/assets/Pasted%20image%2020210819154110.png)\n![](notes/2021/2021.7/assets/Pasted%20image%2020210819154123.png)","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.13_Cost_Function-Logistic_RegressionML_Andrew.Ng.":{"title":"Part.13_Cost_Function-Logistic_Regression(ML_Andrew.Ng.)","content":"# Cost Function - Logistic Regression\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #CostFunction #LogisticRegression #MachineLearning \n\n## Representation\nå¦‚æœæˆ‘ä»¬é‡‡ç”¨[çº¿æ€§å›å½’çš„æŸå¤±å‡½æ•°](notes/2021/2021.8/Part.4_Cost_Function_Intuition(ML_Andrew.Ng.).md): [å‡æ–¹è¯¯å·®](notes/2021/2021.8/Mean_Squared_Error_å‡æ–¹è¯¯å·®.md), é‚£ä¹ˆå› ä¸ºLogistic å›å½’çš„$h(x)$é‡Œé¢æœ‰å½¢å¼å¾ˆå¤æ‚çš„Logisticå‡½æ•°, æŸå¤±å‡½æ•°å°†ä¸å†æ˜¯[å‡¸å‡½æ•°](notes/2021/2021.8/å‡¸ä¼˜åŒ–ä¸çº¿æ€§å›å½’é—®é¢˜.md), å°†ä¼šå¾ˆéš¾æœ€å°åŒ–, æ‰€ä»¥æˆ‘ä»¬éœ€è¦è€ƒè™‘å¦å¤–çš„æŸå¤±å‡½æ•°å½¢å¼:\n\næˆ‘ä»¬é‡‡ç”¨è¿™æ ·çš„å¯¹æ•°å½¢å¼\nUpdate: è¿™å…¶å®æ˜¯[Cross_Entropy-äº¤å‰ç†µ](notes/2022/2022.2/Cross_Entropy-äº¤å‰ç†µ.md)\n\n$$\n\\begin{array}{ll}\nJ(\\theta)=\\frac{1}{m} \n\\sum_{i=1}^{m} \\operatorname{Cost}\\left(h_{\\theta}\\left(x^{(i)}\\right), y^{(i)}\\right) \u0026 \\\\\n\\\\\n\\operatorname{Cost}\\left(h_{\\theta}(x), y\\right)=-\\log \\left(h_{\\theta}(x)\\right) \u0026 \\text { if } \\mathrm{y}=1 \\\\\n\n\\operatorname{Cost}\\left(h_{\\theta}(x), y\\right)=-\\log \\left(1-h_{\\theta}(x)\\right) \u0026 \\text { if } \\mathrm{y}=0\n\\end{array}$$\n\n## Intuition\n- åœ¨$y=1$æ—¶: æˆ‘ä»¬çš„æŸå¤±å‡½æ•°åœ¨æ¥è¿‘0çš„æ—¶å€™(é”™è¯¯çš„ä¸€ç«¯)è¶‹å‘äºæ— ç©·å¤§, åœ¨ç­‰äº1çš„æ—¶å€™(æ­£ç¡®çš„ä¸€ç«¯)è¾¾åˆ°æœ€å°å€¼0.\n$$\\operatorname{Cost}\\left(h_{\\theta}(x), y\\right)=-\\log \\left(h_{\\theta}(x)\\right)\n$$\n![300](notes/2021/2021.7/assets/img_2022-10-15-19.png)\n\n- åœ¨$y=0$æ—¶: æˆ‘ä»¬çš„æŸå¤±å‡½æ•°åœ¨æ¥è¿‘1çš„æ—¶å€™(é”™è¯¯çš„ä¸€ç«¯)è¶‹å‘äºæ— ç©·å¤§, åœ¨ç­‰äº0çš„æ—¶å€™(æ­£ç¡®çš„ä¸€ç«¯)è¾¾åˆ°æœ€å°å€¼0.\n$$\\operatorname{Cost}\\left(h_{\\theta}(x), y\\right)=-\\log \\left(1-h_{\\theta}(x)\\right) $$\n![250](notes/2021/2021.7/assets/img_2022-10-15-20.png)\n\nè¿™æ ·, æ€»ä½“ä¸Š, åœ¨é¢„æµ‹å€¼ä¸çœŸå®å€¼è¶Šæ¥è¿‘çš„æ—¶å€™æŸå¤±å‡½æ•°è¶Šæ¥è¿‘äº0.\n\n$$\\begin{array}{ll}\nCost(h_Î¸(x),y)=0 \\text{  if  } h_Î¸(x)=y\\\\\nCost(h_Î¸(x),y)â†’âˆ \\text{  if  } y=0 \\text{ and } h_Î¸(x)â†’1\\\\\nCost(h_Î¸(x),y)â†’âˆ \\text{  if  } y=1 \\text{ and } h_Î¸(x)â†’0\\\\\n\\end{array}$$\n\nè¿™æ ·çš„æŸå¤±å‡½æ•°å½¢å¼ç¡®ä¿äº†logistic regressionçš„ $J(Î¸)$ æ˜¯å‡¸å‡½æ•°.\n### è¯æ˜\n[è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°](notes/2021/2021.9/è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°.md)\n\n\n## æ›´ç®€æ´çš„å½¢å¼\næˆ‘ä»¬å¯ä»¥æŠŠä¸¤ç§æƒ…å†µå†™æˆä¸€ä¸ªå¼å­:\n$$\\operatorname{Cost}\\left(h_{\\theta}(x), y\\right)=-y \\log \\left(h_{\\theta}(x)\\right)-(1-y) \\log \\left(1-h_{\\theta}(x)\\right)$$\n(è§‚å¯Ÿä¸Šé¢çš„å¼å­: åœ¨$y=1$çš„æ—¶å€™, $1-y=0$, åœ¨$y=0$çš„æ—¶å€™, $1-y=1$)\n\n### Cost Function\næ‰€ä»¥æŸå¤±å‡½æ•°å¯ä»¥è¡¨ç¤ºä¸º:\n$$\n\\begin{align}\nJ(\\theta)\u0026=\\frac{1}{m} \n\\sum_{i=1}^{m} \\operatorname{Cost}\\left(h_{\\theta}\\left(x^{(i)}\\right), y^{(i)}\\right)  \\\\\n\u0026=-\\frac{1}{m} \\sum_{i=1}^{m}\\left[y^{(i)} \\log \\left(h_{\\theta}\\left(x^{(i)}\\right)\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h_{\\theta}\\left(x^{(i)}\\right)\\right)\\right]\\\\\n\\end{align}\n$$\n(æ³¨æ„æå‡ºæ¥çš„è´Ÿå·)\n\n[å‘é‡åŒ–](notes/2021/2021.8/Part.10_Octave_Tutorial(ML_Andrew.Ng.).md#å®ç”¨æŠ€å·§%20å‘é‡åŒ–Vectorization)çš„è¡¨ç¤ºä¸º:\n$$\n\\begin{aligned}\nh\u0026=g(X \\theta) \\\\\nJ(\\theta)\u0026=-\\frac{1}{m} \\cdot\\left[y^{T} \\log (h)+(1-y)^{T} \\log (1-h)\\right]\n\\end{aligned}\n$$","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.14_Logistic_RegressionGradient_DescentML_Andrew.Ng.":{"title":"Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.)","content":"# Logistic Regression \u0026 Gradient Descent\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #LogisticRegression  #GradientDescent  #MachineLearning \n\n- **Gradient Descent:**\n![Algorithm](notes/2021/2021.8/Part.5_Gradient_Descent(ML_Andrew.Ng.).md#Algorithm)\n\n- **Cost Function:**\n![Cost Function](notes/2021/2021.8/Part.13_Cost_Function-Logistic_Regression(ML_Andrew.Ng.).md#æ›´ç®€æ´çš„å½¢å¼#Cost%20Function)\n\n## æ¨å¯¼\næŸå¤±å‡½æ•°é‡Œé¢çš„$g(x)$ä¸ºLogisticå‡½æ•°, [Logisticçš„å¯¼å‡½æ•°](notes/2021/2021.8/Sigmoid_Function.md#Logistic%20Function)ä¸º:\n$$\\begin{aligned}\n\\frac {d}{dx}g(x)\u0026=g(x)\\left(1-g(x)\\right)\\\\\n\\end{aligned}$$\n\næ±‚åå¯¼æ•°$\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}} J(\\theta)$:\n\nä¸ºäº†ä½¿æ€è·¯æ¸…æ™°, æˆ‘ä»¬å…ˆè®¡ç®—å¯¹äºä¸€ä¸ªæ•°æ®ç‚¹çš„åå¯¼æ•°, å³å…ˆè®¡ç®—æ±‚å’Œç¬¦å·çš„ååŠéƒ¨åˆ†: $\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}}  C(\\theta)$, æ ¹æ®å¯¼æ•°çš„æ€§è´¨, æœ‰$\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}} J(\\theta)=-\\frac{\\Large1}{\\Large m} \\sum_{i=1}^{m} \\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}}  C^{(i)}(\\theta)$ :\n\n$$\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} C(\\theta) \n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}\\left(\\space y \\log \\left(h_{\\theta}\\left(x\\right)\\right)\n+\\left(1-y\\right) \\log \\left(1-h_{\\theta}\\left(x\\right)\\right)\\space \\right)\\\\\n\n\u0026=\\left(y \\frac{1}{g\\left(\\theta^Tx\\right)}-(1-y) \\frac{1}{1-g\\left(\\theta^Tx\\right)}\\right) \\frac{\\partial}{\\partial \\theta_{j}} g\\left(\\theta^Tx\\right) \\\\\n\u0026=\\left(y \\frac{1}{g\\left(\\theta^Tx\\right)}-(1-y) \\frac{1}{1-g\\left(\\theta^Tx\\right)}\\right) g\\left(\\theta^Tx\\right)\\left(1-g\\left(\\theta^Tx\\right)\\right) \\frac{\\partial}{\\partial \\theta_{j}} \\theta^Tx\\\\\n\u0026=\\left(y\\left(1-g\\left(\\theta^Tx\\right)\\right)-(1-y) g\\left(\\theta^Tx\\right)\\right) x_{j} \\\\\n\u0026=\\left(y-yg\\left(\\theta^Tx\\right)+yg\\left(\\theta^Tx\\right)-g\\left(\\theta^Tx\\right)\\right) x_{j} \\\\\n\u0026=\\left(y-h_{\\theta}(x)\\right) x_{j}\n\\end{aligned}$$\n\n(æ³¨æ„: è¯æ˜é‡Œé¢$\\theta,x$å‡ä¸ºåˆ—å‘é‡, æœ‰æ‰€ä¸åŒçš„æ˜¯: åœ¨ä¸Šé¢å‘é‡åŒ–çš„æŸå¤±å‡½æ•°é‡Œé¢, $X_{m\\times n}$æ˜¯æ¯ä¸€è¡Œä¸ºä¸€ä¸ªæ•°æ®)\n\nå¸¦å…¥æ‰€æœ‰æ ·æœ¬ç‚¹, è®¡ç®— $\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}} J(\\theta)$ :\n$$\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta) \n\u0026=-\\frac{1}{m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial \\theta_{j}}   C^{(i)}(\\theta)\\\\\n\u0026=\\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) x^{(i)}_{j}\n\\end{aligned}$$\n\n## ç»“æœ\nå¸¦å…¥æ¢¯åº¦ä¸‹é™é‡Œé¢:\n$$\n\\begin{array}{l}\n\\text { repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\u0026\\theta_{j}:=\\theta_{j}-\\alpha \\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) x_j^{(i)} \n\\end{array}\\\\\n\\text { \\} }\n\\\\\\\\ \\text { (simultaneously update } \nj=0, \\cdots ,j=n)\n\\end{array}\n$$\n\nå‘é‡åŒ–åçš„å…¬å¼:\n$$\\theta:=\\theta-\\alpha\\frac{1}{m} X^{T}(g(X \\theta)-\\vec{y})$$\n\n- æ¯”è¾ƒLinear Regressioné‡Œé¢çš„æ¢¯åº¦ä¸‹é™å…¬å¼: \n[Relation_Between_Linear_Regression\u0026Gradient_Descent_æ¢¯åº¦ä¸‹é™å’Œçº¿æ€§å›å½’çš„å…³ç³»](notes/2021/2021.8/Relation_Between_Linear_Regression\u0026Gradient_Descent_æ¢¯åº¦ä¸‹é™å’Œçº¿æ€§å›å½’çš„å…³ç³».md)\nå‘ç°æ˜¯å®Œå…¨ä¸€æ ·çš„.","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.15_Advanced_OptimizationML_Andrew.Ng.":{"title":"Part.15_Advanced_Optimization(ML_Andrew.Ng.)","content":"# Advanced Optimization\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #Octave #MachineLearning #GradientDescent #LinearRegression #LogisticRegression \n\n\n- **More sophisticated, faster way to optimize parameters**: \n\t- Conjugate gradient\n\t- BFGS\n\t- L-BFGS\n\n\n[Link:å…¶ä»–Gradient_Descent Different_Gradient_Descent_Methods](notes/2021/2021.8/Different_Gradient_Descent_Methods.md)\n\nåœ¨[Octave](notes/2021/2021.8/Part.10_Octave_Tutorial(ML_Andrew.Ng.).md)é‡Œé¢, åªéœ€è¦å†™å‡ºæ€ä¹ˆè®¡ç®—$J(\\theta)$, $\\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}} J(\\theta)$å³å¯è°ƒç”¨å†…ç½®çš„åº“å‡½æ•°å¿«é€Ÿè®¡ç®—å‚æ•°å€¼.\n\n```matlab\nfunction [jVal, gradient] = costFunction(theta)\n  jVal = [...code to compute J(theta)...];\n  gradient = [...code to compute derivative of J(theta)...];\nend\n```\n\n```matlab\noptions = optimset('GradObj', 'on', 'MaxIter', 100);\ninitialTheta = zeros(2,1);\n   [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);\n```\n\n- MATLABé‡Œé¢æ˜¯`optimoptions`å‡½æ•°\n- åœ¨ç¬¬äºŒæ¬¡ä½œä¸š(Logistic Regression)é‡Œé¢æœ‰å¯¹è¿™ä¸ªæ–¹æ³•æ›´å…·ä½“çš„ä»‹ç».","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.16_MulticlassClassification-One_vs_RestML_Andrew.Ng.":{"title":"Part.16_MulticlassClassification-One_vs_Rest(ML_Andrew.Ng.)","content":"# One vs Rest\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #MulticlassClassification #Classification #MachineLearning \n\n- AKA: One vs All\n\n## MulticlassClassification\n![](notes/2021/2021.7/assets/img_2022-10-15-21.png)\n\n$$\\begin{aligned}\n\u0026y \\in\\{0,1 \\ldots n\\} \\\\\n\u0026h_{\\theta}^{(0)}(x)=P(y=0 \\mid x ; \\theta) \\\\\n\u0026h_{\\theta}^{(1)}(x)=P(y=1 \\mid x ; \\theta) \\\\\n\u0026\\cdots \\\\\n\u0026h_{\\theta}^{(n)}(x)=P(y=n \\mid x ; \\theta) \\\\\n\u0026\\text { prediction }=\\max _{i}\\left(h_{\\theta}^{(i)}(x)\\right)\n\\end{aligned}$$\n\n## One vs Rest\nå°†äºŒåˆ†ç±»é—®é¢˜åº”ç”¨åˆ°å¤šåˆ†ç±»é‡Œé¢, å³å¯¹æ¯ä¸€ä¸ªåˆ†ç±»åˆ†åˆ«è®­ç»ƒä¸€ä¸ªäºŒåˆ†ç±»æ¨¡å‹$h^{(i)}(x)$ , å› ä¸º$h^{(i)}(x)$çš„å¤§å°å¯ä»¥çœ‹ä½œå±äºè¿™ä¸ªåˆ†ç±»çš„æ¦‚ç‡, åœ¨é¢„æµ‹çš„æ—¶å€™å°†æ•°æ®ç‚¹å¸¦å…¥$n$ä¸ª$h^{(i)}(x)$é‡Œé¢, å–æ¦‚ç‡æœ€å¤§çš„åˆ†ç±»ä½œä¸ºé¢„æµ‹ç»“æœ.\n![](notes/2021/2021.7/assets/img_2022-10-15-22.png)\n![](notes/2021/2021.7/assets/img_2022-10-15-23.png)","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.17_Overfitting_UnderfittingML_Andrew.Ng.":{"title":"Part.17_Overfitting_Underfitting(ML_Andrew.Ng.)","content":"# Overfitting Underfitting\n\n\u003cdiv align=\"right\"\u003e 2021-08-20\u003c/div\u003e\n\nTags: #Overfitting #Underfitting #MachineLearning\n\n![](notes/2021/2021.7/assets/img_2022-10-15-24.png)\n\n## Underfitting\nUnderfitting çš„å¦ä¸€ ç§è¡¨è¿°æ˜¯è¿™ä¸ªæ¨¡å‹æœ‰ \"High Bias\", ç›´è§‚ä¸Šç†è§£, è¿™ä¸ªæ¨¡å‹å¯¹æ•°æ®é›†æœ‰ç€å…ˆå…¥ä¸ºä¸»çš„\"åè§\", \"ä¸å…è®¸\"æ•°æ®é›†ä¸ºäºŒæ¬¡çš„, å¯¼è‡´é¢„æµ‹æ•ˆæœä¸å¥½.\nBias=Preconception\n\nåŸå› : æ¨¡å‹å¤ªç®€å•/ä½¿ç”¨çš„ç‰¹å¾å¤ªå°‘\n\n## Overfitting\nOverfittingçš„å¦ä¸€ç§è¡¨è¿°åˆ™æ˜¯ \"High Variance\", å³è¿™ä¸ªæ¨¡å‹æœ‰ç€å¤ªå¤šçš„å¯èƒ½æ€§, è€Œæˆ‘ä»¬çš„æ•°æ®å¤ªå°‘, æˆ‘ä»¬ç°æœ‰çš„æ•°æ®ä¸è¶³ä»¥ç¡®å®šè¿™ä¸ªæ¨¡å‹ / åŸºäºç°æœ‰çš„æ•°æ®, è¿™ä¸ªæ¨¡å‹æœ‰ç€å¾ˆé«˜çš„å˜æ•°.\n\nThe term high variance is another historical or technical one. But, the intuition is that, if we're fitting such a high order polynomial, then, the hypothesis can fit, you know, it's almost as if it can fit almost any function and this face of possible hypothesis is just too large, it's too variable. And we don't have enough data to constrain it to give us a good hypothesis.\n\nåŸå› : æ¨¡å‹å¤ªå¤æ‚\n\n## è§£å†³æ–¹æ³•\n\n1) å‡å°‘ç‰¹å¾æ•°ç›®\n\t-  æ‰‹åŠ¨ç­›é€‰\n\t-  åˆ©ç”¨é™ç»´ç®—æ³•\n\n2) Regularization æ­£åˆ™åŒ–\n\t- ä¿ç•™æ‰€æœ‰ç‰¹å¾, ä½†æ˜¯å‡å°å‚æ•°çš„Magnitude\n\t- Regularization works well when we have a lot of slightly useful features.\n\n\n- åœ¨ä»¥å‰çš„å…³äºä¸ºä»€ä¹ˆè¦åˆ©ç”¨å‡æ–¹è¯¯å·®çš„ç¬”è®°é‡Œé¢ä¹Ÿæœ‰å…³äºBias_Variance_Trade-off çš„é˜è¿°:\n![](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md#^91cd90)\n\n## åç»­æ€è€ƒ\n1. Source: [4.6. æš‚é€€æ³•ï¼ˆDropoutï¼‰ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/dropout.html#id1)\n\t- çº¿æ€§æ¨¡å‹çš„ High Bias ä¸€å®šç¨‹åº¦ä¸Šæ˜¯å› ä¸ºçº¿æ€§æ¨¡å‹æ²¡æœ‰è€ƒè™‘åˆ°ç‰¹å¾ä¹‹é—´çš„äº¤äº’ä½œç”¨ã€‚ å¯¹äºæ¯ä¸ªç‰¹å¾ï¼Œçº¿æ€§æ¨¡å‹å¿…é¡»æŒ‡å®šæ­£çš„æˆ–è´Ÿçš„æƒé‡ï¼Œè€Œå¿½ç•¥å…¶ä»–ç‰¹å¾ã€‚\n\t- æ·±åº¦ç¥ç»ç½‘ç»œä½äºåå·®-æ–¹å·®è°±çš„å¦ä¸€ç«¯ã€‚ ä¸çº¿æ€§æ¨¡å‹ä¸åŒï¼Œç¥ç»ç½‘ç»œå¹¶ä¸å±€é™äºå•ç‹¬æŸ¥çœ‹æ¯ä¸ªç‰¹å¾ï¼Œè€Œæ˜¯å­¦ä¹ ç‰¹å¾ä¹‹é—´çš„äº¤äº’ã€‚ ä¾‹å¦‚ï¼Œç¥ç»ç½‘ç»œå¯èƒ½æ¨æ–­â€œå°¼æ—¥åˆ©äºšâ€å’Œâ€œè¥¿è”æ±‡æ¬¾â€ä¸€èµ·å‡ºç°åœ¨ç”µå­é‚®ä»¶ä¸­è¡¨ç¤ºåƒåœ¾é‚®ä»¶ï¼Œ ä½†å•ç‹¬å‡ºç°åˆ™ä¸è¡¨ç¤ºåƒåœ¾é‚®ä»¶ã€‚\n\n\t- å³ä½¿æˆ‘ä»¬æœ‰æ¯”ç‰¹å¾å¤šå¾—å¤šçš„æ ·æœ¬ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œä¹Ÿæœ‰å¯èƒ½è¿‡æ‹Ÿåˆã€‚ 2017 å¹´ï¼Œä¸€ç»„ç ”ç©¶äººå‘˜é€šè¿‡åœ¨éšæœºæ ‡è®°çš„å›¾åƒä¸Šè®­ç»ƒæ·±åº¦ç½‘ç»œã€‚ è¿™å±•ç¤ºäº†ç¥ç»ç½‘ç»œçš„æå¤§çµæ´»æ€§ï¼Œå› ä¸ºäººç±»å¾ˆéš¾å°†è¾“å…¥å’Œéšæœºæ ‡è®°çš„è¾“å‡ºè”ç³»èµ·æ¥ï¼Œ ä½†é€šè¿‡éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–çš„ç¥ç»ç½‘ç»œå¯ä»¥å®Œç¾åœ°æ ‡è®°è®­ç»ƒé›†ä¸­çš„æ¯ä¸€å¹…å›¾åƒã€‚ æƒ³ä¸€æƒ³è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿ å‡è®¾æ ‡ç­¾æ˜¯éšæœºå‡åŒ€åˆ†é…çš„ï¼Œå¹¶ä¸”æœ‰ 10 ä¸ªç±»åˆ«ï¼Œé‚£ä¹ˆåˆ†ç±»å™¨åœ¨æµ‹è¯•æ•°æ®ä¸Šå¾ˆéš¾å–å¾—é«˜äº 10%çš„ç²¾åº¦ï¼Œ é‚£ä¹ˆè¿™é‡Œçš„æ³›åŒ–å·®è·å°±é«˜è¾¾ 90%ï¼Œå¦‚æ­¤ä¸¥é‡çš„è¿‡æ‹Ÿåˆã€‚\n\n\n---\nå´æ©è¾¾ç»ƒä¹ äºŒé‡Œé¢çš„ä¾‹å­:\n![](notes/2021/2021.8/assets/Pasted%20image%2020210911160311.png)\n![](notes/2021/2021.8/assets/Pasted%20image%2020210911160325.png)\n\n![400](notes/2021/2021.8/assets/lambda=0.png)\n![400](notes/2021/2021.8/assets/lambda=1.png)\n![400](notes/2021/2021.8/assets/lambda=10.png)\n![400](notes/2021/2021.8/assets/lambda=100.png)","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.1_Supervised_LearningML_Andrew.Ng.":{"title":"Part.1_Supervised_Learning(ML_Andrew.Ng.)","content":"# Supervised Learning-Introduction\n\n\u003cdiv align=\"right\"\u003e 2021-07-27\u003c/div\u003e\n\nTags: #MachineLearning #SupervisedLearning\n\n## What is supervised learning?\nSupervised learning refers to the fact that we gave the algorithm a dataset in which \"Right Answers\" were given.\nç›‘ç£å­¦ä¹ éœ€è¦ç»™æœºå™¨æ ‡ç­¾, æŒ‡å‡ºæ­£ç¡®ç­”æ¡ˆæ˜¯ä»€ä¹ˆ\n\n## What topics does supervised learning include?\n### Regression\nPredict a continuous valued output.\næ ¹æ®æœ‰é™çš„ä¿¡æ¯é¢„æµ‹å‡ºè¿ç»­çš„å˜åŒ–èŒƒå›´\n\n### Classification\næ ¹æ®æœ‰é™çš„è¾“å‡ºåšå‡ºç¦»æ•£çš„(Discrete)åˆ¤æ–­\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.2_Unsupervised_LearningML_Andrew.Ng.":{"title":"Part.2_Unsupervised_Learning(ML_Andrew.Ng.)","content":"# Unsupervised Learning-Introduction\n\n\u003cdiv align=\"right\"\u003e 2021-07-27\u003c/div\u003e\n\nTags: #MachineLearning #UnsupervisedLearning\n\n## What is unsupervised learning?\nIn Unsupervised Learning, we're given data that looks different than data that looks like this that doesn't have any labels or that all has the same label or really no labels.\nç›‘ç£å­¦ä¹ ä¸éœ€è¦ç»™æœºå™¨æ­£ç¡®ç­”æ¡ˆ, æœºå™¨ä¼šè‡ªåŠ¨æ‰¾å‡ºè§„å¾‹\n\n## What topics does unsupervised learning include?\n### Clustering\nåœ¨ä¸€ç»„æ•°æ®é‡Œé¢æ‰¾å‡ºè§„å¾‹, æŠŠç›¸ä¼¼çš„å½’ä¸ºä¸€ç±»\n\n### Cocktail Party Algorithm\nfind structure in a chaotic environment, åœ¨æ··ä¹±çš„æ•°æ®é‡Œé¢æ‰¾åˆ°ç‹¬ç«‹çš„æˆåˆ†/ç»“æ„\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.3_Linear_RegressionML_Andrew.Ng.":{"title":"Part.3_Linear_Regression(ML_Andrew.Ng.)","content":"# Linear Regression\n\n\u003cdiv align=\"right\"\u003e 2021-07-31\u003c/div\u003e\n\nTags: #MachineLearning #SelfLearning\n\n## Model Representation\n- [Supervised Learning](notes/2021/2021.8/Part.1_Supervised_Learning(ML_Andrew.Ng.).md)\n- [Regression Problem](notes/2021/2021.8/Part.1_Supervised_Learning(ML_Andrew.Ng.).md#Regression)\n### Structure\nåŸºäºè®­ç»ƒé›†, æˆ‘ä»¬å¸Œæœ›é€šè¿‡å­¦ä¹ ç®—æ³•å¾—åˆ°ä¸€ä¸ªHypothesiså‡½æ•°$h$, åœ¨æˆ¿ä»·é¢„æµ‹é—®é¢˜ä¸Š. è¾“å…¥æˆ¿å­çš„å¤§å°, å¾—åˆ°ä¼°è®¡çš„ä»·æ ¼. \n![](notes/2021/2021.7/assets/img_2022-10-15-5.png)\nå¯¹äºå•å˜é‡çš„çº¿æ€§å›å½’é—®é¢˜(Univariate Linear Regression), å¯ä»¥è¡¨ç°ä¸ºå¦‚ä¸‹å½¢å¼:\n$$ h_\\theta(x)=\\theta_1 x+\\theta_0$$\nå…¶ä¸­$h_\\theta$å¯ä»¥ç®€è®°ä¸º$h$\n\nå¯¹äºè®­ç»ƒæ•°æ®:\n\n- **A pair** $(x^{(i)} , y^{(i)} )$ is called a **training example**\n\n- The dataset that weâ€™ll be using to learnâ€”**a list of m training examples** $(x^{(i)},y^{(i)})\\space , (i=1,...,m)$ â€” is called a **training set**.\n\n\n## Cost Function\næŸå¤±å‡½æ•°æ˜¯ç”¨æ¥è¡¡é‡Hypothesis functionçš„ç²¾ç¡®åº¦çš„, æŸå¤±å‡½æ•°å¯ä»¥è¡¡é‡Hypothesisåœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šé¢å¹³å‡è¯¯å·®\n\nä¸‹é¢æ˜¯ä¸€ä¸ªåå«\"[å¹³æ–¹è¯¯å·®å‡½æ•°/Squared Error Function/Mean Squared Error](notes/2021/2021.8/Mean_Squared_Error_å‡æ–¹è¯¯å·®.md)\"çš„æŸå¤±å‡½æ•°:\n$$J\\left(\\theta_{0}, \\theta_{1}\\right)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(\\hat{y}^{(i)}-y^{(i)}\\right)^{2}=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$$\nåˆ†å¼€æ¥çœ‹, $J\\left(\\theta_{0}, \\theta_{1}\\right)$å®é™…ä¸Šæ˜¯$\\frac 1 2\\overline{x}$, $\\overline{x}$æ˜¯é¢„æµ‹å€¼ä¸çœŸå®å€¼è¯¯å·®çš„å¹³æ–¹\n\nLink:\n[Why_do_cost_functions_use_the_square_error](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md)\n\n### ç›´è§‚æ„Ÿå—\n[Part.4_Cost_Function_Intuition](notes/2021/2021.8/Part.4_Cost_Function_Intuition(ML_Andrew.Ng.).md)\n\n## æ¨å¹¿:å¤šé¡¹å¼å›å½’\n- Our hypothesis function need not be linear (a straight line) if that does not fit the data well.\n- We can **change the behavior or curve** of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.4_Cost_Function_IntuitionML_Andrew.Ng.":{"title":"Part.4_Cost_Function_Intuition(ML_Andrew.Ng.)","content":"# Cost Function Intuition: Linear Regression\n\n\u003cdiv align=\"right\"\u003e 2021-08-02\u003c/div\u003e\n\nTags: #MachineLearning #CostFunction #LinearRegression \n\n\n## 2-Dimension Intuition\né¦–å…ˆç®€åŒ–ä¸€ä¸‹æˆ‘ä»¬çš„é—®é¢˜, ç°åœ¨åªæœ‰ä¸‰ä¸ªæ•°æ®ç‚¹$(1,1),(2,2),(3,3)$, æˆ‘ä»¬çš„Hypothesis Function$:h=\\theta_1 x$ åªæœ‰ä¸€ä¸ªå‚æ•°$\\theta_1$è¡¨ç¤ºæ–œç‡, Cost Functionè¿˜æ˜¯:\n$$\nJ\\left(\\theta_{0}, \\theta_{1}\\right)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(\\hat{y}^{(i)}-y^{(i)}\\right)^{2}=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}\n$$\nåˆ™æˆ‘ä»¬å¤§æ¦‚å¯ä»¥æŠŠCost Functionçš„å˜åŒ–è¿‡ç¨‹è¡¨ç¤ºæˆè¿™æ ·: \n![](notes/2021/2021.7/assets/img_2022-10-15-1.gif)\nå¯ä»¥çœ‹å‡º, æ–œç‡ä¸º1çš„æ—¶å€™Cost Functionæœ‰æœ€å°å€¼1, æ­¤æ—¶Hypothesisæœ€ä¼˜.\n\n\n## 3-Dimension Intuition\nä¸‰ç»´çš„æƒ…å†µå³Costæœ‰ä¸¤ä¸ªå‚æ•°$\\theta_0, \\theta_1$, å¦‚æœ$z$è½´è¡¨ç¤ºCost Functionçš„å¤§å°é‚£ä¹ˆä¼šæ˜¯ä¸€ä¸ªç¢—è£…çš„æ›²é¢, è¡¨ç¤ºåœ¨ä¸€ä¸ªå¹³é¢é‡Œé¢å¯ä»¥ç”¨ç­‰é«˜çº¿å›¾(Contour Map)æ¥è¡¨ç¤º. \n![](notes/2021/2021.7/assets/img_2022-10-15-6.png)\næœ€ä¼˜çš„æƒ…å†µå³æ›²é¢çš„æœ€ä½å¤„\n![](notes/2021/2021.7/assets/img_2022-10-15-7.png)\n\n[å¯è§†åŒ–æŸå¤±å‡½æ•°çš„å›°éš¾](notes/2022/2022.2/å¯è§†åŒ–æŸå¤±å‡½æ•°çš„å›°éš¾.md)","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.5_Gradient_DescentML_Andrew.Ng.":{"title":"Part.5_Gradient_Descent(ML_Andrew.Ng.)","content":"# Gradient Descent\n\n\u003cdiv align=\"right\"\u003e 2021-08-02\u003c/div\u003e\n\nTags: #MachineLearning #GradientDescent \n\næ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§æœ€å°åŒ–æŸå¤±å‡½æ•°çš„æ ‡å‡†æ–¹æ³•\nSo we have our hypothesis function and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in the hypothesis function. That's where gradient descent comes in.\n\n## Intuition\n![](notes/2021/2021.7/assets/img_2022-10-15-8.png)\nè¿™ä¸ªæ›²é¢æ˜¯åœ¨CostFunctionç©ºé—´é‡Œé¢çš„, XYåæ ‡è¡¨ç¤ºHypothesisé‡Œé¢çš„å‚æ•°$\\theta_0,\\theta_1 \\cdots$\nCostFunctionä»£è¡¨Hypothesisä¸çœŸå®å€¼çš„åå·®, CostFunctionçš„ç›®æ ‡æ˜¯ä½¿è‡ªå·±çš„å€¼æœ€å°, å³Hypothesisä¸çœŸå®å€¼çš„åå·®æœ€å°.\næ›´æ–°å“ªä¸ªå‚æ•°å°±ç›¸å½“äºåœ¨é‚£ä¸ªå‚æ•°çš„æ–¹å‘ä¸Šèµ°ä¸€æ­¥.\n\n## Algorithm\n$$\n\\begin{array}{l}\n\\text {repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\\theta_{j}:=\\theta_{j}-\\alpha \\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}}   J\\left(\\theta_{0},\\cdots ,\\theta_{n}\\right) \u0026 \\text { (simultaneously update } \nj=0, \\cdots ,j=n)\n\\end{array}\\\\\n\\text { \\} }\n\\end{array}\n$$\n- é‡Œé¢çš„$:=$è¡¨ç¤º\"èµ‹å€¼\"\n\n## Learning Rate / å­¦ä¹ ç‡\n~~å³æ¯ä¸€æ­¥çš„é•¿åº¦~~\n- æ¯ä¸€æ­¥é•¿åº¦çš„æ¯”ä¾‹å¤§å°, ä¸Šæ–¹å…¬å¼é‡Œé¢çš„  $\\Large\\alpha$\n- ç›¸å½“äºä¸€ä¸ªäººè…¿çš„é•¿åº¦, **å¹¶ä¸èƒ½ç›´æ¥ç­‰åŒäºæ¯ä¸€æ­¥çš„é•¿åº¦**, å› ä¸ºæ¯ä¸€æ­¥çš„é•¿åº¦è¿˜å’Œåå¯¼æ•°çš„å¤§å°æœ‰å…³\n\t![|500](notes/2021/2021.7/assets/img_2022-10-15-9.png)\n### No need to decrease Learning Rate overtime\n![|300](notes/2021/2021.7/assets/img_2022-10-15-10.png)\n\nAs we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease Î± over time.\n\n### åˆç†è°ƒæ•´å­¦ä¹ ç‡\nè°ƒæ•´æ¯ä¸€æ­¥çš„å¤§å°æ¯”ä¾‹\n![](notes/2021/2021.7/assets/img_2022-10-15-11.png)\n![](notes/2021/2021.7/assets/img_2022-10-15-2.gif)\n![](notes/2021/2021.7/assets/img_2022-10-15-3.gif)\n### éœ€è¦åŒæ—¶èµ‹å€¼\n![](notes/2021/2021.7/assets/img_2022-10-15-12.png)\n- è¿™æ ·æ‰èƒ½å¤Ÿä¿è¯èµ°çš„æ–¹å‘æ˜¯æ¢¯åº¦æœ€å¤§çš„æ–¹å‘\n- å¦‚æœä¸€å‰ä¸€ååœ°èµ‹å€¼, é‚£ä¹ˆèµ°çš„è·¯çº¿æ˜¯è¿™æ ·ZigZagå½¢çŠ¶çš„, å¯èƒ½èƒ½å¤Ÿè¿ä½œ, ä½†æ˜¾ç„¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„è¿ä½œæ–¹å¼.\n\t![](notes/2021/2021.7/assets/img_2022-10-15-13.png)\n\t\n\t\n## Different Gradient Descent Methods\n[Different_Gradient_Descent_Methods](notes/2021/2021.8/Different_Gradient_Descent_Methods.md)\n\n\n## [Linear Regression \u0026 Gradient Descent](notes/2021/2021.8/Linear_Regression\u0026Gradient_Descent.md)\n[Linear_Regression\u0026Gradient_Descent](notes/2021/2021.8/Linear_Regression\u0026Gradient_Descent.md)\n\n[Relation_Between_Linear_Regression\u0026Gradient_Descent_æ¢¯åº¦ä¸‹é™å’Œçº¿æ€§å›å½’çš„å…³ç³»](notes/2021/2021.8/Relation_Between_Linear_Regression\u0026Gradient_Descent_æ¢¯åº¦ä¸‹é™å’Œçº¿æ€§å›å½’çš„å…³ç³».md)\n\n## [Logistic Regression \u0026 Gradient Descent](notes/2021/2021.8/Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.).md)\n[Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.)](notes/2021/2021.8/Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.).md)\n\n\n\n## [[notes/2021/2021.8/å‡¸ä¼˜åŒ–ä¸çº¿æ€§å›å½’é—®é¢˜]]\n\n[å‡¸ä¼˜åŒ–ä¸çº¿æ€§å›å½’é—®é¢˜](notes/2021/2021.8/å‡¸ä¼˜åŒ–ä¸çº¿æ€§å›å½’é—®é¢˜.md)\n\t","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.6_Linear_Algerba_ReviewML_Andrew.Ng.":{"title":"Part.6_Linear_Algerba_Review(ML_Andrew.Ng.)","content":"# Linear Algebra Review \n\n\u003cdiv align=\"right\"\u003e 2021-08-04\u003c/div\u003e\n\nTags: #Math #Math/LinearAlgebra\n\n- **Scalar**: æ ‡é‡, A physical quantity that is completely described by its magnitude.\n- Vectoræœ‰ä¸¤ç§Indexæ–¹å¼: 0-indexed \u0026 1-indexedå°±æ˜¯æŒ‡ç¬¬ä¸€ä¸ªå…ƒç´ åºå·æ˜¯0è¿˜æ˜¯1\n\n- ä¸€ä¸ªæŠŠæ•°æ®å¸¦å…¥å›å½’æ–¹ç¨‹çš„ä¸€ä¸ªçŸ©é˜µæŠ€å·§\n\t![](notes/2021/2021.7/assets/img_2022-10-15-14.png)\n- äº¤æ¢å¾‹: **Commutative Property**\n- ç»“åˆå¾‹: **Associative Property**\n- å•ä½çŸ©é˜µ: **Identity Matrix** \n\tè¡¨ç¤ºä¸º$I$ : Denoted $I$\n- é€†: **Inverse**\n- è½¬ç½®: **Transpose**\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.7_Feature_ScalingML_Andrew.Ng.":{"title":"Part.7_Feature_Scaling(ML_Andrew.Ng.)","content":"# Feature Scaling\n\n\u003cdiv align=\"right\"\u003e 2021-08-06\u003c/div\u003e\n\nTags: #MachineLearning #FeatureEngineering \n\n![](notes/2021/2021.7/assets/img_2022-10-15-15.png)[^2]\n\næ·±å…¥é˜…è¯»çš„é“¾æ¥:\nhttps://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n\n## When to Use\n- åœ¨æ¢¯åº¦ä¸‹é™çš„æ—¶å€™, ç¼©æ”¾æ•°æ®å¯ä»¥è®©æ¢¯åº¦å˜åŒ–æ›´å¹³æ»‘\n- ![](notes/2021/2021.7/assets/img_2022-10-15-16.png)\n\u003e If an algorithm uses gradient descent, then the difference in ranges of features will cause different step sizes for each feature. To ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features, we scale the data before feeding it to the model. Having features on a similar scale will help the gradient descent converge more quickly towards the minima.\n\u003e \n\u003e Specifically, in the case of Neural Networks Algorithms, feature scaling benefits optimization by:\n\u003e \n\u003e -   It makes the training faster\n\u003e -   It prevents the optimization from getting stuck in local optima\n\u003e -   It gives a better error surface shape\n\u003e -   Weight decay and Bayes optimization can be done more conveniently\n- åœ¨ä»¥è·ç¦»ä¸ºåŸºç¡€çš„ç®—æ³•é‡Œé¢, æ”¾ç¼©æ•°æ®å¯ä»¥è®©æ•°æ®åˆ†å¸ƒæ›´å‡åŒ€\n\u003e Distance-based algorithms like KNN, K-means, and SVM are most affected by the range of features. This is because behind the scenes they are using distances between data points to determine their similarity and hence perform the task at hand. Therefore, we scale our data before employing a distance-based algorithm so that all the features contribute equally to the result.\n- åœ¨ä¸»æˆåˆ†åˆ†æé‡Œé¢, æ”¾ç¼©æ•°æ®å¯ä»¥è®©å‡¸æ˜¾å‡ºæ•°æ®çš„\"å˜åŒ–\", (ä¸€ä¸ªæ•°é‡çº§å¾ˆå¤§çš„æ•°æ®å˜ä¸€ç‚¹ç‚¹\u003e\u003eä¸€ä¸ªæ•°é‡çº§å¾ˆå°çš„æ•°æ®å˜åŒ–å‡ å€)\n\u003e InÂ [PCA](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html) we are interested in the components that maximize the variance. If one component (e.g. age) varies less than another (e.g. salary) because of their respective scales, PCA might determine that the direction of maximal variance more closely corresponds with the â€˜salaryâ€™ axis, if those features are not scaled. As a change in the age of one year can be considered much more important than the change in salary of one euro, this is clearly incorrect.\n\n\n## Normalization å½’ä¸€åŒ–\n\n![](notes/2021/2021.7/assets/img_2022-10-15-17.png)\n\n$$x^\\prime= \\frac{x-x_{min}}{x_{max}-x_{min}}$$\n\n- å¯ä»¥è‡ªå·±è°ƒæ§æ•°æ®åˆ†å¸ƒçš„èŒƒå›´, æ¯”å¦‚ä½ æƒ³è®©æ•°æ®åˆ†å¸ƒåœ¨$[a,b]$èŒƒå›´å†…, å…¬å¼å˜ä¸º:\n$$x^{\\prime}=a+\\left(\\frac{x-\\min (x)}{\\max (x)-\\min (x)}\\right)(b-a)$$\n\n- å½’ä¸€åŒ–å¯¹ç¦»ç¾¤å€¼ååˆ†æ•æ„Ÿ\n\n- ä¼šç¼©å°å¾ˆå¤§çš„æ•°æ®, ä¼šæ”¹å˜æ•°é‡çº§\n## Standardization æ ‡å‡†åŒ–\n![Probability density function for the Normal distribtion|500](https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/1920px-Normal_Distribution_PDF.svg.png)\n- æ‹¿æ­£æ€åˆ†å¸ƒçš„æ•°æ®åšä¾‹å­: å°±ç›¸å½“äºæŠŠå…¶ä»–é¢œè‰²çš„æ›²çº¿éƒ½å˜æˆçº¢è‰²çš„é‚£æ¡æ ‡å‡†æ­£æ€æ›²çº¿\n\n$$x^\\prime= \\frac{x-\\mu}{\\sigma}$$\n$\\mu$æ˜¯å‡å€¼, $\\sigma$æ˜¯æ ‡å‡†å·®(æ–¹å·®çš„å¹³æ–¹æ ¹)\n\n- å¯¹ç¦»ç¾¤å€¼ä¸æ˜¯é‚£ä¹ˆæ•æ„Ÿ\n\n- æ ‡å‡†åŒ–ä¹Ÿæ”¹å˜æ•°é‡çº§, ä¼šå‡å»å‡å€¼\n\n### å¦‚ä½•é€‰æ‹©[^1]\n**Normalization** åœ¨æ•°æ®ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒçš„æ—¶å€™æ¯”è¾ƒé€‚ç”¨, åƒKNNè¿™ç§å¯¹æ•°æ®åˆ†å¸ƒæ²¡æœ‰è¦æ±‚çš„æ¨¡å‹æ›´é€‚ç”¨äºå½’ä¸€åŒ–\n\nåœ¨ç¥ç»ç½‘ç»œé‡Œé¢å¸¸å¸¸è¦æ±‚æ•°æ®åˆ†å¸ƒåœ¨0-1ä¹‹é—´, è¿™æ—¶å€™å½’ä¸€åŒ–å¿…ä¸å¯å°‘; å¦ä¸€ä¸ªä¾‹å­æ˜¯å›¾åƒå¤„ç†çš„æ—¶å€™å¸¸å¸¸ä¼šæŠŠæ•°æ®ç¼©å°åˆ°ä¸€ä¸ªèŒƒå›´(æ¯”å¦‚0-255), åœ¨è¿™æ—¶æ ‡å‡†åŒ–æ›´åŠ é€‚ç”¨. \n\n\n**Standardization**Â åœ¨æ•°æ®æ»¡è¶³æ­£æ€åˆ†å¸ƒçš„æ—¶å€™æ›´åŠ é€‚ç”¨, å¹¶ä¸”åœ¨æ”¾ç¼©çš„æ—¶å€™æ²¡æœ‰èŒƒå›´é™åˆ¶, (ä¸åƒå½’ä¸€åŒ–å¯ä»¥æ˜ç¡®çš„è§„å®šä¸€ä¸ªèŒƒå›´$[a,b]$)\n\nåœ¨èšç±»ä¸­, æ ‡å‡†åŒ–åœ¨æ¯”è¾ƒä¸åŒç‰¹å¾çš„ç›¸ä¼¼æ€§çš„æ—¶å€™å¾ˆå¥½ç”¨(why? #todo), å¦ä¸€ä¸ªä¾‹å­æ˜¯PCAçš„æ—¶å€™å¸¸å¸¸ç”¨æ ‡å‡†åŒ–æ¥çªå‡ºæ•°æ®åˆ†å¸ƒçš„å·®å¼‚åº¦, è€Œä¸æ˜¯ç”¨å½’ä¸€åŒ–æŠŠæœ€å¤§çš„å˜æˆä¸€. ^375f2a\n\n- æ€»ä¹‹: \n\t- Standardization é€‚ç”¨äº**æ­£æ€åˆ†å¸ƒ**çš„æ•°æ®, \n\t- Normalization é€‚ç”¨äº**éæ­£æ€åˆ†å¸ƒ**çš„æ•°æ®\n- Normalizationé‡Œé¢ç¦»ç¾¤å€¼å¯¹æ•°æ®çš„å½±å“æ˜¾è‘—\n- ä¸çŸ¥é“æ€ä¹ˆåŠå°±éƒ½è¯•è¯•, æ¯”è¾ƒå“ªä¸€ä¸ªæ•ˆæœæœ€å¥½\n\n\n## Feature Scaling \u0026 Regression\nåœ¨å¤šé¡¹å¼å›å½’é‡Œé¢, æ•°æ®æ”¾ç¼©å¾ˆé‡è¦, å› ä¸ºçº§æ•°å¢é•¿å¾ˆå¿«\n\n\n## Don't Confuse Regularization Normalization \u0026 Standardization\n - **Regularization:** æ­£åˆ™åŒ– \n - **Normalization:** å½’ä¸€åŒ–\n - **Standardization:** æ ‡å‡†åŒ–\n\n\n\n[^1]: https://www.atoti.io/when-to-perform-a-feature-scaling/\n[^2]:https://sebastianraschka.com/Articles/2014_about_feature_scaling.html ","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.8_Train_Gradient_DescentML_Andrew.Ng.":{"title":"Part.8_Train_Gradient_Descent(ML_Andrew.Ng.)","content":"# Train Gradient Descent\n\n\u003cdiv align=\"right\"\u003e 2021-08-06\u003c/div\u003e\n\nTags: #GradientDescent #MachineLearning \n\n## åˆ¤æ–­æ”¶æ•›(Convergence)çš„æ–¹æ³•\n\n- ç”»å‡ºCost Function - Iterationå›¾, å¹³ç¼“åæ”¶æ•›\n- ç›¸é‚»å‘¨æœŸå˜åŒ–å€¼å°äºä¸€ä¸ªå¾ˆå°çš„å€¼$\\Delta$\n\n## å¯»æ‰¾æ­£å¸¸çš„å­¦ä¹ ç‡\n- åªè¦å­¦ä¹ ç‡$\\alpha$è¶³å¤Ÿå°, æŸå¤±å‡½æ•°ä¸€å®šæ˜¯é€’å‡çš„(å¯ä»¥ä¸¥æ ¼è¯æ˜)\n- å¦‚æœå­¦ä¹ ç‡æ³¢åŠ¨æˆ–è€…é€’å¢, å¸¸å¸¸æ˜¯å› ä¸ºå­¦ä¹ ç‡è¿‡å¤§\n- å­¦ä¹ ç‡è¿‡å¤§ä¹Ÿæœ‰ä¸€å®šå‡ ç‡å¯¼è‡´æ”¶æ•›ç¼“æ…¢\n- å­¦ä¹ ç‡è¿‡å°ä¼šå¯¼è‡´æ”¶æ•›è¿‡æ…¢\n- åˆé€‚çš„æ–¹æ³•æ˜¯ç±»ä¼¼äºäºŒåˆ†æ³•çš„æ€è·¯, ç”¨ä¸€ç³»åˆ—çš„å€¼å»å°è¯•, \n\te.g. $0.001, 0.003, 0.006, 0.01\\cdots$\n\n","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Part.9_Normal_EquationML_Andrew.Ng.":{"title":"Part.9_Normal_Equation(ML_Andrew.Ng.)","content":"# Normal Equation\n\n\u003cdiv align=\"right\"\u003e 2021-08-14\u003c/div\u003e\n\nTags: #MachineLearning #NormalEquation #LinearRegression \n\n- Normal Equation æ˜¯è§£ **çº¿æ€§å›å½’(Linear Regression)** é—®é¢˜çš„ä¸€ç§ä»£æ•°æ–¹æ³•.\n\n## Definition\n\nThe value of $\\theta$ that minimizes $J(\\theta)$ can be given in closed form by the equation\n$$\n\\theta=\\left(X^{T} X\\right)^{-1} X^{T} \\vec{y}\n$$\n\nå…¶ä¸­\n$$\nX_{m\\times (n+1)}=\\left[\\begin{array}{c}\n-\\left(x^{(1)}\\right)^{T}- \\\\\n-\\left(x^{(2)}\\right)^{T}- \\\\\n\\vdots \\\\\n-\\left(x^{(m)}\\right)^{T}-\n\\end{array}\\right] .\n$$\n(å…¶ä¸­$x$æ˜¯$n+1$ç»´åˆ—å‘é‡)\n$$\n\\vec{y}_{m\\times 1}=\\left[\\begin{array}{c}\ny^{(1)} \\\\\ny^{(2)} \\\\\n\\vdots \\\\\ny^{(m)}\n\\end{array}\\right] .\n$$\n\n## Intuitive\n- è¿™å®é™…ä¸Šæ˜¯åœ¨æ±‚$X$çŸ©é˜µåˆ—ç©ºé—´:$\\mathrm{Col}(X)$ä¸­, æœ€æ¥è¿‘å‘é‡$\\vec{y}$çš„å‘é‡$X\\vec\\theta$(æŠ•å½±$\\mathrm{proj}_{\\mathrm{Col(}X\\mathrm )}(\\space \\vec y\\space )$[^3]), è¿™é‡Œ$\\theta$å¯ä»¥çœ‹ä½œæ˜¯è¿™ä¸ªæŠ•å½±åœ¨åˆ—ç©ºé—´é‡Œé¢çš„åæ ‡.\n- è¿™é‡Œçš„åˆ—å‘é‡å°±æ˜¯æ‰€æœ‰æ ·æœ¬é‡Œé¢çš„æ¯ä¸€ä¸ªå•ç‹¬çš„Featureæ„æˆçš„å‘é‡.\n- è¿™æ ·çœ‹æ¥, é—®é¢˜çš„æ±‚è§£å°±æ˜¯è¦åœ¨ç‰¹å¾æ„æˆçš„\"ç‰¹å¾ç©ºé—´\"é‡Œé¢æ‰¾åˆ°ä¸€ä¸ªç‚¹, è¿™ä¸ªç‚¹æœ€æ¥è¿‘çœŸå®å€¼$\\vec y$ (è¿™å…¶å®æ˜¯[Linear Regression](notes/2021/2021.8/Part.3_Linear_Regression(ML_Andrew.Ng.).md)çš„Intuition, Normal Equationæ–¹æ³•ä¿ƒä½¿æˆ‘ç”¨çº¿æ€§ä»£æ•°çš„è§’åº¦æ¥çœ‹å¾…è¿™ä¸ªé—®é¢˜)\n![](notes/2021/2021.7/assets/img_2022-10-15-18.png)[^2]\nä¸Šå›¾æ˜¯__çº¿æ€§ä»£æ•°åŠå…¶åº”ç”¨__æ­¤ä¹¦é‡Œé¢ä¸€ä¸ªå½¢è±¡çš„å›¾ä¾‹, å‚æ•°$\\hat x / \\theta$çš„ç»´æ•°ä¸ç‰¹å¾æ•°ç›¸åŒ(næˆ–è€…n+1), è€Œæ¯ä¸€ä¸ªç‰¹å¾çš„\"é•¿åº¦\"æ˜¯æ ·æœ¬æ•°m, çœŸå®å€¼çš„æ•°é‡ä¹Ÿæ˜¯m\n- æ³¨æ„åˆ—ç©ºé—´çš„ç»´æ•°å¾ˆå¯èƒ½ä¸æ˜¯$m$, ä½†æ˜¯çœŸå®å€¼å‘é‡$\\vec y$æ˜¯åœ¨$\\mathbb R_m$é‡Œé¢å–çš„, æ‰€ä»¥æˆ‘ä»¬å¸¸å¸¸éœ€è¦æ±‚ä¸€ä¸ªè¿‘ä¼¼è§£$X\\vec\\theta$\n\t- å¦‚æœåˆ—ç©ºé—´çš„ç»´æ•°å°±æ˜¯m, é‚£ä¹ˆæˆ‘ä»¬èƒ½å¤ŸæŠŠæŸå¤±å‡½æ•°é™ä¸º0, å³æ‹Ÿåˆæ›²çº¿ç»è¿‡æ‰€æœ‰æ ·æœ¬ç‚¹. [^4]\n\n\u003e å…·ä½“çš„æ•°å­¦çŸ¥è¯†å‚è§Linear Algebra and Its Applications by David C. Lay ç¬¬6ç« \n\n## æ¨å¯¼\nå‡è®¾è¦å¾—åˆ°$\\theta$, ä½¿$X\\theta$å°½å¯èƒ½é è¿‘$\\vec y$\n### é€šè¿‡å‘é‡ç©ºé—´æ¨å¯¼\n\u003e è¯¦ç»†æ¨å¯¼è§ä¸Šæ–¹æåŠçš„ä¹¦Linear Algebra and Its Applications by David C. Lay ç¬¬6ç« \n\nå¤§æ¦‚æ€è·¯:\n$X$ çš„åˆ—å‘é‡å‚ç›´äº$(\\vec y -\\mathrm {proj}_{Col(X)}\\space \\vec y)=(\\vec y-X\\theta)$, æ‰€ä»¥$X$çš„åˆ—ä¸$(\\vec y-X\\theta)$çš„å†…ç§¯ä¸º0, ä¹Ÿå°±ç›¸å½“äº$X^T$ä¸$(\\vec y-X\\theta)$çš„çŸ©é˜µç§¯ä¸º0 $\\Rightarrow X^T(\\vec y-X\\theta)=0 \\Rightarrow X^T\\vec y=X^TX\\theta$\n\nç„¶åå¦‚æœ$X$çš„åˆ—å‘é‡ç‹¬ç«‹, é‚£ä¹ˆ$X^TX$å¯é€†, é‚£ä¹ˆ$\\theta=(X^TX)^{-1}X^T\\vec y$\n\n### æ±‚å¯¼æ•°\n[Normal_Equation_Proof_2_Matrix_Method](notes/2021/2021.8/Normal_Equation_Proof_2_Matrix_Method.md)\n\n\n## å±€é™æ€§\n- é¦–å…ˆ, æ­£è§„æ–¹ç¨‹æ³•åšçš„åªæ˜¯å°½å¯èƒ½åœ°è®©æ‹Ÿåˆçš„æ›²çº¿ä¸æ ·æœ¬ç‚¹çš„å·®åˆ«æœ€å°, å³ä½¿æ›²çº¿é€šè¿‡æ‰€æœ‰çš„æ ·æœ¬ç‚¹ä¹Ÿä¸ä»£è¡¨æ¨¡å‹çš„é¢„æµ‹æ•ˆæœå¾ˆå¥½, å› ä¸ºè¿˜è¦è€ƒè™‘æ¨¡å‹é€‰å–çš„åˆç†æ€§(æ›²çº¿è¿˜æ˜¯ç›´çº¿, etc), æ•°æ®é‡Œé¢çš„å™ªå£°ç­‰ç­‰å› ç´ . è¿™æ ·çœ‹æ¥æ­£è§„æ–¹ç¨‹æ³•å…¶å®åªæ˜¯ä¸€ç§è§£æ–¹ç¨‹çš„æ–¹æ³•.\n\n- Normal Equationæ–¹æ³•è§£å†³çš„é—®é¢˜éƒ½å…·æœ‰è¿™æ ·çš„å½¢å¼: $$y=X\\beta+\\varepsilon$$(å…¶ä¸­$\\varepsilon$æ˜¯ä½™å·®å‘é‡, ç›¸å½“äºé¢„æµ‹å€¼ä¸çœŸå®å€¼çš„è¯¯å·®), è¿™æ ·çš„æ–¹ç¨‹ç§°ä¸º**çº¿æ€§æ¨¡å‹**.[^1] \n\n- çº¿æ€§æ¨¡å‹å¯ä»¥è¿›è¡Œç›´çº¿æ‹Ÿåˆä¹Ÿå¯ä»¥è¿›è¡Œæ›²çº¿æ‹Ÿåˆ, æ‰€æ±‚çš„æœ€ä¼˜è§£éƒ½æ˜¯æœ€å°äºŒä¹˜æ‹Ÿåˆ.\n\t- æ›²çº¿çš„ä¸€ä¸ªä¾‹å­:\n\n$$\t\\begin{aligned}\n\u0026\\left[\\begin{array}{c}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{n}\n\\end{array}\\right]=\\left[\\begin{array}{ccc}\n1 \u0026 x_{1} \u0026 x_{1}^{2} \\\\\n1 \u0026 x_{2} \u0026 x_{2}^{2} \\\\\n\\vdots \u0026 \\vdots \u0026 \\vdots \\\\\n1 \u0026 x_{n} \u0026 x_{n}^{2}\n\\end{array}\\right]\\left[\\begin{array}{c}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\beta_{2}\n\\end{array}\\right]+\\left[\\begin{array}{c}\n\\varepsilon_{1} \\\\\n\\varepsilon_{2} \\\\\n\\vdots \\\\\n\\varepsilon_{n}\n\\end{array}\\right]\\\\\n\u0026\\quad y\\quad=\\quad\\quad X \\quad \\quad\\quad \\quad \\beta\\quad+\\quad\\varepsilon\n\\end{aligned}$$\n\n- ä¸€èˆ¬çš„, ä¸€ä¸ªæœ‰ä¸¤ä¸ªç‹¬ç«‹å˜é‡$u,v$çš„çº¿æ€§æ¨¡å‹å¯ä»¥ç”¨ä»¥ä¸‹æ–¹ç¨‹æ¥é¢„æµ‹:\n$$\ny=\\beta_{0} f_{0}(u, v)+\\beta_{1} f_{1}(u, v)+\\cdots+\\beta_{k} f_{k}(u, v)\n$$\næ­¤å¤„, $f_{0}, \\cdots, f_{k}$ æ˜¯æŸç±»å·²çŸ¥å‡½æ•°, $\\beta_{0}, \\cdots, \\beta_{k}$ æ˜¯æœªçŸ¥æƒå€¼.\n\n## Normal Equation \u0026 Noninvertibility\nå› ä¸ºæ–¹ç¨‹æ˜¯$\\theta=\\left(X^{T} X\\right)^{-1} X^{T} \\vec{y}$ , åœ¨ä»¥ä¸‹ä¸¤ç§æƒ…å†µçš„æ—¶å€™, å¯èƒ½ä¼šå‡ºç°$(X^{T} X)$ä¸å¯é€†çš„æƒ…å†µ:\n- æœ‰å¤šä½™çš„ç‰¹å¾ / ç‰¹å¾ä¹‹é—´çº¿æ€§ç›¸å…³ $\\rightarrow$ åˆ é™¤å¤šäºç‰¹å¾å³å¯\n- ç‰¹å¾æ•°ç›®å¤§äºæ ·æœ¬æ•°ç›®: $n\u003em$, $\\rightarrow$ åˆ é™¤ä¸€äº›ç‰¹å¾æˆ–è€…åˆ©ç”¨\"æ­£åˆ™åŒ–Regularization\"\n- [Don't Confuse Regularization Normalization and Standardization](notes/2021/2021.8/Part.7_Feature_Scaling(ML_Andrew.Ng.).md#Don't%20Confuse%20Regularization%20Normalization%20Standardization)\n\nåœ¨Octaveè¯­è¨€é‡Œé¢ `pinv` (pseudo inverse) å¯ä»¥ç”¨äºæ±‚ä¸å¯é€†çŸ©é˜µçš„é€† (`inv` åªèƒ½ç”¨äºå¯é€†çŸ©é˜µ)\n\n## Normal Equation \u0026 Gradient Descent\n\nNormal Equationæ–¹æ³•åªèƒ½è§£å†³çº¿æ€§å›å½’é—®é¢˜(æˆ–è€…, æ›´ä¸€èˆ¬åœ°: å¤šé‡å›å½’çš„çº¿æ€§æ¨¡å‹[^1]), ç›¸æ¯”ä¹‹ä¸‹, æ¢¯åº¦ä¸‹é™èƒ½è§£å†³æ›´å¤šæœºå™¨å­¦ä¹ æ¨¡å‹çš„å‚æ•°é—®é¢˜\n\nä¸‹é¢æ˜¯å¯¹ä¸¤ä¸ªæ–¹æ³•çš„ä¸€ä¸ªæ¯”è¾ƒ:\n\n| Gradient Descent     |  Normal Equation    |\n| ---- | ---- |\n|  Need to choose alpha    |   No need to choose alpha   |\n| Needs many iterations     |   No need to iterate   |\n| $O(kn^2)$ | $O(n^3)$, need to calculate inverse of $X^TX$ |\n| Works well when n is large | Slow if n is very large |\n\n\nåœ¨æ­£è§„æ–¹ç¨‹æ³•é‡Œé¢, è®¡ç®—çŸ©é˜µçš„é€†çš„æ—¶é—´å¤æ‚åº¦æ˜¯$\\mathcal{O}\\left(n^{3}\\right) .$ æ‰€ä»¥åœ¨ç‰¹å¾æ•°é‡å¾ˆå¤§çš„æ—¶å€™, è¿™ä¸ªæ–¹æ³•çš„é€Ÿåº¦ä¼šå¾ˆæ…¢. åœ¨å®é™…åº”ç”¨ä¸­, å¦‚æœn \u003e 10,000 å°±éœ€è¦è€ƒè™‘ä½¿ç”¨æ¢¯åº¦ä¸‹é™è¿™ç§è¿­ä»£å½¢å¼æ¥æ±‚å‚æ•°çš„æœ€ä¼˜è§£äº†.\n\n### åœ¨åº”ç”¨çš„æ—¶å€™éœ€è¦æ³¨æ„çš„åœ°æ–¹\nåœ¨å®Œæˆä½œä¸šçš„æ—¶å€™, æˆ‘å‘ç°åˆ©ç”¨Normal Equation æ–¹æ³•å’Œ æ¢¯åº¦ä¸‹é™æ–¹æ³•æ‰€å¾—åˆ°çš„$\\theta$å€¼ä¸ä¸€æ ·:\n![](notes/2021/2021.7/assets/Pasted%20image%2020210819132727.png)![](notes/2021/2021.7/assets/Pasted%20image%2020210819132842.png)\n\nè¿™æ˜¯å› ä¸ºåœ¨æ¢¯åº¦ä¸‹é™é‡Œé¢æˆ‘ä»¬è¿ç”¨äº†Feature Scaling, è€Œåœ¨Normal Equationæ–¹æ³•é‡Œé¢, æˆ‘ä»¬ä¸éœ€è¦å¯¹å˜é‡è¿›è¡Œæ”¾ç¼©.\n\næœ€åä»–ä»¬çš„é¢„æµ‹ç»“æœæ˜¯å®Œå…¨ä¸€æ ·çš„(è€ƒè™‘è¯¯å·®):\n![](notes/2021/2021.7/assets/Pasted%20image%2020210819133047.png)![](notes/2021/2021.7/assets/Pasted%20image%2020210819133106.png)\n\n\n[^1]: Linear Algebra and Its Applications (4th Edition) by David C. Lay ç¬¬6.6èŠ‚, æœ€å°äºŒä¹˜æ³•åœ¨çº¿æ€§æ¨¡å‹ä¸­çš„åº”ç”¨:\n\n\t\u003e ä¾‹4è¡¨æ˜ï¼Œå¤šé‡å›å½’çš„çº¿æ€§æ¨¡å‹å’Œå‰é¢ä¾‹é¢˜ä¸­çš„ç®€å•å›å½’æ¨¡å‹å…·æœ‰åŒæ ·çš„æŠ½è±¡å½¢å¼ï¼Œçº¿æ€§ä»£æ•°ä¸ºæˆ‘ä»¬ç†è§£æ‰€æœ‰çº¿æ€§æ¨¡å‹å†…åœ¨çš„ä¸€èˆ¬åŸç†æä¾›äº†å¸®åŠ©ï¼Œå®šä¹‰åªè¦$X$é€‚å½“ï¼Œå…³äº$Î²$çš„æ ‡å‡†æ–¹ç¨‹å°±å…·æœ‰ç›¸åŒçš„çŸ©é˜µå½¢å¼ï¼Œä¸ç®¡åŒ…å«å¤šå°‘å˜é‡ï¼Œè¿™æ ·ï¼Œå¯¹$X^TX$å¯é€†çš„ä»»ä½•çº¿æ€§æ¨¡å‹ï¼Œæœ€å°äºŒä¹˜ä¸­çš„$\\hat Î²$æ€»å¯ç”±$\\left(X^{T} X\\right)^{-1} X^{T} \\vec{y}$ è®¡ç®—å¾—åˆ°.\n\t\n[^2]: Linear Algebra and Its Applications (4th Edition) by David C. Lay ç¬¬6.5èŠ‚\n[^3]: æ¬§æ°è·ç¦»æœ€å°, å³[æœ€å°äºŒä¹˜æ³•](notes/2021/2021.8/Mean_Squared_Error_å‡æ–¹è¯¯å·®.md#^0a7c67), ä¹Ÿå³[å‡æ–¹è¯¯å·®](notes/2021/2021.8/Mean_Squared_Error_å‡æ–¹è¯¯å·®.md)ä½œä¸ºæŸå¤±å‡½æ•°è¦æœ€å°åŒ–\n[^4]: è¿™æ—¶å¯èƒ½æœ‰ä¸€è§£æˆ–è€…å¤šè§£, è”ç³»çº¿æ€§ä»£æ•°é‡Œé¢çº¿æ€§æ–¹ç¨‹ç»„çš„çŸ¥è¯†, å¦‚æœæœ‰å¤šè§£, é‚£ä¹ˆè¯´æ˜åˆ—å‘é‡å¹¶ä¸æ˜¯ç‹¬ç«‹çš„, è¯´æ˜ç‰¹å¾ä¸æ˜¯ç‹¬ç«‹çš„. å…·ä½“å‚è§ Linear Algebra and Its Applications (4th Edition) by David C. Lay ç¬¬6.5èŠ‚","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Relation_Between_Linear_RegressionGradient_Descent_%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%92%8C%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%85%B3%E7%B3%BB":{"title":"Relation_Between_Linear_Regression\u0026Gradient_Descent_æ¢¯åº¦ä¸‹é™å’Œçº¿æ€§å›å½’çš„å…³ç³»","content":"# æ¢¯åº¦ä¸‹é™æ³•å’Œçº¿æ€§å›å½’çš„å…³ç³»\n\n\u003cdiv align=\"right\"\u003e 2021-08-05\u003c/div\u003e\n\nTags: #MachineLearning #LinearRegression  #GradientDescent\n\n\n```mermaid\ngraph TD\n\tA([æ¢¯åº¦ä¸‹é™])--\u003eB([æ¢¯åº¦ä¸‹é™+å¹³æ–¹æŸå¤±])--\u003eC([æ¢¯åº¦ä¸‹é™+å¹³æ–¹æŸå¤±+çº¿æ€§å›å½’])\n\n```\n\n\n\n- æ¢¯åº¦ä¸‹é™æ³•å…¬å¼\n$$\n\\begin{array}{l}\n\\text { repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\\theta_{j}:=\\theta_{j}-\\alpha \\frac{\\Large\\partial}{\\Large\\partial \\Large\\theta_{j}}   J\\left(\\theta_{0},\\cdots ,\\theta_{n}\\right) \u0026 \\text { (simultaneously update } \nj=0, \\cdots ,j=n)\n\\end{array}\\\\\n\\text { \\} }\n\\end{array}\n$$\n\n---\n- æ¢¯åº¦ä¸‹é™ + Cost Function=å¹³æ–¹æŸå¤±\n$$J\\left(\\theta_{0},\\cdots ,\\theta_{n}\\right)=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(\\hat{y}^{(i)}-y^{(i)}\\right)^{2}=\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$$\n\næ‰€ä»¥\n\n$$\n\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta) \n=\\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) f_{j}(x^{(i)}) \n$$\n\nå…¬å¼å˜ä¸º:\n$$\n\\begin{array}{l}\n\\text { repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\u0026\\theta_{j}:=\\theta_{j}-\\alpha \\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) f_{j}(x^{(i)}) \n\\end{array}\\\\\n\\text { \\} }\n\\\\\\\\ \\text { (simultaneously update } \nj=0, \\cdots ,j=n)\n\\end{array}\n$$\n---\n- æ¢¯åº¦ä¸‹é™ + å¹³æ–¹æŸå¤± + Hypothesis Function=çº¿æ€§å›å½’\n\n\tå¯¹äºæˆ‘ä»¬çš„çº¿æ€§å›å½’é—®é¢˜, $f_j(x^{(i)})=x_j^{(i)}$\n\t\n\tå…¬å¼å˜æˆäº†: ^fe416b\n\n$$\n\\begin{array}{l}\n\\text { repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\u0026\\theta_{j}:=\\theta_{j}-\\alpha \\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) x_j^{(i)} \n\\end{array}\\\\\n\\text { \\} }\n\\\\\\\\ \\text { (simultaneously update } \nj=0, \\cdots ,j=n)\n\\end{array}\n$$","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Sigmoid-Definition":{"title":"Sigmoid-Definition","content":"# Sigmoid\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #Sigmoid\n\nSigmoid means resembling the lower-case Greek letter sigma (uppercase Î£, lowercase Ïƒ, lowercase in word-final position Ï‚) or the Latin letter S[^1]\n\n\n[^1]: Wikipedia","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Sigmoid_Function":{"title":"Sigmoid_Function","content":"# Sigmoid Function\n\n\u003cdiv align=\"right\"\u003e 2021-08-19\u003c/div\u003e\n\nTags: #Sigmoid #MachineLearning #ActivationFunction\n\n## ä»€ä¹ˆæ˜¯Sigmoidå‡½æ•°?\n- [Sigmoidçš„å«ä¹‰æ˜¯](notes/2021/2021.8/Sigmoid-Definition.md)åƒSå‹çš„, æ‰€ä»¥Sigmoidå‡½æ•°ä¾¿æ˜¯å…·æœ‰Så½¢çŠ¶çš„ä¸€ç±»å‡½æ•°.\n\n- Sigmoidå‡½æ•°æŠŠæ•´ä¸ªå®æ•°åŸŸä¸Šçš„ä»»æ„æ•°æ˜ å°„åˆ°ä¸€ä¸ªæœ‰é™çš„åŒºé—´é‡Œé¢: $(0,1)$\n- åœ¨åˆ†ç±»é—®é¢˜é‡Œé¢,  it's useful for transforming an arbitrary-valued function into a function better suited for classification.\n\n## Logistic Function\n- é€»è¾‘æ–¯è’‚å‡½æ•°æ˜¯Sigmoidå‡½æ•°ä¹‹ä¸€.\n$$S(x)=\\frac{1}{1+e^{-x}}=\\frac{e^{x}}{e^{x}+1}=1-S(-x)$$\n\n![](notes/2021/2021.7/assets/img_2022-10-15-25.png)\nä¸‹å›¾ä¸­è“è‰²æ›²çº¿ä¸ºå¯¼å‡½æ•°\n$$\\frac {d}{dx}S(x)=\\frac{e^{-x}}{(1+e^{-x})^2}\n=\\left(\\frac{1}{1+e^{-x}}\\right)\\left(1-\\frac{1}{1+e^{-x}}\\right)=S(x)\\left(1-S(x)\\right)$$\n![](notes/2021/2021.7/assets/Logistic.svg)\n\n![](notes/2021/2021.8/assets/derivative%20Sigmoid.png)","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.8/Why_do_cost_functions_use_the_square_error":{"title":"Why_do_cost_functions_use_the_square_error","content":"# Why do cost functions use the square error?\n\n\u003cdiv align=\"right\"\u003e 2021-07-31\u003c/div\u003e\n\nTags: #MachineLearning #CostFunction #MeanSquareError\n\nReference: [StackExchange: why-do-cost-functions-use-the-square-error?](https://datascience.stackexchange.com/questions/10188/why-do-cost-functions-use-the-square-error?newreg=50bfd55599464f059209bd22b6898660)\n\nStackExchangeä¸Šé¢ä¸€ä¸ªå…³äºå‡æ–¹å·®çš„ä¸€ä¸ªå¾ˆå¥½çš„è§£é‡Š, ç¿»è¯‘å¦‚ä¸‹:\n\n## Question:\n\u003eI'm just getting started with some machine learning, and until now I have been dealing with linear regression over one variable.\nI have learnt that there is a hypothesis, which is:\n$h_{\\theta}(x)=\\theta_{0}+\\theta_{1} x$\nTo find out good values for the parameters $\\theta_{0}$ and $\\theta_{1}$ we want to minimize the difference between the calculated result and the actual result of our test data. So we subtract\n$h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}$\nfor all $i$ from 1 to $m$. Hence we calculate the sum over this difference and then calculate the average by multiplying the sum by $\\frac{1}{m}$. So far, so good. This would result in:\n$\\frac{1}{m} \\sum_{i=1}^{m} \\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)$\nBut this is not what has been suggested. Instead the course suggests to take the square value of the difference, and to multiply by $\\frac{1}{2 m}$. So the formula is:\n$\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$\nWhy is that? Why do we use the square function here, and why do we multiply by $\\frac{1}{2 m}$ instead of $\\frac{1}{m} ?$\n\n\næˆ‘æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ çš„åˆå­¦è€…, ç°åœ¨æ­£åœ¨å­¦ä¹ ä¸€å…ƒçº¿æ€§å›å½’é—®é¢˜.\næˆ‘å­¦åˆ°äº†ä¸‹é¢è¿™ä¸ªå‡è®¾å‡½æ•°:\n$h_{\\theta}(x)=\\theta_{0}+\\theta_{1} x$\nä¸ºäº†æ‰¾åˆ°å‚æ•°$\\theta_{0}$ å’Œ $\\theta_{1}$ çš„æœ€ä¼˜å€¼, æˆ‘ä»¬éœ€è¦ä½¿é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„è¯¯å·®æœ€å°, æ‰€ä»¥æˆ‘ä»¬æŠŠä»–ä»¬ç›¸å‡: $h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}$  å…¶ä¸­ $i$ å–é $1$ åˆ° $m$.\nç„¶åæˆ‘ä»¬è®¡ç®—æ‰€æœ‰è¯¯å·®çš„å’Œ, å¹¶ä¸”ä¹˜ä¸Š $\\frac{1}{m}$å¾—åˆ°è¯¯å·®çš„å¹³å‡æ•°, å¾—åˆ°:\n$\\frac{1}{m} \\sum_{i=1}^{m} \\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)$\nä½†æ˜¯è¿™å¹¶ä¸æ˜¯æ­£ç¡®çš„å…¬å¼, è¯¾ç¨‹é‡Œé¢è¯´æˆ‘ä»¬éœ€è¦æŠŠè¯¯å·®è¿›è¡Œå¹³æ–¹, ç„¶åä¹˜ä»¥$\\frac{1}{2 m}$, æ‰€ä»¥åº”è¯¥æ˜¯\n$\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}$\nä¸ºä»€ä¹ˆè¦è¿™æ ·åš? ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å°†è¯¯å·®è¿›è¡Œå¹³æ–¹, å¹¶ä¸”ä¹˜ä¸Š$\\frac{1}{2 m}$ è€Œä¸æ˜¯ $\\frac{1}{m} ?$\n\n## Answer:\nYour loss function would not work because it incentivizes setting $\\theta_{1}$ to any finite value and $\\theta_{0}$ to $-\\infty$.\n\nLet's call $r(x, y)=\\frac{1}{m} \\sum_{i=1}^{m} \\left(h_{\\theta}\\left(x^{(i)}\\right)-y\\right)$ the residual for $h$.\n\nYour goal is to make $r$ as close to zero as possible, not just minimize it. A high negative value is just as bad as a high positive value.\n\nEDIT: You can counter this by artificially limiting the parameter space $\\boldsymbol{\\Theta}$ (e.g. you want $\\left|\\theta_{0}\\right|\u003c\\mathbf{1 0}$ ). In this case, the optimal parameters would lie on certain points on the boundary of the parameter space. See [https://math.stackexchange.com/q/896388/12467](https://math.stackexchange.com/q/896388/12467). This is not what you want.\n\n## Why do we use the square loss\nThe squared error forces $h(x)$ and $y$ to match. It's minimized at $\\boldsymbol{u}=v$, if possible, and is always $\\geq 0$, because it's a square of the real number $\\boldsymbol{u}-\\boldsymbol{v}$.\n\n$|\\boldsymbol{u}-\\boldsymbol{v}|$ would also work for the above purpose, as would $(\\boldsymbol{u}-\\boldsymbol{v})^{2 n}$, with $\\boldsymbol{n}$ some positive integer. The first of these is actually used (it's called the $\\ell_{1}$ loss; you might also come across the $\\ell_{2}$ loss, which is another name for squared error).\n\nSo, why is the squared loss better than these? This is a *deep* question related to the link between Frequentist and Bayesian inference. In short, the squared error relates to **Gaussian Noise**.\n\nIf your data does not fit all points exactly, i.e. $h(x)-y$ is not zero for some point no matter what $\\theta$ you choose (as will always happen in practice), that might be because of noise. In any complex system there will be many small **independent** causes for the difference between your model $h$ and reality $y$ : measurement error, environmental factors etc. By the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) $(\\mathrm{CLT})$, the total noise would be distributed Normally, i.e. according to the **Gaussian distribution**. We want to pick the best fit $\\boldsymbol{\\theta}$ taking this noise distribution into account. Assume $\\boldsymbol{R}=\\boldsymbol{h}(\\boldsymbol{X})-\\boldsymbol{Y}$, the part of $\\mathbf{y}$ that your model cannot explain, follows the Gaussian distribution $\\mathcal{N}(\\mu, \\sigma)$. We're using capitals because we're talking about random variables now.\n\nThe Gaussian distribution has two parameters, mean $\\mu=\\mathbb{E}[R]=\\frac{1}{m} \\sum_{i}\\left(h_{\\theta}\\left(X^{(i)}\\right)-Y^{(i))}\\right)$ and variance $\\sigma^{2}=E\\left[R^{2}\\right]=\\frac{1}{m} \\sum_{i}\\left(h_{\\theta}\\left(X^{(i)}\\right)-Y^{(i))}\\right)^{2}$. See [here](https://math.stackexchange.com/questions/518281/how-to-derive-the-mean-and-variance-of-a-gaussian-random-variable) to understand these terms better.\n\n- Consider $\\boldsymbol{\\mu}$, it is the systematic error of our measurements. Use $\\boldsymbol{h}^{\\prime}(\\boldsymbol{x})=\\boldsymbol{h}(\\boldsymbol{x})-\\boldsymbol{\\mu}$ to correct for systematic error, so that $\\boldsymbol{\\mu}^{\\prime}=\\mathbb{E}\\left[\\boldsymbol{R}^{\\prime}\\right]=\\mathbf{0}$ (exercise for the reader). Nothing else to do here.\n\n- $\\sigma$ represents the random error, also called noise. Once we've taken care of the systematic noise component as in the previous point, the best predictor is obtained when $\\boldsymbol{\\sigma}^{2}=\\frac{1}{m} \\sum_{i}\\left(h_{\\theta}\\left(X^{(i)}\\right)-Y^{(i))}\\right)^{2}$ is minimized. Put another way, the best predictor is the one with the tightest distribution (smallest variance) around the predicted value, i.e. smallest variance. **Minimizing the the least squared loss is the same thing as minimizing the variance**! That explains why the least squared loss works for a wide range of problems. The underlying noise is very often Gaussian, because of the $\\mathrm{CLT}$, and minimizing the squared error turns out to be the *right* thing to do!\n\nTo simultaneously take both the mean and variance into account, we include a _bias_ term in our classifier (to handle systematic error Î¼), then minimize the square loss.\n\nFollowup questions:\n- **Least squares loss = Gaussian error. Does every other loss function also correspond to some noise distribution?** Yes. For example, the $\\ell_{1}$ loss (minimizing absolute value instead of squared error) corresponds to the [Laplace distribution](https://en.wikipedia.org/wiki/Laplace_distribution) (Look at the formula for the PDF in the infobox -- it's just the Gaussian with  $|\\boldsymbol{x}-\\boldsymbol{\\mu}|$ instead of $(\\boldsymbol{x}-\\boldsymbol{\\mu})^{2}$). A popular loss for probability distributions is the [KL-divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence). -The Gaussian distribution is very well motivated because of the **Central Limit Theorem**, which we discussed earlier. When is the Laplace distribution the right noise model? There are some circumstances where it comes about naturally, but it's more commonly as a regularizer [to enforce **sparsity**](https://math.stackexchange.com/q/1904767/12467): the $\\ell_{1}$ loss is the _least convex_ among all convex losses.\n ^b7e1c9\n\t-  As [Jan](https://datascience.stackexchange.com/users/14904/jan-van-der-vegt) mentions in the comments, the minimizer of _squared_ deviations is the mean and the minimizer of the sum of **absolute** deviations is the **median**. Why would we want to find the median of the residuals instead of the mean? Unlike the mean, the median isn't thrown off by one very large outlier. So, the â„“1 loss is used for increased robustness. Sometimes a combination of the two is used.\n- **Are there situations where we minimize both the Mean and Variance?** Yes. Look up [Bias-Variance Trade-off](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff). Here, we are looking at a set of classifiers $h_\\theta \\in H$ and asking which among them is best. If we ask which _set_ of classifiers is the best for a problem, minimizing both the bias and variance becomes important. It turns out that there is always a trade-off between them and we use **regularization** to achieve a compromise. ^91cd90\n\n## Regarding the $\\frac1 2$ term\n\nThe 1/2 does not matter and actually, neither does the $m$ - they're both constants. The optimal value of $\\theta$ would remain the same in both cases.\n\n- The expression for the gradient becomes prettier with the $\\frac1 2$, because the 2 from the square term cancels out.\n\t- When writing code or algorithms, we're usually concerned more with the gradient, so it helps to keep it concise. You can check progress just by checking the norm of the gradient. The loss function itself is sometimes omitted from code because it is used only for validation of the final answer.\n- The $m$ is useful if you solve this problem with gradient descent. Then your gradient becomes the average of $m$ terms instead of a sum, so its' scale does not change when you add more data points.\n\t- I've run into this problem before: I test code with a small number of points and it works fine, but when you test it with the entire dataset there is loss of precision and sometimes over/under-flows, i.e. your gradient becomes `nan` or `inf`. To avoid that, just normalize w.r.t. number of data points.\n- These aesthetic decisions are used here to maintain consistency with future equations where you'll add **regularization** terms. If you include the $m$, the regularization parameter Î» will not depend on the dataset size $m$ and it will be more interpretable across problems.\n\n\n---\nä½ çš„æŸå¤±å‡½æ•°å¹¶ä¸æ­£ç¡®, å› ä¸ºå®ƒå€¾å‘äºå°†$\\theta_{1}$ è®¾ç½®ä¸ºä»»æ„æœ‰é™å€¼,å¹¶ä¸”å°† $\\theta_{0}$ è®¾ç½®ä¸º $-\\infty$.\n\næˆ‘ä»¬ä¸å¦¨æŠŠ$r(x, y)=\\frac{1}{m} \\sum_{i=1}^{m} \\left(h_{\\theta}\\left(x^{(i)}\\right)-y\\right)$ ç§°ä¸º $h$çš„æ®‹å·®.\n\nä½ çš„ç›®æ ‡æ˜¯è®©$r$ **å°½å¯èƒ½åœ°æ¥è¿‘0**, **ä¸æ˜¯è®©å…¶å°½å¯èƒ½åœ°å°**. ä¸€ä¸ª(ç»å¯¹å€¼)å¾ˆå¤§çš„è´Ÿæ•°å’Œä¸€ä¸ªå¾ˆå¤§çš„æ•´æ•°ä¸€æ ·ç³Ÿç³•.\n\n**é™„**: ä½ ä¹Ÿå¯ä»¥äººä¸ºé™åˆ¶å‚æ•°çš„å˜åŒ–èŒƒå›´ $\\boldsymbol{\\Theta}$ (æ¯”å¦‚: ä»¤$\\left|\\theta_{0}\\right|\u003c\\mathbf{1 0}$ ). æ­¤æ—¶,ä½ çš„æ–¹æ³•å¾—åˆ°çš„æœ€ä¼˜å‚æ•°ä¼šæ˜¯å¾ˆé è¿‘è¾¹ç•Œçš„ä¸€ä¸ªå€¼. (å‚è§ [https://math.stackexchange.com/q/896388/12467](https://math.stackexchange.com/q/896388/12467)). è¿™å¹¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ç»“æœ.\n\n## ä¸ºä»€ä¹ˆè¦ä½¿ç”¨å¹³æ–¹è¯¯å·®\nå¹³æ–¹è¯¯å·®ä¼šè®© $h(x)$ é è¿‘ $y$. å®ƒåœ¨ $\\boldsymbol{u}=v$çš„æ—¶å€™å–å¾—æœ€å°å€¼,  å¹¶ä¸”å› ä¸ºå®ƒæ˜¯å®æ•° $\\boldsymbol{u}-\\boldsymbol{v}$çš„å¹³æ–¹, å®ƒå§‹ç»ˆ$\\geq 0$.\n\n$|\\boldsymbol{u}-\\boldsymbol{v}|$ ä¹Ÿæœ‰ä¸€æ ·çš„æ•ˆæœ,  æ­£å¦‚$(\\boldsymbol{u}-\\boldsymbol{v})^{2 n}$,  ($\\boldsymbol{n}$ æ˜¯ä»»æ„æ­£æ•°)ä¹Ÿä¸€æ ·. ç»å¯¹å€¼è¯¯å·®å…¶å®åœ¨å®é™…é—®é¢˜ä¸­ä¹Ÿç”¨åˆ°äº† (ç§°ä¸º $\\ell_{1}$ è¯¯å·®; ä½ æœ‰æ—¶ä¹Ÿä¼šçœ‹åˆ° $\\ell_{2}$ è¯¯å·®, è¿™æ˜¯å¹³æ–¹è¯¯å·®çš„å¦ä¸€ç§ç§°å‘¼).\n\næ‰€ä»¥ä¸ºä»€ä¹ˆå¹³æ–¹è¯¯å·®æ¯”å®ƒä»¬éƒ½å¥½? è¿™ä¸ªé—®é¢˜å…¶å®ååˆ†æ·±å…¥, å®ƒæ¶‰åŠåˆ°äº†é¢‘ç‡å­¦æ´¾æ¨æ–­[^1]å’Œè´å¶æ–¯æ¨æ–­[^2]ä¹‹é—´çš„è”ç³». ç®€è€Œè¨€ä¹‹, å¹³æ–¹è¯¯å·®å…¶å®å’Œ**é«˜æ–¯å™ªå£°**æœ‰å…³. [^3]\n\nå¦‚æœä½ çš„é¢„æµ‹å€¼å’ŒçœŸå®å€¼æ€»æ˜¯å¯¹ä¸ä¸Š, ä¹Ÿå°±æ˜¯æ— è®º$\\theta$é€‰ä»€ä¹ˆå€¼, æ€»æœ‰ä¸€äº›ç‚¹$h(x)-y$ ä¸ä¸ºé›¶(è¿™å¾ˆå¸¸è§). é‚£ä¹ˆå¾ˆå¯èƒ½ä½ çš„æ•°æ®æœ‰å™ªå£°. åœ¨ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿä¸­, è®¸å¤šå¾®å°ä½†æ˜¯**ç›¸äº’ç‹¬ç«‹**çš„å› ç´ ä¼šä½¿ $h$ å’ŒçœŸå®å€¼ $y$ä¸ä¸€æ · : æ¯”å¦‚æµ‹é‡è¯¯å·®, ç¯å¢ƒå› ç´ ç­‰ç­‰. æ ¹æ®[ä¸­å¿ƒæé™å®šç†](https://en.wikipedia.org/wiki/Central_limit_theorem)  Central Limit Theorem$(\\mathrm{CLT})$ , æ•´ä½“ä¸Šè¿™äº›å™ªå£°ä¼šå‘ˆæ­£æ€åˆ†å¸ƒ, ä¹Ÿå°±æ˜¯è¯´, å®ƒä»¬æœä» **é«˜æ–¯åˆ†å¸ƒ**(ä¹Ÿç§°æ­£æ€åˆ†å¸ƒ). æˆ‘ä»¬åœ¨é€‰å– $\\boldsymbol{\\theta}$ çš„æ—¶å€™, ä¹Ÿéœ€è¦å°½å¯èƒ½åœ°è€ƒè™‘åˆ°è¿™äº›å› ç´ . å‡è®¾ $\\boldsymbol{R}=\\boldsymbol{h}(\\boldsymbol{X})-\\boldsymbol{Y}$, å…¶ä¸­$\\mathbf{y}$çš„æœ‰ä¸€éƒ¨åˆ†æ˜¯ä½ çš„æ¨¡å‹æ— æ³•è§£é‡Šçš„å™ªå£°, æœä»é«˜æ–¯åˆ†å¸ƒ$\\mathcal{N}(\\mu, \\sigma)$. (æˆ‘ä»¬ä¹‹æ‰€ä»¥ä½¿ç”¨å¤§å†™å­—æ¯, æ˜¯å› ä¸ºå®ƒä»¬éƒ½ä»£è¡¨éšæœºå˜é‡)\n\né«˜æ–¯åˆ†å¸ƒåŒ…å«ä¸¤ä¸ªå˜é‡: æœŸæœ›å€¼$\\mu=\\mathbb{E}[R]=\\frac{1}{m} \\sum_{i} h_{\\theta}\\left(X^{(i)}\\right)-Y^{(i))}$ å’Œæ–¹å·® $\\sigma^{2}=E\\left[R^{2}\\right]=\\frac{1}{m} \\sum_{i}\\left(h_{\\theta}\\left(X^{(i)}\\right)-Y^{(i))}\\right)^{2}$. å¦‚æœä½ æƒ³è¦äº†è§£æ›´å¤š,å¯ä»¥å‚è€ƒ [è¿™ä¸ªé“¾æ¥](https://math.stackexchange.com/questions/518281/how-to-derive-the-mean-and-variance-of-a-gaussian-random-variable) .\n\n- å¯¹äº $\\boldsymbol{\\mu}$, å®ƒè¡¨ç¤ºæˆ‘ä»¬æµ‹é‡çš„ç³»ç»Ÿè¯¯å·®. æˆ‘ä»¬å¯ä»¥åˆ©ç”¨$\\boldsymbol{h}^{\\prime}(\\boldsymbol{x})=\\boldsymbol{h}(\\boldsymbol{x})-\\boldsymbol{\\mu}$ æ¥ä¿®æ­£ç³»ç»Ÿè¯¯å·®, æ‰€ä»¥ $\\boldsymbol{\\mu}^{\\prime}=\\mathbb{E}\\left[\\boldsymbol{R}^{\\prime}\\right]=\\mathbf{0}$ (ä½ å¯ä»¥è¯•ä¸€è¯•). è¿™æ ·æˆ‘ä»¬ä¾¿å·²ç»ä¿®æ­£äº†ç³»ç»Ÿè¯¯å·®.\n\n- $\\sigma$ ä»£è¡¨ç³»ç»Ÿçš„éšæœºè¯¯å·®, ä¹Ÿç§°ä½œ*å™ªå£°*. åœ¨ä¿®æ­£äº†ç³»ç»Ÿè¯¯å·®ä¹‹å, æœ€å¥½çš„é¢„æµ‹ç»“æœåœ¨$\\boldsymbol{\\sigma}^{2}=\\frac{1}{m} \\sum_{i}\\left(h_{\\theta}\\left(X^{(i)}\\right)-Y^{(i))}\\right)^{2}$ æœ€å°çš„æ—¶å€™å–å¾—. æ¢å¥è¯è¯´, æœ€å¥½çš„é¢„æµ‹ç»“æœåœ¨é¢„æµ‹å€¼å‘¨å›´æœ‰ç€æœ€ç´§å¯†çš„åˆ†å¸ƒ (æœ€å°çš„æ–¹å·®) . **å–å¹³æ–¹è¯¯å·®æœ€å°å€¼çš„è¿‡ç¨‹å°±æ˜¯å–æ–¹å·®æœ€å°å€¼çš„è¿‡ç¨‹**! è¿™ä¹Ÿæ˜¯æœ€å°äºŒä¹˜æ³•[^4]é€‚ç”¨é¢å¦‚æ­¤ä¹‹å¹¿çš„åŸå› . ä¸€ä¸ªç³»ç»Ÿé‡Œé¢éšè—çš„å™ªå£°å¸¸å¸¸æ˜¯æˆæ­£æ€åˆ†å¸ƒçš„, æ ¹æ®ä¸­å¿ƒæé™å®šç†, æˆ‘ä»¬éœ€è¦ä½¿å¹³æ–¹è¯¯å·®æœ€å°åŒ–!\n\nä¸ºäº†åŒæ—¶è€ƒè™‘æ•°å­¦æœŸæœ›å’Œæ–¹å·®, æˆ‘ä»¬åœ¨åˆ¤åˆ«å™¨é‡Œé¢å¼•å…¥äº†ä¸€ä¸ª*åç½®* (ä¸ºäº†ä¿®æ­£ç³»ç»Ÿè¯¯å·®Î¼), ç„¶åæœ€å°åŒ–å¹³æ–¹è¯¯å·®.\n\nè¿›ä¸€æ­¥çš„é—®é¢˜:\n- **æœ€å°äºŒä¹˜æ³• å¯¹åº” é«˜æ–¯è¯¯å·®. å…¶ä»–ç±»å‹çš„æŸå¤±å‡½æ•°ä¹Ÿæœ‰å¯¹åº”çš„è¯¯å·®åˆ†å¸ƒå—?** \n\tæ˜¯çš„. æ¯”å¦‚ $\\ell_{1}$ è¯¯å·® (ä½¿ç»å¯¹å€¼ä¹‹å’Œæœ€å°è€Œä¸æ˜¯å¹³æ–¹è¯¯å·®æœ€å°) å¯¹åº”ç€ [æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒ(Laplace distribution)](https://en.wikipedia.org/wiki/Laplace_distribution) (æ³¨æ„è§‚å¯Ÿä¸€ä¸‹æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•° -- ç›¸å½“äºæŠŠé«˜æ–¯åˆ†å¸ƒ $(\\boldsymbol{x}-\\boldsymbol{\\mu})^{2}$  çš„æ¢æˆ $|\\boldsymbol{x}-\\boldsymbol{\\mu}|$).[^5] å¦ä¸€ä¸ªå¸¸è§çš„æŸå¤±å‡½æ•°å¯¹åº”çš„è¯¯å·®åˆ†å¸ƒæ˜¯ [KL-æ•£åº¦ï¼ˆç›¸å¯¹ç†µï¼‰](notes/2022/2022.2/KL_Divergence-KLæ•£åº¦.md). æˆ‘ä»¬ä¹‹å‰æåˆ°è¿‡ï¼Œå› ä¸ºä¸­å¿ƒæé™å®šç†ï¼Œé«˜æ–¯åˆ†å¸ƒéå¸¸å¸¸è§. é‚£ä¹ˆæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒåˆåœ¨ä»€ä¹ˆæ—¶å€™é€‚ç”¨å‘¢? çš„ç¡®æœ‰çš„é—®é¢˜ç¬¦åˆæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒ, ä½†æ˜¯æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒæ›´å¸¸è¢«ç”¨äº\"æ­£åˆ™åŒ–\"æ¥[ä¿è¯**ç¨€ç–æ€§(Sparsity)**](https://math.stackexchange.com/q/1904767/12467):  $\\ell_{1}$ æŸå¤±æ˜¯æ‰€æœ‰å‡¸æŸå¤±å‡½æ•°é‡Œé¢å‡¸èµ·æœ€å°çš„. ^269677\n\t- æ­£å¦‚Janåœ¨è¯„è®ºé‡Œé¢æåˆ°çš„ä¸€æ ·, **å¹³å‡å€¼**ä½¿**å¹³æ–¹è¯¯å·®**æœ€å°, è€Œ**ä¸­ä½æ•°**ä½¿**ç»å¯¹è¯¯å·®**æœ€å°, ä¸ºä»€ä¹ˆ($\\ell_{1}$æŸå¤±ä¸­)æˆ‘ä»¬è¦å»æ‰¾æ®‹å·®çš„ä¸­ä½æ•°è€Œä¸æ˜¯å‡å€¼å‘¢? è¿™æ˜¯å› ä¸ºä¸åƒå¹³å‡å€¼, ä¸­ä½æ•°ä¸ä¼šè¢«å¾ˆå¤§çš„ç¦»ç¾¤å€¼å¹²æ‰°. æ‰€ä»¥$\\ell_{1}$æŸå¤±è¢«ç”¨æ¥å¢åŠ é²æ£’æ€§, æœ‰æ—¶ä¹Ÿä¼šç»¼åˆåˆ©ç”¨ä¸¤è€….\n\t- é™„: ç­”æ¡ˆä¸‹æ–¹çš„è¯„è®º:\n\t\t- æŠ±æ­‰å†é—®ä¸€ä¸‹, ä¸ºä»€ä¹ˆä¸ç”¨ç»å¯¹å€¼è€Œæ˜¯ç”¨å¹³æ–¹è¯¯å·®? â€“ Alexander Suraphel Sep 5 '17 at 16:42\n\t\t- ç»å¯¹è¯¯å·®ä¹Ÿå¯ä»¥, ä½†æ˜¯ä½ å°±æ˜¯åœ¨æ‰¾ä¸­ä½æ•°è€Œä¸æ˜¯å¹³å‡å€¼äº†, ä½ å¯ä»¥ç”¨ä¸€å°ç»„æ•°æ®æ¥è¯•ä¸€è¯•, è§‚å¯Ÿä¸åŒä¼°è®¡å€¼å¯¹äºä¸¤ä¸ªæŸå¤±å‡½æ•°çš„å½±å“ - Jan van der Vegt Oct 26 '17 at 10:58\n\n- **æœ‰æ²¡æœ‰åŒæ—¶æœ€å°åŒ–æ•°å­¦æœŸæœ›å’Œæ–¹å·®çš„æ–¹æ³•?** \n\tæœ‰. å‚è§ [åå·®-æ–¹å·®æƒè¡¡_Bias-Variance Trade-off](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff). æ¯”æ–¹è¯´æˆ‘ä»¬éœ€è¦ä»ä¸€å †åˆ†ç±»å™¨$h_\\theta \\in H$ é‡Œé¢é€‰å‡ºæœ€å¥½çš„åˆ†ç±»å™¨.  å¦‚æœæˆ‘ä»¬éœ€è¦æ‰¾å‡º*ä¸€ç»„*æœ€å¥½çš„åˆ†ç±»å™¨, é‚£ä¹ˆå°±éœ€è¦åŒæ—¶æœ€å°åŒ–åå·®(Bias, é¢„æœŸæœŸæœ›å’ŒçœŸå®å€¼çš„å·®è·) å’Œæ–¹å·®. å…¶å®ç°å®ä¸­æ€»æ˜¯éœ€è¦åœ¨è¿™ä¸¤ä¸ªé‡ä¹‹é—´åšå‡ºå–èˆçš„, è€Œè¿™ä¸ªå–èˆçš„è¿‡ç¨‹å¸¸å¸¸é€šè¿‡**æ­£åˆ™åŒ–**æ¥å®ç°.\n\n## å…³äºæŸå¤±å‡½æ•°é‡Œé¢çš„$\\frac1 2$ \n\nå…¶å®è¿™ä¸ª 1/2 å¹¶ä¸é‡è¦,  $m$ ä¹Ÿæ˜¯ - ä»–ä»¬éƒ½æ˜¯å¸¸æ•°.  $\\theta$ çš„æœ€ä¼˜å€¼ä¸å®ƒä»¬æ— å…³.\n\n- åŠ ä¸Š $\\frac1 2$ä¼šè®©æ¢¯åº¦çš„è¡¨è¾¾å¼æ›´å¥½çœ‹, [å› ä¸ºå¹³æ–¹é¡¹çš„2è¢«çº¦æ‰äº†](notes/2021/2021.8/Linear_Regression\u0026Gradient_Descent.md#^021e6f).\n\t- åœ¨è®¾è®¡ç®—æ³•å’Œå†™ä»£ç çš„æ—¶å€™, æˆ‘ä»¬é€šå¸¸æ›´å…³æ³¨æ¢¯åº¦, æ‰€ä»¥è®©æ¢¯åº¦çš„è¡¨è¾¾å¼æ›´ç®€æ´æ˜¯å¾ˆæœ‰ç”¨çš„, ä½ å¯ä»¥é€šè¿‡æ£€æŸ¥æ¢¯åº¦çš„èŒƒæ•°æ¥æ£€æŸ¥è¡¨è¾¾å¼, è€Œåœ¨ä»£ç ä¸­æŸå¤±å‡½æ•°æœ‰æ—¶ä¼šè¢«çœç•¥æ‰, å› ä¸ºå®ƒåªæœ‰åœ¨æ ¸éªŒæœ€ç»ˆç­”æ¡ˆçš„æ—¶å€™æ‰ä¼šè¢«ç”¨åˆ°.\n- åœ¨ä½ ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•çš„æ—¶å€™, $m$ æ˜¯å¾ˆæœ‰ç”¨çš„. è¿™æ ·ä½ çš„æ¢¯åº¦å°±æ˜¯$m$é¡¹çš„å¹³å‡å€¼, è€Œä¸æ˜¯ä»–ä»¬çš„å’Œ, è¿™æ ·åœ¨ä½ æ”¹å˜æ•°æ®é‡çš„æ—¶å€™, æ¢¯åº¦çš„æ•°é‡çº§ä¸ä¼šæ”¹å˜. \n\t- æˆ‘é‡åˆ°è¿‡è¿™æ ·çš„é—®é¢˜: åœ¨å°‘é‡çš„æ•°æ®ä¸Šé¢ä»£ç è¿è¡Œçš„å¾ˆå¥½, ä½†æ˜¯å½“æˆ‘ç”¨æ•´ä¸ªæ•°æ®é›†æ¥æµ‹è¯•çš„æ—¶å€™å°±å‡ºç°äº†ç²¾åº¦çš„æŸå¤±, æœ‰æ—¶å€™ç”šè‡³ä¼šå‡ºç°ä¸Š/ä¸‹æº¢, ä¹Ÿå°±æ˜¯è¯´, æ¢¯åº¦å˜æˆäº†`nan` æˆ–è€… `inf`. åªè¦ç”¨æ•°æ®é¡¹çš„ä¸ªæ•°$m$æ¥è§„æ ¼åŒ–æ•°æ®å³å¯\n- è¿™å…¶ä¸­ä¹Ÿæœ‰å®¡ç¾çš„å› ç´ åœ¨, å¦‚æœå°†æ¥å¯èƒ½æ·»åŠ æ›´å¤šçš„å…¬å¼, æ­¤ä¸¾å¯ä»¥ä¿æŒ\"ä¸€è‡´æ€§\", å› ä¸ºè¿™æ ·å¦‚æœå°†æ¥çš„å…¬å¼é‡Œé¢åŒ…å«**æ­£åˆ™åŒ–**çš„éƒ¨åˆ†, é‚£ä¹ˆæ­£åˆ™åŒ–çš„å‚æ•°Î»å°†ä¸ä¾èµ–äºæ•°æ®é›†å¤§å°$m$, è¿™æ ·æ›´æœ‰åˆ©äºä¸åŒè§„æ ¼é—®é¢˜ä¹‹é—´çš„ç»Ÿä¸€.\n\n\n[^1]: https://en.wikipedia.org/wiki/Frequentist_inference\n[^2]: https://en.wikipedia.org/wiki/Bayesian_inference\n[^3]: https://en.wikipedia.org/wiki/Gaussian_noise\n[^4]: åœ¨é«˜ä¸­å­¦ä¹ çš„æ—¶å€™å¹¶æ²¡æœ‰è®²è§£æœ€å°äºŒä¹˜æ³•åå­—çš„å«ä¹‰, ç°åœ¨çœ‹æ¥, å¯ä»¥ç†è§£æˆ\"å–æœ€å°çš„å¹³æ–¹è¯¯å·®çš„æ–¹æ³•\"\n[^5]: [Related_Post](notes/2021/2021.8/æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒä¸é«˜æ–¯åˆ†å¸ƒçš„è”ç³»_Relation_of_Laplace_distribution%20_and_Gaussian_distribution.md)","lastmodified":"2023-11-19T19:19:34.210468736Z","tags":null},"/notes/2021/2021.9/%E6%AD%A3%E5%88%99%E9%A1%B9%E4%B8%8D%E5%BD%B1%E5%93%8D%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%87%B8%E6%80%A7":{"title":"æ­£åˆ™é¡¹ä¸å½±å“çº¿æ€§å›å½’æŸå¤±å‡½æ•°çš„å‡¸æ€§","content":"# æ­£åˆ™é¡¹ä¸å½±å“çº¿æ€§å›å½’æŸå¤±å‡½æ•°çš„å‡¸æ€§\n\n\u003cdiv align=\"right\"\u003e 2021-09-10\u003c/div\u003e\n\nTags: #MachineLearning #Regularization #GradientDescent #LinearRegression #ConvexOptimization \n\n\n- **Question:** åŠ ä¸Šæ­£åˆ™é¡¹ä»¥åå‡½æ•°è¿˜æ˜¯å‡¸çš„å—? æ¢¯åº¦ä¸‹é™è¿˜é€‚ç”¨å—?\n- è¿˜æ˜¯é€‚ç”¨çš„, è¯æ˜å¦‚ä¸‹\n\n## é¦–å…ˆ, å¦‚ä½•è¯æ˜ä¸€ä¸ªå‡½æ•°ä¸ºå‡¸å‡½æ•°?\nå¦‚æœ$f$æ˜¯äºŒé˜¶å¯å¾®çš„ï¼Œé‚£ä¹ˆå¦‚æœ$f$çš„å®šä¹‰åŸŸæ˜¯å‡¸é›†ï¼Œå¹¶ä¸”$\\forall x\\in dom(f), \\nabla^2 f(x)\\geqslant0$ï¼Œé‚£ä¹ˆ$f$ å°±æ˜¯ä¸€ä¸ªå‡¸å‡½æ•°.[^1]\n- ä¸¥æ ¼å‡¸å‡½æ•°åˆ™è¦æ±‚äºŒé˜¶å¯¼æ•°æ’å¤§äºé›¶\n- $dom(f)$æ„æŒ‡å‡½æ•°$f$çš„å®šä¹‰åŸŸ(Domian)\n\n## æˆ‘ä»¬é¦–å…ˆè¯æ˜æ²¡æœ‰æ­£åˆ™é¡¹çš„$J(\\theta)$æ˜¯å‡¸çš„\n$$\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta) \n\n\u0026=\\frac{1}{2 m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial \\theta_{j}} \\left(h_{\\theta}(x)-y\\right)^{2} \\\\\n\n\u0026=\\frac{1}{2 m} \\sum_{i=1}^{m} 2 \\left(h_{\\theta}(x)-y\\right) \\cdot \\frac{\\partial}{\\partial \\theta_{j}}\\left(h_{\\theta}(x)-y\\right) \\\\\n\n\u0026=\\frac{1}{ m} \\sum_{i=1}^{m} \\left(h_{\\theta}(x)-y\\right) x_j \\\\\n\\end{aligned}$$\n\n$$\\begin{aligned}\n\\frac{\\partial^2}{\\partial \\theta_{j}^2} J(\\theta) \n\n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}\\left(\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta)\\right) \\\\\n\n\u0026=\\frac{1}{ m} \\sum_{i=1}^{m}\\frac{\\partial}{\\partial \\theta_{j}}  \\left(h_{\\theta}(x)-y\\right) x_j \\\\\n\n\u0026=\\frac{1}{ m} \\sum_{i=1}^{m}x_j^2 \\\\\n\\end{aligned}$$\næ˜¾ç„¶æ˜¯å‡¸çš„.\n\n## ç„¶ååŠ ä¸Šæ­£åˆ™é¡¹\n$$\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta) \n\n\u0026=\\frac{1}{2 m} \\left[\\sum_{i=1}^{m} \\frac{\\partial}{\\partial \\theta_{j}} \\left(h_{\\theta}(x)-y\\right)^{2} \n+\\lambda \\frac{\\partial}{\\partial \\theta_{j}} \\sum_{i=1}^{n} \\theta_{i}^{2}\\right]\\\\\n\n\u0026=\\frac{1}{2 m}\\left[ \\sum_{i=1}^{m} 2 \\left(h_{\\theta}(x)-y\\right) x_j+2\\lambda\\theta_{j}\\right]\\\\\n\n\u0026=\\lambda\\theta_{j}+\\frac{1}{ m} \\sum_{i=1}^{m} \\left(h_{\\theta}(x)-y\\right) x_j \\\\\n\\end{aligned}$$\n\n$$\\begin{aligned}\n\\frac{\\partial^2}{\\partial \\theta_{j}^2} J(\\theta) \n\n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}\\left(\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta)\\right) \\\\\n\n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}\\left(\\lambda\\theta_{j}+\\frac{1}{ m} \\sum_{i=1}^{m} \\left(h_{\\theta}(x)-y\\right) x_j\\right) \\\\\n\n\u0026=\\lambda+\\frac1{m} \\sum_{i=1}^m x_j^2\n\\end{aligned}$$\nå½“ç„¶åœ¨$\\lambda\u003e0$çš„æ—¶å€™ä¸Šå¼æ’å¤§äºé›¶, æ ¹æ®ä¸Šé¢çš„å®šç†, æŸå¤±å‡½æ•°ä¸€å®šæ˜¯å‡¸å‡½æ•°, è¯æ¯•.\n\n\n[^1]:æ›´è¯¦ç»†çš„æ¨å¯¼è¯¦è§çŸ¥ä¹æ–‡ç« : https://zhuanlan.zhihu.com/p/210252556 ","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2021/2021.9/%E6%AD%A3%E5%88%99%E9%A1%B9%E4%B8%8D%E5%BD%B1%E5%93%8DLogistic%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%87%B8%E6%80%A7":{"title":"æ­£åˆ™é¡¹ä¸å½±å“Logisticå›å½’æŸå¤±å‡½æ•°å‡¸æ€§","content":"# æ­£åˆ™é¡¹ä¸å½±å“Logisticå›å½’æŸå¤±å‡½æ•°å‡¸æ€§\n\n\u003cdiv align=\"right\"\u003e 2021-09-11\u003c/div\u003e\n\nTags: #MachineLearning #LogisticRegression #Regularization #ConvexOptimization #CostFunction \n\n## é¦–å…ˆ, æ²¡æœ‰åŠ æ­£åˆ™é¡¹çš„äºŒé˜¶å¯¼æ•°å¦‚ä¸‹\n![äºŒé˜¶å¯¼æ•°](notes/2021/2021.9/è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°.md#äºŒé˜¶å¯¼æ•°)\n\n\n## é‚£ä¹ˆåªéœ€è¦è®¡ç®—æ­£åˆ™é¡¹çš„äºŒé˜¶å¯¼æ•°\n$$\\begin{align}\nJ(\\theta)\u0026=P(\\theta)+\\frac\\lambda{2m}\\sum^n_{i=1}\\theta_i^2\n\\end{align}$$\n\n$$\\begin{aligned}\n\\frac{\\partial^2}{\\partial \\theta_{j}^2}\n\\left(\\frac\\lambda{2m}\\sum^n_{i=1}\\theta_i^2\\right)\u0026=\n\\frac{\\lambda}{m}\\frac{\\partial}{\\partial \\theta_{j}} \\theta_{j}\\\\\n\u0026=\\frac{\\lambda}{m}\u003e0\n\\end{aligned}$$\næ‰€ä»¥æŸå¤±å‡½æ•°è¿˜æ˜¯å‡¸çš„\n","lastmodified":"2023-11-19T19:19:34.222468932Z","tags":null},"/notes/2021/2021.9/%E6%AD%A3%E5%88%99%E9%A1%B9%E4%BC%9A%E6%B6%88%E9%99%A4%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E6%B3%95%E5%8F%AF%E8%83%BD%E7%9A%84%E4%B8%8D%E5%8F%AF%E9%80%86%E6%80%A7":{"title":"æ­£åˆ™é¡¹ä¼šæ¶ˆé™¤æ­£è§„æ–¹ç¨‹æ³•å¯èƒ½çš„ä¸å¯é€†æ€§","content":"# Normal Equation Non-invertibility \u0026 Regularization\n\n\u003cdiv align=\"right\"\u003e 2021-09-10\u003c/div\u003e\n\nTags: #NormalEquation  #Regularization \n\n\n![](notes/2021/2021.9/Part.19_Regularized_Linear_Regression(ML_Andrew.Ng.).md#^72311a)\n\n$(X^{T} X+\\lambda \\cdot L)$çš„å†…éƒ¨å¦‚ä¸‹å›¾æ‰€ç¤º: \n![](notes/2021/2021.9/assets/NormalEquationRegualrization.svg)\næœ€å…³é”®çš„ä½ç½®å°±æ˜¯æœ€å·¦ä¸Šè§’çš„é‚£ä¸ªåœ°æ–¹, å¦‚æœé‚£ä¸ªä½ç½®ä¸ä¸º0 (æˆ–è€…ç¬¬ä¸€è¡Œ/åˆ—ä¸ŠæŸä¸ªä½ç½®ä¸ä¸ºé›¶, ä¹Ÿå¯ä»¥ç§»è¿‡å»), é‚£ä¹ˆå®¹æ˜“çŸ¥é“è¿™ä¸ªçŸ©é˜µä¸€å®šå¯é€†(æ»¡ç§©), å› ä¸ºLå°±æ˜¯å•ä½çŸ©é˜µé™¤å»ç¬¬ä¸€ä¸ª1.\n![](notes/2021/2021.9/assets/NormalEquationRegualrization2.svg)\n\nå¦‚æœä¸Šé¢ç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—å…ƒç´ å…¨éƒ¨ä¸ºé›¶, é‚£ä¹ˆä¸€å®šæ˜¯å› ä¸ºç¬¬ä¸€ä¸ªç‰¹å¾($\\theta_0$å¯¹åº”çš„ç‰¹å¾)æ„æˆçš„å‘é‡ä¸ºé›¶å‘é‡(Xé‡Œé¢é»„è‰²çš„éƒ¨åˆ†), ä½†æ˜¯å¦‚æœæ˜¯è¿™æ ·, å°†è¿™ä¸€åˆ—ä¸å…¶ä»–ç‰¹å¾äº¤æ¢, ä¾¿å¯åœ¨ä¹˜ç§¯çŸ©é˜µçš„ç¬¬ä¸€è¡Œ/åˆ—å¾—åˆ°éé›¶çš„å…ƒç´ (å› ä¸ºä¸å¯èƒ½æœ‰ä¸¤ä¸ªç‰¹å¾éƒ½æ˜¯é›¶å‘é‡, å¦‚æœæœ‰, é‚£ä¹ˆä¾¿æ˜¯å¤šä½™çš„å‘é‡, åˆ é™¤ä¾¿å¯(emmè¿™æ ·ä¸€æƒ³å¥½åƒé›¶å‘é‡æœ¬æ¥å°±æ˜¯å¤šä½™çš„))\nä»è€Œå¾—çŸ¥æœ€åçš„çŸ©é˜µåŠ å’Œä¸€å®šæ˜¯æ»¡ç§©çš„, è¯æ¯•.","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2021/2021.9/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83_%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_Normal_Distribution-Gaussian_Distribution":{"title":"æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution","content":"# æ­£æ€åˆ†å¸ƒ\n\n\u003cdiv align=\"right\"\u003e 2021-09-16\u003c/div\u003e\n\nTags: #Math/Statistics\n\n## æ¦‚ç‡å¯†åº¦å‡½æ•°\næ­£æ€åˆ†å¸ƒ, æ¦‚ç‡å¯†åº¦å‡½æ•°:\n$$f(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{\\Large -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}}$$\nor\n$$f(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}\\right)$$\n\n## é‡è¦æ€§è´¨\n- Mean $(\\mu)$ and standard deviation $(\\sigma)$\n$$\n\\begin{aligned}\n\u0026\\mu=E(X)=\\int_{-\\infty}^{\\infty} x p(x) d x \\\\\n\u0026\\sigma^{2}=E\\left\\{(X-\\mu)^{2}\\right\\}=\\int_{-\\infty}^{\\infty}(x-\\mu)^{2} p(x) d x\n\\end{aligned}\n$$\n\n- Probability within any particular number of standard deviations of $\\mu$\n$$\n\\begin{aligned}\np\\{\\mu-k \\sigma \\leq x \\leq \\mu+k \\sigma\\} \u0026=\\int_{\\mu-k \\sigma}^{\\mu+k \\sigma} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left[-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right] d x \\\\\n\u0026=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-k}^{k} \\exp \\left[-\\frac{y^{2}}{2}\\right] d y\n\\end{aligned}\n$$\n\n- çº¿æ€§å˜æ¢å: \nå¦‚æœ $X \\sim N\\left(\\mu,\\sigma^{2}\\right)$ ä¸” $a, b$æ˜¯å®æ•°, é‚£ä¹ˆ\n$$a X+b \\sim N\\left(a \\mu+b,(a \\sigma)^{2}\\right)$$\n\n- æ­£æ€åˆ†å¸ƒçš„å’Œè¿˜æ˜¯æ­£æ€åˆ†å¸ƒ[^1]\n$$\\begin{aligned}\n\u0026X \\sim N\\left(\\mu_{X}, \\sigma_{X}^{2}\\right) \\\\\n\u0026Y \\sim N\\left(\\mu_{Y}, \\sigma_{Y}^{2}\\right) \\\\\n\u0026Z=X+Y\n\\end{aligned}$$\nåˆ™\n$$Z \\sim N\\left(\\mu_{X}+\\mu_{Y}, \\sigma_{X}^{2}+\\sigma_{Y}^{2}\\right)$$\n\n## è®°å¿†å…¬å¼\n- æ³¨æ„$\\sigma$åœ¨æ ¹å·å¤–é¢\n- æŒ‡æ•°æ˜¯è´Ÿçš„($x=\\mu$çš„æ—¶å€™ç­‰äº0, åŒæ—¶å–å¾—æœ€å¤§å€¼)\n\n\n## ä¸æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒçš„è”ç³»\n\n[æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒä¸é«˜æ–¯åˆ†å¸ƒçš„è”ç³»_Relation_of_Laplace_distribution _and_Gaussian_distribution](notes/2021/2021.8/æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒä¸é«˜æ–¯åˆ†å¸ƒçš„è”ç³»_Relation_of_Laplace_distribution%20_and_Gaussian_distribution.md)\n\n## Higher Dimensions\n$$\\begin{aligned}\n\u0026p\\{x\\}=\\frac{1}{(\\sqrt{2 \\pi})^{n / 2}|C|^{1 / 2}} \\exp \\left[-\\frac{1}{2}(x-\\mu)^{T} C^{-1}(x-\\mu)\\right] \\\\\n\u0026x=\\left[\\begin{array}{c}\nx_{1} \\\\\n\\cdots \\\\\nx_{n}\n\\end{array}\\right] \\quad \\mu=\\left[\\begin{array}{c}\n\\mu_{1} \\\\\n\\cdots \\\\\n\\mu_{n}\n\\end{array}\\right] \\quad C=\\left[\\begin{array}{ccc}\n\\sigma_{11}^{2} \u0026 \\ldots \u0026 \\sigma_{1 n}^{2} \\\\\n\\cdots \u0026 \u0026 \\ldots \\\\\n\\sigma_{m 1}^{2} \u0026 \\ldots \u0026 \\sigma_{m n}^{2}\n\\end{array}\\right]\n\\end{aligned}$$\n\n\n[^1]: [Sum of normally distributed random variables - Wikipedia](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables)","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2021/2021.9/%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83-IID":{"title":"ç‹¬ç«‹åŒåˆ†å¸ƒ-IID","content":"# ç‹¬ç«‹åŒåˆ†å¸ƒ Independent and identically distributed\n\n\u003cdiv align=\"right\"\u003e 2021-09-16\u003c/div\u003e\n\nTags: #Math/Statistics\n\n## å®šä¹‰\n- åœ¨æ¦‚ç‡è®ºä¸ç»Ÿè®¡å­¦ä¸­ï¼Œç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆè‹±è¯­ï¼š**Independent and identically distributed**ï¼Œæˆ–ç§°ç‹¬ç«‹åŒåˆ†é…ï¼Œç¼©å†™ä¸º**iid**ã€ **i.i.d.**ã€**IID**ï¼‰æ˜¯æŒ‡ä¸€ç»„éšæœºå˜é‡ä¸­æ¯ä¸ªå˜é‡çš„æ¦‚ç‡åˆ†å¸ƒéƒ½ç›¸åŒï¼Œä¸”è¿™äº›éšæœºå˜é‡äº’ç›¸ç‹¬ç«‹.\n\n\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2021/2021.9/%E8%AF%81%E6%98%8ELogistic%E5%9B%9E%E5%BD%92%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%98%AF%E5%87%B8%E5%87%BD%E6%95%B0":{"title":"è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°","content":"# è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°\n\n\u003cdiv align=\"right\"\u003e 2021-09-11\u003c/div\u003e\n\nTags: #MachineLearning #LogisticRegression #ConvexOptimization #CostFunction \n\n![é¦–å…ˆ å¦‚ä½•è¯æ˜ä¸€ä¸ªå‡½æ•°ä¸ºå‡¸å‡½æ•°](notes/2021/2021.9/æ­£åˆ™é¡¹ä¸å½±å“çº¿æ€§å›å½’æŸå¤±å‡½æ•°çš„å‡¸æ€§.md#é¦–å…ˆ%20å¦‚ä½•è¯æ˜ä¸€ä¸ªå‡½æ•°ä¸ºå‡¸å‡½æ•°)\n\n## è¯æ˜\n### åŸå‡½æ•°\n[Part.13_Cost_Function-Logistic_Regression(ML_Andrew.Ng.)](notes/2021/2021.8/Part.13_Cost_Function-Logistic_Regression(ML_Andrew.Ng.).md)\n$$\\begin{aligned}\nh\u0026=g(X \\theta) \\\\\nJ(\\theta)\u0026=-\\frac{1}{m} \\cdot\\left[y^{T} \\log (h)+(1-y)^{T} \\log (1-h)\\right]\n\\end{aligned}$$\n### ä¸€é˜¶å¯¼æ•°\nåœ¨æ¢¯åº¦ä¸‹é™é‡Œé¢æˆ‘ä»¬å·²ç»æ±‚å‡ºäº†ä¸€é˜¶å¯¼æ•°äº†:\n![æ¨å¯¼](notes/2021/2021.8/Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.).md#æ¨å¯¼)\n\n### äºŒé˜¶å¯¼æ•°\n$$h(x)=g\\left(\\theta^Tx\\right) $$\n$$\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} h(x)\u0026=\n\\frac{\\partial}{\\partial \\theta_{j}} g\\left(\\theta^Tx\\right)\\\\\n\u0026=g\\left(\\theta^Tx\\right)\\left(1-g\\left(\\theta^Tx\\right)\\right) \\frac{\\partial}{\\partial \\theta_{j}} \\theta^Tx\\\\\n\u0026=g\\left(\\theta^Tx\\right)\\left(1-g\\left(\\theta^Tx\\right)\\right)x_j\\\\\n\u0026=h(x)\\left(1-h(x)\\right)x_j\n\\end{aligned}$$\n\n\n$$\\begin{aligned}\n\\frac{\\partial^2}{\\partial \\theta_{j}^2} J(\\theta) \n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}\\left[\\frac{1}{m} \\sum_{i=1}^{m}\\left(h(x^{(i)})-y^{(i)}\\right) x^{(i)}_{j}\\right]\\\\\n\u0026=\\frac{1}{m} \\sum_{i=1}^{m}\\left(\\frac{\\partial}{\\partial \\theta_{j}}h(x^{(i)})\\right) x^{(i)}_{j} \\\\\n\u0026=\\frac{1}{m} \\sum_{i=1}^{m}g\\left(\\theta^Tx\\right)\\left(1-g\\left(\\theta^Tx\\right)\\right)\\left(x_j^{(i)}\\right)^2 \\\\\n\u0026=\\frac{1}{m} \\sum_{i=1}^{m}h(x)\\left(1-h(x)\\right)\\left(x_j^{(i)}\\right)^2\n\\end{aligned}$$\n- æ¥ä¸‹æ¥åˆ¤æ–­äºŒé˜¶å¯¼æ•°çš„è´Ÿå·: å¯¹äºSigmoidå‡½æ•°çš„å¯¼å‡½æ•°éƒ¨åˆ†, è§‚å¯Ÿå‡½æ•°å›¾åƒ, è“è‰²æ›²çº¿ä¸ºå¯¼å‡½æ•°å§‹ç»ˆå¤§äºé›¶:\n[Logistic Function](notes/2021/2021.8/Sigmoid_Function.md#Logistic%20Function)\n![Logistic](notes/2021/2021.7/assets/Logistic.svg)\nåŒæ—¶$\\left(x_j^{(i)}\\right)^2$ä¹Ÿéè´Ÿ, æ‰€ä»¥äºŒé˜¶å¯¼æ•°æ’å¤§äºç­‰äºé›¶, å‡½æ•°ä¸ºå‡¸å‡½æ•°, è¯æ¯•.\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2021/2021.9/CMU15-445_1_Lecture_Note":{"title":"CMU15-445_1_Lecture_Note","content":"# Course Intro \u0026 Relational Algebra\n\n\u003cdiv align=\"right\"\u003e 2021-09-08\u003c/div\u003e\n\nTags: #Database \n \n## Overview\n- è¿™é—¨è¯¾æ˜¯å…³äºæ•°æ®åº“çš„DBMSçš„è®¾è®¡å’Œå®ç°çš„, è€Œä¸æ˜¯å…³äºå¦‚ä½•ä½¿ç”¨ä¸€ä¸ªæ•°æ®åº“çš„\n- 2 classes per week, supplementary  reading  materials.\n\n- TextBook: Database System Concepts: The best among all the textbooks - Andy Pavlo\n\n- Project: build your own storage manager from scratch. A relatively complex software yet not a full-fledged system. Domino-way of building. \n\n\n## Database\n\na collection of data that's related together in some way that's try's to model some aspects of real world. \na useful database is the one which you can ask question about it.\n\nFlat Files:\n- CSV File: Comma Separated Value File\n\t- ![](notes/2021/2021.9/assets/Pasted%20image%2020210908111847.png)\n\t- If we want to find out which year the artist \"Ice Cube\" went solo,  we could write the following python code to iterate through the file above:\n```py\nfor line in file:\n\trecord = parse(line)\n\tif record[0]==\"Ice Cube\": \n\t\tprint int(record[1])\n ```\n- Implementation\n\t- However, there could be many issues in this way of storing information.\n\t- For example, this method is slow and becomes problematic when sharing data between programs(e.g. write to the same file at the same time).\n- Durability Problems\n- Data Integrity Problems\n\nDBMS:\n- Allows apps to store and analyze info in a database\n- ä¸ç”¨é‡å¤é€ è½®å­\n- We'll focus on In-disk DB\n- Definition, Creation, Query, Update and Administration of databases are the essential functionalities of a general-purpose DBMS. \n\n### History of DBMSs\n- **Early Stage**\n\tTight coupling between logical and physical layers.\n\t- People: Ted Codd - Purposed Relational Model\n\n**Data Model**: a collection of concepts for describing the data in a database. -\u003e The Higher Concept\n**Schema**: a description of a particular collection of data, Using a given data model. -\u003e The Actual Plan\n- **There are a bunch of data models:**\n\t- ![](notes/2021/2021.9/assets/Pasted%20image%2020210922111326.png)\n\t- ![](notes/2021/2021.9/assets/Pasted%20image%2020210922111354.png)\n\t- ![](notes/2021/2021.9/assets/Pasted%20image%2020210922111439.png)\n\t- ![](notes/2021/2021.9/assets/Pasted%20image%2020210922111456.png)\n\n**Relational Model: Three Parts**\n- Structure: The definitions of relations and their contents.\n- Integrity: Ensure the database's contents satisfy constraints.\n- Manipulation: How to access and modify a database's contents\n\n**Relation: Definition**\nUnordered set that contain the relation of attributes that represent entities.\n\n- Tuple: a set of attribute values(Domains) in the relation.(æ‰€ä»¥Tupleä¸åªæ˜¯ä¸‰å…ƒç»„å“ˆ)\n- `NULL`å¯ä»¥æ”¾å…¥ä»»ä½•Domain\n\n**Primary Key**\nUniquely identify a single tuple.\n\n## DML: Data Manipulation Languages\næœ‰ä¸¤ç§:\n- Procedural: æè¿°DBMSåº”è¯¥æ€ä¹ˆæ‰¾åˆ°ç›®æ ‡æ•°æ®\n\t- å¯¹åº” **Relational Algebra** -\u003eæˆ‘ä»¬è¿™é—¨è¯¾ç ”ç©¶çš„å¯¹è±¡\n- Non-Procedural: æè¿°éœ€è¦ä»€ä¹ˆæ•°æ®, ä½†æ˜¯ä¸ç»™å‡ºæ€ä¹ˆæ‰¾åˆ°è¿™äº›æ•°æ®.\n\t- å¯¹åº”Relational Calculus\n\n\n## Relational Algebra\nDescribe the fundamental operations to retrieve and manipulate tuples in a relation(Based on Set Algebra)\n```mermaid\ngraph LR\nA([realtion1])--\u003eB[\u003cSome Operations\u003e]\nC([realtion2])--\u003eB\nD([...])--\u003eB\nE([realtionN])--\u003eB\nB--\u003eF([New Relation])\n```\n\nå…³ç³»ä»£æ•°æ˜¯Proceduralçš„, æè¿°çš„æ˜¯ç­›é€‰æ•°æ®æ‰€è¦è¿›è¡Œçš„æ“ä½œ.\n![](notes/2021/2021.9/assets/Pasted%20image%2020210926102310.png)\nåœ¨è¯¾ä»¶é‡Œé¢ä»‹ç»äº†ä»¥ä¸Šæ“ä½œ:\n- Select\n- Projection\n- Union\n- Intersection\n- Difference\n- Product\n- Join\n\n- åœ¨è¯¾ä»¶é‡Œé¢ä¸¾äº†ä¸€ä¸ªä¾‹å­, å¦‚æœæˆ‘ä»¬ç”¨Procedural Language(æ¯”å¦‚ å…³ç³»ä»£æ•°)æ¥æè¿°æˆ‘ä»¬éœ€è¦çš„æ•°æ®, é‚£ä¹ˆå¯èƒ½ä¼šå‡ºç°æ•ˆç‡ä½çš„æƒ…å†µ, æœ€ä½³çš„ç­–ç•¥æ˜¯æè¿°æˆ‘ä»¬éœ€è¦çš„æ•°æ®(Non-Proceduralçš„), è®©DBMSæ¥å†³å®šæ€æ ·æŸ¥æ‰¾æ•ˆç‡é«˜, è¿™ä¹Ÿæ˜¯ç°åœ¨æ•°æ®åº“é‡Œé¢çš„ç°è¡Œæ ‡å‡†.(*de facto* standard)\n\n\n\n\n\n\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Codecademy_SQL_Tutorial-Notes-Database":{"title":"Codecademy_SQL_Tutorial-Notes-Database","content":"# SQL Tutorial\n\n\u003cdiv align=\"right\"\u003e 2021-09-26\u003c/div\u003e\n\nTags: #Database #SQL #SQLite\n\n- This course use SQLite\n\n**å¤ä¹ ææ–™:**\n- [SQL Commands - Glossary](https://www.codecademy.com/articles/sql-commands)\n- [CheatSheet](https://www.codecademy.com/learn/learn-sql/modules/learn-sql-manipulation/cheatsheet)\n\nä¸‹é¢åªå™è¿°CheatSheeté‡Œé¢æ²¡æœ‰çš„å†…å®¹\n\n\n\n## Clauses\n`CREATE TABLE` is a _clause_. Clauses perform specific tasks in SQL. By convention, clauses are written in capital letters. Clauses can also be referred to as commands.\n`INSERT`, `SELECT` etc. are also clauses.\nä¸­æ–‡: å­å¥?\n## INSERT\n- insert attribute çš„é¡ºåºå¯ä»¥äº¤æ¢, åªè¦Tupleé‡Œé¢çš„é¡ºåºä¸€ä¸€å¯¹åº”å³å¯.\n```sql\n INSERT INTO celebs (id, name, age)\n VALUES (1, 'Justin Bieber', 22);\n\n INSERT INTO celebs (name, id, age)\n VALUES ('Jeremy Lin', 3, 26);\n```\n\n- Multiple tuples: Quick way:\n```sql\nINSERT INTO table (col1, col2, col3)\nVALUES\n(row1_val1, row1_val2, row1_val3),\n(row2_val1, row2_val2, row2_val3),\n(row3_val1, row3_val2, row3_val3);\n```\n\n## ALTER\nOrder:\n### Question\n\nIn the context of this [exercise 89](https://www.codecademy.com/paths/data-science/tracks/dspath-why-data-python-basics/modules/dspath-introduction-to-sql/lessons/manipulation/exercises/alter), can we add a column at a specific position to a table?\n\n### Answer\n\nNo, unfortunately, you cannot specify what position to add a column to a table.\n\nBy default, a new column will always be added at the end of the table. For most intents and purposes, this should not affect much, since you can always select the columns in any order, for instance, like\n\n```\nSELECT col3, col1, col2\n```\n\nIf column order is very important, then an alternative is to create a new table and add the columns in the specific order they should appear.\n\n## DELETE\n```sql\nDELETE FROM celebs \nWHERE twitter_handle IS NULL;\n```\n- è¿™é‡Œçš„`IS NULL`å¯ä»¥æ¢æˆ`= NULL`å—?\n\t- ä¸å¯ä»¥, æ²¡æ³•åˆ é™¤\n\n\n## SQLite\n- In SQLite, a database is stored in **a single file** â€” a trait that distinguishes it from other database engines.\n- Drawbacks\n\t- Security and Data Integrity issue\n\t- No Data-Type Verification\n\t- Less advanced features\n\t- SQLiteâ€™s maintainers consider it to be among the [most replicated pieces of software in the world](https://www.sqlite.org/mostdeployed.html).\n\t- \n\n## Part 2 Queries\n### AS\n- ASä¸æ”¹å˜åŸæ¥çš„relation\n- ä½ å¯ä»¥ç”¨é€—å·åˆ†éš”ä¸¤ä¸ªæŸ¥è¯¢é‡å‘½åçš„é¡¹: \n```sql\nSELECT name AS movie, imdb_rating AS IMDb\nFROM movies;\n```\n\n### WHERE\n- WHEREé‡Œé¢çš„ç›¸ç­‰æ˜¯ä¸€ä¸ªç­‰å·: `=`\n\n### LIKE\n- wildcard: `_` -\u003e a single character\n- `%` is a wildcard character that matches zero or more missing letters in the pattern.\n- `LIKE` is **not** case sensitive.\n- å¦‚æœè¦æŸ¥æ‰¾`_` æˆ–`%`, åˆ©ç”¨åæ–œæ è¡¨ç¤ºè½¬ä¹‰å­—ç¬¦: `\\_`  `\\%`\n\n\u003e ### Question\n\u003e \n\u003e Can we apply the `LIKE` operator to values other than `TEXT`?\n\u003e \n\u003e ### Answer\n\u003e \n\u003e Yes, you can apply the `LIKE` operator to numerical values as well.\n\u003e \n\u003e Whenever you use `LIKE` however, you must always wrap the pattern within a pair of quotations, whether for matching a number or a string.\n\u003e \n\u003e #### Example\n\u003e \n\u003e ```\n\u003e /* \n\u003e This will select movies where the id number\n\u003e starts with 2 and is followed by any two numbers.\n\u003e */\n\u003e SELECT * \n\u003e FROM movies\n\u003e WHERE id LIKE '2__';\n\u003e ```\n\n\n### BETWEEN\n```sql\nSELECT *\nFROM movies\nWHERE year BETWEEN 1990 AND 1999;\n```\nè¿™ä¸ªèŒƒå›´æ˜¯ [1990, 1999], åŒ…æ‹¬äº†1999,\n\nä½†æ˜¯å¦‚æœæ˜¯å­—ç¬¦ä¸²çš„è¯, å°±å˜å¾—ç¨å¾®æœ‰ä¸€ç‚¹å¤æ‚:\nçœ‹è¿™ä¸ª:\n```sql\nSELECT *\nFROM movies\nWHERE name BETWEEN 'A' AND 'J';\n```\n'Jaw' ä¼šåŒ…æ‹¬åœ¨é‡Œé¢å—? -\u003e ä¸ä¼š\nä½†æ˜¯'J'ä¼šåŒ…æ‹¬åœ¨é‡Œé¢\n\nå› ä¸ºå…¶å®æ˜¯è¿™ä¸ªé¡ºåº:\n'A', 'Aa' ...... 'J', 'Ja',...........\nåˆ°'J'é‚£é‡Œå°±åœä¸‹æ¥äº†.\n\n### CASE\n```sql\nSELECT name,\n CASE\n  WHEN imdb_rating \u003e 8 THEN 'Fantastic'\n  WHEN imdb_rating \u003e 6 THEN 'Poorly Received'\n  ELSE 'Avoid at All Costs'\n END AS 'Review'\nFROM movies;\n```\n- æ³¨æ„ç¬¬ä¸€è¡Œæœ€åæœ‰ä¸€ä¸ªé€—å·!\nELSEä¸æ˜¯å¿…é¡»çš„\n```sql\nSELECT *,\n  CASE\n    WHEN review \u003e 4.5 THEN 'Extraordinary'\n    WHEN review \u003e 4   THEN 'Excellent'\n    WHEN review \u003e 3   THEN 'Good'\n    WHEN review \u003e 2   THEN 'Fair'\n    ELSE 'Poor'\n  END AS 'New Review'\nFROM nomnom;\n```\nCASEæ˜¯ä»ä¸Šå‘ä¸‹åŒ¹é…çš„, æ‰€ä»¥ç¬¬äºŒè¡Œçš„ä¸ç”¨å†è¯´æ˜è¦å°äº4.5:\n![](notes/2021/2021.9/assets/img_2022-10-15.png)\n\n## Multiple Tables\n### Inner Join\n![](https://content.codecademy.com/courses/learn-sql/multiple-tables/inner-join.gif)\n\n### LEFT JOIN\n![](https://content.codecademy.com/courses/learn-sql/multiple-tables/left-join.gif)\n\n\n\n\n## å­¦å®Œäº†\næœ‰ä¸‰ä¸ªç½‘ç«™æ¥å›é¡¾å­¦ä¹ å†…å®¹ï¼š\n- [å­¦å‰é¢„è§ˆ](https://www.codecademy.com/learn/learn-sql/modules/learn-sql-manipulation)\n- [CheatSheet](https://www.codecademy.com/learn/learn-sql/modules/learn-sql-multiple-tables/cheatsheet)\n- [Glossary Article](https://www.codecademy.com/articles/sql-commands)","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/De-facto":{"title":"De facto","content":"# De facto\n\n\u003cdiv align=\"right\"\u003e 2021-09-26\u003c/div\u003e\n\nTags: #English #Latin \n\nIn law and government, de facto (/deÉª ËˆfÃ¦ktoÊŠ, di-, dÉ™-/ day FAK-toh, dee -â ; Latin: de facto [deË ËˆfaktoË], \"in fact\") describes practices that exist in reality, even though they are not officially recognized by laws.\n\nIt is commonly used to refer to what happens in practice, in contrast with de jure (\"by law\"), which refers to things that happen according to law. ","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/OK_should_be_in_capital-lettersor_okay":{"title":"OK_should_be_in_capital letters(or_okay)","content":"# English\n\n- OK/okay is a word with uncertain origin.\n- Both \"OK\" and \"okay\" is acceptable, but ok is only used for convenience.\n\nSources:\n\n- \u003chttps://www.writing-skills.com/ok-ok-okay-how-do-you-write-ok\u003e\n- \u003chttps://english.stackexchange.com/questions/108213/must-ok-only-be-written-in-capital-letters\u003e\n- \u003chttps://www.lifehacker.com.au/2013/08/its-not-ok-to-write-ok/\u003e\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.18_Regularization_IntuitionML_Andrew.Ng.":{"title":"Part.18_Regularization_Intuition(ML_Andrew.Ng.)","content":"# Regularization: Intuition\n\n\u003cdiv align=\"right\"\u003e 2021-09-10\u003c/div\u003e\n\nTags: #MachineLearning #Regularization \n\nå¦‚æœæˆ‘ä»¬çº¦æŸçš„å‚æ•°\"åŠ å¤§æƒé‡\", é‚£ä¹ˆåœ¨ä¼˜åŒ–çš„æ—¶å€™å°±ä¼šé‡ç‚¹æœ€å°åŒ–é‚£äº›åŠ äº†æƒé‡çš„å‚æ•°.\nE.g.\n$$\n\\theta_{0}+\\theta_{1} x+\\theta_{2} x^{2}+\\theta_{3} x^{3}+\\theta_{4} x^{4}\n$$\nWe'll want to eliminate the influence of $\\theta_{3} x^{3}$ and $\\theta_{4} x^{4}$. Without actually getting rid of these features or changing the form of our hypothesis, we can instead modify our cost function:\n$$\n\\min _{\\theta} \\frac{1}{2 m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}+1000 \\cdot \\theta_{3}^{2}+1000 \\cdot \\theta_{4}^{2}\n$$\nåé¢çš„ä¸¤é¡¹å¯ä»¥çº¦æŸ$\\theta_{3}$å’Œ$\\theta_{4}$, å‡å°å®ƒä»¬çš„å½±å“.\n\næ›´ä¸€èˆ¬çš„å½¢å¼å¦‚ä¸‹: \n$$\n\\min _{\\theta} \\frac{1}{2 m} \\left[\\sum_{i=1}^{m}\n\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^{2}\n+\\lambda \\sum_{j=1}^{n} \\theta_{j}^{2}\\right]\n$$\n\n- The $\\lambda$, or lambda, is the regularization parameter. It determines how much the costs of our theta parameters are inflated.\n- æ³¨æ„$j$ä»1å¼€å§‹, æˆ‘ä»¬é€šå¸¸ä¸çº¦æŸ$\\theta_0$ .\n\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.19_Regularized_Linear_RegressionML_Andrew.Ng.":{"title":"Part.19_Regularized_Linear_Regression(ML_Andrew.Ng.)","content":"# Regularization \u0026 Linear Regression\n\n\u003cdiv align=\"right\"\u003e 2021-09-10\u003c/div\u003e\n\nTags: #MachineLearning #Regularization #GradientDescent #LinearRegression #NormalEquation \n\n## Regularization \u0026 Gradient Descent\næ·»åŠ äº†æ­£åˆ™é¡¹ä¹‹åæœ‰ä¸¤ç‚¹éœ€è¦æ³¨æ„:\n- $\\theta_0$éœ€è¦å•ç‹¬å¤„ç† (ä¸éœ€è¦æ­£åˆ™çº¦æŸ, æŸå¤±å‡½æ•°ä¸ä¸€æ ·)\n- $\\theta_1 \\sim \\theta_n$ å› ä¸ºéœ€è¦æ­£åˆ™åŒ–, æŸå¤±å‡½æ•°$J(\\theta)$å‘ç”Ÿäº†å˜åŒ–, æ¢¯åº¦éœ€è¦é‡æ–°è®¡ç®—\n- [æ­£åˆ™é¡¹ä¸å½±å“çº¿æ€§å›å½’æŸå¤±å‡½æ•°çš„å‡¸æ€§](notes/2021/2021.9/æ­£åˆ™é¡¹ä¸å½±å“çº¿æ€§å›å½’æŸå¤±å‡½æ•°çš„å‡¸æ€§.md)\n\nåŒæ—¶è€ƒè™‘ä¸Šé¢ä¸¤ç‚¹, æ¢¯åº¦ä¸‹é™æ›´æ–°å…¬å¼å˜ä¸ºäº†: \n\n$$\n\\begin{aligned}\nRe\u0026peat\\space \\{\\\\\n\u0026\\theta_{0}:=\\theta_{0}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{0}^{(i)} \\\\\n\u0026\\theta_{j}:=\\theta_{j}-\\alpha\\left[ \\frac{1}{m} \\sum_{i=1}^{m}\n\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(i)}+\\frac{\\lambda}{m} \\theta_{j}\\right]\n\\quad\\quad j \\in\\{1,2 \\ldots n\\}\n\\\\ \\}\n\\end{aligned}\n$$\nè¦æ˜¯æŠŠæ–¹æ‹¬å·æ‰“å¼€, ç¬¬äºŒè¡Œçš„æ›´æ–°å…¬å¼å¯ä»¥å˜ä¸º:\n$$\n\\theta_{j}:=\\theta_{j}\\left(1-\\alpha\\frac\\lambda m\\right)\n-\\alpha\\frac{1}{m} \\sum_{i=1}^{m}\n\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(i)}\n\\quad\\quad j \\in\\{1,2 \\ldots n\\}\n$$\nå› ä¸º$\\left(1-\\alpha\\frac\\lambda m\\right)$ä¸€å®šå°äº1, æ‰€ä»¥è¿™ä¸ªæ›´æ–°å…¬å¼æ¯æ¬¡éƒ½ä¼šç¼©å°ä¸€ç‚¹ç‚¹$\\theta_i$, è€Œå…¬å¼çš„ååŠéƒ¨åˆ†å’Œæ²¡æœ‰æ­£åˆ™åŒ–çš„å…¬å¼æ˜¯å®Œå…¨ä¸€æ ·çš„.\n\n\n## Regularization \u0026 Normal Equation\n- æ²¡æœ‰æ­£åˆ™åŒ–çš„å…¬å¼:\t\n$$\n\t\\theta=\\left(X^{T} X\\right)^{-1} X^{T} \\vec{y}\t\n$$\n([Definition](notes/2021/2021.8/Part.9_Normal_Equation(ML_Andrew.Ng.).md#Definition))\n\n- åŠ å…¥æ­£åˆ™é¡¹ä»¥å: \n\n$$\\begin{aligned}\n\u0026\\theta=(X^{T} X+\\lambda \\cdot L)^{-1} X^{T} \\vec y \\\\\n\u0026\\text { where } L=\\left[\\begin{array}{cccc}\n0 \u0026 \u0026 \u0026 \u0026 \\\\\n\u0026 1 \u0026 \u0026 \u0026 \\\\\n\u0026 \u0026 1 \u0026 \u0026 \\\\\n\u0026 \u0026 \u0026 \\ddots \u0026 \\\\\n\u0026 \u0026 \u0026 \u0026 1\n\\end{array}\\right]_{(n+1)\\times(n+1)}\n\\end{aligned}$$\n\n^72311a\n\n$L$çš„ç¬¬ä¸€ä¸ª0å¯ä»¥ç†è§£ä¸ºä¸ç”¨æ­£åˆ™åŒ–$\\theta_0$\n\n- åœ¨æ²¡æœ‰æ­£åˆ™åŒ–ä»¥å‰$(X^{T} X+\\lambda \\cdot L)$å¯èƒ½ä¸å¯é€†, ä½†æ˜¯æ­£åˆ™åŒ–ä»¥åæ˜¯ä¸€å®šå¯é€†çš„:\n\tè¯æ˜:[[notes/2021/2021.9/æ­£åˆ™é¡¹ä¼šæ¶ˆé™¤æ­£è§„æ–¹ç¨‹æ³•å¯èƒ½çš„ä¸å¯é€†æ€§]] \n\n\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.20_Regularized_Logistic_RegressionML_Andrew.Ng.":{"title":"Part.20_Regularized_Logistic_Regression(ML_Andrew.Ng.)","content":"# Regularized Logistic Regression\n\n\u003cdiv align=\"right\"\u003e 2021-09-11\u003c/div\u003e\n\nTags: #MachineLearning #LogisticRegression #Regularization \n\n## å›é¡¾ä¸€ä¸‹æ²¡æœ‰æ­£åˆ™åŒ–çš„æƒ…å†µ\n### æŸå¤±å‡½æ•°\n[æ›´ç®€æ´çš„å½¢å¼](notes/2021/2021.8/Part.13_Cost_Function-Logistic_Regression(ML_Andrew.Ng.).md#æ›´ç®€æ´çš„å½¢å¼)\n$$\\begin{align}\nJ(\\theta)\n\u0026=-\\frac{1}{m} \\sum_{i=1}^{m}\\left[y^{(i)} \\log \\left(h_{\\theta}\\left(x^{(i)}\\right)\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h_{\\theta}\\left(x^{(i)}\\right)\\right)\\right]\\\\\n\\end{align}$$\nor å‘é‡åŒ–çš„\n$$\\begin{aligned}\nh\u0026=g(X \\theta) \\\\\nJ(\\theta)\u0026=-\\frac{1}{m} \\cdot\\left[y^{T} \\log (h)+(1-y)^{T} \\log (1-h)\\right]\n\\end{aligned}$$\n### æ¢¯åº¦ä¸‹é™å…¬å¼\n[ç»“æœ](notes/2021/2021.8/Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.).md#ç»“æœ)\n$$\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta) \n\u0026=\\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) x^{(i)}_{j}\n\\end{aligned}$$\n- æ˜¯å’Œçº¿æ€§å›å½’å®Œå…¨ä¸€æ ·çš„, æ‰€ä»¥æ¢¯åº¦ä¸‹é™å…¬å¼ä¹Ÿä¸€æ ·:\n$$\\begin{array}{l}\n\\text { repeat until convergence }\\{\\\\\n\\begin{array}{cc}\n\u0026\\theta_{j}:=\\theta_{j}-\\alpha \\frac 1 m \\sum_{i=1}^{m} \\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) x_j^{(i)} \n\\end{array}\\\\\n\\text { \\} }\n\\\\\\\\ \\text { (simultaneously update } \nj=0, \\cdots ,j=n)\n\\end{array}$$\n---\n## æ­£åˆ™åŒ–ä»¥åçš„æŸå¤±å‡½æ•°\n$$\\begin{align}\nJ(\\theta)\n\u0026=-\\frac{1}{m} \\sum_{i=1}^{m}\n\\left[y^{(i)} \\log \\left(h\\left(x^{(i)}\\right)\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h\\left(x^{(i)}\\right)\\right)\\right]\n+\\frac\\lambda{2m}\\sum^n_{i=1}\\theta_i^2\\\\\n\u0026=P(\\theta)+\\frac\\lambda{2m}\\sum^n_{i=1}\\theta_i^2\n\\end{align}$$\néœ€è¦æ³¨æ„çš„å°±æ˜¯æ­£åˆ™é¡¹åº”è¯¥æ˜¯åŠ ä¸Šå»çš„, åŸç†æŸå¤±å‡½æ•°å‰é¢çš„è´Ÿå·æ˜¯ä¸ºäº†\"åè½¬\"$log$å‡½æ•°.\n\n## æ­£åˆ™åŒ–ä»¥åçš„æ¢¯åº¦ä¸‹é™\n\nåœ¨è®¡ç®—åå¯¼æ•°çš„æ—¶å€™, åˆ©ç”¨åå¯¼æ•°çš„æ€§è´¨, æˆ‘ä»¬åªéœ€è¦åœ¨æœ€ååŠ ä¸Šæ­£åˆ™é¡¹çš„åå¯¼æ•°å³å¯:\n$$\\begin{aligned}\n\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta) \n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}P(\\theta)+\n\\frac\\lambda{2m}\\frac{\\partial}{\\partial \\theta_{j}}\\sum^n_{i=1}\\theta_i^2\\\\\n\u0026=\\frac{\\partial}{\\partial \\theta_{j}}P(\\theta)+\n\\frac\\lambda{m}\\theta_{j} \\\\\n\u0026=\\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}(x^{(i)})-y^{(i)}\\right) x^{(i)}_{j}\n+\\frac\\lambda{m}\\theta_{j}\n\\end{aligned}$$\n- æ³¨æ„æ­£åˆ™é¡¹åœ¨æ±‚å’Œç¬¦å·çš„å¤–é¢\n\nå¸¦å…¥æ¢¯åº¦æ›´æ–°å…¬å¼æœ‰:\n$$\n\\begin{aligned}\nRe\u0026peat\\space \\{\\\\\n\u0026\\theta_{0}:=\\theta_{0}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{0}^{(i)} \\\\\n\u0026\\theta_{j}:=\\theta_{j}-\\alpha\\left[ \\frac{1}{m} \\sum_{i=1}^{m}\n\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(i)}+\\frac{\\lambda}{m} \\theta_{j}\\right]\n\\quad\\quad j \\in\\{1,2 \\ldots n\\}\n\\\\ \\}\n\\end{aligned}\n$$\nè¦æ˜¯æŠŠæ–¹æ‹¬å·æ‰“å¼€, ç¬¬äºŒè¡Œçš„æ›´æ–°å…¬å¼å¯ä»¥å˜ä¸º:\n$$\n\\theta_{j}:=\\theta_{j}\\left(1-\\alpha\\frac\\lambda m\\right)\n-\\alpha\\frac{1}{m} \\sum_{i=1}^{m}\n\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(i)}\n\\quad\\quad j \\in\\{1,2 \\ldots n\\}\n$$\nå› ä¸º$\\left(1-\\alpha\\frac\\lambda m\\right)$ä¸€å®šå°äº1, æ‰€ä»¥è¿™ä¸ªæ›´æ–°å…¬å¼æ¯æ¬¡éƒ½ä¼šç¼©å°ä¸€ç‚¹ç‚¹$\\theta_i$, è€Œå…¬å¼çš„ååŠéƒ¨åˆ†å’Œæ²¡æœ‰æ­£åˆ™åŒ–çš„å…¬å¼æ˜¯å®Œå…¨ä¸€æ ·çš„.\n\n- ä¸Šé¢è¿™éƒ¨åˆ†æ˜¯ç›´æ¥ä»çº¿æ€§å›å½’é‚£é‡Œæ‹·è´è¿‡æ¥çš„, ä¸¤è€…å”¯ä¸€çš„ä¸åŒå°±æ˜¯$h(x)$çš„å®šä¹‰ä¸åŒ\n\n## è¯æ˜æ­£åˆ™ä»¥åè¿˜æ˜¯å‡¸çš„\n[æ­£åˆ™é¡¹ä¸å½±å“Logisticå›å½’æŸå¤±å‡½æ•°å‡¸æ€§](notes/2021/2021.9/æ­£åˆ™é¡¹ä¸å½±å“Logisticå›å½’æŸå¤±å‡½æ•°å‡¸æ€§.md)\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.21_Neural_Network_IntroductionML_Andrew.Ng.":{"title":"Part.21_Neural_Network_Introduction(ML_Andrew.Ng.)","content":"# Neural Network - Introduction\n\n\u003cdiv align=\"right\"\u003e 2021-09-11\u003c/div\u003e\n\nTags: #NeuralNetwork #MachineLearning \n\n## Non-linear Hypotheses\n![](notes/2021/2021.9/assets/img_2022-10-15-1.png)\næ‰€ä»¥éšç€ç‰¹å¾æ•°é‡çš„æé«˜, å¦‚æœéœ€è¦æ›´åŠ å¤æ‚çš„å‡è®¾å‡½æ•°, ç‰¹å¾æ•°é‡ä¼šçˆ†ç‚¸å¼åœ°å¢é•¿.\næ¯”å¦‚åœ¨å›¾ç‰‡å¤„ç†çš„æ—¶å€™, æ¯ä¸€ä¸ªåƒç´ éƒ½æ˜¯ä¸€ä¸ªç‰¹å¾(RGBå½©è‰²åƒç´ ç”šè‡³æ˜¯ä¸‰ä¸ªç‰¹å¾), é‚£ä¹ˆç‰¹å¾çš„æ•°ç›®å°†ä¼šæ˜¯ååˆ†åºå¤§çš„:\n![](notes/2021/2021.9/assets/img_2022-10-15-2.png)\n\n## The â€œone learning algorithmâ€ hypothesis\n![](notes/2021/2021.9/assets/img_2022-10-15-3.png)\n\n## Neurons in the Brain\n![The Typical Structure of a Neuron](https://www.cusabio.com/statics/images/Structure-Neuron.jpg)\n- æ ‘çª: Dendrite\n- è½´çª: Axon\n- ç¥ç»è„‰å†²: Spike\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.22_Model_Representation-Neural_NetworkML_Andrew.Ng.":{"title":"Part.22_Model_Representation-Neural_Network(ML_Andrew.Ng.)","content":"# Model Representation - NN\n\n\u003cdiv align=\"right\"\u003e 2021-09-11\u003c/div\u003e\n\nTags: #NeuralNetwork #MachineLearning \n\n## Hypothesis\n![](notes/2021/2021.9/assets/Neuron.svg)\nä¸€ä¸ªç¥ç»å…ƒ(Neuron / Activation Unit)çš„è¾“å‡ºè®¡ç®—å…¬å¼ç”±å¦‚ä¸‹å…¬å¼ç»™å‡º:\n$$h_\\Theta(x)=\na = g(x_0\\theta_0+x_1\\theta_1+\\cdots+x_n\\theta_n)$$\næ˜¯çº¿æ€§çš„. ($g(x)$æ˜¯Sigmoid Function)\n\nç¥ç»ç½‘ç»œçš„ç»“æ„å¦‚ä¸‹:\n![](notes/2021/2021.9/assets/Network.svg)\nå¯ä»¥çœ‹å‡º, æ¯ä¸€å±‚(Layer)éƒ½æœ‰è®¸å¤šèŠ‚ç‚¹ç»„æˆ, æ‰€æœ‰çš„eèŠ‚ç‚¹ä¸€å±‚å±‚ç»„æˆä¸€ä¸ªç½‘ç»œ, æ„æˆäº†æ¯”çº¿æ€§Hypothesisæ›´å¤æ‚çš„ç»“æ„.\n\n\u003e **è¿›ä¸€æ­¥æ€è€ƒ:** ä¸ºä»€ä¹ˆä¸€å®šè¦æ˜¯ä¸€å±‚ä¸€å±‚çš„å‘¢? ä¸ºä»€ä¹ˆä¸æ˜¯å›¾ç»“æ„çš„å‘¢?\n\næ¯ä¸€ä¸ªèŠ‚ç‚¹çš„æƒé‡(Weights, å³$\\theta$)éƒ½æ„æˆä¸€ä¸ªè¡Œå‘é‡, æ‰€æœ‰çš„è¡Œå‘é‡ç»„æˆè¿™ä¸€å±‚çš„æƒé‡çŸ©é˜µ$\\Theta^{(i)}$\n![](notes/2021/2021.9/assets/ThetaWeights.svg)\n\n\n\nä»¥ä¸Šå›¾ä¸ºä¾‹:\n$$\\begin{aligned}\na_{1}^{(2)} \u0026=g\\left(\\Theta_{10}^{(1)} x_{0}+\\Theta_{11}^{(1)} x_{1}+\\Theta_{12}^{(1)} x_{2}+\\Theta_{13}^{(1)} x_{3}\\right) \\\\\na_{2}^{(2)} \u0026=g\\left(\\Theta_{20}^{(1)} x_{0}+\\Theta_{21}^{(1)} x_{1}+\\Theta_{22}^{(1)} x_{2}+\\Theta_{23}^{(1)} x_{3}\\right) \\\\\na_{3}^{(2)} \u0026=g\\left(\\Theta_{30}^{(1)} x_{0}+\\Theta_{31}^{(1)} x_{1}+\\Theta_{32}^{(1)} x_{2}+\\Theta_{33}^{(1)} x_{3}\\right) \\\\\nh_{\\Theta}(x) \u0026=a_{1}^{(3)}=g\\left(\\Theta_{10}^{(2)} a_{0}^{(2)}+\\Theta_{11}^{(2)} a_{1}^{(2)}+\\Theta_{12}^{(2)} a_{2}^{(2)}+\\Theta_{13}^{(2)} a_{3}^{(2)}\\right)\n\\end{aligned}$$\n\n![](notes/2021/2021.9/assets/WeightsMatrix.svg)\n\nThe dimensions of these matrices of weights is determined as follows:\n\nIfÂ networkÂ has $s_j$ unitsÂ inÂ layer $j$ and $s_{j+1}$ unitsÂ inÂ layer $j+1$,Â then $Î˜^{(j)}$ willÂ beÂ ofÂ dimension $s_{j+1}Ã—(s_j+1)$. If network has $s_j$ units in layer $j$ and $s_{j+1}$ units in layer $j+1$, then $\\Theta^{(j)}$ will be of dimension $s_{j+1} \\times (s_j + 1)$.\n\nThe $+1$ comes from the addition in $\\Theta^{(j)}$ of the \"bias nodes,\" $x_0$ and $\\Theta_0^{(j)}$. In other words the output nodes will not include the bias nodes while the inputs will.","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.23_Forward_Propagation-Neural_NetworkML_Andrew.Ng.":{"title":"Part.23_Forward_Propagation-Neural_Network(ML_Andrew.Ng.)","content":"# Forward Propagation\n\n\u003cdiv align=\"right\"\u003e 2021-09-12\u003c/div\u003e\n\nTags: #NeuralNetwork #MachineLearning \n\n## Vectorized Implementation\n$$\\begin{aligned}\na_{1}^{(2)} \u0026=g\\left(\\Theta_{10}^{(1)} x_{0}+\\Theta_{11}^{(1)} x_{1}+\\Theta_{12}^{(1)} x_{2}+\\Theta_{13}^{(1)} x_{3}\\right) \\\\\na_{2}^{(2)} \u0026=g\\left(\\Theta_{20}^{(1)} x_{0}+\\Theta_{21}^{(1)} x_{1}+\\Theta_{22}^{(1)} x_{2}+\\Theta_{23}^{(1)} x_{3}\\right) \\\\\na_{3}^{(2)} \u0026=g\\left(\\Theta_{30}^{(1)} x_{0}+\\Theta_{31}^{(1)} x_{1}+\\Theta_{32}^{(1)} x_{2}+\\Theta_{33}^{(1)} x_{3}\\right) \\\\\n\\end{aligned}$$\næˆ‘ä»¬æŠŠSigmoidå‡½æ•°é‡Œé¢çš„éƒ¨åˆ†ç”¨$z$ä»£æ›¿:\n$$\\begin{aligned}\n\u0026a_{1}^{(2)}=g\\left(z_{1}^{(2)}\\right) \\\\\n\u0026a_{2}^{(2)}=g\\left(z_{2}^{(2)}\\right) \\\\\n\u0026a_{3}^{(2)}=g\\left(z_{3}^{(2)}\\right)\n\\end{aligned}$$\nåŒæ—¶:\n$$\\begin{aligned}\n\u0026X = \\left[\\begin{array}{cccc}\nx_0  \\\\x_1  \\\\x_2  \\\\x_3  \\\\\n\\end{array}\\right]\n=a^{(1)}\n\\end{aligned}$$\n\nç¬¬ä¸€æ­¥å˜ä¸º:\n$$\\begin{aligned}\n\\Theta^{(1)}X =Z^{(1)}= \\left[\\begin{array}{cccc}\nz_1^{(2)}  \\\\z_2^{(2)}  \\\\z_3^{(2)}  \\\\\n\\end{array}\\right]\n\\end{aligned}$$\n\n![](notes/2021/2021.9/assets/Forward_Propagation_p1.svg)\nå¸¦å…¥Sigmoidå‡½æ•°å¾—åˆ°ç¬¬äºŒå±‚activation unitsçš„è¾“å‡ºå€¼:\n$$\\begin{aligned}\nA^{(1)}= Sigmoid(\\left[\\begin{array}{cccc}\nz_1^{(2)}  \\\\z_2^{(2)}  \\\\z_3^{(2)}  \\\\\n\\end{array}\\right]) = \\left[\\begin{array}{cccc}\na_1^{(2)}  \\\\a_2^{(2)}  \\\\a_3^{(2)}  \\\\\n\\end{array}\\right]\n\\end{aligned}$$\n![](notes/2021/2021.9/assets/Forward_Propagation_p2.svg)\nåŒæ—¶åŠ ä¸ŠBias Unit.\n\nä¸‹ä¸€å±‚é‡å¤ä¸Šè¿°æ­¥éª¤, ç›´åˆ°å¾—åˆ°æœ€ç»ˆçš„ç»“æœ\n![](notes/2021/2021.9/assets/Forward_Propagation_p3.svg)\n\nå‰å‘ä¼ æ’­æ˜¯ä»è¾“å…¥å¼€å§‹, é€æ­¥å‘å‰, åˆ©ç”¨æƒé‡è®¡ç®—è¾“å‡ºçš„è¿‡ç¨‹.\n\næ€»è§ˆ:\n![](notes/2021/2021.9/assets/Forward_Propagation_all.svg)\n\n## ä¸Logistic Regressionçš„è”ç³»\n\nåœ¨æœ€åä¸€æ­¥çš„æ—¶å€™, æˆ‘ä»¬è¿›è¡Œçš„æ“ä½œå…¶å®å’ŒLogistic Regressionä¸€æ¨¡ä¸€æ ·, æ¯ä¸€ä¸ªActivation Unitçš„è®¡ç®—è¿‡ç¨‹éƒ½å¯ä»¥ç†è§£ä¸ºä¸€æ¬¡Logistic Regression.\n\n\n![](notes/2021/2021.9/assets/Pasted%20image%2020210912142652.png)","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.24_Neural_Network-ExamplesML_Andrew.Ng.":{"title":"Part.24_Neural_Network-Examples(ML_Andrew.Ng.)","content":"# Examples of Neural Network\n\n\u003cdiv align=\"right\"\u003e 2021-09-12\u003c/div\u003e\n\nTags: #NeuralNetwork #MachineLearning \n \n - æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ç›´è§‚çš„ç»„åˆè¿‡ç¨‹, ä½“ä¼šç¥ç»ç½‘ç»œåˆ©ç”¨Linearityæ„å»ºNon-Linearityçš„è¿‡ç¨‹.\n \n## OR function\n![](notes/2021/2021.9/assets/img_2022-10-15-4.png)\n## AND function\n![](notes/2021/2021.9/assets/img_2022-10-15-5.png)\n## NOT function\n![](notes/2021/2021.9/assets/img_2022-10-15-6.png)\n\n## Putting together -\u003e XNOR Function\n![](notes/2021/2021.9/assets/img_2022-10-15-7.png)\n![](notes/2021/2021.9/assets/img_2022-10-15-8.png)","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.25_Multiclass_Classification-Neural_NetworkML_Andrew.Ng.":{"title":"Part.25_Multiclass_Classification-Neural_Network(ML_Andrew.Ng.)","content":"# Multiclass Classification\n\n\u003cdiv align=\"right\"\u003e 2021-09-12\u003c/div\u003e\n\nTags: #MachineLearning #NeuralNetwork \n\n\n\n![](notes/2021/2021.9/assets/img_2022-10-15-9.png)\n\nWe can define our set of resulting classes as y:\n$$\ny^{(i)}=\\left[\\begin{array}{l}\n1 \\\\\n0 \\\\\n0 \\\\\n0\n\\end{array}\\right],\\left[\\begin{array}{l}\n0 \\\\\n1 \\\\\n0 \\\\\n0\n\\end{array}\\right],\\left[\\begin{array}{l}\n0 \\\\\n0 \\\\\n1 \\\\\n0\n\\end{array}\\right],\\left[\\begin{array}{l}\n0 \\\\\n0 \\\\\n0 \\\\\n1\n\\end{array}\\right]\n$$\nEach $y^{(i)}$ represents a different image corresponding to either a car, pedestrian, truck, or motorcycle. **The inner layers, each provide us with some new information which leads to our final hypothesis function.** The setup looks like:\n$$\n\\left[\\begin{array}{c}\nx_{0} \\\\\nx_{1} \\\\\nx_{2} \\\\\n\\cdots \\\\\nx_{n}\n\\end{array}\\right] \\rightarrow\\left[\\begin{array}{c}\na_{0}^{(2)} \\\\\na_{1}^{(2)} \\\\\na_{2}^{(2)} \\\\\n\\ldots\n\\end{array}\\right] \\rightarrow\\left[\\begin{array}{c}\na_{0}^{(3)} \\\\\na_{1}^{(3)} \\\\\na_{2}^{(3)} \\\\\n\\cdots\n\\end{array}\\right] \\rightarrow \\ldots \\rightarrow\\left[\\begin{array}{l}\nh_{\\Theta}(x)_{1} \\\\\nh_{\\Theta}(x)_{2} \\\\\nh_{\\Theta}(x)_{3} \\\\\nh_{\\Theta}(x)_{4}\n\\end{array}\\right]\n$$","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.26_Probabilistic_Interpretation_of_MSEML_Andrew.Ng.":{"title":"Part.26_Probabilistic_Interpretation_of_MSE(ML_Andrew.Ng.)","content":"# å‡æ–¹å·®çš„åˆç†æ€§ - æ¦‚ç‡è§£é‡Š\n\n\u003cdiv align=\"right\"\u003e 2021-09-16\u003c/div\u003e\n\nTags: #MachineLearning #Math/Statistics #MeanSquareError #CostFunction \n\n## ä¹‹å‰çš„ä¸€äº›è®¨è®º\n- [Mean_Squared_Error-å‡æ–¹è¯¯å·®](notes/2021/2021.8/Mean_Squared_Error_å‡æ–¹è¯¯å·®.md)\n- [Why_do_cost_functions_use_the_square_error](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md)\n\n## CS229 - Probabilistic Interpretation\n\n- [ç‹¬ç«‹åŒåˆ†å¸ƒ-IID](notes/2021/2021.9/ç‹¬ç«‹åŒåˆ†å¸ƒ-IID.md)\n- [[notes/2021/2021.9/æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution]]\n\nPrerequisite: [ä¼¼ç„¶å‡½æ•°](https://zh.wikipedia.org/zh-hans/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0)\n\u003e æˆ‘éœ€è¦è¿›ä¸€æ­¥å­¦ä¹ æ¦‚ç‡è®º(è´å¶æ–¯ç»Ÿè®¡)\n\n---\n\nä¸‹é¢å™è¿°ä»æ¦‚ç‡è§’åº¦è¯¥æ€ä¹ˆç†è§£å‡æ–¹å·®çš„åˆç†æ€§, å…¶å®æ˜¯æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„æ€æƒ³, å’ŒBayesianä¼°è®¡çš„æ€æƒ³å¾ˆåƒ.\n\n- **å‰æ:** è¯¯å·®$\\epsilon$æ˜¯**ç‹¬ç«‹åŒåˆ†å¸ƒ(IID)** çš„ä¸”æœä»**æ­£æ€åˆ†å¸ƒ(Normal Distribution)** \n\t- **ç†è®ºåŸºç¡€:** ä¸­å¿ƒæé™å®šç†.\n\n\næˆ‘ä»¬è¿™æ ·è¡¨ç¤ºè¾“å…¥å’Œè¾“å‡ºçš„å…³ç³»: å…¶ä¸­$x^{(i)}$æ˜¯è¾“å…¥, $y^{(i)}$æ˜¯è¾“å‡º, $\\theta^{T}$æ˜¯å‚æ•°å‘é‡, $\\epsilon^{(i)}$è¡¨ç¤ºè¯¯å·®.\n$$y^{(i)}=\\theta^{T} x^{(i)}+\\epsilon^{(i)}$$\n\næ ¹æ®æˆ‘ä»¬çš„å‡è®¾, è¯¯å·®æœä»æ­£æ€åˆ†å¸ƒ: \n\n$$\n\\begin{aligned}\n\\epsilon^{(i)}\u0026\\sim\\mathcal{N}\\left(0, \\sigma^{2}\\right)\\quad\\Rightarrow\n\\\\p\\left(\\epsilon^{(i)}\\right)\u0026=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{\\left(\\epsilon^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\n\\end{aligned}$$\nå°†è¾“å…¥è¾“å‡ºçš„å…³ç³»å¸¦è¿›å», å¯ä»¥å¾—åˆ°$y^{(i)}$çš„æ¦‚ç‡å¯†åº¦åˆ†å¸ƒ:\n$$\np\\left(y^{(i)} \\mid x^{(i)} ; \\theta\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\n$$\n\nè”ç³»[æ­£æ€åˆ†å¸ƒçš„è¡¨è¾¾å¼](notes/2021/2021.9/æ­£æ€åˆ†å¸ƒ_é«˜æ–¯åˆ†å¸ƒ_Normal_Distribution-Gaussian_Distribution.md#æ¦‚ç‡å¯†åº¦å‡½æ•°):\n\n$$f(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}\\right)$$\n\nå…¶ä¸­çš„$\\theta^{T} x^{(i)}$å°±æ˜¯æ•°å­¦æœŸæœ›$\\mu$, æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¿™æ ·è¡¨ç¤º:\n\n$$y^{(i)} \\mid x^{(i)} ; \\theta \\sim \\mathcal{N}\\left(\\theta^{T} x^{(i)}, \\sigma^{2}\\right)$$\n\n- **ä¸‹é¢æ˜¯å…³é”®çš„ä¸€æ­¥:**\n\næˆ‘ä»¬æ€»æ˜¯æƒ³è¦æ ¹æ®ç»™å®šçš„$X$ (the design matrix, which contains all the $x^{(i)}$â€™s), è°ƒæ•´$\\theta$, æ¥å¾—åˆ°å¯¹äºè¾“å‡º$Y$çš„æœ€ä½³é¢„æµ‹.\n\næ‰€ä»¥æˆ‘ä»¬ç»™å‡ºè¿™ä¸ªé—®é¢˜çš„ä¼¼ç„¶å‡½æ•°:\n$$L(\\theta)=L(\\theta ; X, \\vec{y})=p(\\vec{y} \\mid X ; \\theta)$$\nå®ƒè¡¨ç¤ºåœ¨ç»™å®šçš„$\\theta$ä¸‹, ç”±è®­ç»ƒé›†é‡Œé¢çš„$X$å¾—åˆ°å¯¹åº”çš„$Y$çš„\"ä¼¼ç„¶æ€§/å¯èƒ½æ€§/åˆç†æ€§\"\n\næ ¹æ®ä¼¼ç„¶å‡½æ•°çš„å®šä¹‰(å°±ç›¸å½“äºæ¡ä»¶æ¦‚ç‡), å¯¹äºæˆ‘ä»¬çš„è®­ç»ƒé›†, $L(\\theta)$è¡¨ç¤ºå¦‚ä¸‹:\n$$\\begin{aligned}\nL(\\theta) \u0026=\\prod_{i=1}^{m} p\\left(y^{(i)} \\mid x^{(i)} ; \\theta\\right) \\\\\n\u0026=\\prod_{i=1}^{m} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\n\\end{aligned}$$\n- æ³¨æ„æ˜¯è¿ä¹˜, å› ä¸ºæ˜¯è”åˆæ¦‚ç‡\n\næ ¹æ®**æå¤§ä¼¼ç„¶ä¼°è®¡**çš„æ€æƒ³, æˆ‘ä»¬æƒ³è¦çŸ¥é“$L(\\theta)$å–å¾—æœ€å¤§å€¼çš„æ—¶å€™çš„$\\theta$å€¼, å› ä¸ºæœ€å¤§åŒ–è¿™ä¸ªå‡½æ•°ååˆ†å¤æ‚, æˆ‘ä»¬å¯ä»¥å–å¯¹æ•°(å› ä¸ºå¯¹æ•°å‡½æ•°æ˜¯ä¸¥æ ¼é€’å¢çš„, è€Œè¿™ä¸ªçš„å€¼åŸŸä¹Ÿåœ¨å¯¹æ•°å‡½æ•°çš„å®šä¹‰åŸŸé‡Œé¢)\n\næˆ‘ä»¬ç”¨$\\ell(\\theta)$è¡¨ç¤º$log\\space likelihood$:\n$$\\begin{aligned}\n\\ell(\\theta) \u0026=\\log L(\\theta) \\\\\n\u0026=\\log \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right) \\\\\n\u0026=\\sum_{i=1}^{m} \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right) \\\\\n\u0026=m \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{\\sigma^{2}} \\cdot \\frac{1}{2} \\sum_{i=1}^{m}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}\n\\end{aligned}$$\næ‰€ä»¥è¦æœ€å¤§åŒ–$\\ell(\\theta)$ç›¸å½“äºæœ€å°åŒ– \n$$\\frac{1}{2} \\sum_{i=1}^{m}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}$$\nè¿™å’Œå¹³æ–¹è¯¯å·®å’Œåªå·®ä¸€ä¸ª$\\frac 1 m$\n\n\n\u003e Note also that, in our previous discussion, **our final choice of $Î¸$ did not depend on what was $Ïƒ^2$,** and indeed weâ€™d have arrived at the same result even if $Ïƒ^2$ were unknown. We will use this fact again later, when we talk about the **exponential family** and **generalized linear models**.","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Part.27_Locally_Weighted_Linear_RegressionML_Andrew.Ng.":{"title":"Part.27_Locally_Weighted_Linear_Regression(ML_Andrew.Ng.)","content":"# Locally Weighted Linear Regression\n\n\u003cdiv align=\"right\"\u003e 2021-09-30\u003c/div\u003e\n\nTags: #MachineLearning #LinearRegression \n\nAbbreviation: LWR\n\n![](notes/2021/2021.9/assets/img_2022-10-15-10.png)\n\nä¸Šå›¾å±•ç°äº†Underfitting \u0026 Overfittingçš„æƒ…å†µï¼Œè€Œ \nLocally weighted linear regression (LWR) is an algorithm which, assuming there is sufficient training data, makes the choice of features less critical.\n\n## å¯¹æ¯”\nIn the original linear regression algorithm, to make a prediction at a query point $x$ (i.e., to evaluate $h(x)$ ), we would:\n1. Fit $\\theta$ to minimize $\\sum_{i}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}$.\n2. Output $\\theta^{T} x$.\n\nIn contrast, the locally weighted linear regression algorithm does the following:\n\n1. Fit $\\theta$ to minimize $\\sum_{i} w^{(i)}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}$.\n2. Output $\\theta^{T} x$.\n\nä¸åŒ:\n- å¤šäº†ä¸€ä¸ª$w^{(i)}$, å¯¹äºæ¯ä¸€æ¬¡query, æˆ‘ä»¬éƒ½éœ€è¦é‡æ–°æ‹Ÿåˆ$\\theta$\n\n## è¯¦ç»†è§£é‡Š\n\nå…¶ä¸­$w^{(i)}$çš„ä½œç”¨æ˜¯ ç»™æœ€æ¥è¿‘è¿™æ¬¡æŸ¥è¯¢ç›®æ ‡$x$çš„æ ·æœ¬ç‚¹æ›´å¤§çš„æƒé‡(æ ·æœ¬è¶Šæ¥è¿‘æŸ¥è¯¢ç›®æ ‡, é‚£ä¹ˆå°±å¯èƒ½å’ŒæŸ¥è¯¢ç›®æ ‡\"æ›´åƒ\")\n\nä¸€ä¸ªå¸¸ç”¨çš„$w^{(i)}$æ˜¯:\n\n$$w^{(i)}=\\exp \\left(-\\frac{\\left(x^{(i)}-x\\right)^{2}}{2 \\tau^{2}}\\right)$$\nå‘é‡å½¢å¼:\n$$w^{(i)}=\n\\exp\\left(-\\frac{(x^{(i)}-x)^{T}(x^{(i)}-x)}\n{(2 \\tau^{2})}\\right)$$\n\n\nå› ä¸º$w^{(i)}$çš„æŒ‡æ•°éƒ¨åˆ†ä¸€å®šæ˜¯éæ­£çš„, è€ƒè™‘æŒ‡æ•°å‡½æ•°çš„è´ŸåŠè½´éƒ¨åˆ†:\n![](notes/2021/2021.9/assets/img_2022-10-15-11.png)\n\nè§‚å¯Ÿå‘ç°: $x$è¶Šæ¥è¿‘$x^{(i)}$, æŒ‡æ•°éƒ¨åˆ†è¶Šæ¥è¿‘$0$, $w^{(i)}$è¶Šæ¥è¿‘$1$, è¿™éƒ¨åˆ†ç‰¹å¾åœ¨æŸå¤±å‡½æ•°é‡Œé¢çš„æƒé‡è¶Šå¤§, ä¼šæ›´ç€é‡äºè®©è¿™éƒ¨åˆ†çš„æŸå¤±è¶Šå°, é‚£ä¹ˆå°±ä¼šæ›´åé‡äºè¿™éƒ¨åˆ†çš„å‚æ•°.\nåä¹‹, If $w^{(i)}$ is small, then the $\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}$ error term will be pretty much ignored in the fit.\n\n\n**bandwidth parameter**: The parameter $\\tau$ controls how quickly the weight of a training example falls off with distance of its $x^{(i)}$ from the query point $x ; \\tau$ is called *the bandwidth parameter*.\n(è°ƒæ•´\"åˆ°åº•è·ç¦»$x$å¤šè¿œæ‰ç®—é‡è¦çš„æ ·æœ¬ç‚¹\")\n\n- è™½ç„¶ $w^{(i)}$çš„è¿™ä¸ªå½¢å¼å’Œæ­£æ€åˆ†å¸ƒå¾ˆåƒ, ä½†æ˜¯å…¶å®æ²¡æœ‰ä»€ä¹ˆè”ç³», å› ä¸º $w^{(i)}$ä¸æ˜¯éšæœºå˜é‡, ä¹Ÿä¸æœä»ç‹¬ç«‹åŒåˆ†å¸ƒ.\n\n- LWRæ˜¯ä¸€ç§**éå‚æ•°ç®—æ³•**, å› ä¸ºè¿™ä¸ªç®—æ³•çš„è¾“å‡ºå’Œæ ·æœ¬è¿˜æœ‰ç´§å¯†çš„è”ç³»:\n- Locally weighted linear regression is the first example weâ€™re seeing of a ***non-parametric algorithm***. The (unweighted) linear regression algorithm that we saw earlier is known as a ***parametric learning algorithm***, because it has a fixed, finite number of parameters (the $Î¸_i$â€™s), which are fit to the data. Once weâ€™ve fit the $Î¸_i$â€™s and stored them away, **we no longer need to keep the training data around to make future predictions**. In contrast, to make predictions using locally weighted linear regression, **we need to keep the entire training set around**. The term â€œ***non-parametric***â€ (roughly) refers to the fact that the amount of stuff we need to keep in order to represent the hypothesis h grows linearly with the size of the training set.","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/ROC_and_AUC_Graph":{"title":"ROC_and_AUC_Graph","content":"#  ROC AUC Clearly Explained\n\n\u003cdiv align=\"right\"\u003e 2021-09-30\u003c/div\u003e\n\nTags: #MachineLearning #ROC #AUC\n\n- **ROC:** Receiver Operator Characteristic ç”¨æ¥åˆ¤æ–­å“ªä¸€ä¸ªæ˜¯æœ€å¥½çš„Classification Threshold.\n- **AUC:** the area under the curve, ç”¨æ¥åˆ¤æ–­å“ªä¸€ä¸ªæ˜¯æœ€å¥½çš„æ¨¡å‹\n\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4jRBRDbJemM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Underline_in_Markdown_MD%E4%B8%8B%E5%88%92%E7%BA%BF":{"title":"Underline_in_Markdown_MDä¸‹åˆ’çº¿","content":"# Markdowné‡Œé¢çš„ä¸‹åˆ’çº¿\n\n\u003cdiv align=\"right\"\u003e 2021-09-18\u003c/div\u003e\n\nTags: #Markdown #HTML\n\n## `\u003cins\u003e \u003c/ins\u003e`\n**Example:**\n```md\n\u003cins\u003eThis line is UNDERLINED!\u003c/ins\u003e \n```\n\n\u003cins\u003eThis line is UNDERLINED!\u003c/ins\u003e \n\n## `\u003cu\u003e \u003c/u\u003e`\n**Example:** \n```md\n\u003cu\u003eThis line is UNDERLINED!\u003c/u\u003e \n```\n\n\u003cu\u003eThis line is UNDERLINED!\u003c/u\u003e \n\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/Why_printf_is_called_printf":{"title":"Why_printf_is_called_printf","content":"# Why `printf` is called `printf` \n\n\u003cdiv align=\"right\"\u003e 2021-09-06\u003c/div\u003e\n\nTags: #Programming #English \n\n## What f stands for in `printf` ?\n\nThe title of section **_7.3 Formatted output - printf_** on page 145 of original K\u0026R strongly suggest that the `f` stands for formatted:\n\nSearching in other sources will show that B's and C's `printf` [both seem to originate from BCPL's `writef` function](https://en.wikipedia.org/wiki/Printf_format_string#1960s:_BCPL.2C_ALGOL_68.2C_Multics_PL.2FI) which used already in 1966 the `%` formatting character.\n\nAlso worth to note that Algol68 also adopted `printf` function for formatted output. Yet the formatting logic was a little different.\n\nSource: https://softwareengineering.stackexchange.com/questions/317462/why-isnt-cs-most-basic-printing-function-named-print-instead-of-printf\n\n\n\n","lastmodified":"2023-11-19T19:19:34.214468801Z","tags":null},"/notes/2021/2021.9/i.e._Meaning":{"title":"i.e._Meaning","content":"# Latin Expression: i.e.\n\n\u003cdiv align=\"right\"\u003e 2021-09-11\u003c/div\u003e\n\nTags: #English \n\n## _id est (i.e.)_\n**that is** (literally \"**it is**\")\n\n\"**That is (to say)**\" in the sense of \"**that means**\" and \"**which means**\", or \"**in other words**\", \"**namely**\", or sometimes \"**in this case**\", depending on the context.\n\nused especially in writing before a piece of information that makes the meaning of something clearer or shows its true meaning\nä¹Ÿå°±æ˜¯ï¼Œå³\n\n- The hotel is closed during low season, i.e. from October to March. è¿™å®¶æ—…é¦†åœ¨æ·¡å­£ï¼Œå³ä»10æœˆåˆ°3æœˆï¼Œå…³é—¨åœä¸šã€‚\n- The price must be more realistic, i.e. lower. ä»·æ ¼å¿…é¡»æ›´åˆ‡åˆå®é™…äº›ï¼Œä¹Ÿå°±æ˜¯è¯´è¦æ›´ä½äº›ã€‚\n\n## More info\n- It is OK to use i.e. or e.g. in formal essays.[^1]\n- [List_of_Latin_abbreviations_on_Wikipedia](https://en.wikipedia.org/wiki/List_of_Latin_abbreviations)\n\n\n[^1]: Also, [[notes/2021/2021.9/OK_should_be_in_capital letters(or_okay)]]","lastmodified":"2023-11-19T19:19:34.222468932Z","tags":null},"/notes/2022/2022.1/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%AF%94%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%9B%B4%E9%AB%98%E6%95%88":{"title":"ä¸ºä»€ä¹ˆåå‘ä¼ æ’­æ¯”å‰å‘ä¼ æ’­æ›´é«˜æ•ˆ","content":"æ‰¾åˆ°äº†ä¸€ä¸ªå¾ˆå¥½çš„è§£é‡Š:\n\n\u003e ä¸ºä»€ä¹ˆè¯´åå‘ä¼ æ’­ç®—æ³•å¾ˆé«˜æ•ˆï¼Ÿè¦å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè®©æˆ‘ä»¬æ¥è€ƒè™‘å¦ä¸€ç§è®¡ç®—æ¢¯åº¦çš„æ–¹å¼ã€‚è®¾æƒ³ç°åœ¨æ˜¯ç¥ç»ç½‘ç»œç ”ç©¶çš„æ—©æœŸé˜¶æ®µï¼Œå¤§æ¦‚æ˜¯åœ¨ä¸Šä¸–çºª50å¹´ä»£æˆ–60å¹´ä»£å·¦å³ï¼Œå¹¶ä¸”ä½ æ˜¯ç¬¬ä¸€ä¸ªæƒ³åˆ°ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ–¹æ³•æ¥è¿›è¡Œè®­ç»ƒçš„äººï¼ä½†æ˜¯è¦å®ç°è¿™ä¸ªæƒ³æ³•ï¼Œä½ éœ€è¦ä¸€ç§è®¡ç®—ä»£ä»·å‡½æ•°æ¢¯åº¦çš„æ–¹å¼ã€‚ä½ å›æƒ³äº†ä½ ç›®å‰å…³äºæ¼”ç®—çš„çŸ¥è¯†ï¼Œå†³å®šè¯•ä¸€ä¸‹æ˜¯å¦èƒ½ç”¨é“¾å¼æ³•åˆ™æ¥è®¡ç®—æ¢¯åº¦ã€‚ä½†æ˜¯ç¢ç£¨äº†ä¸€ä¼šä¹‹åå‘ç°ï¼Œä»£æ•°è®¡ç®—çœ‹èµ·æ¥éå¸¸å¤æ‚ï¼Œä½ ä¹Ÿå› æ­¤æœ‰äº›å¤±è½ã€‚æ‰€ä»¥ä½ å°è¯•ç€å¯»æ‰¾å¦ä¸€ç§æ–¹æ³•ã€‚ä½ å†³å®šæŠŠä»£ä»·å•ç‹¬å½“åšæƒé‡çš„å‡½æ•°$C=C(w)$ï¼ˆæˆ‘ä»¬ä¸€ä¼šå†æ¥è®¨è®ºåç½®ï¼‰ã€‚å°†æƒé‡å†™ä½œ$w1,w2,â€¦$ï¼Œå¹¶ä¸”è¦å¯¹æŸä¸ªæƒé‡è®¡ç®—$âˆ‚C/âˆ‚w_j$ã€‚ä¸€ä¸ªå¾ˆæ˜æ˜¾çš„è®¡ç®—æ–¹å¼æ˜¯ä½¿ç”¨è¿‘ä¼¼ï¼š\n\u003e $$\\frac{\\partial C}{\\partial w_{j}} \\approx \\frac{C\\left(w+\\epsilon e_{j}\\right)-C(w)}{\\epsilon}$$\n\u003e å…¶ä¸­$\\epsilon$æ˜¯ä¸€ä¸ªå¤§äºé›¶çš„æå°æ•°, $e_j$æ˜¯ç¬¬$j$ä¸ªæ–¹å‘ä¸Šçš„å•ä½å‘é‡ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—ä¸¤ä¸ªå·®è·å¾ˆå°çš„$w_j$çš„ä»£ä»·ï¼Œç„¶ååˆ©ç”¨ä¸Šé¢çš„ç­‰å¼æ¥ä¼°è®¡$âˆ‚C/âˆ‚w_j$ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ç›¸åŒçš„æ€æƒ³æ¥å¯¹åç½®æ±‚åå¯¼$âˆ‚C/âˆ‚b$ã€‚\n\u003e\n\u003e è¿™ç§æ–¹å¼çœ‹èµ·æ¥å¾ˆä¸é”™ã€‚å®ƒçš„æ¦‚å¿µå¾ˆç®€å•ï¼Œå®ç°èµ·æ¥ä¹Ÿå¾ˆç®€å•ï¼Œåªéœ€è¦å‡ è¡Œä»£ç ã€‚å½“ç„¶äº†ï¼Œä»–çœ‹èµ·æ¥è¦æ¯”ä½¿ç”¨é“¾å¼æ³•åˆ™æ¥è®¡ç®—æ¢¯åº¦é è°±å¤šäº†ï¼\n\u003e\n\u003e ç„¶è€Œé—æ†¾çš„æ˜¯ï¼Œè™½ç„¶è¿™ç§æ–¹å¼çœ‹èµ·æ¥å¾ˆç¾å¥½ï¼Œä½†å½“ç”¨ä»£ç å®ç°ä¹‹åå°±ä¼šå‘ç°ï¼Œå®ƒå®åœ¨æ˜¯å¤ªæ…¢äº†ã€‚è¦ç†è§£å…¶ä¸­çš„åŸå› çš„è¯ï¼Œè®¾æƒ³åœ¨æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œä¸­æœ‰ä¸€ç™¾ä¸‡ä¸ªæƒé‡ï¼Œå¯¹äºæ¯ä¸€ä¸ªä¸åŒçš„æƒé‡$w_j$ï¼Œä¸ºäº†è®¡ç®—$C(w+Ïµe_j)$ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—$âˆ‚C/âˆ‚w_j$ã€‚è¿™æ„å‘³ç€ä¸ºäº†è®¡ç®—æ¢¯åº¦ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—ä¸€ç™¾ä¸‡æ¬¡ä»£ä»·å‡½æ•°ï¼Œè¿›è€Œå¯¹äºæ¯ä¸€ä¸ªè®­ç»ƒæ ·ä¾‹ï¼Œéƒ½éœ€è¦åœ¨ç¥ç»ç½‘ç»œä¸­å‰å‘ä¼ æ’­ä¸€ç™¾ä¸‡æ¬¡ã€‚æˆ‘ä»¬åŒæ ·éœ€è¦è®¡ç®—$C(w)$ï¼Œå› æ­¤æ€»è®¡éœ€è¦ä¸€ç™¾ä¸‡é›¶ä¸€æ¬¡å‰å‘ä¼ æ’­ã€‚\n\u003e\n\u003e åå‘ä¼ æ’­çš„ä¼˜ç‚¹åœ¨äºå®ƒä»…åˆ©ç”¨ä¸€æ¬¡å‰å‘ä¼ æ’­å°±å¯ä»¥åŒæ—¶è®¡ç®—å‡ºæ‰€æœ‰çš„åå¯¼$âˆ‚C/âˆ‚w_j$ï¼Œéšåä¹Ÿä»…éœ€è¦ä¸€æ¬¡åå‘ä¼ æ’­ã€‚å¤§è‡´æ¥è¯´ï¼Œåå‘ä¼ æ’­ç®—æ³•æ‰€éœ€è¦çš„æ€»è®¡ç®—é‡ä¸ä¸¤æ¬¡å‰å‘ä¼ æ’­çš„è®¡ç®—é‡åŸºæœ¬ç›¸ç­‰ï¼ˆè¿™åº”å½“æ˜¯åˆç†çš„ï¼Œä½†è‹¥è¦ä¸‹å®šè®ºçš„è¯åˆ™éœ€è¦æ›´åŠ ç»†è‡´çš„åˆ†æã€‚åˆç†çš„åŸå› åœ¨äºå‰å‘ä¼ æ’­æ—¶ä¸»è¦çš„è®¡ç®—é‡åœ¨äºæƒé‡çŸ©é˜µçš„ä¹˜æ³•è®¡ç®—ï¼Œè€Œåå‘ä¼ æ’­æ—¶ä¸»è¦çš„è®¡ç®—é‡åœ¨äºæƒé‡çŸ©é˜µè½¬ç½®çš„ä¹˜æ³•ã€‚å¾ˆæ˜æ˜¾ï¼Œå®ƒä»¬çš„è®¡ç®—é‡å·®ä¸å¤šï¼‰ã€‚è¿™ä¸åŸºäºç­‰å¼(46)çš„æ–¹æ³•æ‰€éœ€è¦çš„ä¸€ç™¾ä¸‡é›¶ä¸€æ¬¡å‰å‘ä¼ æ’­ç›¸æ¯”ï¼Œè™½ç„¶åå‘ä¼ æ’­çœ‹èµ·æ¥æ›´å¤æ‚ä¸€äº›ï¼Œä½†å®ƒç¡®å®æ›´æ›´æ›´æ›´æ›´å¿«ã€‚\n\u003e\n\u003e è¿™ç§åŠ é€Ÿæ–¹å¼åœ¨1986å¹´é¦–æ¬¡è¢«äººä»¬æ‰€é‡è§†ï¼Œæå¤§åœ°æ‹“å±•äº†ç¥ç»ç½‘ç»œèƒ½å¤Ÿé€‚ç”¨çš„èŒƒå›´ï¼Œä¹Ÿå¯¼è‡´äº†ç¥ç»ç½‘ç»œè¢«å¤§é‡çš„åº”ç”¨ã€‚å½“ç„¶äº†ï¼Œåå‘ä¼ æ’­ç®—æ³•ä¹Ÿä¸æ˜¯ä¸‡èƒ½çš„ã€‚åœ¨80å¹´ä»£åæœŸï¼Œäººä»¬ç»ˆäºè§¦åŠåˆ°äº†æ€§èƒ½ç“¶é¢ˆï¼Œåœ¨åˆ©ç”¨åå‘ä¼ æ’­ç®—æ³•æ¥è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆå³å…·æœ‰å¾ˆå¤šéšå«å±‚çš„ç½‘ç»œï¼‰æ—¶å°¤ä¸ºæ˜æ˜¾ã€‚åœ¨æœ¬ä¹¦åé¢çš„ç« èŠ‚ä¸­æˆ‘ä»¬å°†ä¼šçœ‹åˆ°ç°ä»£è®¡ç®—æœºä»¥åŠä¸€äº›éå¸¸èªæ˜çš„æ–°æƒ³æ³•æ˜¯å¦‚ä½•è®©åå‘ä¼ æ’­èƒ½å¤Ÿç”¨æ¥è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œçš„ã€‚\n\nSource: [ä¸ºä»€ä¹ˆè¯´åå‘ä¼ æ’­ç®—æ³•å¾ˆé«˜æ•ˆ Â· ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ](https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap2/c2s8.html) åŸæ–‡æ— å…¬å¼, å¯¹ç…§[è‹±æ–‡åŸæ–‡: Neural networks and deep learning](http://neuralnetworksanddeeplearning.com/chap2.html#in_what_sense_is_backpropagation_a_fast_algorithm)æ·»åŠ äº†å…¬å¼\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.1/%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B8%8D%E5%90%8C%E4%B9%98%E6%B3%95-Hadamard-Kronecker":{"title":"çŸ©é˜µçš„ä¸åŒä¹˜æ³•-Hadamard-Kronecker","content":"# çŸ©é˜µçš„ä¸åŒä¹˜ç§¯\n\n\u003cdiv align=\"right\"\u003e 2022-02-01\u003c/div\u003e\n\nTags: #Matrix #Math \n\n## ä¸€èˆ¬çš„çŸ©é˜µä¹˜æ³•\n![Matrix_multiplication_qtl1](notes/2022/2022.1/assets/Matrix_multiplication_qtl1.svg)\n\n## Hadamard Product $\\odot$\nå¯¹åº”ä½ç½®çš„å…ƒç´ ç›¸ä¹˜\n$$  \\begin{bmatrix}\n    a_{11} \u0026 a_{12} \u0026 a_{13}\\\\\n    a_{21} \u0026 a_{22} \u0026 a_{23}\\\\\n    a_{31} \u0026 a_{32} \u0026 a_{33}\n  \\end{bmatrix} \\circ \\begin{bmatrix}\n    b_{11} \u0026 b_{12} \u0026 b_{13}\\\\\n    b_{21} \u0026 b_{22} \u0026 b_{23}\\\\\n    b_{31} \u0026 b_{32} \u0026 b_{33}\n  \\end{bmatrix} = \\begin{bmatrix}\n    a_{11}\\, b_{11} \u0026 a_{12}\\, b_{12} \u0026 a_{13}\\, b_{13}\\\\\n    a_{21}\\, b_{21} \u0026 a_{22}\\, b_{22} \u0026 a_{23}\\, b_{23}\\\\\n    a_{31}\\, b_{31} \u0026 a_{32}\\, b_{32} \u0026 a_{33}\\, b_{33}\n  \\end{bmatrix}$$\n  -  **Hadamard product** ç¬¦å·è¡¨ç¤ºä¸º:  $A \\circ B$ or  $A \\odot B$\n![Hadamard_product_qtl1](notes/2022/2022.1/assets/Hadamard_product_qtl1.svg)\n\n## Kronecker Product $\\bigotimes$\n- å…‹ç½—å†…å…‹ç§¯ï¼ˆè‹±è¯­ï¼šKronecker productï¼‰æ˜¯ä¸¤ä¸ªä»»æ„å¤§å°çš„çŸ©é˜µé—´çš„è¿ç®—ï¼Œè¡¨ç¤ºä¸º$\\bigotimes$ã€‚å…‹ç½—å†…å…‹ç§¯æ˜¯å¤–ç§¯ä»å‘é‡åˆ°çŸ©é˜µçš„æ¨å¹¿ï¼Œä¹Ÿæ˜¯å¼ é‡ç§¯åœ¨æ ‡å‡†åŸºä¸‹çš„çŸ©é˜µè¡¨ç¤ºã€‚\n- ç±»ä¼¼äºå¤–ç§¯:\n- ![300](notes/2022/2022.1/assets/Pasted%20image%2020220201164342.png)\n- å¯¹äºå‘é‡: \n\t- $$\\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}$$\n\t\tå’Œ\n\t\t$$\\mathbf{w} = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_m \\end{bmatrix}$$\n\t\ttheir outer product or Kronecker product is given by the $n \\times m$ matrix\n\t\t$$\\mathbf{v} \\otimes \\mathbf{w} = \\begin{bmatrix} v_1 w_1 \u0026\u0026 v_1 w_2 \u0026\u0026 \\cdots \u0026\u0026 v_1 w_m \\\\ v_2 w_1 \u0026\u0026 v_2 w_2 \u0026\u0026 \\cdots \u0026\u0026 v_2 w_m \\\\ \\vdots \u0026\u0026 \\vdots \u0026\u0026 \\ddots \u0026\u0026 \\vdots \\\\ v_n w_1 \u0026\u0026 v_n w_2 \u0026\u0026 \\cdots \u0026\u0026 v_n w_m\\end{bmatrix}$$\n- è¿›ä¸€æ­¥åœ°, å¯¹äº $2 \\times 2$ çŸ©é˜µ $A$ å’Œ $3 \\times 2$ çŸ©é˜µ $B$ ä»–ä»¬çš„Kronecker Productæ˜¯$6 \\times 4$ çŸ©é˜µ: \n\t$$\n\t\\begin{aligned}\n\t\\mathrm{A} \\otimes \\mathrm{B} \u0026=\\left[\\begin{array}{lll}\n\ta_{11} \\mathrm{~B} \u0026 a_{12} \\mathrm{~B} \\\\\n\ta_{21} \\mathrm{~B} \u0026 a_{22} \\mathrm{~B}\n\t\\end{array}\\right] \\\\\n\t\u0026=\\left[\\begin{array}{llll}\n\ta_{11} b_{11} \u0026 a_{11} b_{12} \u0026 a_{12} b_{11} \u0026 a_{12} b_{12} \\\\\n\ta_{11} b_{21} \u0026 a_{11} b_{22} \u0026 a_{12} b_{21} \u0026 a_{12} b_{22} \\\\\n\ta_{11} b_{31} \u0026 a_{11} b_{32} \u0026 a_{12} b_{31} \u0026 a_{12} b_{32} \\\\\n\ta_{21} b_{11} \u0026 a_{21} b_{12} \u0026 a_{22} b_{11} \u0026 a_{22} b_{12} \\\\\n\ta_{21} b_{21} \u0026 a_{21} b_{22} \u0026 a_{22} b_{21} \u0026 a_{22} b_{22} \\\\\n\ta_{21} b_{31} \u0026 a_{21} b_{32} \u0026 a_{22} b_{31} \u0026 a_{22} b_{32}\n\t\\end{array}\\right]\n\t\\end{aligned}\n\t$$\n\n\n### [Tensor Product](D2L-1-What_is_a_tensor.md#Tensor%20Product) vs Kronecker Product\n[Tensors for Beginners 13: Tensor Product vs Kronecker Product - YouTube](https://www.youtube.com/watch?v=qp_zg_TD0qE)\n\n\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.1/D2L-1-What_is_a_tensor":{"title":"D2L-1-What_is_a_tensor","content":"# What is a *tensor*?\n\n\u003cdiv align=\"right\"\u003e 2022-01-25\u003c/div\u003e\n\nTags: #Tensor #DeepLearning\n\n- æœ€åˆ, **å¼ é‡**æ˜¯åœ¨ç‰©ç†å’Œæ•°å­¦é‡Œé¢çš„ä¸€ä¸ªæ¦‚å¿µ, åæ¥æ·±åº¦å­¦ä¹ å€Ÿç”¨äº†è¿™ä¸ªåè¯, ä½†æ˜¯æ„ä¹‰æœ‰æ‰€æ”¹å˜. \n- åœ¨**æ•°å­¦ä¸ç‰©ç†å­¦çš„è¯­å¢ƒ**é‡Œé¢, \"Tensor\"æ˜¯ä¸€ä¸ªæŠ½è±¡çš„æ¦‚å¿µ, ç”¨äºè¡¨ç¤ºåœ¨åæ ‡å˜æ¢ä¸‹çš„ä¸€ç§ä¸å˜é‡, æ¯”å¦‚å¹¿ä¹‰ç›¸å¯¹è®ºä¸­, åæ ‡çš„å˜æ¢ä¼šå¼•èµ·è§‚æµ‹çš„æ—¶ç©ºçš„å˜æ¢ã€‚è€Œçˆ±å› æ–¯å¦å¼ é‡ï¼ˆEinstein tensorï¼‰æ˜¯å¹¿ä¹‰ç›¸å¯¹è®ºä¸­ç”¨æ¥æè¿°æ—¶ç©ºæ›²ç‡çš„ä¸€ä¸ªå¼ é‡, ä¸éšåæ ‡çš„å˜æ¢è€Œå˜æ¢.\n- åœ¨**æ·±åº¦å­¦ä¹ çš„è¯­å¢ƒ**é‡Œé¢, \"Tensor\"æ˜¯å¤šç»´æ•°ç»„çš„ä¸€ç§è¡¨ç¤ºæ–¹å¼\n\n- è¦ç†æ¸…è¿™å…¶ä¸­çš„å…³ç³», è¿˜éœ€è¦ç¨å¾®æ·±å…¥çš„è®¤è¯†ä¸€ä¸‹å¼ é‡æ˜¯ä¸ªä»€ä¹ˆä¸œè¥¿.\n\n## å¼ é‡ - å«ä¹‰ä¸€\n![](notes/2022/2022.1/assets/img_2022-10-15.png)\n- åœ¨ç»™å®šåæ ‡ç³»çš„æƒ…å†µä¸‹, å¼ é‡å¯ä»¥è¡¨ç¤ºä¸ºå¤šç»´æ•°ç»„çš„å½¢å¼. æ¯”å¦‚æ ‡é‡(Scalar)å°±æ˜¯ä¸€ä¸ªé›¶é˜¶çš„å¼ é‡, å‘é‡æ˜¯ä¸€é˜¶çš„å¼ é‡, çŸ©é˜µæ˜¯äºŒé˜¶çš„å¼ é‡. åœ¨è¿™ä¸ªå«ä¹‰ä¸Š, å¼ é‡å¯ä»¥çœ‹ä½œçŸ©é˜µçš„æ›´é«˜é˜¶çš„æ¨å¹¿å½¢å¼.\n- ä½†æ˜¯è¿™ç§å®šä¹‰å¼ é‡çš„æ–¹å¼æ˜¯ç‰‡é¢çš„, æ²¡æœ‰è¡¨æ˜å¼ é‡\"åæ ‡ç³»å˜æ¢ä¸‹çš„ä¸å˜æ€§\"è¿™ä¸€ä¸ªé‡è¦çš„ç‰¹å¾, åé¢æˆ‘ä»¬ä¼šåšç®€è¦è¯´æ˜.\n\n## æ·±åº¦å­¦ä¹ é‡Œé¢çš„å¼ é‡\næœç´¢äº†å¤šæ–¹èµ„æ–™[^1], å¾—çŸ¥è®¡ç®—æœºç§‘å­¦é‡Œé¢çš„\"å¼ é‡\"åªæ˜¯ N-d Array çš„ä¸€ç§è¡¨è¿°æ–¹æ³•, å¯ä»¥çœ‹ä½œæ˜¯çŸ©é˜µè¡¨ç¤ºæ³•çš„ä¸€ç§å¤šç»´æ¨å¹¿, è€ŒçŸ©é˜µåªæ˜¯ä¸€ç§ç»„ç»‡æ•°å­—çš„äºŒä½å½¢å¼è€Œå·².\n![](notes/2022/2022.1/assets/img_2022-10-15-1.png)\n### Tensorflowä¸ºä»€ä¹ˆå«\"Tensor\"flow\næ ¹æ®Tensorflowç»™å®˜æ–¹æ•™ç¨‹: [^2]\n\u003e å¼ é‡æ˜¯å…·æœ‰ç»Ÿä¸€ç±»å‹ï¼ˆç§°ä¸º `dtype`ï¼‰çš„å¤šç»´æ•°ç»„ã€‚æ‚¨å¯ä»¥åœ¨ `tf.dtypes.DType` ä¸­æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„ `dtypes`ã€‚\n\u003e å¦‚æœæ‚¨ç†Ÿæ‚‰ [NumPy](https://numpy.org/devdocs/user/quickstart.html)ï¼Œå°±ä¼šçŸ¥é“å¼ é‡ä¸ `np.arrays` æœ‰ä¸€å®šçš„ç›¸ä¼¼æ€§ã€‚\n\nå’ŒWikipediaçš„ä»‹ç»: [^3]\n\u003e The name TensorFlow derives from the operations that such neural networks perform on multidimensional data arrays, which are referred to as _[tensors](https://en.wikipedia.org/wiki/Tensor \"Tensor\")_.\n\næ‰€ä»¥Tensorflowé‡Œé¢çš„Tensorå…¶å®å°±æ˜¯å¤šç»´æ•°ç»„çš„æ„æ€, ä¸å…·å¤‡æ•°å­¦å®šä¹‰ä¸Šå¼ é‡å…·å¤‡çš„å…¶ä»–æ€§è´¨.\n\n## å¼ é‡: å…¶ä»–å«ä¹‰\n- Youtubeä¸Šé¢çš„åšä¸»æœ‰ä¸€ä¸ªå…³äºå¼ é‡çš„è¯¦ç»†ä»‹ç»[^4], é‡Œé¢ç»™å‡ºäº†å¼ é‡çš„å¦å¤–ä¸¤ç§å®šä¹‰: \n\t- ![](notes/2022/2022.1/assets/img_2022-10-15-2.png)\n\t- ![](notes/2022/2022.1/assets/img_2022-10-15-3.png)\n- è€ƒè™‘å®šä¹‰2. ä»ä¸€é˜¶å¼ é‡, å³å‘é‡çš„è§’åº¦æ¥çœ‹, ä¸å˜çš„æ˜¯åæ ‡ç³»é‡Œé¢çš„å‘é‡è‡ªèº«, è€Œèƒ½å¤Ÿæ”¹å˜çš„Componentsæ˜¯å‘é‡çš„åæ ‡è¡¨ç¤º, è¿™ä¸ªåæ ‡è¡¨ç¤ºæ ¹æ®åæ ‡ç³»çš„å˜åŒ–è€Œå˜æ¢, å˜åŒ–çš„æ–¹å¼èƒ½å¤Ÿç”¨åŸºå˜æ¢çŸ©é˜µæ¥åˆ»ç”».\n\t- ![](notes/2022/2022.1/assets/img_2022-10-15-4.png)\n- ![500](notes/2022/2022.1/assets/img_2022-10-15-5.png)\n\n### Covector\nCovectoråœ¨æ­£äº¤åŸºä¸‹é¢å°±æ˜¯è¡Œå‘é‡, å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªå‡½æ•°, è¿™ä¸ªå‡½æ•°æŠŠå‘é‡æ˜ å°„æˆå®æ•°(å†…ç§¯).\n![](notes/2022/2022.1/assets/img_2022-10-15-6.png)\n- Covectorçš„å¯è§†åŒ–: \n![](notes/2022/2022.1/assets/img_2022-10-15-7.png)\n- Covectorçš„å˜æ¢è§„åˆ™:  $\\epsilon$æ˜¯covectorçš„åŸºå‘é‡, $\\alpha$æ˜¯covectoråœ¨$\\epsilon$ä¸‹çš„åæ ‡\n![](assets/Pasted%20image%2020220201004409.png)\n![](notes/2022/2022.1/assets/img_2022-10-15-8.png)\n### Tensor Product \n![|300](notes/2022/2022.1/assets/img_2022-10-15-9.png)\n- ä¸€ä¸ªå¾ˆå¥½çš„ç®€ä»‹: [The Tensor Product, Demystified](https://www.math3ma.com/blog/the-tensor-product-demystified)\n![](notes/2022/2022.1/assets/img_2022-10-15-10.png)\n### Linear Map\n![](notes/2022/2022.1/assets/img_2022-10-15-11.png)\n\n![](notes/2022/2022.1/assets/img_2022-10-15-12.png)\n\n\n\n\n\n[^1]: å¹¶æ²¡æœ‰æ‰¾åˆ°ä¸¥è°¨çš„æƒå¨èµ„æ–™. æ‰¾åˆ°çš„å¤§å¤šæ˜¯å’Œæˆ‘æœ‰åŒæ ·ç–‘é—®çš„ä¸€äº›äººçš„æé—®. æ¯”å¦‚: [Does the word tensor in TensorFlow have the same meaning with tensor in physics or mathematics? - Quora](https://www.quora.com/Does-the-word-tensor-in-TensorFlow-have-the-same-meaning-with-tensor-in-physics-or-mathematics) [machine learning - Why the sudden fascination with tensors? - Cross Validated](https://stats.stackexchange.com/questions/198061/why-the-sudden-fascination-with-tensors/198064#198064)\n[^2]: [å¼ é‡ç®€ä»‹ Â |Â  TensorFlow Core](https://www.tensorflow.org/guide/tensor?hl=zh-cn)\n[^3]: [TensorFlow - Wikipedia](https://en.wikipedia.org/wiki/TensorFlow#History)\n[^4]: [Tensors for Beginners 0: Tensor Definition - YouTube](https://www.youtube.com/watch?v=TvxmkZmBa-k\u0026list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG\u0026index=2)","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-10-%E5%B0%8F%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D":{"title":"D2L-10-å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™","content":"# å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™(Mini-Batch)æ˜¯æ·±åº¦å­¦ä¹ é»˜è®¤çš„æ±‚è§£æ–¹æ³•\n\n\u003cdiv align=\"right\"\u003e 2022-02-02\u003c/div\u003e\n\nTags: #MachineLearning #GradientDescent #DeepLearning #Optimization \n\n- [Different_Gradient_Descent_Methods](notes/2021/2021.8/Different_Gradient_Descent_Methods.md)\n\næ³¨æ„æœ‰ä¸¤ä¸ªç‚¹: å°æ‰¹é‡(Mini-Batch), éšæœº(Stochastic) æ¢¯åº¦ä¸‹é™\nå…¶ä¸­: \n- å°æ‰¹é‡æ˜¯å› ä¸ºåœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šé¢è®­ç»ƒä¸€æ¬¡åˆæ…¢åˆè´µ\n\t- åŒæ—¶å°æ‰¹é‡è¿˜èƒ½ä»å¤šä¸ªç›¸ä¼¼çš„æ•°æ®ç‚¹ä¸­é€‰ä¸€ä¸ªä»£è¡¨æ¥è®¡ç®—, èŠ‚çº¦äº†è®¡ç®—èµ„æº\n\t- ä½†æ˜¯æ ·æœ¬ä¸èƒ½å¤ªå°, å¤ªå°çš„æ ·æœ¬ä¸é€‚åˆç”¨GPUå¹¶è¡Œè®¡ç®—\n- éšæœºæ˜¯é€‰å–å°æ ·æœ¬çš„æ–¹æ³•: éšæœºé€‰å– ","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-11-%E6%B3%9B%E5%8C%96Generalization":{"title":"D2L-11-æ³›åŒ–(Generalization)","content":"# Generalization: æ³›åŒ–\n\n\u003cdiv align=\"right\"\u003e 2022-02-08\u003c/div\u003e\n\nTags: #MachineLearning #DeepLearning \n\n- çº¿æ€§å›å½’æ°å¥½æ˜¯ä¸€ä¸ªåœ¨æ•´ä¸ªåŸŸä¸­åªæœ‰ä¸€ä¸ªæœ€å°å€¼çš„å­¦ä¹ é—®é¢˜ã€‚ [^1]ä½†æ˜¯å¯¹äºåƒæ·±åº¦ç¥ç»ç½‘ç»œè¿™æ ·å¤æ‚çš„æ¨¡å‹æ¥è¯´ï¼ŒæŸå¤±å¹³é¢ä¸Šé€šå¸¸åŒ…å«å¤šä¸ªæœ€å°å€¼ã€‚ \n\n- æ·±åº¦å­¦ä¹ å®è·µè€…å¾ˆå°‘ä¼šå»èŠ±è´¹å¤§åŠ›æ°”å¯»æ‰¾è¿™æ ·ä¸€ç»„å‚æ•°ï¼Œä½¿å¾—åœ¨_è®­ç»ƒé›†_ä¸Šçš„æŸå¤±è¾¾åˆ°æœ€å°ã€‚ äº‹å®ä¸Šï¼Œæ›´éš¾åšåˆ°çš„æ˜¯æ‰¾åˆ°ä¸€ç»„å‚æ•°ï¼Œè¿™ç»„å‚æ•°èƒ½å¤Ÿåœ¨æˆ‘ä»¬ä»æœªè§è¿‡çš„æ•°æ®ä¸Šå®ç°è¾ƒä½çš„æŸå¤±ï¼Œ è¿™ä¸€æŒ‘æˆ˜è¢«ç§°ä¸º_**æ³›åŒ–**_ï¼ˆgeneralizationï¼‰ã€‚\n\n\n[^1]: å¯ä»¥è¯æ˜, æ­£åˆ™åçš„çº¿æ€§å›å½’æŸå¤±å‡½æ•°MSEä¾ç„¶æ˜¯å‡¸çš„: [æ­£åˆ™é¡¹ä¸å½±å“çº¿æ€§å›å½’æŸå¤±å‡½æ•°çš„å‡¸æ€§](notes/2021/2021.9/æ­£åˆ™é¡¹ä¸å½±å“çº¿æ€§å›å½’æŸå¤±å‡½æ•°çš„å‡¸æ€§.md)","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-2-Tensor%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C":{"title":"D2L-2-Tensoræ•°æ®æ“ä½œ","content":"# Tensoræ•°æ®æ“ä½œ\n\n\u003cdiv align=\"right\"\u003e 2022-02-01\u003c/div\u003e\n\nTags: #Tensor #DeepLearning \n\n## `[è¡Œ, åˆ—]`\nç”¨å†’å·å¯ä»¥è¡¨ç¤ºèŒƒå›´, å³ä¸€ä¸ªå­åŒºåŸŸ\n![](notes/2022/2022.1/assets/img_2022-10-15-13.png)\næ³¨æ„è¿˜å¯ä»¥ç”¨åŒå†’å·é—´éš”é€‰æ‹©, åŒå†’å·åçš„æ•°å­—ä¸ºé—´éš”çš„å‘¨æœŸ\n![](notes/2022/2022.1/assets/img_2022-10-15-14.png)\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-3-%E4%BA%9A%E5%AF%BC%E6%95%B0":{"title":"D2L-3-äºšå¯¼æ•°","content":"# äºšå¯¼æ•°\n\n\u003cdiv align=\"right\"\u003e 2022-02-01\u003c/div\u003e\n\nTags: #Math \n\n- å°†å¯¼æ•°æ‹“å±•åˆ°äº†ä¸å¯å¾®çš„å‡½æ•°: \n\t- ä¸¾ä¾‹: \n\t\t- ![](notes/2022/2022.1/assets/img_2022-10-15-15.png)\n\t\t- ![](notes/2022/2022.1/assets/img_2022-10-15-16.png)\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-4-%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC":{"title":"D2L-4-çŸ©é˜µæ±‚å¯¼","content":"# çŸ©é˜µæ±‚å¯¼\n\n\u003cdiv align=\"right\"\u003e 2022-02-01\u003c/div\u003e\n\nTags: #Math #Matrix \n\n- çŸ©é˜µçš„æ±‚å¯¼ä¸€ç›´å¾ˆè®©äººå¤´ç–¼ğŸ˜–\n- ä¹‹å‰çš„ç¬”è®°: [çŸ©é˜µçš„æ±‚å¯¼](notes/2021/2021.8/çŸ©é˜µçš„æ±‚å¯¼.md)\n- ææ²è¿™æ¬¡çš„è®²è§£æ–¹å¼ä¸å¤ªä¸€æ ·ï¼Œæ˜¯ä»æ ‡é‡é€æ­¥æ¨å¹¿åˆ°çŸ©é˜µï¼Œè¿˜è›®æ¸…æ™°çš„ã€‚\n\n## ä»æ ‡é‡åˆ°å‘é‡\n![400](notes/2022/2022.1/assets/img_2022-10-15-17.png)\nå…¶ä¸­ $\\Large{\\frac{\\partial y}{\\partial x}, \\frac{\\partial \\mathbf y}{\\partial x}}$éƒ½å¾ˆå¥½ç†è§£, å°¤å…¶éœ€è¦æ³¨æ„çš„æ˜¯å½“æ±‚å¯¼çš„è‡ªå˜é‡$\\mathbf x$ä¸ºå‘é‡çš„æ—¶å€™, ä¸º\n$$\\mathbf{x}=\\left[\\begin{array}{c}\nx_{1} \\\\\nx_{2} \\\\\n\\vdots \\\\\nx_{n}\n\\end{array}\\right] \\quad \\frac{\\partial y}{\\partial \\mathbf{x}}=\\left[\\frac{\\partial y}{\\partial x_{1}}, \\frac{\\partial y}{\\partial x_{2}}, \\ldots, \\frac{\\partial y}{\\partial x_{n}}\\right]$$\nç»“æœå˜æˆäº†ä¸€ä¸ªè¡Œå‘é‡.\n### Useful Results\n![](notes/2022/2022.1/assets/img_2022-10-15-18.png)\n#### $\\frac{\\partial \\|\\mathbf{x}\\|^2}{\\partial \\mathbf x}=2\\mathbf{x^T}$\n$$\\mathbf{x}=\\left[\\begin{array}{c}\nx_{1} \\\\x_{2} \\\\\\vdots \\\\x_{n}\n\\end{array}\\right]\\quad \\|\\mathbf{x}\\|^2=\\sum^n_1x_i^2$$\n$$\\begin{aligned}\n\\frac{\\partial\\|\\mathbf{x}\\|^2}{\\partial \\mathbf{x}}\u0026=\n\\left[\\frac{\\partial x_i^2}{\\partial x_{1}}, \\frac{\\partial x_i^2}{\\partial x_{2}}, \\ldots, \\frac{\\partial x_i^2}{\\partial\nx_{n}}\\right]\\\\\n\u0026=\\left[2x_1, 2x_{2}, \\ldots, 2x_{n}\\right]\\\\\n\u0026=2\\mathbf{x^T}\n\\end{aligned}$$\n\n\n### è¿›ä¸€æ­¥\nè€Œå½“$\\mathbf{x, y}$éƒ½æ˜¯å‘é‡çš„æ—¶å€™, å¯ä»¥è¿™æ ·ç†è§£:\n$$\\begin{aligned}\n\u0026\\mathbf{x}=\\left[\\begin{array}{c}\nx_{1} \\\\\nx_{2} \\\\\n\\vdots \\\\\nx_{n}\n\\end{array}\\right] \\quad \\mathbf{y}=\\left[\\begin{array}{c}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{m}\n\\end{array}\\right] \\\\\n\\end{aligned}$$\n$$\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}=\n\\left[\\begin{array}{c}\n\\frac{\\partial y_{1}}{\\partial \\mathbf{x}} \\\\\n\\frac{\\partial y_{2}}{\\partial \\mathbf{x}} \\\\\n\\vdots \\\\\n\\frac{\\partial y_{m}}{\\partial \\mathbf{x}}\n\\end{array}\\right]=\\begin{bmatrix}\n\\frac{\\partial y_{1}}{\\partial x_{1}}\u0026 \\frac{\\partial y_{1}}{\\partial x_{2}}\u0026 \\ldots\u0026 \\frac{\\partial y_{1}}{\\partial x_{n}} \\\\\n\\frac{\\partial y_{2}}{\\partial x_{1}}\u0026 \\frac{\\partial y_{2}}{\\partial x_{2}}\u0026 \\ldots\u0026 \\frac{\\partial y_{2}}{\\partial x_{n}} \\\\\n\u0026\u0026\\vdots \\\\\n\\frac{\\partial y_{m}}{\\partial x_{1}}\u0026 \\frac{\\partial y_{m}}{\\partial x_{2}}\u0026 \\ldots\u0026 \\frac{\\partial y_{m}}{\\partial x_{n}}\n\\end{bmatrix}$$\n\nä¹Ÿå°±æ˜¯è¯´: \n$$\\mathbf{x} \\in \\mathbb{R}^{n}, \\quad \\mathbf{y} \\in \\mathbb{R}^{m}, \\quad \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} \\in \\mathbb{R}^{m \\times n}$$\n\n### ç›´è§‚å«ä¹‰\n![](notes/2022/2022.1/assets/img_2022-10-15-19.png)\næ±‚å¯¼åå¾—åˆ°æ¢¯åº¦å‘é‡, ä¸ºå¢é•¿æœ€å¿«çš„æ–¹å‘\n\n### Useful Results\n#### $\\frac{\\partial \\mathbf x}{\\partial \\mathbf x}=I$\n$$\\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{x}}=\n\\begin{bmatrix}\n\\frac{\\partial x_{1}}{\\partial \\mathbf{x}} \\\\\n\\frac{\\partial x_{2}}{\\partial \\mathbf{x}} \\\\\n\\vdots \\\\\n\\frac{\\partial x_{m}}{\\partial \\mathbf{x}}\n\\end{bmatrix}=\\begin{bmatrix}\n\\frac{\\partial x_{1}}{\\partial x_{1}}\u0026 \\frac{\\partial x_{1}}{\\partial x_{2}}\u0026 \\ldots\u0026 \\frac{\\partial x_{1}}{\\partial x_{n}} \\\\\n\\frac{\\partial x_{2}}{\\partial x_{1}}\u0026 \\frac{\\partial x_{2}}{\\partial x_{2}}\u0026 \\ldots\u0026 \\frac{\\partial x_{2}}{\\partial x_{n}} \\\\\n\u0026\u0026\\vdots \\\\\n\\frac{\\partial x_{m}}{\\partial x_{1}}\u0026 \\frac{\\partial x_{m}}{\\partial x_{2}}\u0026 \\ldots\u0026 \\frac{\\partial x_{m}}{\\partial x_{n}}\n\\end{bmatrix}=\n\\begin{bmatrix}\n1 \u00260 \u0026\\ldots \u00260 \\\\\n0 \u00261 \u0026\\ldots \u00260 \\\\\n\\vdots \u0026\\vdots\u0026\\ddots \u0026\\vdots \\\\\n0 \u00260 \u0026\\ldots \u00261\n\\end{bmatrix}\n$$\n\n#### $\\frac{\\partial \\mathbf{Ax}}{\\partial \\mathbf x}=\\mathbf A$\n$$\\mathbf{x} \\in \\mathbb{R}^{n}, \\quad \\mathbf{A} \\in \\mathbb{R}^{m\\times n}$$\nä»¤$\\mathbf r_i$ä»£è¡¨çŸ©é˜µ$\\mathbf A$çš„è¡Œå‘é‡, ç”¨ $\\langle \\mathbf{a} , \\mathbf{b} \\rangle$è¡¨ç¤ºå†…ç§¯, ç¬¬äºŒè¡Œä¸ºäº†ç®€åŒ–è¡¨ç¤º, ä½¿ç”¨äº†[Einstein Notation](notes/2022/2022.1/Einstein%20Notation.md): \n\n$$\\begin{aligned}\\frac{\\partial \\mathbf{Ax}}{\\partial \\mathbf{x}}\u0026=\n\\begin{bmatrix}\n\\frac{\\partial \\langle r_1 , \\mathbf x\\rangle}{\\partial \\mathbf{x}} \\\\\n\\frac{\\partial \\langle r_2 , \\mathbf x\\rangle}{\\partial \\mathbf{x}} \\\\\n\\vdots \\\\\n\\frac{\\partial \\langle r_m , \\mathbf x\\rangle}{\\partial \\mathbf{x}} \\\\\n\\end{bmatrix}\\\\\u0026=\n\\large{\\begin{bmatrix}\n\\frac{\\partial a_{1i}x_i}{\\partial x_{1}}\u0026 \n\\frac{\\partial a_{1i}x_i}{\\partial x_{2}}\u0026 \n\\ldots\u0026 \n\\frac{\\partial a_{1i}x_i}{\\partial x_{n}} \\\\\n\\frac{\\partial a_{2i}x_i}{\\partial x_{1}}\u0026 \n\\frac{\\partial a_{2i}x_i}{\\partial x_{2}}\u0026 \n\\ldots\u0026 \n\\frac{\\partial a_{2i}x_i}{\\partial x_{n}} \\\\\n\u0026\u0026\\vdots \\\\\n\\frac{\\partial a_{mi}x_i}{\\partial x_{1}}\u0026 \n\\frac{\\partial a_{mi}x_i}{\\partial x_{2}}\u0026 \n\\ldots\u0026 \n\\frac{\\partial a_{mi}x_i}{\\partial x_{n}}\n\\end{bmatrix}}\\\\\u0026=\n\\begin{bmatrix}\na_{11} \u0026a_{12} \u0026\\ldots \u0026a_{1n} \\\\\na_{21} \u0026a_{22} \u0026\\ldots \u0026a_{2n} \\\\\n\\vdots \u0026\\vdots\u0026\\ddots \u0026\\vdots \\\\\na_{m1} \u0026a_{m2} \u0026\\ldots \u0026a_{mn}\n\\end{bmatrix}=\\mathbf{A}\n\\end{aligned}$$\n#### $\\frac{\\partial \\mathbf{x^{T}A}}{\\partial \\mathbf x}=\\mathbf{A^T}$\n$$\\mathbf{x} \\in \\mathbb{R}^{n}, \\quad \\mathbf{A} \\in \\mathbb{R}^{\\color{red}{n\\times m}}$$\nä»¤$\\mathbf c_i$ä»£è¡¨çŸ©é˜µ$\\mathbf A$çš„åˆ—å‘é‡:\n$$\\begin{aligned}\\frac{\\partial \\mathbf{x^{T}A}}{\\partial \\mathbf{x}}\u0026=\n\\begin{bmatrix}\n\\frac{\\partial \\langle c_1 , \\mathbf x\\rangle}{\\partial \\mathbf{x}} \\\\\n\\frac{\\partial \\langle c_2 , \\mathbf x\\rangle}{\\partial \\mathbf{x}} \\\\\n\\vdots \\\\\n\\frac{\\partial \\langle c_n , \\mathbf x\\rangle}{\\partial \\mathbf{x}} \\\\\n\\end{bmatrix}\\\\\u0026=\n\\large{\\begin{bmatrix}\n\\frac{\\partial a_{1i}x_i}{\\partial x_{1}}\u0026 \n\\frac{\\partial a_{1i}x_i}{\\partial x_{2}}\u0026 \n\\ldots\u0026 \n\\frac{\\partial a_{1i}x_i}{\\partial x_{n}} \\\\\n\\frac{\\partial a_{2i}x_i}{\\partial x_{1}}\u0026 \n\\frac{\\partial a_{2i}x_i}{\\partial x_{2}}\u0026 \n\\ldots\u0026 \n\\frac{\\partial a_{2i}x_i}{\\partial x_{n}} \\\\\n\u0026\u0026\\vdots \\\\\n\\frac{\\partial a_{mi}x_i}{\\partial x_{1}}\u0026 \n\\frac{\\partial a_{mi}x_i}{\\partial x_{2}}\u0026 \n\\ldots\u0026 \n\\frac{\\partial a_{mi}x_i}{\\partial x_{n}}\n\\end{bmatrix}}\\\\\u0026=\n\\begin{bmatrix}\na_{11} \u0026a_{12} \u0026\\ldots \u0026a_{1n} \\\\\na_{21} \u0026a_{22} \u0026\\ldots \u0026a_{2n} \\\\\n\\vdots \u0026\\vdots\u0026\\ddots \u0026\\vdots \\\\\na_{m1} \u0026a_{m2} \u0026\\ldots \u0026a_{mn}\n\\end{bmatrix}=\\mathbf{A^T}\n\\end{aligned}$$\n##### ç‰¹ä¾‹: $\\frac{\\partial \\mathbf{x^T}}{\\partial \\mathbf x}=\\mathbf{I}$\n$$\\frac{\\partial \\mathbf{x^T}}{\\partial \\mathbf x}=\n\\frac{\\partial\\mathbf{x^{T}I}}{\\partial \\mathbf x}=\\mathbf{I^T}=\\mathbf{I}$$\n\n### å¤åˆè¿ç®—\n![](notes/2022/2022.1/assets/img_2022-10-15-20.png)\n- éœ€è¦æ³¨æ„çš„æ˜¯$u, v$éƒ½æ˜¯æ ‡é‡, $\\mathbf{u,v}$åˆ™æ˜¯å‘é‡, ä¸Šé¢å¯ä»¥çœ‹å‡º**æ ‡é‡ç›¸ä¹˜çš„è¿ç®—å¾‹**å’Œ**å‘é‡ç›¸ä¹˜(å†…ç§¯)çš„è¿ç®—å¾‹**æ˜¯ä¸ä¸€æ ·çš„, å‘é‡å†…ç§¯éœ€è¦è½¬ç½®, å¹¶ä¸”äº¤æ¢ä½ç½®.\n\n\n## ä»å‘é‡åˆ°çŸ©é˜µ\n![](notes/2022/2022.1/assets/img_2022-10-15-21.png)\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-5-%E6%8B%93%E5%B1%95%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99":{"title":"D2L-5-æ‹“å±•é“¾å¼æ³•åˆ™","content":"# æ‹“å±•çš„æ±‚å¯¼é“¾å¼æ³•åˆ™\n\n\u003cdiv align=\"right\"\u003e 2022-02-02\u003c/div\u003e\n\nTags: #Math #Derivative \n\n- ä»æ ‡é‡åˆ°å‘é‡, ä¸ä»…ç¬¦å·éœ€è¦å¯¹åº”ä¸Š, çŸ©é˜µçš„å½¢çŠ¶ä¹Ÿéœ€è¦å¯¹åº”ä¸Š\n\n$$\\begin{align}\n\u0026\\frac{\\partial y}{\\partial \\mathbf{x}}=\\frac{\\partial y}{\\partial u} \\frac{\\partial u}{\\partial \\mathbf{x}}\\\\\n\u0026\\small{(1, n)}\\quad{(1,1)(1,n)}\n\\end{align}$$\n\n$$\\begin{align}\n\u0026\\frac{\\partial y}{\\partial \\mathbf{x}}=\\frac{\\partial y}{\\partial \\mathbf{u}} \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}}\\\\\n\u0026\\small{(1, n)}\\quad{(1,k)(k,n)}\n\\end{align}$$\n\n$$\\begin{align}\n\u0026\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}=\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{u}} \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}}\\\\\n\u0026\\small{(m, n)}\\quad{(m,k)(k,n)}\n\\end{align}$$\n\n## ä¾‹å­: çº¿æ€§å›å½’\n### å•ä¸ªæ ·æœ¬ç‚¹çš„æŸå¤±\n$$\\mathbf{x}, \\mathbf{w} \\in \\mathbb{R}^{n}, \\quad y \\in \\mathbb{R},\\quad z=(\\langle\\mathbf{x}, \\mathbf{w}\\rangle-y)^{2}$$\n- è®¡ç®—:  $$\\frac{\\partial z}{\\partial \\mathbf{w}}$$\n\n**è§£**:\n\n- åˆ©ç”¨é“¾å¼æ³•åˆ™: \n\t- é¦–å…ˆè¿›è¡Œå˜é‡æ›¿æ¢: \n\t\t- $a=\\langle\\mathbf{x}, \\mathbf{w}\\rangle$ , ä¸ºæ ‡é‡\n\t\t- $b=\\langle\\mathbf{x}, \\mathbf{w}\\rangle-y=a-y$, ä¸ºæ ‡é‡\n\t\t- $z=a^2$, ä¸ºæ ‡é‡\n\n\t- æˆ‘ä»¬æœ‰: $$\\begin{aligned}\n\t\\frac{\\partial z}{\\partial \\mathbf{w}} \u0026=\\frac{\\partial z}{\\partial b} \\frac{\\partial b}{\\partial a} \\frac{\\partial a}{\\partial \\mathbf{w}} \\\\\n\t\u0026=\\frac{\\partial b^{2}}{\\partial b} \\frac{\\partial (a-y)}{\\partial a} \\frac{\\partial\\langle\\mathbf{x}, \\mathbf{w}\\rangle}{\\partial \\mathbf{w}} \\\\\n\t(\\because \\langle\\mathbf{x}, \\mathbf{w}\\rangle=\\mathbf{x^T\\cdot w})\u0026=2 b \\cdot 1 \\cdot \\mathbf{x}^{T} \\\\\n\t\u0026=2(\\langle\\mathbf{x}, \\mathbf{w}\\rangle-y) \\mathbf{x}^{T}\n\t\\end{aligned}$$\n\t\n### nä¸ªæ ·æœ¬ç‚¹çš„æŸå¤±\n$$\\mathbf{X} \\in \\mathbb{R}^{m \\times n}, \\quad \\mathbf{w} \\in \\mathbb{R}^{n}, \\quad \\mathbf{y} \\in \\mathbb{R}^{m}$$\n$$\nz=\\|\\mathbf{X} \\mathbf{w}-\\mathbf{y}\\|^{2}\n$$\n- è®¡ç®—:  $$\\frac{\\partial z}{\\partial \\mathbf{w}}$$\n\n**è§£**:\n\n- åˆ©ç”¨é“¾å¼æ³•åˆ™: \n\t- é¦–å…ˆè¿›è¡Œå˜é‡æ›¿æ¢: \n\t\t- $\\mathbf a=\\mathbf{Xw},\\quad \\mathbf{a} \\in \\mathbb{R}^{m}$\n\t\t- $\\mathbf b=\\mathbf{a-y,\\quad b} \\in \\mathbb{R}^{m}$\n\t\t- $z=\\|\\mathbf{b}\\|^2$, ä¸ºæ ‡é‡\n\n\t- æˆ‘ä»¬æœ‰: $$\\begin{aligned}\n\t\\frac{\\partial z}{\\partial \\mathbf{w}} \u0026=\\frac{\\partial z}{\\partial \\mathbf{b}} \\frac{\\partial \\mathbf{b}}{\\partial \\mathbf{a}} \\frac{\\partial \\mathbf{a}}{\\partial \\mathbf{w}} \\\\\n\t\u0026=\\frac{\\partial\\|\\mathbf{b}\\|^{2}}{\\partial \\mathbf{b}} \\frac{\\partial \\mathbf{a}-\\mathbf{y}}{\\partial \\mathbf{a}} \\frac{\\partial \\mathbf{X} \\mathbf{w}}{\\partial \\mathbf{w}} \\\\\n\t\u0026=2 \\mathbf{b}^{T} \\times \\mathbf{I} \\times \\mathbf{X} \\\\\n\t\u0026=2(\\mathbf{X} \\mathbf{w}-\\mathbf{y})^{T} \\mathbf{X}\n\t\\end{aligned}$$\n\tæ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…:\n\t$$\\begin{aligned}\n\t\\frac{\\partial z}{\\partial \\mathbf{w}} \u0026=\\frac{\\partial z}{\\partial \\mathbf{b}} \\frac{\\partial \\mathbf{b}}{\\partial \\mathbf{a}} \\frac{\\partial \\mathbf{a}}{\\partial \\mathbf{w}} \\\\\n\t\\small{\\frac{1\\times 1}{n\\times 1}}\u0026=\\small{\\frac{1\\times 1}{m\\times 1}\\frac{m\\times 1}{m\\times 1}\\frac{m\\times 1}{n\\times 1}}\\\\\\small{1\\times n}\u0026=\\small{(1\\times m)\\space (m\\times m) (m\\times n)}\\end{aligned}$$\n\t\n\n\n\t\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-6-%E8%AE%A1%E7%AE%97%E5%9B%BE":{"title":"D2L-6-è®¡ç®—å›¾","content":"# è®¡ç®—å›¾\n\n\u003cdiv align=\"right\"\u003e 2022-02-02\u003c/div\u003e\n\nTags: #MachineLearning #DeepLearning \n\n- å°†è®¡ç®—è¡¨ç¤ºä¸ºä¸€ä¸ªæ— ç¯å›¾\n\n[ä¾‹å­ çº¿æ€§å›å½’](notes/2022/2022.1/D2L-5-æ‹“å±•é“¾å¼æ³•åˆ™.md#ä¾‹å­%20çº¿æ€§å›å½’):\n![](notes/2022/2022.1/assets/img_2022-10-15-22.png)\n\n- è®¡ç®—å›¾æœ‰ä¸¤ç§æ„é€ æ–¹æ³•:\n\t- **æ˜¾å¼æ„é€ **\n\t\t- ä¸»è¦åº”ç”¨äº:  `Tensorflow/Theano/MXNet`\n\t\t- ä¾‹å­: \n\t```python\n\tfrom mxnet import sym\n\ta = sym.var()\n\tb = sym.var()\n\tc = 2 * a + b\n\t# bind data into a and b later\n\t```\n\t- **éšå¼æ„é€ **\n\t\t- ä¸»è¦åº”ç”¨äº: `PyTorch/MXNet`\n\t\t- ä¾‹å­: \n\t```python\n\tfrom mxnet import autograd, nd\n\twith autograd.record():\n\ta = nd.ones((2,1))#åˆ›å»ºä¸¤ä¸ªäºŒç»´å‘é‡\n\tb = nd.ones((2,1))\n\tc = 2 * a + b\n\t```\n\t","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-7-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC":{"title":"D2L-7-è‡ªåŠ¨æ±‚å¯¼","content":"# è‡ªåŠ¨æ±‚å¯¼\n\n\u003cdiv align=\"right\"\u003e 2022-02-02\u003c/div\u003e\n\nTags: #DeepLearning \n\nåœ¨æœºå™¨å­¦ä¹ é‡Œé¢, æ·±åº¦å­¦ä¹ æ¡†æ¶å¯ä»¥å¸®æˆ‘ä»¬è‡ªåŠ¨æ±‚å¯¼, è®¡ç®—æ¢¯åº¦.\n\n## è‡ªåŠ¨æ±‚å¯¼çš„ä¸¤ç§æ–¹å¼\nåŸºäºé“¾å¼æ³•åˆ™, æ±‚å¯¼æœ‰ä¸¤ç§é¡ºåº:\n- æ­£å‘ç´¯ç§¯ \n$$\\frac{\\partial y}{\\partial x}=\\frac{\\partial y}{\\partial u_{n}}\\left(\\frac{\\partial u_{n}}{\\partial u_{n-1}}\\left(\\ldots\\left(\\frac{\\partial u_{2}}{\\partial u_{1}} \\frac{\\partial u_{1}}{\\partial x}\\right)\\right)\\right)$$\n- åå‘ç´¯ç§¯ã€åˆç§°åå‘ä¼ é€’\n$$\n\\frac{\\partial y}{\\partial x}=\\left(\\left(\\left(\\frac{\\partial y}{\\partial u_{n}} \\frac{\\partial u_{n}}{\\partial u_{n-1}}\\right) \\ldots\\right) \\frac{\\partial u_{2}}{\\partial u_{1}}\\right) \\frac{\\partial u_{1}}{\\partial x}\n$$\n\n## åå‘ç´¯ç§¯/ä¼ æ’­\nåå‘ä¼ æ’­åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µ: æ­£å‘é˜¶æ®µå’Œåå‘é˜¶æ®µ\n\nä¾‹å­: $$z=(\\langle\\mathbf{x}, \\mathbf{w}\\rangle-y)^{2}$$\n### æ­£å‘é˜¶æ®µ\n![400](notes/2022/2022.1/assets/img_2022-10-15-23.png)\næ ¹æ®[è®¡ç®—å›¾](notes/2022/2022.1/D2L-6-è®¡ç®—å›¾.md), æˆ‘ä»¬å…ˆæŒ‰ç…§ç®­å¤´çš„æ–¹å‘**å‘å‰**è®¡ç®—ä¸€æ¬¡, å¹¶ä¸”å­˜å‚¨æ¯ä¸€æ­¥çš„ä¸­é—´ç»“æœ. åœ¨åå‘è®¡ç®—çš„æ—¶å€™, æˆ‘ä»¬éœ€è¦ç”¨è¿™äº›ä¸­é—´ç»“æœæ¥è®¡ç®—æ¢¯åº¦.\n\n### åå‘é˜¶æ®µ\n![Backpropagation](notes/2022/2022.1/assets/img_2022-10-15.gif)\nåå‘ä¼ æ’­é€šè¿‡ä¸æ–­è°ƒç”¨å‰ä¸€æ­¥çš„ç»“æœ, ä»å‰å‘åè®¡ç®—æ¯ä¸€æ­¥çš„åå¯¼æ•°.\n\n\n## ä¸ºä»€ä¹ˆåå‘ä¼ æ’­æ¯”å‰å‘ä¼ æ’­æ›´é«˜æ•ˆ?\n[ä¸ºä»€ä¹ˆåå‘ä¼ æ’­æ¯”å‰å‘ä¼ æ’­æ›´é«˜æ•ˆ](notes/2022/2022.1/ä¸ºä»€ä¹ˆåå‘ä¼ æ’­æ¯”å‰å‘ä¼ æ’­æ›´é«˜æ•ˆ.md)\n\n\n## PyTorchçš„Autograd\n[PyTorch Autograd Explained - In-depth Tutorial - YouTube](https://www.youtube.com/watch?v=MswxJw-8PvE)","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-8-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E7%9C%8B%E4%BD%9C%E5%8D%95%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C":{"title":"D2L-8-çº¿æ€§æ¨¡å‹å¯ä»¥çœ‹ä½œå•å±‚ç¥ç»ç½‘ç»œ","content":"\n$$y=w_{1} x_{1}+w_{2} x_{2}+\\ldots+w_{n} x_{n}+b$$\n![](notes/2022/2022.1/assets/img_2022-10-15-24.png)\n\nLinks:\n\n- [Part.3_Linear_Regression(ML_Andrew.Ng.)](notes/2021/2021.8/Part.3_Linear_Regression(ML_Andrew.Ng.).md)\n- [Part.24_Neural_Network-Examples(ML_Andrew.Ng.)](notes/2021/2021.9/Part.24_Neural_Network-Examples(ML_Andrew.Ng.).md)\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/D2L-9-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E6%96%B9%E5%90%91":{"title":"D2L-9-æ¢¯åº¦ä¸‹é™çš„æ–¹å‘","content":"# æ¢¯åº¦ä¸‹é™çš„æ–¹å‘æ˜¯æ¢¯åº¦çš„åæ–¹å‘\n\n\u003cdiv align=\"right\"\u003e 2022-02-02\u003c/div\u003e\n\nTags: #GradientDescent #DeepLearning #MachineLearning \n\n- æ¢¯åº¦æ˜¯ä¸€ä¸ªå‡½æ•°**å¢é•¿æœ€å¿«**çš„æ–¹å‘, é€šå¸¸æˆ‘ä»¬éƒ½æ˜¯æƒ³è·å¾—**æŸå¤±å‡½æ•°çš„æœ€å°å€¼**, æ‰€ä»¥éœ€è¦æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘æ¥ç§»åŠ¨.\n\n- æ³¨æ„è¿™å¹¶ä¸æ˜¯ä¸€å®šçš„, [æ¢¯åº¦ä¸‹é™](notes/2021/2021.8/Part.5_Gradient_Descent(ML_Andrew.Ng.).md)/ä¸Šå‡åªæ˜¯ä¸€ç§ä¼˜åŒ–æ–¹æ³•è€Œå·², å¦‚æœæˆ‘ä»¬æƒ³è¦ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°å–å¾—æœ€å¤§å€¼, é‚£ä¹ˆå°±åº”è¯¥æ²¿ç€æ¢¯åº¦çš„æ–¹å‘å˜åŒ–.\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/Dummy_Variables":{"title":"Dummy_Variables","content":"# Dummy Variable\n\n\u003cdiv align=\"right\"\u003e 2022-02-10\u003c/div\u003e\n\nTags: #Math/Statistics \n\n[Dummy variable (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Dummy_variable_(statistics))\n\u003e In statistics and econometrics, particularly in regression analysis, a dummy variable is one that takes only the value 0 or 1 to indicate the absence or presence of some categorical effect that may be expected to shift the outcome.\n\nDummy Variable é‡Œé¢çš„Dummyå¯ä¸æ˜¯å‚»å­çš„æ„æ€, è¿™é‡Œçš„Dummyçš„æ„æ€æ˜¯\"å‡çš„, è¾…åŠ©çš„\", æ„æ€æ˜¯è¿™ä¸ªå˜é‡ä»…ä»…ç”¨äºè¡¨ç¤ºæŸä¸ªå› ç´ å­˜åœ¨ä¸å¦, è€Œæ²¡æœ‰å®é™…æ„ä¹‰, å¾ˆç±»ä¼¼äº[Kronecker delta](notes/2022/2022.1/Kronecker%20delta%20-%20å…‹ç½—å†…å…‹Î´å‡½æ•°.md) $\\delta_{ij}$åœ¨çº¿æ€§ä»£æ•°ä¸­çš„åº”ç”¨.\n\nä¸€ä¸ªå®ä¾‹å¯ä»¥å¾ˆå¥½çš„è§£é‡ŠDummy Variableçš„ä½œç”¨: \n\n- **Section 1**\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9yTui_LoSOc?start=175\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- **Section 2**\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9yTui_LoSOc?start=944\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/Einstein-Notation":{"title":"Einstein Notation","content":"# Einstein Notation\n\n\u003cdiv align=\"right\"\u003e 2022-02-01\u003c/div\u003e\n\nTags: #Tensor #EinsteinNotation \n\n- [Einstein notation - Wikipedia](https://en.wikipedia.org/wiki/Einstein_notation)\n- ä¸€ç§æ±‚å’Œç¬¦å·çš„ç®€åŒ–ä¹¦å†™æ–¹å¼, åœ¨å¼ é‡è¿ç®—ä¸­ç»å¸¸ä½¿ç”¨, ç”±çˆ±å› æ–¯å¦å‘æ˜.\n\n\u003ciframe width=\"720\" height=\"480\" src=\"https://www.youtube.com/embed/SSSGA6ohkfw?start=340\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\n\u003ciframe width=\"720\" height=\"480\" src=\"https://www.youtube.com/embed/CLrTj7D2fLM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/Kronecker-delta-%E5%85%8B%E7%BD%97%E5%86%85%E5%85%8B%CE%B4%E5%87%BD%E6%95%B0":{"title":"Kronecker delta - å…‹ç½—å†…å…‹Î´å‡½æ•°","content":"# Kronecker delta\n\n\u003cdiv align=\"right\"\u003e 2022-02-10\u003c/div\u003e\n\nTags: #Math \n\n$$\\delta_{ij} = \\left\\{\\begin{matrix} \n1 \u0026 (i=j)  \\\\ \n0 \u0026 (i \\ne j) \\end{matrix}\\right.$$\n\nåœ¨çº¿æ€§ä»£æ•°ä¸­ï¼Œå•ä½çŸ©é˜µå¯ä»¥å†™ä½œ $\\left(\\delta_{i j}\\right)_{i, j=1}^{n}$\n\n","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.1/One-hot_Encoding-%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81":{"title":"One-hot_Encoding-ç‹¬çƒ­ç¼–ç ","content":"# ç‹¬çƒ­ç¼–ç  One-hot Encoding\n\n\u003cdiv align=\"right\"\u003e 2022-02-09\u003c/div\u003e\n\nTags: #One-hot #DeepLearning #Encoding\n\n\n$$\\begin{array}{ll}\n    apple \u0026=\\quad [\\space 1\\quad 0\\quad 0\\space ] \\\\\n    banana \u0026=\\quad [\\space 0\\quad 1\\quad 0\\space ] \\\\\n    pineapple \u0026=\\quad [\\space 0\\quad 0\\quad 1\\space ]\n\\end{array}$$\n\n\u003e [Dive into Deep Learning](https://zh-v2.d2l.ai/chapter_linear-networks/softmax-regression.html#subsec-classification-problem): \n\u003e ç»Ÿè®¡å­¦å®¶å¾ˆæ—©ä»¥å‰å°±å‘æ˜äº†ä¸€ç§è¡¨ç¤ºåˆ†ç±»æ•°æ®çš„ç®€å•æ–¹æ³•ï¼š_ç‹¬çƒ­ç¼–ç _ï¼ˆone-hot encodingï¼‰: \n\u003e [[notes/2022/2022.1/Dummy_Variables]]","lastmodified":"2023-11-19T19:19:34.226468997Z","tags":null},"/notes/2022/2022.10/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B":{"title":"ç»å…¸æ¨¡å‹","content":"- [LeNet](notes/2022/2022.2/D2L-39-LeNet.md)\n- [AlexNet](notes/2022/2022.2/D2L-40-AlexNet.md)\n- [VGG](notes/2022/2022.2/D2L-41-VGG.md)\n- [NiN](notes/2022/2022.3/D2L-42-NiN.md)\n- [GoogLeNet(Inception)](notes/2022/2022.3/D2L-43-GoogLeNet(Inception).Md)\n- [ResNet](notes/2022/2022.3/D2L-45-ResNet.md)\n- [DenseNet](notes/2022/2022.3/D2L-46-DenseNet.md)\n- [RNN](notes/2022/2022.4/D2L-53-å¾ªç¯ç¥ç»ç½‘ç»œRNN.md)\n- [LSTM](notes/2022/2022.4/D2L-57-LSTM-é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ.md)\n- [GRU](notes/2022/2022.4/D2L-56-é—¨æ§å¾ªç¯å•å…ƒGRU.md)\n- [Encoder-Decoder](notes/2022/2022.4/D2L-60-Encoder-Decoder.md)\n- [BERT](notes/2022/2022.4/D2L-75-BERT.md)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.10/Gilbert-Strang-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%9F%A9%E9%98%B5%E7%9F%A5%E8%AF%86":{"title":"Gilbert Strang æ·±å…¥æµ…å‡ºæœºå™¨å­¦ä¹ çš„çŸ©é˜µçŸ¥è¯†","content":"\n- [MIT 18.065 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning,](notes/2021/2021.11/MIT%2018.065%20Matrix%20Methods%20in%20Data%20Analysis,%20Signal%20Processing,%20and%20Machine%20Learning,.md)\n- [MIT_18.065-Part_1-A_Column_Space_Perspective](notes/2021/2021.11/MIT_18.065-Part_1-A_Column_Space_Perspective.md)\n- [MIT_18.065-Part_2-Matrix_Factorization](notes/2021/2021.11/MIT_18.065-Part_2-Matrix_Factorization.md)\n- [MIT_18.065-Part_3-A_Different_Perspectvie_of_Matrix_Multiplication-An_Example](notes/2021/2021.11/MIT_18.065-Part_3-A_Different_Perspectvie_of_Matrix_Multiplication-An_Example.md)\n- [MIT_18.065-Part_4-LU_Factorization](notes/2021/2021.11/MIT_18.065-Part_4-LU_Factorization.md)\n- [MIT_18.065-Part_5-Four_Subspaces](notes/2021/2021.11/MIT_18.065-Part_5-Four_Subspaces.md)\n- [MIT_18.065-Part_6-Orthonormal Columns in Q Give Q'Q = I](notes/2021/2021.11/MIT_18.065-Part_6-Orthonormal%20Columns%20in%20Q%20Give%20Q'Q%20=%20I.Md)\n- [MIT_18.065-Part_7-Eigenvalues and Eigenvectors](notes/2021/2021.11/MIT_18.065-Part_7-Eigenvalues%20and%20Eigenvectors.md)\n- [MIT_18.065-Part_8-Positive Definite and Semidefinite Matrices](notes/2021/2021.11/MIT_18.065-Part_8-Positive%20Definite%20and%20Semidefinite%20Matrices.md)\n- [MIT_18.065-Part_9-Singular Value Decomposition-SVD](notes/2021/2021.11/MIT_18.065-Part_9-Singular%20Value%20Decomposition-SVD.md)\n- [MIT_18.065-Part_10-SVD_in_Action](notes/2021/2021.11/MIT_18.065-Part_10-SVD_in_Action.md)\n- [MIT_18.065-Part_11-SVD_\u0026_Linear_System](notes/2021/2021.11/MIT_18.065-Part_11-SVD_\u0026_Linear_System.md)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%82%E6%95%B0%E4%B8%8D%E8%83%BD%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%BA%E5%90%8C%E4%B8%80%E4%B8%AA%E5%B8%B8%E6%95%B0":{"title":"ä¸ºä»€ä¹ˆå‚æ•°ä¸èƒ½åˆå§‹åŒ–ä¸ºåŒä¸€ä¸ªå¸¸æ•°","content":"# æ·±åº¦å­¦ä¹ : å‚æ•°åŒ–æ‰€å›ºæœ‰çš„å¯¹ç§°æ€§\n\n\u003cdiv align=\"right\"\u003e 2022-02-19\u003c/div\u003e\n\nTags: #DeepLearning \n\n- [4.8.1.3. æ‰“ç ´å¯¹ç§°æ€§](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html#id5 \"Permalink to this headline\")\n\n\u003e - å¯¹äºä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœº, å‡è®¾éšè—å±‚åªæœ‰ä¸¤ä¸ªå•å…ƒ, è¾“å‡ºå±‚åªæœ‰ä¸€ä¸ªè¾“å‡ºå•å…ƒã€‚ æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœæˆ‘ä»¬å°†éšè—å±‚çš„æ‰€æœ‰å‚æ•°åˆå§‹åŒ–ä¸º $W^{(1)}=c$ï¼Œ $c$ ä¸ºå¸¸é‡ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ \n\u003e - åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨å‰å‘ä¼ æ’­æœŸé—´ï¼Œä¸¤ä¸ªéšè—å•å…ƒé‡‡ç”¨ç›¸åŒçš„è¾“å…¥å’Œå‚æ•°ï¼Œ äº§ç”Ÿç›¸åŒçš„æ¿€æ´»ï¼Œè¯¥æ¿€æ´»è¢«é€åˆ°è¾“å‡ºå•å…ƒã€‚ åœ¨åå‘ä¼ æ’­æœŸé—´ï¼Œæ ¹æ®å‚æ•° $W^{(1)}$ å¯¹è¾“å‡ºå•å…ƒè¿›è¡Œå¾®åˆ†ï¼Œ å¾—åˆ°ä¸€ä¸ªæ¢¯åº¦ï¼Œå…¶å…ƒç´ éƒ½å–ç›¸åŒçš„å€¼ã€‚ å› æ­¤ï¼Œåœ¨ä¸€æ¬¡æ¢¯åº¦ä¸‹é™ï¼ˆä¾‹å¦‚ï¼Œå°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ï¼‰ä¹‹åï¼Œ $W^{(1)}$ çš„æ‰€æœ‰å…ƒç´ ä»ç„¶æœ‰ç›¸åŒçš„å€¼ã€‚ è€Œæ¯ä¸€æ¬¡è¿­ä»£æ°¸è¿œéƒ½ä¸ä¼šæ‰“ç ´å¯¹ç§°æ€§ï¼Œè¿™ä¹Ÿæ„å‘³ç€éšè—å±‚çš„è¡Œä¸ºå°±å¥½åƒåªæœ‰ä¸€ä¸ªå•å…ƒ, æˆ‘ä»¬æ°¸è¿œä¹Ÿæ— æ³•åˆ©ç”¨å¤šå±‚ç½‘ç»œå¼ºå¤§çš„è¡¨è¾¾èƒ½åŠ›ã€‚ \n\u003e - è¯·æ³¨æ„ï¼Œè™½ç„¶å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ä¸ä¼šæ‰“ç ´è¿™ç§å¯¹ç§°æ€§ï¼Œä½†æš‚é€€æ³• [(Dropout-ä¸¢å¼ƒæ³•)](notes/2022/2022.2/D2L-23-Dropout-ä¸¢å¼ƒæ³•.md) æ­£åˆ™åŒ–å¯ä»¥ã€‚","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E4%B8%BA%E4%BB%80%E4%B9%88Softmax%E5%9B%9E%E5%BD%92%E4%B8%8D%E7%94%A8MSE":{"title":"ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE","content":"# ä¸ºä»€ä¹ˆSoftmax (æˆ–è€…Logistic) ä¸ç”¨MSEä½œä¸ºæŸå¤±å‡½æ•°?\n\n\u003cdiv align=\"right\"\u003e 2022-02-28\u003c/div\u003e\n\nTags: #DeepLearning #MachineLearning #SoftmaxRegression #LogisticRegression #CostFunction #MeanSquareError #CrossEntropy \n\n- **å›é¡¾:** \n\t- MSEå‡è®¾æ ·æœ¬è¯¯å·®i.i.d., å¹¶ä¸”æœä»æ­£æ€åˆ†å¸ƒ, æœ€å°åŒ–MSEç­‰ä»·äºæå¤§ä¼¼ç„¶ä¼°è®¡. é€šå¸¸ç”¨äºå›å½’é—®é¢˜. MSEåŸºäºè¾“å‡ºä¸çœŸå®å€¼çš„æ¬§æ°è·ç¦».\n\t- æœ€å°åŒ–Cross Entropyç­‰ä»·äºæœ€å°åŒ–KLæ•£åº¦, ç›¸å½“äºæœ€å°åŒ–è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒä¸çœŸå®æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„åŒºåˆ«. é€šå¸¸ç”¨äºåˆ†ç±»é—®é¢˜\n\n- åœ¨åˆ†ç±»é—®é¢˜é‡Œé¢, æˆ‘ä»¬ä¸ä½¿ç”¨MSEçš„åŸå› ä¸»è¦æœ‰: \n\t- **åˆ†ç±»é—®é¢˜é‡Œé¢MSEå¹¶ä¸æ˜¯ä¸€ä¸ªå‡¸å‡½æ•°**, è¿™å¯èƒ½ä¼šå¯¼è‡´ç®—æ³•æ— æ³•å­¦ä¹ åˆ°æœ€ä¼˜çš„å‚æ•°.\n\t- äº¤å‰ç†µæ¢¯åº¦çš„**å˜åŒ–è¶‹åŠ¿**ä¸**å€¼åŸŸ**éƒ½æ›´ç†æƒ³:\n\n\t- äº¤å‰ç†µçš„**è®¡ç®—æ›´ç®€å•**.\n\n- ä¸‹é¢æˆ‘ä»¬ä¾æ¬¡æ¢ç©¶è¿™å‡ ç‚¹, ç”±äºLogisticå›å½’å°±æ˜¯ç‰¹æ®Šçš„Softmaxå›å½’, æˆ‘ä»¬å…ˆè®¨è®ºé€»è¾‘æ–¯è’‚å›å½’, ç„¶åå†è¿›ä¸€æ­¥è®¨è®ºSoftmax.\n\n## Logistic\n- æˆ‘ä»¬å…ˆè¿›è¡Œå…¬å¼æ¨å¯¼, ç„¶åè¿›è¡Œç›¸åº”çš„è§£é‡Š.\n\n### å…¬å¼æ¨å¯¼\n- å¯¹äºä¸€ä¸ªæ ·æœ¬ $(\\mathbf{x}, y)$ å›å¿† [Logistic Regressionçš„Hypothesis](notes/2021/2021.8/Part.12_Logistic_Regression(ML_Andrew.Ng.).md) (æˆ‘ä»¬å°†åç½®ç›´æ¥åŠ åˆ° $\\mathbf{w, x}$ é‡Œé¢): \t\n\t$$h(\\mathbf{x})=\\operatorname{Sigmoid}(\\mathbf{w^T x})$$\n- **æŸå¤±å‡½æ•°ä¸ºäº¤å‰ç†µ:** \n\t[Part.13_Cost_Function-Logistic_Regression(ML_Andrew.Ng.)](notes/2021/2021.8/Part.13_Cost_Function-Logistic_Regression(ML_Andrew.Ng.).md)]\n\t$$L\\left(h(\\mathbf{x}), y\\right)=-y \\log \\left(h(\\mathbf{x})\\right)-(1-y) \\log \\left(1-h(\\mathbf{x})\\right)$$\n\t- å¯¹å…¶æ±‚å¯¼[Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.)](notes/2021/2021.8/Part.14_Logistic_Regression\u0026Gradient_Descent(ML_Andrew.Ng.).md)\n\t$$\\frac{\\partial}{\\partial w_{j}} L\\left(h(\\mathbf{x}), y\\right)\n\t=\\left(y-h(\\mathbf x)\\right) x_{j}$$\n\t- å¯¹å…¶æ±‚äºŒé˜¶å¯¼:\n\t\t[è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°](notes/2021/2021.9/è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°.md)\n\t$$\\frac{\\partial^2}{\\partial w_{j}^2} L\\left(h(\\mathbf{x}), y\\right)\n\t=h(\\mathbf x)\\left(1-h(\\mathbf x)\\right) x^2_{j}$$\n\t- éœ€è¦æ³¨æ„çš„æ˜¯ä¸Šé¢éƒ½æ˜¯å¯¹äºä¸€ä¸ªæ ·æœ¬çš„æƒ…å†µ, [å¯¹äºå¤šä¸ªæ ·æœ¬éœ€è¦åŠ ä¸Šæ±‚å’Œç¬¦å·](notes/2022/2022.2/å¯è§†åŒ–æŸå¤±å‡½æ•°çš„å›°éš¾.md)\n\t\n- **æŸå¤±å‡½æ•°ä¸ºMSE:** \n\t$$L\\left(h(\\mathbf{x}), y\\right)=\\frac 1 2(y-h(\\mathbf{x}))^2$$\n\t- å¯¹å…¶æ±‚å¯¼: \n\t$$\\begin{aligned}\\frac{\\partial}{\\partial w_{j}} L\\left(h(\\mathbf{x}), y\\right)\u0026=-(y-h(\\mathbf{x}))\\frac{\\partial \\operatorname{Sigmoid}(\\mathbf{w^T x})}{\\partial w_{j}}\\\\\n\t\u0026=-(y-h(\\mathbf{x}))h'(\\mathbf{x})\\frac{\\partial\\mathbf{w^T x}}{\\partial w_{j}}\\\\\n\t\u0026=-(y-h(\\mathbf{x}))h'(\\mathbf{x})x_{j}\\\\\n\t\\text{(å˜æˆé¢„æµ‹å€¼çš„å‡½æ•°)}\u0026=-(y-h(\\mathbf{x}))(1-h(\\mathbf{x}))h(\\mathbf{x})x_{j}\n\t\\end{aligned}$$ \n\t- æ±‚äºŒé˜¶å¯¼æ•°(è¿‡ç¨‹ç•¥):\n\t\t$$\\begin{aligned}\\frac{\\partial^2}{\\partial w_{j}^2} L\\left(h(\\mathbf{x}), y\\right)\u0026=-\\left(3\\cdot h^2(\\mathbf{x})-2\\cdot h(\\mathbf{x}) -2y\\cdot h(\\mathbf{x})+y\\right)h'(\\mathbf{x})(x_j)^2\n\t\\end{aligned}$$ \n\t\n### è§£é‡Š \n- å¯è§†åŒ–çš„å‡½æ•°é¡µé¢: [Cross Entropy Loss and MSE â€“ GeoGebra](https://www.geogebra.org/m/buakfzn8)\n\t- æ³¨: è¿™ä¸ªä¾‹å­å‡è®¾æœ‰ä¸‰ä¸ªæ ·æœ¬: $(a,1);(b,1);(c,0)$, å…¶ä¸­è¾“å…¥: $abc$ éƒ½æ˜¯å¯ä»¥è°ƒèŠ‚çš„\n\n#### åˆ†ç±»é—®é¢˜é‡Œé¢MSEå¹¶ä¸æ˜¯ä¸€ä¸ªå‡¸å‡½æ•°, è¿™å¯èƒ½å¯¼è‡´ç®—æ³•æ— æ³•å­¦ä¹ åˆ°æœ€ä¼˜çš„å‚æ•°.\næˆ‘ä»¬ä½œå‡ºMSEçš„äºŒé˜¶å¯¼å‡½æ•°å›¾åƒå¦‚ä¸‹: \n![](notes/2022/2022.2/assets/img_2022-10-15-1.png)\nå¯ä»¥çœ‹åˆ°å¹¶ä¸æ˜¯æ’ä¸ºéè´Ÿçš„, è¿™è¯´æ˜å‡½æ•°å¹¶ä¸æ˜¯å‡¸å‡½æ•°.\n\n- è€Œäº¤å‰ç†µçš„äºŒé˜¶å¯¼å›¾åƒä¸º: \n![](notes/2022/2022.2/assets/img_2022-10-15-2.png)\n- è¿™æ˜¯ä¸€ä¸ªå‡¸å‡½æ•°: [è¯¦ç»†è¯æ˜è§: è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°](notes/2021/2021.9/è¯æ˜Logisticå›å½’çš„æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°.md)\n\n#### äº¤å‰ç†µæ¢¯åº¦çš„å˜åŒ–è¶‹åŠ¿ä¸å€¼åŸŸéƒ½æ›´ç†æƒ³\n- **å€¼åŸŸ:** ç›¸æ¯”å‡æ–¹è¯¯å·®ï¼Œäº¤å‰ç†µçš„æ¢¯åº¦å¤§å°æ›´å‡åŒ€,  è€ŒMSEæ¢¯åº¦è¿‡å°ä¸”ä¸å¤Ÿå‡åŒ€, å®¹æ˜“å‡ºç°æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜.\n- ä¸‹å›¾æ˜¯åŸå‡½æ•°çš„å›¾åƒ. å¯ä»¥çœ‹åˆ°äº¤å‰ç†µçš„å¡åº¦å¾ˆ\"å¹³ç¨³\", æ¢¯åº¦ä¸‹é™èƒ½å¤Ÿæ„‰å¿«åœ°æ»‘åˆ°æœ€ä½å€¼.\n![](notes/2022/2022.2/assets/img_2022-10-15-3.png)\n\n- æˆ‘ä»¬å†åšå‡ºå…¶æ¢¯åº¦å›¾åƒ: \n\t![](notes/2022/2022.2/assets/img_2022-10-15-4.png)\n- æˆ‘ä»¬å‘ç°: MSEçš„æ¢¯åº¦ä¸ä»…èŒƒå›´å°, è€Œä¸”å€¼çš„å˜åŒ–è¿˜å¾ˆåå¸¸, åœ¨è·ç¦»æœ€ä¼˜å€¼(æ¢¯åº¦é›¶ç‚¹)å¾ˆè¿œçš„åœ°æ–¹åè€Œå˜å¾—å¾ˆå°. \n\t- è¿™å¯¼è‡´çš„åæœæ˜¯: å¦‚æœå‚æ•°åˆå§‹åŒ–åœ¨è·ç¦»æœ€ä¼˜å€¼å¾ˆè¿œçš„åœ°æ–¹, è®­ç»ƒæ²¡æœ‰è¿›å±•. \n\n- æˆ‘ä»¬å†ä»æ•°å­¦ä¸Šåˆ†æä¸€ä¸‹å…¶ä¸­çš„åŸå› : \n\t- **äº¤å‰ç†µçš„ä¸€é˜¶å¯¼æ•°**ä¸º: \t$$\\frac{\\partial}{\\partial w_{j}}L\\left(h(\\mathbf{x}), y\\right)=\\left(y-h(\\mathbf x)\\right) x_{j}$$\n\t- **MSEçš„ä¸€é˜¶å¯¼æ•°**ä¸º: $$\\frac{\\partial}{\\partial w_{j}} L\\left(h(\\mathbf{x}), y\\right)=(y-h(\\mathbf{x}))h'(\\mathbf{x})x_{j}$$ \n\t- MSEçš„æ¢¯åº¦è¡¨è¾¾å¼é‡Œé¢å¤šäº†ä¸€é¡¹Sigmoidå‡½æ•°çš„å¯¼æ•°, è€ŒSigmoidå‡½æ•°çš„å¯¼æ•°é•¿ä¸‹é¢è¿™ä¸ªæ ·å­(çº¢è‰²è™šçº¿): \n\t\t![](notes/2022/2022.2/assets/img_2022-10-15-5.png)\n\t\tå¯ä»¥çœ‹åˆ°åœ¨ç»å¯¹å€¼è¾ƒå¤§çš„åœ°æ–¹, Sigmoidçš„å¯¼æ•°ä¼šå˜å¾—å¾ˆå°, è¿™ä¹Ÿæ˜¯MSEæ¢¯åº¦ä¸ç†æƒ³çš„åŸå› .\n- (æ¥è‡ªä¸€ç¯‡åšå®¢[^2]) ....Finally, it reminds me of something said in DL-book by Bengio, 'You must have some log form loss to cancel the exponential part when your output is sigmoid'\n\t- å¦‚æœä½ ç½‘ç»œçš„æœ€åä¸€å±‚æ˜¯Sigmoid, é‚£ä¹ˆä½ çš„æŸå¤±å‡½æ•°éœ€è¦ä¸€äº› $\\log$ çš„éƒ¨åˆ†æ¥æŠµæ¶ˆæ‰(Sigmoidé‡Œé¢çš„)æŒ‡æ•°éƒ¨åˆ†.\n\n#### äº¤å‰ç†µçš„è®¡ç®—æ›´ç®€å•\n- è¿™æ˜¯å› ä¸º: \n\t- **äº¤å‰ç†µçš„ä¸€é˜¶å¯¼æ•°**ä¸º: \t$$\\frac{\\partial}{\\partial w_{j}}L\\left(h(\\mathbf{x}), y\\right)=\\left(y-h(\\mathbf x)\\right) x_{j}$$\n\t- **MSEçš„ä¸€é˜¶å¯¼æ•°**ä¸º: $$\\frac{\\partial}{\\partial w_{j}} L\\left(h(\\mathbf{x}), y\\right)=(y-h(\\mathbf{x}))h'(\\mathbf{x})x_{j}$$ \n- å¾ˆæ˜æ˜¾äº¤å‰ç†µå°‘äº†ä¸€ä¸ª $h'(\\mathbf{x})$\n\n\n#### å¦æ³¨\n- åœ¨æœ‰äº›è§£è¯´é‡Œé¢, ä½œè€…åšå‡ºçš„å›¾åƒæ˜¯æŸå¤±å‡½æ•°å…³äºæ¨¡å‹è¾“å‡ºçš„æ›²çº¿, æˆ‘è®¤ä¸ºè¿™è™½ç„¶æœ‰ä¸€å®šé“ç†, ä½†ä¹Ÿæ˜¯ä¸å¤ªåˆç†çš„: \n\t![å¦‚ä½•å¾—åˆ°æŸå¤±å‡½æ•°çš„å›¾åƒ](notes/2022/2022.2/assets/img_2022-10-15-6.png)\n\t- æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¦å¾—åˆ°æŸå¤±ä¸å‚æ•°çš„å…³ç³», ä¸ä»…éœ€è¦ç»è¿‡æŸå¤±å‡½æ•°, è¿˜éœ€è¦ç»è¿‡æ¨¡å‹, è€Œæ¨¡å‹å¹¶ä¸ä¸€å®šæ˜¯çº¿æ€§çš„. æ‰€ä»¥\"é¢„æµ‹å€¼-æŸå¤±\"å›¾åƒå¹¶ä¸èƒ½çœŸå®åœ°åæ˜ æŸå¤±å‡½æ•°æ˜¯å¦‚ä½•å½±å“æ¢¯åº¦çš„å¤§å°ä¸å˜åŒ–é€Ÿåº¦, è¿›è€Œå½±å“å‚æ•°æ›´æ–°è¿‡ç¨‹çš„.\n\n- ä¸¾ä¸ªä¾‹å­: ä¸‹å›¾å±•ç¤ºäº†çœŸå®å€¼ $y=1$ æ—¶, æ¢¯åº¦ $\\frac{\\partial}{\\partial w_{j}} L\\left(h(\\mathbf{x}), y\\right)$ ç›¸å¯¹äºæ¨¡å‹é¢„æµ‹å€¼ $h(\\mathbf{x})$ çš„å˜åŒ–å›¾åƒ: \n\t- è“è‰²ä¸ºäº¤å‰ç†µ, ç»¿è‰²ä¸ºMSE\t\n\t![350](notes/2022/2022.2/assets/img_2022-10-15.png)\n- è™½ç„¶çœ‹èµ·æ¥äº¤å‰ç†µçš„å˜åŒ–æ›´å¹³ç¨³, è€Œä¸”å•è°ƒæ€§å¾ˆå¥½, ä½†æ˜¯å› ä¸ºè‡ªå˜é‡æ˜¯æ¨¡å‹è¾“å‡º, æˆ‘ä»¬å¹¶ä¸çŸ¥é“å®é™…ä¸Šå‚æ•°æ›´æ–°æ—¶åˆ°åº•å¹³ä¸å¹³ç¨³. è€Œä¸”è¿™ä¸ªå›¾ç»™äººä¸€ç§é”™è§‰: å¥½åƒè¦æ˜¯æ¨¡å‹ä¸€å¼€å§‹çš„è¾“å‡ºå°äº0.25, é‚£ä¹ˆå°±æ°¸è¿œä¹Ÿå­¦ä¹ ä¸åˆ°æ­£ç¡®çš„å‚æ•°äº†.\n\n- ä¸‹å›¾æ˜¯ä¸€ä¸ªæ­£ç¡®çš„ä¾‹å­, å›¾ä¸­ä¹Ÿå¯ä»¥çœ‹å‡ºäº¤å‰ç†µä½œä¸ºæŸå¤±çš„ä¼˜è¶Šæ€§.[^1]\n![500](notes/2022/2022.2/assets/img_2022-10-15-7.png)\n\n\n\n## Softmax\nSoftmaxçš„æƒ…å†µå¤ªå¤æ‚äº†, æˆ‘ä»¬ç»™å‡ºä¸€äº›å…¶ä»–è®ºæ–‡é‡Œé¢çš„è®ºè¯: \n\n- ä¸€ä¸ªéªŒè¯å®éªŒçš„ç»“æœ: [Sigmoid-MSE vs. Softmax Cross-Entropy â€“ Weights \u0026 Biases](https://wandb.ai/ayush-thakur/dl-question-bank/reports/Sigmoid-MSE-vs-Softmax-Cross-Entropy--VmlldzoyMDA3ODQ)\n\t- MSEä¹Ÿèƒ½å¤Ÿè®­ç»ƒ, ä½†æ˜¯ç²¾ç¡®åº¦è¦ä½ä¸€ç‚¹\n\n- æœ‰ä¸€ç¯‡è®ºæ–‡[^4]æ¢ç©¶äº†äº¤å‰ç†µä¸å¹³æ–¹æŸå¤±çš„ä¸åŒ, å¯¹äºæ¢¯åº¦, MSEåœ¨Softmaxé‡Œé¢æœ‰åŒæ ·çš„é—®é¢˜: è·ç¦»æœ€ä¼˜å€¼è¾ƒè¿œçš„æ—¶å€™æ¢¯åº¦ä¹Ÿå¾ˆå°: \n![](notes/2022/2022.2/assets/img_2022-10-15-37.png)\n\n## Others\n- ç½‘ä¸Šçœ‹åˆ°è¿™å¼ å›¾è›®æœ‰æ„æ€çš„, ä½†æ˜¯ä»–å¥½åƒè¯´çš„ä¸å¤ªå¯¹[^3]\n![](notes/2022/2022.2/assets/img_2022-10-15-8.png)\n\n[^1]:è¿™ç¯‡æ–‡ç« æ˜¯Xavieråˆå§‹åŒ–çš„æ–‡ç« (zotero://select/items/@glorot2010understanding)\n[^2]: [Sigmoid in cross-entropy and mean-squared-error](http://antosny.github.io/2017/10/16/sigmoid-cross-entropy-mean-sqared-error/)\n[^3]: [æŸå¤±å‡½æ•°çš„å¯è§†åŒ–â€”â€”æµ…è®ºæ¨¡å‹çš„å‚æ•°ç©ºé—´ä¸æ­£åˆ™_æœºå™¨å­¦ä¹ æ‚è´§é“º1å·åº—-CSDNåšå®¢](https://blog.csdn.net/LoseInVain/article/details/83473975)\n[^4]:P. Golik, P. Doetsch, and H. Ney, â€œCross-entropy vs. squared error training: a theoretical and experimental comparison,â€(zotero://select/items/@Golik2013CrossentropyVS) 2013. doi: [10.21437/Interspeech.2013-436](https://doi.org/10.21437/Interspeech.2013-436) . ","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2-Affine_Transformation":{"title":"ä»¿å°„å˜æ¢-Affine_Transformation","content":"# ä»¿å°„å˜æ¢ Affine Transformation\n\n\u003cdiv align=\"right\"\u003e 2022-02-10\u003c/div\u003e\n\nTags: #Math/LinearAlgebra \n\nä»¿å°„å˜æ¢å°±æ˜¯å¹³ç§»åçš„çº¿æ€§å˜æ¢:\n\n![](notes/2022/2022.2/assets/img_2022-10-15.gif)\n[^1]\nHere is an Interaction: \n[Affine transformations / Kjerand Pedersen / Observable](https://observablehq.com/@kjerandp/affine-transformations)\n![](notes/2022/2022.2/assets/img_2022-10-15-1.gif)\n\n\n- æœ‰è¶£çš„æ˜¯, æˆ‘ä»¬å¯ä»¥åœ¨é«˜ç»´åº¦é€šè¿‡çº¿æ€§å˜æ¢æ¥å®Œæˆä»¿å°„å˜æ¢[^2]\n\n\u003ciframe src=\"https://commons.wikimedia.org/wiki/File:Affine_transformations.ogv?embedplayer=yes\" width=\"512\" height=\"512\" frameborder=\"0\" \u003e\u003c/iframe\u003e \n\n[^3]\n\n\u003e - æ™®é€šçŸ©é˜µå‘é‡ä¹˜æ³•æ€»å°†åŸç‚¹æ˜ å°„è‡³åŸç‚¹ï¼Œå› æ­¤æ— æ³•å‘ˆç°å¹³ç§»ï¼ˆåŸç‚¹å¿…é¡»æ˜ å°„è‡³å…¶ä»–ç‚¹ï¼‰ã€‚å€Ÿç”±äºæ‰€æœ‰å‘é‡ä¸Šæ‰©å¢ä¸€åæ ‡ â€œ1â€ï¼Œæˆ‘ä»¬å°†åŸç©ºé—´æ˜ è‡³æ›´é«˜ç»´ç©ºé—´çš„ä¸€ä¸ªå­é›†åˆä»¥è¿›è¡Œå˜æ¢ã€‚åœ¨è¯¥ç©ºé—´ä¸­ï¼ŒåŸæœ¬ä¹‹ç©ºé—´å æœ‰äº†æ‰©é•¿åæ ‡ä¸€çš„1çš„å­é›†åˆã€‚ å› æ­¤åŸç©ºé—´çš„åŸç‚¹å¯åœ¨(0,0, ... 0, 1)ã€‚åŸç©ºé—´çš„å¹³ç§»å¯å€Ÿç”±æ›´é«˜ç»´åº¦ç©ºé—´çš„çº¿æ€§å˜æ¢æ¥è¾¾æˆï¼ˆå³ä¸º[é”™åˆ‡å˜æ¢](https://zh.wikipedia.org/wiki/%E9%8C%AF%E5%88%87 \"é”™åˆ‡\")ï¼‰ã€‚åœ¨é«˜ç»´åº¦ä¸­çš„åæ ‡å³ä¸º [é½æ¬¡åæ ‡](https://zh.wikipedia.org/wiki/%E9%BD%8A%E6%AC%A1%E5%BA%A7%E6%A8%99 \"é½æ¬¡åæ ‡\")çš„ä¸€ä¾‹ã€‚ å‡å¦‚åŸç©ºé—´ä¸ºæ¬§å‡ é‡Œå¾·ç©ºé—´), åˆ™æ›´é«˜ç»´ç©ºé—´ä¸º[å®å°„å½±ç©ºé—´](https://zh.wikipedia.org/wiki/%E5%AE%9E%E5%B0%84%E5%BD%B1%E7%A9%BA%E9%97%B4 \"å®å°„å½±ç©ºé—´\")ã€‚\n\u003e - ä½¿ç”¨é½æ¬¡åæ ‡çš„ä¼˜ç‚¹ä¸ºï¼Œå€Ÿç”±ç›¸å¯¹åº”çŸ©é˜µä¹‹ä¹˜ç§¯ï¼Œå¯å°†ä»»æ„æ•°ç›®çš„ä»¿å°„å˜æ¢[ç»“åˆ](https://zh.wikipedia.org/wiki/%E5%A4%8D%E5%90%88%E5%87%BD%E6%95%B0 \"å¤åˆå‡½æ•°\")ä¸ºä¸€ã€‚æ­¤æ€§è´¨è¢«å¤§é‡è¿ç”¨äº [è®¡ç®—æœºå›¾å½¢](https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2 \"è®¡ç®—æœºå›¾å½¢\"), [è®¡ç®—æœºè§†è§‰](https://zh.wikipedia.org/wiki/%E8%A8%88%E7%AE%97%E6%A9%9F%E8%A6%96%E8%A6%BA \"è®¡ç®—æœºè§†è§‰\") ä¸ [æœºå™¨äººå­¦](https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6 \"æœºå™¨äººå­¦\")ã€‚[^3]\n\n\n\n\n\n[^1]: [Understanding Transformations in Computer Vision: | by Felix Liu | Towards Data Science](https://towardsdatascience.com/understanding-transformations-in-computer-vision-b001f49a9e61)\n[^2]: [å¦‚ä½•é€šä¿—åœ°è®²è§£ã€Œä»¿å°„å˜æ¢ã€è¿™ä¸ªæ¦‚å¿µï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/20666664)\n[^3]: [ä»¿å°„å˜æ¢ - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-cn/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2)","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%82%E6%95%B0%E5%A4%A7%E5%B0%8F%E7%9A%84%E8%AE%A1%E7%AE%97":{"title":"å·ç§¯å±‚å‚æ•°å¤§å°çš„è®¡ç®—","content":"![å·ç§¯å±‚æƒé‡å¤§å°çš„è®¡ç®—](notes/2022/2022.2/assets/å·ç§¯å±‚æƒé‡å¤§å°çš„è®¡ç®—.svg)\n\n- **è¾“å…¥é€šé“æ•°**å†³å®šäº†æ¯ä¸€ä¸ªå·ç§¯æ ¸çš„\"åšåº¦\"\n- **è¾“å‡ºé€šé“æ•°**å†³å®šäº†å·ç§¯æ ¸çš„\"ä¸ªæ•°\"\n- **å·ç§¯æ ¸çš„å¤§å°**åˆ™å’Œè¾“å‡ºçš„å°ºå¯¸å¯†åˆ‡ç›¸å…³\n- å…¶å® **å±‚æ•°(åšåº¦)** å’Œ **é¢ç§¯(å°ºå¯¸)** æ²¡æœ‰ä»€ä¹ˆè”ç³», æ˜¯ä¸¤ä¸ªæ¯”è¾ƒç‹¬ç«‹çš„å‚æ•°\n","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%9B%B0%E9%9A%BE":{"title":"å¯è§†åŒ–æŸå¤±å‡½æ•°çš„å›°éš¾","content":"## å¯è§†åŒ–æŸå¤±å‡½æ•°çš„å›°éš¾\n\n- æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹Loss Functionçš„å½¢å¼: $$L_{\\theta}\\space (\\hat{y},\\space y)=\\cdots$$\n  - é‡Œé¢æœ‰å››ä¸ªç»„æˆéƒ¨åˆ†: $L, \\theta, \\hat{y}$ å’Œ $y$\n  - éœ€è¦ç‰¢è®°çš„ä¸€ç‚¹æ˜¯: é€‰æ‹©Loss Function $L$ çš„æ—¶å€™é€‰æ‹©çš„æ˜¯\"è®¡ç®—æ–¹å¼\", ä¹Ÿå°±æ˜¯æˆ‘ä»¬æ€æ ·è®¡ç®—æ¨¡å‹è¾“å‡º $\\hat y$ å’ŒçœŸå®å€¼ $y$, è€ŒæŸå¤±å‡½æ•°å®é™…ä¸Šæ˜¯å…³äºæƒé‡ $\\theta$ çš„å‡½æ•°, æˆ‘ä»¬åœ¨åå‘ä¼ æ’­çš„æ—¶å€™æ˜¯å¯¹å­¦ä¹ ç›®æ ‡ $\\theta$ æ±‚æ¢¯åº¦, è€Œç›´è§‚çš„æ¢¯åº¦ä¸‹é™æ³•ä¹Ÿæ˜¯åœ¨ $L$ å…³äº $\\theta$ çš„å›¾åƒä¸Šé€æ­¥ä¸‹é™çš„.\n  - æ ·æœ¬ $y$ å’ŒæŸå¤±å‡½æ•° $L$ å½±å“ç€æ•´ä¸ªæ¢¯åº¦åœ°å½¢å›¾çš„å½¢çŠ¶, è€Œæ¨¡å‹è¾“å‡º $\\hat{y}$ å’Œæƒé‡ $\\theta$ åˆ™ä»£è¡¨ç­‰é«˜çº¿å›¾é‡Œé¢çš„ä¸€ä¸ªå°äºº, åœ¨è®­ç»ƒæ—¶ä¸æ–­ç§»åŠ¨.\n  - å®¹æ˜“å¿½ç•¥çš„ä¸€ç‚¹æ˜¯: å½±å“\"æŸå¤±åœ°å½¢å›¾\"çš„ä¸ä»…æœ‰ $L$,  è¿˜æœ‰æ ·æœ¬ $y$. æ²¡æœ‰è®­ç»ƒæ ·æœ¬, æŸå¤±å‡½æ•°åªæ˜¯ä¸€ä¸ªè®¡ç®—æ–¹å¼è€Œå·².\n\n  - è¦å¾—åˆ°\"æŸå¤±åœ°å½¢å›¾\", éœ€è¦ç»è¿‡å¦‚ä¸‹å‡ æ­¥:\n  ![å¦‚ä½•å¾—åˆ°æŸå¤±å‡½æ•°çš„å›¾åƒ](notes/2022/2022.2/assets/img_2022-10-15-6.png)\n    - å¯ä»¥çœ‹åˆ°: å› ä¸ºå‚æ•° $\\theta$ éœ€è¦ç»è¿‡**æ¨¡å‹**å’Œ**æŸå¤±å‡½æ•°**ä¸¤æ¬¡å˜æ¢, è€Œä¸”æ¨¡å‹çš„å‚æ•° $\\theta$ é€šå¸¸æ•°ç›®åºå¤§, æ‰€ä»¥å®é™…å›¾åƒæ˜¯éå¸¸å¤æ‚çš„.\n\n    - å°½ç®¡å®é™…å›¾åƒéå¸¸å¤æ‚, æˆ‘ä»¬åœ¨å­¦ä¹ çš„æ—¶å€™è¿˜æ˜¯å¯ä»¥æ„é€ ç®€å•çš„ç‰¹ä¾‹, æ¥ç†è§£æ¨¡å‹è®­ç»ƒä¸­çš„ä¸€äº›é—®é¢˜, æ¯”å¦‚:\n      - [ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE](notes/2022/2022.2/ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE.md)\n","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E5%A5%BD%E7%9A%84%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E8%B4%A8":{"title":"å¥½çš„é¢„æµ‹æ¨¡å‹çš„ç‰¹è´¨","content":"# \"å¥½\"çš„é¢„æµ‹æ¨¡å‹çš„ç‰¹å¾\n\n\u003cdiv align=\"right\"\u003e 2022-02-14\u003c/div\u003e\n\nTags: #DeepLearning \n\n- **æ³›åŒ–æ€§çš„è§’åº¦:** \n\t- æˆ‘ä»¬æœŸå¾…â€œå¥½â€çš„é¢„æµ‹æ¨¡å‹èƒ½åœ¨æœªçŸ¥çš„æ•°æ®ä¸Šæœ‰å¾ˆå¥½çš„è¡¨ç°ï¼š ç»å…¸æ³›åŒ–ç†è®ºè®¤ä¸ºï¼Œ**ä¸ºäº†ç¼©å°è®­ç»ƒå’Œæµ‹è¯•æ€§èƒ½ä¹‹é—´çš„å·®è·ï¼Œåº”è¯¥ä»¥ç®€å•çš„æ¨¡å‹ä¸ºç›®æ ‡ã€‚** \n\t- ç®€å•æ€§ä»¥è¾ƒå°ç»´åº¦çš„å½¢å¼å±•ç°. æ­¤å¤–, $L_2$ æ­£åˆ™åŒ–çš„æœ‰æ•ˆæ€§ä¹Ÿè¯´æ˜, å‚æ•°çš„èŒƒæ•°ä¹Ÿä»£è¡¨äº†ä¸€ç§æœ‰ç”¨çš„ç®€å•æ€§åº¦é‡ã€‚\n\n- ç®€å•æ€§çš„å¦ä¸€ä¸ªè§’åº¦æ˜¯**å¹³æ»‘æ€§**ï¼Œå³å‡½æ•°ä¸åº”è¯¥å¯¹å…¶è¾“å…¥çš„å¾®å°å˜åŒ–æ•æ„Ÿã€‚ ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»æ—¶ï¼Œæˆ‘ä»¬é¢„è®¡å‘åƒç´ æ·»åŠ ä¸€äº›éšæœºå™ªå£°åº”è¯¥æ˜¯åŸºæœ¬æ— å½±å“çš„ã€‚ [1995å¹´ï¼Œå…‹é‡Œæ–¯æ‰˜å¼—Â·æ¯•æ™“æ™®è¯æ˜äº† å…·æœ‰è¾“å…¥å™ªå£°çš„è®­ç»ƒç­‰ä»·äºTikhonovæ­£åˆ™åŒ–ã€‚](notes/2022/2022.2/D2L-22-æƒé‡è¡°å‡.md#^c88d1b) **è¿™é¡¹å·¥ä½œç”¨æ•°å­¦è¯å®äº†â€œè¦æ±‚å‡½æ•°å…‰æ»‘â€å’Œâ€œè¦æ±‚å‡½æ•°å¯¹è¾“å…¥çš„éšæœºå™ªå£°å…·æœ‰é€‚åº”æ€§â€ä¹‹é—´çš„è”ç³»**ã€‚\n\n\t- å¹³æ»‘çš„å‡½æ•°èƒ½è¾ƒå¥½åœ°é€‚åº”è¾“å…¥çš„éšæœºå™ªå£°\n\n\t- [Dropout](notes/2022/2022.2/D2L-23-Dropout-ä¸¢å¼ƒæ³•.md) å°±æ˜¯åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æ¯ä¸€å†…éƒ¨å±‚çš„åŒæ—¶æ³¨å…¥å™ªå£°ï¼Œä»è€Œå¢åŠ æ¨¡å‹çš„å¹³æ»‘æ€§.\n","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E5%AF%B9%E4%BA%8E%E7%AD%89%E4%BB%B7%E7%9A%84%E7%BD%91%E7%BB%9C-%E5%B0%8F%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%8F%82%E6%95%B0%E6%9B%B4%E5%B0%91":{"title":"å¯¹äºç­‰ä»·çš„ç½‘ç»œ, å°çš„å·ç§¯æ ¸å‚æ•°æ›´å°‘","content":"- æˆ‘ä»¬çŸ¥é“ [2ä¸ª3x3å·ç§¯æ ¸å †å åç­‰ä»·äºä¸€ä¸ª5x5å·ç§¯æ ¸](notes/2022/2022.2/2ä¸ª3x3å·ç§¯æ ¸å †å åç­‰ä»·äºä¸€ä¸ª5x5å·ç§¯æ ¸.md), ä»¥æ­¤ä¸ºä¾‹æˆ‘ä»¬æ¥æ¯”è¾ƒä¸€ä¸‹ä¸¤è€…çš„å‚æ•°å¤§å°.\n\n[å·ç§¯å±‚å‚æ•°å¤§å°çš„è®¡ç®—](notes/2022/2022.2/å·ç§¯å±‚å‚æ•°å¤§å°çš„è®¡ç®—.md)\n\n- å‡è®¾è¾“å…¥é€šé“æ•°ä¸º $C_{in}$, è¾“å‡ºé€šé“æ•°ä¸º $C_{out}$\n\n- å¯¹äº $5\\times5$ å·ç§¯, å‚æ•°æ•°é‡ä¸º: $$5\\times5\\times C_{in} \\times C_{out}$$\n\n- å¯¹äº $3\\times3$ å·ç§¯, å‡è®¾ç¬¬ä¸€æ¬¡å·ç§¯çš„è¾“å‡ºé€šé“æ•°ä¸º $C_{mid}$\n  - ä¸€æ¬¡ $3\\times3$ å·ç§¯çš„å‚æ•°æ•°é‡ä¸º $$3\\times3\\times \\textcolor{Orange}{C_{in}}\\times \\textcolor{ForestGreen}{C_{mid}}$$\n  - ç¬¬äºŒæ¬¡å·ç§¯çš„å‚æ•°æ•°é‡ä¸º $$3\\times3\\times \\textcolor{ForestGreen}{C_{mid}}\\times \\textcolor{RoyalBlue}{C_{out}}$$\n  - æ€»çš„å‚æ•°æ•°é‡ä¸º: $$9\\times\\textcolor{ForestGreen}{C_{mid}}\\left(\\textcolor{Orange}{C_{in}}+\\textcolor{RoyalBlue}{C_{out}}\\right)$$\n\n- **å¦‚æœè¾“å…¥è¾“å‡ºé¢‘é“æ•°ç›¸åŒ:**\n  - $5\\times5$ å·ç§¯: $$25\\times C^2$$\n  - $3\\times3$ å·ç§¯: $$18\\times C^2$$\n  - æ˜¾ç„¶æ›´å°çš„å·ç§¯æ ¸å‚æ•°æ•°é‡æ›´å°‘\n\n- **å¦‚æœè¾“å…¥è¾“å‡ºé¢‘é“æ•°ä¸åŒ:**\n  - å¯¹äº $3\\times3$ å·ç§¯:\n    - æˆ‘ä»¬é€šå¸¸é€‰å– $\\textcolor{ForestGreen}{C_{mid}}$ ä¸º $\\textcolor{Orange}{C_{in}},\\textcolor{RoyalBlue}{C_{out}}$ çš„å‡ ä½•å¹³å‡æ•°, ä¹Ÿå°±æ˜¯è¯´: $$\\textcolor{ForestGreen}{C_{mid}}=\\sqrt{\\textcolor{Orange}{C_{in}}\\textcolor{RoyalBlue}{C_{out}}}$$\n  å¦‚æœ $\\textcolor{Orange}{C_{in}}\\times \\alpha=\\textcolor{RoyalBlue}{C_{out}}$, åˆ™ $$\\textcolor{ForestGreen}{C_{mid}}=\\sqrt{\\alpha}\\times\\textcolor{Orange}{C_{in}}$$\n  - å¯¹æ¯”ä¸€ä¸‹ä¸¤è€…çš„å‚æ•°æ•°é‡:\n    - $5\\times5$ å·ç§¯: $$25\\times C_{in} \\times C_{out}$$\n    - $3\\times3$ å·ç§¯: $$9\\times \\sqrt{\\textcolor{Orange}{C_{in}}\\textcolor{RoyalBlue}{C_{out}}}\\left(\\textcolor{Orange}{C_{in}}+\\textcolor{RoyalBlue}{C_{out}}\\right)$$\n    - è¿™ä¸ªå°±ä¸æ˜¯å¾ˆå¥½æ¯”è¾ƒäº†, æˆ‘ä»¬æŠŠå›¾åšå‡ºæ¥çœ‹çœ‹:\n   ![](notes/2022/2022.2/assets/Pasted%20image%2020220304104453.png)[^1]\n   \n    - å¯ä»¥çœ‹åˆ°ä¸€èˆ¬çš„å‚æ•°èŒƒå›´å†…, éƒ½æ˜¯å°çš„å·ç§¯æ ¸å‚æ•°æ›´å°‘.\n\n[^1]: [Different Kernel Size - Who's Parameter is larger â€“ GeoGebra](https://www.geogebra.org/m/zq6vnwcp)\n","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E5%BD%92%E7%BA%B3%E5%81%8F%E7%BD%AE-Inductive-bias-learning-bias":{"title":"å½’çº³åç½®-Inductive bias - learning bias","content":"# Inductive Bias - å½’çº³åç½® / å½’çº³åå¥½\n\n\u003cdiv align=\"right\"\u003e 2022-02-26\u003c/div\u003e\n\nTags: #DeepLearning #MachineLearning \n\n\n- å½“å­¦ä¹ å™¨å»é¢„æµ‹å…¶æœªé‡åˆ°è¿‡çš„è¾“å…¥çš„ç»“æœæ—¶ï¼Œä¼šåšä¸€äº›å‡è®¾ï¼ˆMitchell, 1980ï¼‰ã€‚è€Œå­¦ä¹ ç®—æ³•ä¸­çš„å½’çº³åç½®ï¼ˆInductive biasï¼‰åˆ™æ˜¯è¿™äº›å‡è®¾çš„é›†åˆã€‚[^1]\n\n- ä¸€ä¸ªå…¸å‹çš„å½’çº³åç½®ä¾‹å­æ˜¯[å¥¥å¡å§†å‰ƒåˆ€](https://zh.wikipedia.org/wiki/%E5%A5%A7%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80 \"å¥¥å¡å§†å‰ƒåˆ€\")ï¼Œå®ƒå‡è®¾æœ€ç®€å•è€Œåˆä¸€è‡´çš„å‡è®¾æ˜¯æœ€ä½³çš„ã€‚è¿™é‡Œçš„ä¸€è‡´æ˜¯æŒ‡å­¦ä¹ å™¨çš„å‡è®¾ä¼šå¯¹æ‰€æœ‰æ ·æœ¬äº§ç”Ÿæ­£ç¡®çš„ç»“æœã€‚\n\n[^1]: Machine Learning - Mitchell Chapter 2.7 ","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/%E7%81%B0%E5%BA%A6%E5%9B%BE%E5%83%8F%E4%B8%8E%E5%AE%87%E5%AE%99%E4%B8%AD%E7%9A%84%E6%89%80%E6%9C%89%E5%8E%9F%E5%AD%90":{"title":"ç°åº¦å›¾åƒä¸å®‡å®™ä¸­çš„æ‰€æœ‰åŸå­","content":"\n\u003e - è€ƒè™‘$28Ã—28$çš„ç°åº¦å›¾åƒã€‚ å¦‚æœæ¯ä¸ªåƒç´ å¯ä»¥å–$256$ä¸ªç°åº¦å€¼ä¸­çš„ä¸€ä¸ªï¼Œ åˆ™æœ‰$256^{784}$ä¸ªå¯èƒ½çš„å›¾åƒã€‚ è¿™æ„å‘³ç€æŒ‡ç”²å¤§å°çš„ä½åˆ†è¾¨ç‡ç°åº¦å›¾åƒçš„æ•°é‡æ¯”å®‡å®™ä¸­çš„åŸå­[^3]è¦å¤šå¾—å¤šã€‚[^1]\n\n- åè¿‡æ¥æƒ³, å°å°çš„$28Ã—28$çš„ç°åº¦å›¾åƒä¸­, ä¸€å®šæœ‰å¾ˆå¤šå¾ˆå¤šå›¾åƒæ•´ä¸ªå®‡å®™ä¸­éƒ½ä¸å­˜åœ¨, å› ä¸ºè¦æ˜¯ä¸€ä¸ªå›¾åƒåªç”¨ä¸€ä¸ªåŸå­å°±èƒ½è¡¨è¾¾çš„è¯[^2], å®‡å®™ä¸­çš„æ‰€æœ‰åŸå­éƒ½è¡¨è¾¾ä¸å®Œè¿™äº›å›¾ç‰‡.\n\n[^1]: https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html#id2\n[^2]: æ˜¾ç„¶ä¸å¤Ÿ\n[^3]: $10^{80}$\n","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.2/2%E4%B8%AA3x3%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%A0%86%E5%8F%A0%E5%90%8E%E7%AD%89%E4%BB%B7%E4%BA%8E%E4%B8%80%E4%B8%AA5x5%E5%8D%B7%E7%A7%AF%E6%A0%B8":{"title":"2ä¸ª3x3å·ç§¯æ ¸å †å åç­‰ä»·äºä¸€ä¸ª5x5å·ç§¯æ ¸","content":"- VGG16ç›¸æ¯”AlexNetçš„ä¸€ä¸ªæ”¹è¿›æ˜¯**é‡‡ç”¨è¿ç»­çš„å‡ ä¸ª3x3çš„å·ç§¯æ ¸ä»£æ›¿AlexNetä¸­çš„è¾ƒå¤§å·ç§¯æ ¸ï¼ˆ11x11ï¼Œ7x7ï¼Œ5x5ï¼‰**ã€‚\n  - å¯¹äºç»™å®šçš„æ„Ÿå—é‡ï¼ˆä¸è¾“å‡ºæœ‰å…³çš„è¾“å…¥å›¾ç‰‡çš„å±€éƒ¨å¤§å°ï¼‰ï¼Œé‡‡ç”¨å †ç§¯çš„å°å·ç§¯æ ¸ä¼˜äºå¤§çš„å·ç§¯æ ¸ï¼Œå› ä¸ºå¤šå±‚éçº¿æ€§å±‚å¯ä»¥å¢åŠ ç½‘ç»œæ·±åº¦æ¥ä¿è¯å­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼ï¼Œè€Œä¸”ä»£ä»·è¿˜æ¯”è¾ƒå°ï¼ˆå‚æ•°æ›´å°‘ï¼‰ã€‚\n  - **ä»£ä»·æ›´å°:**  [[notes/2022/2022.2/å¯¹äºç­‰ä»·çš„ç½‘ç»œ, å°çš„å·ç§¯æ ¸å‚æ•°æ›´å°‘]]\n\n- ç®€å•æ¥è¯´ï¼Œåœ¨VGGä¸­ï¼Œä½¿ç”¨äº†3ä¸ª3x3å·ç§¯æ ¸æ¥ä»£æ›¿7x7å·ç§¯æ ¸ï¼Œä½¿ç”¨äº†2ä¸ª3x3å·ç§¯æ ¸æ¥ä»£æ›¿5x5å·ç§¯æ ¸ï¼Œè¿™æ ·åšçš„ä¸»è¦ç›®çš„æ˜¯åœ¨ä¿è¯å…·æœ‰ç›¸åŒæ„ŸçŸ¥é‡çš„æ¡ä»¶ä¸‹ï¼Œæå‡äº†ç½‘ç»œçš„æ·±åº¦ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šæå‡äº†ç¥ç»ç½‘ç»œçš„æ•ˆæœã€‚\n\n## ä¸ºä»€ä¹ˆä½¿ç”¨2ä¸ª3x3å·ç§¯æ ¸å¯ä»¥æ¥ä»£æ›¿5x5å·ç§¯æ ¸\n\n- 5x5å·ç§¯çœ‹åšä¸€ä¸ªå°çš„å…¨è¿æ¥ç½‘ç»œåœ¨5x5åŒºåŸŸæ»‘åŠ¨ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆç”¨ä¸€ä¸ª3x3çš„æ»¤æ³¢å™¨å·ç§¯ï¼Œç„¶åå†ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚è¿æ¥è¿™ä¸ª3x3å·ç§¯è¾“å‡º.  åŒæ—¶, è¿™ä¸ªå…¨è¿æ¥å±‚æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åšä¸€ä¸ª3x3å·ç§¯å±‚ã€‚è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ç”¨ä¸¤ä¸ª3x3å·ç§¯çº§è”ï¼ˆå åŠ ï¼‰èµ·æ¥ä»£æ›¿ä¸€ä¸ª 5x5å·ç§¯ã€‚\n\n- å…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n![](notes/2022/2022.2/assets/img_2022-10-15.jpg)\n\nè‡³äºä¸ºä»€ä¹ˆä½¿ç”¨3ä¸ª3x3å·ç§¯æ ¸å¯ä»¥æ¥ä»£æ›¿ $7\\times7$ å·ç§¯æ ¸ï¼Œæ¨å¯¼è¿‡ç¨‹ä¸ä¸Šè¿°ç±»ä¼¼ã€‚\n\nref: [ä¸€æ–‡è¯»æ‡‚VGGç½‘ç»œ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/41423739)\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/CAPTCHA":{"title":"CAPTCHA","content":"\nå®Œå…¨è‡ªåŠ¨å›¾çµæµ‹è¯•:\nCompletely Automated Public Turing test to tell Computer and Humans Apart\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Cross_Entropy-%E4%BA%A4%E5%8F%89%E7%86%B5":{"title":"Cross_Entropy-äº¤å‰ç†µ","content":"# Cross Entropy - äº¤å‰ç†µ\n\n\u003cdiv align=\"right\"\u003e 2022-02-11\u003c/div\u003e\n\nTags: #InformationTheory #DeepLearning \n\n## Intuition\n- ç†µæ˜¯ç¼–ç ä¸€ä¸ªäº‹ä»¶æ‰€éœ€è¦çš„æœ€çŸ­å¹³å‡é•¿åº¦\n\t$$\\begin{aligned}H(p)\u0026=\\sum_{x_{i}} p\\left(x_{i}\\right) \\log \\frac{1}{p\\left(x_{i}\\right)} \\\\\n\t\u0026=-\\sum_{x} p(x) \\log p(x)\t\\end{aligned}$$\n- è€Œäº¤å‰ç†µåˆ™æ˜¯ä¸€ç§ç‰¹æ®Šæƒ…å†µä¸‹ç¼–ç çš„å¹³å‡æœ€çŸ­é•¿åº¦: äº‹ä»¶çœŸå®çš„æ¦‚ç‡åˆ†å¸ƒæ˜¯ $p(x)$, ä½†æ˜¯æˆ‘ä»¬ä»¥ä¸ºäº‹ä»¶çš„åˆ†å¸ƒæ˜¯ $q(x)$ .  \n\n\t- å› æ­¤, äº¤å‰ç†µå¯ä»¥çœ‹ä½œæ¯ä¸ªä¿¡æ¯ç‰‡æ®µåœ¨é”™è¯¯åˆ†å¸ƒ $q$ ä¸‹çš„æœŸæœ›ç¼–ç ä½é•¿åº¦ï¼Œè€Œä¿¡æ¯å®é™…åˆ†å¸ƒä¸º $p$ã€‚è¿™å°±æ˜¯æœŸæœ› $\\operatorname{E}_p$ æ˜¯åŸºäº $p$ è€Œä¸æ˜¯ $q$ çš„åŸå› .[^3]\n\t$$\\begin{aligned}   H(p, q)\u0026=\\sum_{x_{i}} p\\left(x_{i}\\right) \\log \\frac{1}{q\\left(x_{i}\\right)} \\\\\n\t\u0026=-\\sum_{x} p(x) \\log q(x) \\end{aligned}$$\n\n\n\n## Formal Definition\n- åœ¨æŒ‡å®šé›†åˆä¸‹, åˆ†å¸ƒ $q$  ç›¸å¯¹äºåˆ†å¸ƒ $p$ çš„äº¤å‰ç†µå®šä¹‰å¦‚ä¸‹:\n$$H(p, q) = -\\operatorname{E}_p[\\log q]$$\nå…¶ä¸­ç¬¦å· $E_p[\\cdot]$ çš„å«ä¹‰æ˜¯ ç›¸å¯¹äºåˆ†å¸ƒ $p$ çš„æœŸæœ›å€¼.\n\n- äº¤å‰ç†µçš„å®šä¹‰ä¹Ÿå¯ä»¥ä» [KLæ•£åº¦](notes/2022/2022.2/KL_Divergence-KLæ•£åº¦.md) $D_{\\mathrm{KL}}(p \\parallel q)$ å¾—å‡º(KLæ•£åº¦ä¹Ÿå«åš$p$ ç›¸å¯¹äº $q$çš„ç›¸å¯¹ç†µ).\n$$H(p, q) = H(p) + D_{\\mathrm{KL}}(p \\parallel q)$$\nå…¶ä¸­ $H(p)$ æ˜¯åˆ†å¸ƒ $p$ çš„ [ç†µ(Entropy)](notes/2022/2022.2/Entropy-ç†µ.md) .\n\n- å¯¹äºç¦»æ•£åˆ†å¸ƒ $p$ å’Œ $q$ :\n$$H(p, q)=-\\sum_{x \\in \\mathcal{X}} p(x) \\log q(x)$$\n[^1]\n## æ€§è´¨\n- äº¤å‰ç†µä¸æ˜¯å¯¹ç§°çš„: *i.e.* $$H(p,q)\\neq H(q,p)$$\n\t- KLæ•£åº¦ä¹Ÿä¸æ˜¯å¯¹ç§°çš„\n\t- å°½ç®¡ä¸æ˜¯å¯¹ç§°çš„ï¼Œä½†æ˜¯æ— è®ºæ˜¯ $H(p,q)$ è¿˜æ˜¯ $H(p,q)$ å…¶å®éƒ½å¯ä»¥ä½œä¸ºæ¦‚ç‡ç›¸ä¼¼ç¨‹åº¦çš„è¡¡é‡æ ‡å‡†\n\n\n- äº¤å‰ç†µæ˜¯éè´Ÿçš„: $$H(p, q)=-\\sum_{x } p(x) \\log q(x)$$\n\tå…¶ä¸­ $p(x), q(x)\\in[\\space 0,1\\space ], \\log q(x)\\leq0$\n\t\n## äº¤å‰ç†µ: ä½œä¸ºæŸå¤±å‡½æ•°\n[äº¤å‰ç†µæ˜¯æ€æ ·è¡¡é‡è¾“å‡ºå’ŒçœŸå®å€¼çš„å·®åˆ«çš„å‘¢?](notes/2022/2022.2/D2L-14-Cross%20Entropy%20as%20Loss.md)\n\n## Cross Entropy in Neural Networks\n![](notes/2022/2022.2/assets/img_2022-10-15-9.png)\n- åœ¨[Softmaxå›å½’](notes/2022/2022.2/D2L-13-Softmax_Regression.md)é‡Œé¢, å‰é¢çš„çœŸå®æ¦‚ç‡åˆ†å¸ƒæ˜¯[One-hot_Encoding-ç‹¬çƒ­ç¼–ç ](notes/2022/2022.1/One-hot_Encoding-ç‹¬çƒ­ç¼–ç .md)çš„, æ‰€ä»¥æ•´ä¸ªæ±‚å’Œå¼é‡Œåªæœ‰ä¸€é¡¹ç•™ä¸‹æ¥äº†, å³æ¨¡å‹è¾“å‡ºç±»çš„é¢„æµ‹æ¦‚ç‡çš„è´Ÿå¯¹æ•°$-\\log q(x)$\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6ArSys5qHAU?start=170\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n[^1]: å…¶ä¸­$\\mathcal{X}$ æŒ‡çš„æ˜¯æµ‹åº¦è®ºé‡Œé¢çš„\"æ”¯æ’‘é›†\". Reference: [Support (measure theory) - Wikipedia](https://en.wikipedia.org/wiki/Support_(measure_theory))\n[^2]: [ä¸ºä»€ä¹ˆç”¨äº¤å‰ç†µåšæŸå¤±å‡½æ•° - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/70804197)\n[^3]: [äº¤å‰ç†µ - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E7%86%B5)   [Cross entropy - Wikipedia](https://en.wikipedia.org/wiki/Cross_entropy) [è¯¦è§£æœºå™¨å­¦ä¹ ä¸­çš„ç†µã€æ¡ä»¶ç†µã€ç›¸å¯¹ç†µå’Œäº¤å‰ç†µ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/35379531)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-12-Predication_or_Inference-Difference":{"title":"D2L-12-Predication_or_Inference-Difference","content":"# Prediction or Inference? The Difference\n\n\u003cdiv align=\"right\"\u003e 2022-02-08\u003c/div\u003e\n\nTags: #DeepLearning #Math/Statistics #Inference #Prediction\n\n- åœ¨æ·±åº¦å­¦ä¹ é‡Œé¢, **ç»™å®šç‰¹å¾ä¼°è®¡ç›®æ ‡**çš„è¿‡ç¨‹é€šå¸¸ç§°ä¸º_é¢„æµ‹_ï¼ˆpredictionï¼‰æˆ–_æ¨æ–­_ï¼ˆinferenceï¼‰ã€‚\n- ä½†æ˜¯, è™½ç„¶ _æ¨æ–­_ è¿™ä¸ªè¯å·²ç»æˆä¸ºæ·±åº¦å­¦ä¹ çš„æ ‡å‡†æœ¯è¯­ï¼Œä½†å…¶å® _æ¨æ–­_ è¿™ä¸ªè¯æœ‰äº›ç”¨è¯ä¸å½“ã€‚ **åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œ_æ¨æ–­_ æ›´å¤šåœ°è¡¨ç¤ºåŸºäºæ•°æ®é›†ä¼°è®¡å‚æ•°ã€‚**[^1] å½“æ·±åº¦å­¦ä¹ ä»ä¸šè€…ä¸ç»Ÿè®¡å­¦å®¶äº¤è°ˆæ—¶ï¼Œæœ¯è¯­çš„è¯¯ç”¨ç»å¸¸å¯¼è‡´ä¸€äº›è¯¯è§£ã€‚[^2]\n\n\n[^1]: å¦‚Bayesian Inference: [Bayesian_Estimation(Inference)è´å¶æ–¯ä¼°è®¡](notes/2021/2021.12/Bayesian_Estimation(Inference)è´å¶æ–¯ä¼°è®¡.md)\n[^2]: https://zh-v2.d2l.ai/chapter_linear-networks/linear-regression.html","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-13-Softmax_Regression":{"title":"D2L-13-Softmax_Regression","content":"# Softmax å›å½’\n\n\u003cdiv align=\"right\"\u003e 2022-02-11\u003c/div\u003e\n\nTags: #SoftmaxRegression #MachineLearning #Classification #MulticlassClassification \n\n- Softmaxå›å½’è§£å†³çš„æ˜¯å¤šåˆ†ç±»é—®é¢˜[^1], å®ƒå¯ä»¥çœ‹ä½œæ˜¯äºŒåˆ†ç±»çš„[Logistic_Regression](notes/2021/2021.8/Part.12_Logistic_Regression(ML_Andrew.Ng.).md)çš„æ¨å¹¿.\n\n[Softmaxå‡½æ•°](notes/2022/2022.2/Softmaxå‡½æ•°.md)\n\n## Softmaxå›å½’\n- Softmaxå›å½’å°±æ˜¯åœ¨çº¿æ€§å›å½’çš„åŸºç¡€ä¸Šå¥—ä¸Šä¸€ä¸ªSoftmaxå‡½æ•°, å–è¾“å‡ºç»“æœä¸­æ¦‚ç‡æœ€å¤§çš„é¡¹ä½œä¸ºé¢„æµ‹ç»“æœ.\n![](notes/2022/2022.2/assets/Pasted%20image%2020220211175631.png)\n\n### äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°\n[D2L-14-Cross Entropy as Loss](notes/2022/2022.2/D2L-14-Cross%20Entropy%20as%20Loss.md)\n\n\n\n\n## Softmax and Argmax\n- ä¸åƒSoftmaxè¾“å‡ºKä¸ªæ¦‚ç‡å€¼, Argmaxå‡½æ•°ç›´æ¥å°†è¾“å…¥å‘é‡é‡Œé¢æœ€å¤§çš„å…ƒç´ è®¾ç½®ä¸º1, å…¶ä»–å‡ç½®ä¸º0.\n- Argmaxå¸¸å¸¸ç”¨äºè¾“å‡ºé¢„æµ‹ç»“æœ, ä½†æ˜¯Argmaxæœ‰ä¸ªå¾ˆä¸¥é‡çš„ç¼ºç‚¹: å®ƒçš„ç»“æœæ²¡æ³•ç”¨äºåå‘ä¼ æ’­ä¼˜åŒ–å‚æ•°: (å› ä¸ºå®ƒè¦ä¹ˆä¸å¯å¯¼è¦ä¹ˆå¯¼æ•°ä¸º0)\n\nè§£é‡Š: \n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KpKog-L9veg?start=185\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n### Softmaxåç§°çš„ç”±æ¥\n\u003e Softmaxçš„åå­—æ˜¯æ€ä¹ˆæ¥çš„ï¼Ÿ - 2WaveTechçš„æ–‡ç«  - çŸ¥ä¹ https://zhuanlan.zhihu.com/p/58859958\n\nSoftmaxæ˜¯\"Hardmax\"å‡½æ•°çš„Softç‰ˆæœ¬: \n![](notes/2022/2022.2/assets/Pasted%20image%2020220211181821.png)\n\n\n\n## ä¸Logistic(Sigmoid)å›å½’çš„è”ç³»\n[Relation_between_Softmax_and_Logistic_Regression](notes/2022/2022.2/Relation_between_Softmax_and_Logistic_Regression.md)\n\n\n## æ•°å€¼ç¨³å®šæ€§ä¸Šé¢çš„ä¸€äº›ç»†èŠ‚\n\u003e softmaxå’Œcross-entropyæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ - è‘£é‘«çš„å›ç­” - çŸ¥ä¹ https://www.zhihu.com/question/294679135/answer/885285177\n\n\n\n[^1]: å’ŒLogisticå›å½’ä¸€æ ·, è™½ç„¶å®ƒåå­—å«å›å½’, å®é™…ä¸Šè§£å†³çš„å´æ˜¯åˆ†ç±»é—®é¢˜. ä¸ºä»€ä¹ˆå‘¢? æœç´¢äº†ä¸€ä¼šå„¿æ²¡æœ‰å¾—åˆ°ç»“æœğŸ˜¥\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-14-Cross-Entropy-as-Loss":{"title":"D2L-14-Cross Entropy as Loss","content":"# äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°\n\n\n- åœ¨ä½œä¸ºæŸå¤±å‡½æ•°çš„æ—¶å€™, æ„æˆ[äº¤å‰ç†µ](notes/2022/2022.2/Cross_Entropy-äº¤å‰ç†µ.md)çš„æ¦‚ç‡åˆ†å¸ƒä¸º:\n\t- çœŸå®åˆ†å¸ƒ: $P^*$\n\t- æ¨¡å‹è¾“å‡º: $P$\n\n![](notes/2022/2022.2/assets/img_2022-10-15-10.png)\n\n- ä½œä¸ºæŸå¤±å‡½æ•°, äº¤å‰ç†µçš„ä½œç”¨æ˜¯ **è¡¡é‡æ¨¡å‹è¾“å‡ºä¸çœŸå®å€¼çš„å·®è·**, ä½œä¸ºä¼˜åŒ–ç®—æ³•çš„ä¼˜åŒ–å¯¹è±¡, è¿˜éœ€è¦å°½é‡ç®€æ´, å‡å°‘è®­ç»ƒæ¨¡å‹çš„å¼€é”€.\n\n## ä¸ºä»€ä¹ˆäº¤å‰ç†µå¯ä»¥è¡¡é‡è¾“å‡ºä¸çœŸå®å€¼çš„å·®åˆ«?\n- æˆ‘ä»¬ç”±[KL_Divergence](notes/2022/2022.2/KL_Divergence-KLæ•£åº¦.md)ä¸€èŠ‚çŸ¥é“, KLæ•£åº¦å¯ä»¥ä½œä¸ºè¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒå·®è·çš„æŒ‡æ ‡: KLæ•£åº¦è¶Šæ¥è¿‘0, ä¸¤ä¸ªåˆ†å¸ƒçš„ç›¸ä¼¼åº¦è¶Šé«˜. \n\n- æˆ‘ä»¬å¯ä»¥è¯æ˜: æœ€å°åŒ– $D_{KL}(P^*||P)$ çš„è¿‡ç¨‹, å°±æ˜¯æœ€å°åŒ– $H(P^*|P)$ çš„è¿‡ç¨‹: \n\nè¯æ˜è§†é¢‘é˜è¿°å¾—éå¸¸å¥½ `(2:39)` : \n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Pwgpl9mKars\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write;  gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- Reference: [Intuitively Understanding the Cross Entropy Loss - YouTube](https://www.youtube.com/watch?v=Pwgpl9mKars)\n\n- **é‡ç‚¹:** \n\t- äº¤å‰ç†µå’ŒKLæ•£åº¦æœ‰è¿™æ ·çš„å…³ç³»: \n\t\t$$H(p, q) = H(p) + D_{\\mathrm{KL}}(p \\parallel q)$$\n\t\tä¹Ÿå°±æ˜¯è¯´: KLæ•£åº¦ (ç›¸å¯¹ç†µ) = äº¤å‰ç†µ - ä¿¡æ¯ç†µ\t\n\t\t- ç”±äºä¿¡æ¯ç†µæè¿°çš„æ˜¯æ¶ˆé™¤ $p$ (å³çœŸå®åˆ†å¸ƒ) çš„ä¸ç¡®å®šæ€§æ‰€éœ€ä¿¡æ¯é‡çš„åº¦é‡ï¼Œæ‰€ä»¥å…¶å€¼åº”è¯¥æ˜¯æœ€å°çš„ã€å›ºå®šçš„ã€‚é‚£ä¹ˆï¼š**ä¼˜åŒ–å‡å°ç›¸å¯¹ç†µä¹Ÿå°±æ˜¯ä¼˜åŒ–äº¤å‰ç†µï¼Œæ‰€ä»¥åœ¨æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨äº¤å‰ç†µå°±å¯ä»¥äº†ã€‚**\n\n## Cross Entropyä¸Softmax\n**ä¸ºä»€ä¹ˆç»å¸¸çœ‹åˆ°Cross Entropyå’ŒSoftmaxåœ¨ä¸€èµ·?**\n- åˆ©ç”¨äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°çš„æ—¶å€™, è¦æ±‚æ¨¡å‹çš„è¾“å‡º $P$ æ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ, è€ŒSoftmaxçš„ä½œç”¨å°±æ˜¯å°†æ¨¡å‹çš„\"ç›´æ¥è¾“å‡º\"è½¬åŒ–ä¸º\"æ¦‚ç‡è¾“å‡º\".\n\n\t- æ¨¡å‹çš„ç›´æ¥è¾“å‡ºåˆç§°ä¸º \"[Logit](notes/2022/2022.2/Logit.md)\"(è‡³å°‘åœ¨æ·±åº¦å­¦ä¹ é‡Œé¢)\n\n## è¯¦ç»†æ¨å¯¼\n- å‡è®¾ä¸€å…±æœ‰ $K$ ä¸ªç±»åˆ«, ä»¤ $\\mathbf{y}$ ä¸ºçœŸå®æ ‡ç­¾([One-hotç¼–ç ](notes/2022/2022.1/One-hot_Encoding-ç‹¬çƒ­ç¼–ç .md), åªæœ‰ ${y}_k=1$), $\\mathbf{\\hat y}$ ä¸º Softmax æ¨¡å‹é¢„æµ‹çš„è¾“å‡º[^2], $\\mathbf{o}$ è¡¨ç¤º logits(Softmax å±‚çš„è¾“å…¥).\n- å…ˆå‚è€ƒä¸€ä¸‹äº¤å‰ç†µçš„å®šä¹‰:\n\t[Cross Entropy - äº¤å‰ç†µ](notes/2022/2022.2/Cross_Entropy-äº¤å‰ç†µ.md#Cross%20Entropy%20-%20äº¤å‰ç†µ)\n- æŸå¤±å‡½æ•°æ˜¯äº¤å‰ç†µ $H(\\mathbf{y}, \\mathbf{\\hat y})$ :\n$$\\begin{aligned}\nL(\\mathbf{y},\\hat{\\mathbf{y}}) \u0026=\\sum_{j=1}^K {y}_j \\log \\frac{1}{\\hat{y}_j} \\\\ \u0026=-\\sum_{j=1}^K {y}_j \\log{\\hat{y}_j}\\\\\n\u0026=-\\sum_{j=1}^K {y}_j \\log{\\frac{\\exp \\left(o_{j}\\right)}{\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)}}\\\\\n(\\text{ç‹¬çƒ­ç¼–ç ,åªæœ‰}{y}_k\\text{ä¸º}1)\u0026=-\\log{\\frac{\\exp \\left(o_{k}\\right)}{\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)}}\\\\\n\u0026=-\\log \\hat{y}_k\n\\end{aligned}$$\n\n- å…¶å®å°±æ˜¯é¢„æµ‹æ¦‚ç‡ $\\hat{y}_k$ çš„è´Ÿå¯¹æ•°, å…¶ä¸­ $k$ å¯¹åº”çœŸå®æ ‡ç­¾ ${y}_k$ \n\n- æ¥ä¸‹æ¥æ±‚ $L(\\mathbf{y}, \\hat{\\mathbf{y}})$ å¯¹äºSoftmaxå±‚è¾“å…¥Logit $o_p$ çš„å¯¼æ•°: \n\n$$\\begin{aligned}\\frac{\\partial}{\\partial o_p}L(\\mathbf{y}, \\hat{\\mathbf{y}})\u0026=-\\frac{\\partial}{\\partial o_p}\\left(\\log{\\frac{\\exp \\left(o_{k}\\right)}{\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)}}\\right)\\\\\n\u0026=-\\frac{\\partial}{\\partial o_p}\\left(o_{k}-{\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)}\\right)\n\\\\\n\u0026=\\begin{cases}\n\\frac{\\partial}{\\partial o_p}\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)-1 \u0026 \\text{when }p=k\\\\    \n\\frac{\\partial}{\\partial o_p}\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)-0 \u0026 \\text{when }p\\neq k\n\\end{cases}\\\\\n\u0026=\\frac{\\partial}{\\partial o_p}\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)-{y}_p\\\\   \n\u0026=\\frac{\\exp{o_p}}{\\sum_{i=1}^{K} \\exp (o_{i})}-{y}_p\\\\\u0026=\\operatorname{Softmax}(\\mathbf{o})_p-{y}_p\n\\end{aligned}$$\n\nå…¶ä¸­ $\\mathbf{o=W^T X+b}$\n\n- å¯ä»¥çœ‹åˆ°è¿™ä¸ªå¯¼æ•°ååˆ†ç®€å•, å°±æ˜¯æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡å€¼ $\\operatorname{Softmax}(\\mathbf{o})_p$ å‡å»çœŸå®çš„æ¦‚ç‡å€¼ ${y}_p$.[^1]\n\n### å¦ä¸€ç§æ¨å¯¼\nè¿™é‡Œç»™å‡ºå¦ä¸€ç§æ¨å¯¼æ–¹å¼:\n\n$$\\begin{aligned}\nL(\\mathbf{y}, \\hat{\\mathbf{y}}) \u0026=-\\sum_{j=1}^{K} {y}_{j} \\log \\frac{\\exp \\left(o_{j}\\right)}{\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)} \\\\\n(\\text{å°†è´Ÿå·ç§»è¿›å»})\u0026=\\quad\\sum_{j=1}^{K} {y}_{j} \\log \\frac{\\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)}{\\exp \\left(o_{j}\\right)} \\\\\n\u0026=\\sum_{j=1}^{K} {y}_{j} \\log \\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)-\\sum_{j=1}^{K} {y}_{j} o_{j} \\\\\n(\\text{ç‹¬çƒ­ç¼–ç ,åªæœ‰ä¸€ä¸ª}{y}_j\\text{ä¸º}1)\u0026=\\log \\sum_{i=1}^{K} \\exp \\left(o_{i}\\right)-\\sum_{j=1}^{K} {y}_{j} o_{j} .\n\\end{aligned}$$\n\n- ä¸Šé¢çš„æ¨å¯¼é‡Œé¢, å¹¶æ²¡æœ‰æŠŠååŠéƒ¨åˆ†çš„${y}_j$æ¶ˆå», è¿™ä½¿å¾—ä¸‹é¢æ±‚åå¯¼ä¸ç”¨åˆ†ç±»è®¨è®º:\n\n- æˆ‘ä»¬æ±‚ $L(\\mathbf{y}, \\hat{\\mathbf{y}})$ å¯¹äºSoftmaxå±‚è¾“å…¥ $o_p$ çš„å¯¼æ•°:\n$$\\begin{aligned}\\frac{\\partial}{\\partial o_p}L(\\mathbf{y}, \\hat{\\mathbf{y}})\u0026=\\frac{\\exp{o_p}}{\\sum_{i=1}^{K} \\exp (o_{i})}-{y}_p\\\\\u0026=\\operatorname{Softmax}(\\mathbf{o})_p-{y}_p\n\\end{aligned}$$\n\n## å¯¹æ¯”äº¤å‰ç†µä¸å‡æ–¹è¯¯å·®\n[ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE](notes/2022/2022.2/ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE.md)\n\n## PyTorchçš„Cross Entropy LossåŒ…æ‹¬Softmax\n\u003e - `class torch.nn.CrossEntropyLoss(weight=None, size_average=True)`\n\u003e - æ­¤æ ‡å‡†å°†`LogSoftMax`å’Œ`NLLLoss`é›†æˆåˆ°ä¸€ä¸ªç±»ä¸­ã€‚å½“è®­ç»ƒä¸€ä¸ªå¤šç±»åˆ†ç±»å™¨çš„æ—¶å€™ï¼Œè¿™ä¸ªæ–¹æ³•æ˜¯ååˆ†æœ‰ç”¨çš„ã€‚\n\n- [torch.nn - PyTorchä¸­æ–‡æ–‡æ¡£](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/)\n- [CrossEntropyLoss â€” PyTorch 1.10 documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n\n- PyTorch çš„å®ç°è¿˜éœ€è¦è€ƒè™‘ä¸€ä¸ª Batch é‡Œé¢çš„å¤šç»„æ•°æ®, æ‰€ä»¥æ¯”è¾ƒéš¾æ‡‚.\n- å‡è®¾ä¸€ä¸ª Batch ç”± $N$ ç»„æ•°æ®ç»„æˆ, åˆ™æˆ‘ä»¬å¯ä»¥å¯¹ä¸€ä¸ª Batch çš„ $N$ ä¸ªæŸå¤±è¿›è¡Œä¸‰ç§æ“ä½œ:\n\t- å–å¹³å‡\n\t- æ±‚å’Œ\n\t- ä»€ä¹ˆä¹Ÿä¸åš\n- ä¸Šé¢ä¸‰ç§æ“ä½œåˆ†åˆ«å¯¹åº” `reduction='mean', 'sum', 'none'`, é»˜è®¤ `reduction='mean'`\n\n### `reduction='none'`\n\n$$\\ell(x, y)=L=\\left\\{l_{1}, \\ldots, l_{N}\\right\\}^{\\top}, \\quad l_{n}=-w_{y_{n}} \\log \\frac{\\exp \\left(x_{n, y_{n}}\\right)}{\\sum_{c=1}^{C} \\exp \\left(x_{n, c}\\right)} \\cdot 1\\left\\{y_{n} \\neq \\text { ignore\\_index }\\right\\}$$\n\n- åœ¨ä¸Šé¢çš„å¼å­é‡Œé¢, $\\ell(x, y)=L=\\left\\{l_{1}, \\ldots, l_{N}\\right\\}^{\\top}$ çš„æ„æ€æ˜¯: ä¸€ä¸ª Batch é‡Œé¢æœ‰ $N$ ç»„æ•°æ®, è€Œè¾“å‡ºæ˜¯è¿™ $N$ ç»„æŸå¤±ç»„æˆçš„ä¸€ä¸ªå‘é‡.\n- $w_{y_{n}}$ ç”¨äºå¯¹ä¸åŒç±»åˆ«çš„æŸå¤±è¿›è¡ŒåŠ æƒ, è¿™å¸¸å¸¸åœ¨ç±»åˆ«æ•°æ®ä¸å¹³è¡¡çš„æ—¶å€™ä½¿ç”¨.\n- $\\cdot 1\\left\\{y_{n} \\neq \\text { ignore\\_index }\\right\\}$ è¡¨ç¤ºå¿½ç•¥ $y_{n} = \\text { ignore\\_index }$ çš„ç±»åˆ« \n\n### `reduction='sum', 'mean'`\n\n$$\n\\ell(x, y)= \\begin{cases}\\sum_{n=1}^{N} \\frac{1}{\\sum_{n=1}^{N} w_{y_{n}} \\cdot 1\\left\\{y_{n} \\neq \\text { ignore\\_index }\\right\\}}l_{n}, \u0026 \\text { if reduction }=\\text { 'mean'; } \\\\ \\sum_{n=1}^{N} l_{n}, \u0026 \\text{ if reduction }=\\text { 'sum' }\\end{cases}\n$$\n\n## éœ€è¦æŠŠæ ‡ç­¾ one-hot ä¹‹åå†è¾“å…¥åˆ°æŸå¤±å‡½æ•°é‡Œé¢å—?\n[Cross_Entropy_Loss_Input_Format-äº¤å‰ç†µæŸå¤±å‡½æ•°è¾“å…¥æ ¼å¼](notes/2022/2022.5/Cross_Entropy_Loss_Input_Format-äº¤å‰ç†µæŸå¤±å‡½æ•°è¾“å…¥æ ¼å¼.md)\n\n\n\n[^1]:æ•™æé‡Œé¢è¯´: è¿™ä¸æ˜¯å·§åˆï¼Œåœ¨ä»»ä½•æŒ‡æ•°æ—åˆ†å¸ƒæ¨¡å‹ä¸­ ï¼ˆå‚è§[æœ¬ä¹¦é™„å½•ä¸­å…³äºæ•°å­¦åˆ†å¸ƒçš„ä¸€èŠ‚](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html) ï¼‰ï¼Œ å¯¹æ•°ä¼¼ç„¶çš„æ¢¯åº¦æ­£æ˜¯ç”±æ­¤å¾—å‡ºçš„ã€‚ è¿™ä½¿æ¢¯åº¦è®¡ç®—åœ¨å®è·µä¸­å˜å¾—å®¹æ˜“å¾ˆå¤šã€‚ ä½†æ˜¯æˆ‘è¿˜æ˜¯ä¸æ˜¯å¾ˆç†è§£è¿™é‡Œä»€ä¹ˆæ„æ€. https://zh-v2.d2l.ai/chapter_linear-networks/softmax-regression.html#subsec-softmax-and-derivatives\n[^2]: Y hat (written $yÌ‚$ ) is **the predicted value of y** (the [dependent variable](https://www.statisticshowto.com/dependent-variable-definition/)) in a [regression equation](https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/what-is-a-regression-equation/). [Y Hat: Definition - Statistics How To](https://www.statisticshowto.com/y-hat-definition/)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-15-Perceptron":{"title":"D2L-15-Perceptron","content":"# Perceptron - æ„ŸçŸ¥æœº\n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #MachineLearning #Perceptron\n\n![Perceptron](notes/2022/2022.2/assets/Perceptron.pdf)\n\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-16-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%97%AE%E9%A2%98":{"title":"D2L-16-çº¿æ€§æ¨¡å‹çš„é—®é¢˜","content":"# çº¿æ€§æ¨¡å‹å­˜åœ¨çš„é—®é¢˜\n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #DeepLearning \n\n- çº¿æ€§æ„å‘³ç€ _\"å•è°ƒæ€§\"_ å‡è®¾ï¼š è¾“å‡ºå’Œè¾“å…¥ä»¥ç›¸åŒçš„é€Ÿåº¦å˜åŒ–.\n\t- ä½†æ˜¯æœ‰å¾ˆå¤šé—®é¢˜è™½ç„¶æ˜¯å•è°ƒçš„, ä½†æ˜¯å¹¶ä¸æ˜¯çº¿æ€§\"åŒ€é€Ÿ\"å˜åŒ–çš„\n\t- å¯¹ç­–: å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿çº¿æ€§å˜å¾—æ›´åˆç†ï¼Œå¦‚è¿›è¡Œå¯¹æ•°å˜æ¢ã€‚\n\n- ä½†æ˜¯å¾ˆå¤šæƒ…å†µä¹Ÿä¸æ˜¯å•è°ƒçš„ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬æƒ³è¦æ ¹æ®ä½“æ¸©é¢„æµ‹æ­»äº¡ç‡ã€‚ å¯¹äºä½“æ¸©é«˜äº37æ‘„æ°åº¦çš„äººæ¥è¯´ï¼Œæ¸©åº¦è¶Šé«˜é£é™©è¶Šå¤§ã€‚ ç„¶è€Œï¼Œå¯¹äºä½“æ¸©ä½äº37æ‘„æ°åº¦çš„äººæ¥è¯´ï¼Œæ¸©åº¦è¶Šé«˜é£é™©å°±è¶Šä½ã€‚\n\t- å¯¹ç­–: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ä¸€äº›å·§å¦™çš„é¢„å¤„ç†æ¥è§£å†³é—®é¢˜ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸37æ‘„æ°åº¦çš„è·ç¦»ä½œä¸ºç‰¹å¾ã€‚\n\n- ä½†æ˜¯ï¼Œå¦‚ä½•å¯¹çŒ«å’Œç‹—çš„å›¾åƒè¿›è¡Œåˆ†ç±»å‘¢ï¼Ÿ å¢åŠ ä½ç½®(13,17)å¤„åƒç´ çš„å¼ºåº¦æ˜¯å¦æ€»æ˜¯å¢åŠ ï¼ˆæˆ–é™ä½ï¼‰å›¾åƒæç»˜ç‹—çš„ä¼¼ç„¶ï¼Ÿ \n- ä¸å‰é¢çš„ä¾‹å­ç›¸æ¯”ï¼Œè¿™é‡Œä»»ä½•åƒç´ çš„é‡è¦æ€§éƒ½ä»¥å¤æ‚çš„æ–¹å¼å–å†³äºå‘¨å›´åƒç´ çš„å€¼ã€‚æ•°æ®éœ€è¦è€ƒè™‘åˆ°ç‰¹å¾ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚ä»è€Œ, åœ¨åŸºäºç›¸äº’ä½œç”¨çš„è¡¨ç¤ºçš„åŸºç¡€ä¸Šå»ºç«‹ä¸€ä¸ªçº¿æ€§æ¨¡å‹å¯èƒ½ä¼šæ˜¯åˆé€‚çš„ï¼Œä½†æˆ‘ä»¬ä¸çŸ¥é“å¦‚ä½•æ‰‹åŠ¨è®¡ç®—è¿™ä¹ˆä¸€ç§è¡¨ç¤ºã€‚ \n\t- **å¯¹ç­–:** æ·±åº¦ç¥ç»ç½‘ç»œ. æˆ‘ä»¬å°†è§‚æµ‹æ•°æ®è¾“å…¥**éšè—å±‚**, åœ¨æ­¤åŸºç¡€ä¸Šå»ºç«‹çº¿æ€§é¢„æµ‹å™¨ã€‚\n\n![](notes/2022/2022.2/assets/mlp.svg)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-17-MLP-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA":{"title":"D2L-17-MLP-å¤šå±‚æ„ŸçŸ¥æœº","content":"# Multilayer Perceptron  \n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #MultilayerPerceptron #DeepLearning #Perceptron \n\n## éšè—å±‚\n![mlp](notes/2022/2022.2/assets/mlp.svg)\n \n ## ä»çº¿æ€§åˆ°éçº¿æ€§\n- ç”¨$\\mathbf{X, H, O}$ åˆ†åˆ«ä»£è¡¨è¾“å…¥å±‚, éšè—å±‚å’Œè¾“å‡ºå±‚, å¸¦åç½®çš„æ¨¡å‹å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹:\n$$\\begin{aligned}\n\u0026\\mathbf{H}=\\mathbf{X} \\mathbf{W}^{(1)}+\\mathbf{b}^{(1)} \\\\\n\u0026\\mathbf{O}=\\mathbf{H} \\mathbf{W}^{(2)}+\\mathbf{b}^{(2)}\n\\end{aligned}$$\n \n - ä½†æ˜¯çº¿æ€§ä»£æ•°å‘Šè¯‰æˆ‘ä»¬, çº¿æ€§ç»„åˆçš„çº¿æ€§ç»„åˆä¾ç„¶æ˜¯ä¸€ä¸ªçº¿æ€§ç»„åˆ, æ‰€ä»¥ä»…ä»…åŠ å…¥ä¸€ä¸ªéšè—å±‚å¹¶æ²¡æœ‰å¢åŠ æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ğŸ˜.\n\t - è¯æ˜: \n\t \t$$\\begin{aligned}\n\t\\mathbf{O}\u0026=\\left(\\mathbf{X W}^{(1)}+\\mathbf{b}^{(1)}\\right) \\mathbf{W}^{(2)}+\\mathbf{b}^{(2)}\\\\\n\t\u0026=\\mathbf{X} \\mathbf{W}^{(1)} \\mathbf{W}^{(2)}+\\mathbf{b}^{(1)} \\mathbf{W}^{(2)}+\\mathbf{b}^{(2)}\\\\\n\t\u0026=\\mathbf{X} \\mathbf{W'}+\\mathbf{b'}\\end{aligned}$$\n\n- ä¸ºäº†å‘æŒ¥å¤šå±‚æ¶æ„çš„æ½œåŠ›ï¼Œ æˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªé¢å¤–çš„å…³é”®è¦ç´ ï¼š **æ¿€æ´»å‡½æ•°**ï¼ˆ**activation function**ï¼‰$Ïƒ$ã€‚ \n\t- åœ¨æˆ‘ä»¬çš„å•éšè—å±‚æ¨¡å‹é‡Œé¢, è¾“å…¥ä¹‹åçš„æƒé‡å¯¹æ•°æ®è¿›è¡Œäº†[ä»¿å°„å˜æ¢](notes/2022/2022.2/ä»¿å°„å˜æ¢-Affine_Transformation.md), æ­¤åé€šè¿‡å¯¹æ¯ä¸ªéšè—å±‚å•å…ƒåº”ç”¨éçº¿æ€§çš„**æ¿€æ´»å‡½æ•°**, æˆ‘ä»¬çš„å¤šå±‚æ„ŸçŸ¥æœºä¸å†é€€åŒ–æˆçº¿æ€§æ¨¡å‹.\n\t\t$$\\begin{aligned}\u0026\\mathbf{H}=\\sigma\\left(\\mathbf{X W}^{(1)}+\\mathbf{b}^{(1)}\\right) \\\\\n\t\u0026\\mathbf{O}=\\mathbf{H W}^{(2)}+\\mathbf{b}^{(2)}\n\t\\end{aligned}$$\n\t- æ¿€æ´»å‡½æ•°çš„è¾“å‡º $Ïƒ(â‹…)$ è¢«ç§°ä¸º**æ´»æ€§å€¼**ï¼ˆ**activation**ï¼‰ã€‚ \n\t- æ³¨æ„, é€šå¸¸æˆ‘ä»¬ä¸åœ¨è¾“å‡ºå±‚ä¸Šä½œç”¨æ¿€æ´»å‡½æ•°, è¾“å‡ºå±‚ä¸Šé¢å¸¸å¸¸æ˜¯[Softmax](notes/2022/2022.2/D2L-13-Softmax_Regression.md)æˆ–è€…å…¶ä»–å˜æ¢.\n\n\t- ä¸ºäº†æ„å»ºæ›´é€šç”¨çš„å¤šå±‚æ„ŸçŸ¥æœºï¼Œ æˆ‘ä»¬å¯ä»¥ç»§ç»­å †å è¿™æ ·çš„éšè—å±‚ï¼Œ ä¾‹å¦‚$\\mathbf{H^{(1)}=Ïƒ_1(XW^{(1)}+b^{(1)})}$ å’Œ $\\mathbf{H^{(2)}=Ïƒ_2(H^{(1)}W^{(2)}+b^{(2)})}$ï¼Œ ä»è€Œäº§ç”Ÿæ›´æœ‰è¡¨è¾¾èƒ½åŠ›çš„æ¨¡å‹ã€‚\n\n## ææ¸…æ¥šçŸ©é˜µçš„å½¢çŠ¶\n- ä¸ºäº†ä½¿æ€è·¯æ¸…æ™°ï¼Œ æˆ‘ä»¬æ¥ç†ä¸€ä¸‹D2Lé‡Œé¢MLPå„ä¸ªçŸ©é˜µçš„å½¢çŠ¶ï¼š\n- **è¾“å…¥**: $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ è¡¨ç¤º $n$ ä¸ªæ ·æœ¬çš„å°æ‰¹é‡, å…¶ä¸­æ¯ä¸ªæ ·æœ¬å…·æœ‰ $d$ ä¸ªè¾“å…¥ç‰¹å¾ã€‚\n\t\t![Xçš„ç»´åº¦](notes/2022/2022.2/assets/Xçš„ç»´åº¦.svg)\n- **æƒé‡çŸ©é˜µ**: ä»¥ç¬¬ä¸€å±‚æƒé‡ä¸ºä¾‹ï¼š  $\\mathbf{W}^{(1)} \\in \\mathbb{R}^{d \\times h}$ \n\t![Wçš„ç»´åº¦](notes/2022/2022.2/assets/Wçš„ç»´åº¦.svg)\n\n- **éšè—å±‚åç½®** $\\mathbf{b}^{(1)} \\in \\mathbb{R}^{1 \\times h}$\n\t![Biasçš„ç»´åº¦](notes/2022/2022.2/assets/Biasçš„ç»´åº¦.svg)\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-18-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0-Activation_Functions":{"title":"D2L-18-æ¿€æ´»å‡½æ•°-Activation_Functions","content":"# å¸¸ç”¨æ¿€æ´»å‡½æ•°\n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #DeepLearning #ActivationFunction \n\n![](notes/2022/2022.2/assets/img_2022-10-15-2.gif)[^2]\n\n## ReLU\n**ä¿®æ­£çº¿æ€§å•å…ƒ**ï¼ˆRectified Linear Unitï¼Œ_ReLU_ï¼‰\n![](notes/2022/2022.2/assets/ReLU.svg)\n- ReLUå°±æ˜¯ä¸€ä¸ª $max(0,x)$ å‡½æ•°.\n- ReLUæ˜¯åˆ†æ®µçº¿æ€§çš„\n- ReLUçš„å˜ä½“é€šè¿‡è®¾ç½®ä¸€ä¸ªçº¿æ€§é¡¹, ä½¿å¾—è´Ÿè½´çš„ä¸€äº›ä¿¡æ¯å¾—åˆ°ä¿ç•™(Parameterized ReLU)\n\t$\\mathbf{pReLU}(x)=max(0,x)+Î±\\space min(0,x).$\n\t![](notes/2022/2022.2/assets/Pasted%20image%2020220212160706.png)\n\n### å¯¼æ•°\n![](notes/2022/2022.2/assets/Derivative_of_ReLU.svg)\n- ä½¿ç”¨ReLUçš„åŸå› æ˜¯ï¼Œå®ƒæ±‚å¯¼è¡¨ç°å¾—ç‰¹åˆ«å¥½ï¼šè¦ä¹ˆè®©å‚æ•°æ¶ˆå¤±ï¼Œè¦ä¹ˆè®©å‚æ•°é€šè¿‡ã€‚\n- æ³¨æ„ï¼Œå½“è¾“å…¥å€¼ç²¾ç¡®ç­‰äº0æ—¶ï¼ŒReLUå‡½æ•°ä¸å¯å¯¼ã€‚ åœ¨æ­¤æ—¶ï¼Œæˆ‘ä»¬é»˜è®¤ä½¿ç”¨å·¦ä¾§çš„å¯¼æ•°ï¼Œå³å½“è¾“å…¥ä¸º0æ—¶å¯¼æ•°ä¸º0ã€‚[^1]\n\n## Sigmoid å‡½æ•°\n[Sigmoid_Function](notes/2021/2021.8/Sigmoid_Function.md)\n\n## Tanh å‡½æ•°\n- ä¸sigmoidå‡½æ•°ç±»ä¼¼ï¼Œ tanh(åŒæ›²æ­£åˆ‡)å‡½æ•°å°†å…¶è¾“å…¥å‹ç¼©è½¬æ¢åˆ°åŒºé—´$(-1, 1)$ä¸Šã€‚\n\t- ä¸Sigmoidçš„åŒºåˆ«æ˜¯å‹ç¼©çš„åŒºé—´ä¸ä¸€æ ·(Sigmoid: $(0,1)$, Tanh: $(-1,1)$). åŒæ—¶, tanhå‡½æ•°æ˜¯å¥‡å‡½æ•°.\n\n$$\\tanh (x)=\\frac{1-\\exp (-2 x)}{1+\\exp (-2 x)}$$\n\n![](notes/2022/2022.2/assets/Tanh.svg)\n### å¯¼æ•°\n$$\\frac{d}{d x} \\tanh (x)=1-\\tanh ^{2}(x)$$\n\n![](notes/2022/2022.2/assets/Derivative-of-Tanh.svg)\n\n\n\n\n\n\n[^1]: æˆ‘ä»¬å¯ä»¥å¿½ç•¥è¿™ç§æƒ…å†µï¼Œå› ä¸ºè¾“å…¥å¯èƒ½æ°¸è¿œéƒ½ä¸ä¼šæ˜¯0ã€‚ è¿™é‡Œå¼•ç”¨ä¸€å¥å¤è€çš„è°šè¯­ï¼Œâ€œå¦‚æœå¾®å¦™çš„è¾¹ç•Œæ¡ä»¶å¾ˆé‡è¦ï¼Œæˆ‘ä»¬å¾ˆå¯èƒ½æ˜¯åœ¨ç ”ç©¶æ•°å­¦è€Œéå·¥ç¨‹â€ï¼Œ è¿™ä¸ªè§‚ç‚¹æ­£å¥½é€‚ç”¨äºè¿™é‡Œã€‚\n[^2]: [Activation Functions Explained - GELU, SELU, ELU, ReLU and more](https://mlfromscratch.com/activation-functions-explained/#/)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-19-%E9%AA%8C%E8%AF%81%E9%9B%86_or_%E6%B5%8B%E8%AF%95%E9%9B%86":{"title":"D2L-19-éªŒè¯é›†_or_æµ‹è¯•é›†","content":"- **éªŒè¯** æ•°æ®é›†: **Validation** set, æ˜¯è®­ç»ƒçš„æ—¶å€™è°ƒæ•´å‚æ•°çš„ä¾æ®\n  - è®­ç»ƒæ—¶è¢«å¤šæ¬¡ä½¿ç”¨\n\n- **æµ‹è¯•** æ•°æ®é›†: **Test** set, æ˜¯æœ€ç»ˆæµ‹è¯•æ¨¡å‹æ€§èƒ½çš„æ•°æ®\n  - è®­ç»ƒå®Œååªæµ‹è¯•ä¸€æ¬¡\n\nè¿™ä¸¤ä¸ªè¯å¸¸å¸¸è¢«æ··æ·†, ä½†æ˜¯æœ‰ç€å¾ˆé‡è¦çš„åŒºåˆ«:\n\n- æµ‹è¯•æ•°æ®é›†ä¸è¢«ç”¨æ¥è°ƒæ•´æ¨¡å‹å‚æ•°\n\n**ä¸€ä¸ªç±»æ¯”:**\n\n- éªŒè¯é›†æ˜¯é«˜è€ƒæ¨¡è€ƒè¯•å·\n  - å¹³æ—¶æµ‹è¯•è‡ªå·±çš„æ°´å¹³ç”¨æ¨¡è€ƒå·å­, æ ¹æ®æˆç»©è°ƒæ•´å­¦ä¹ ç­–ç•¥\n- æµ‹è¯•é›†æ˜¯é«˜è€ƒè¯•å·\n  - é«˜è€ƒåªèƒ½å‚åŠ ä¸€æ¬¡, ä¸èƒ½è¯´çœ‹äº†é«˜è€ƒå·ä¹‹åå†å»å‡†å¤‡å‡†å¤‡é‡æ–°è€ƒä¸€æ¬¡.\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-20-%E8%AE%AD%E7%BB%83%E8%AF%AF%E5%B7%AE%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%AF%AF%E5%B7%AE":{"title":"D2L-20-è®­ç»ƒè¯¯å·®ä¸æ³›åŒ–è¯¯å·®","content":"# è®­ç»ƒè¯¯å·®ä¸æ³›åŒ–è¯¯å·®\n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #DeepLearning \n\n- è¿™ä¸€å°èŠ‚å†™çš„æŒºå¥½çš„: [è®­ç»ƒè¯¯å·®å’Œæ³›åŒ–è¯¯å·®Â¶](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html#id2 \"Permalink to this headline\")\n\n## å®šä¹‰\n- _è®­ç»ƒè¯¯å·®_ï¼ˆtraining errorï¼‰æ˜¯æŒ‡ï¼Œ æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè®¡ç®—å¾—åˆ°çš„è¯¯å·®ã€‚ \n- _æ³›åŒ–è¯¯å·®_ï¼ˆgeneralization errorï¼‰æ˜¯æŒ‡ï¼Œ æ¨¡å‹åº”ç”¨åœ¨åŒæ ·ä»åŸå§‹æ ·æœ¬çš„åˆ†å¸ƒä¸­æŠ½å–çš„æ— é™å¤šæ•°æ®æ ·æœ¬æ—¶ï¼Œæ¨¡å‹è¯¯å·®çš„æœŸæœ›ã€‚\n\n- å› ä¸ºæˆ‘ä»¬ä¸èƒ½å¾—åˆ°æ— é™å¤šçš„æ ·æœ¬, æ‰€ä»¥æˆ‘ä»¬åªèƒ½ä¼°è®¡æ³›åŒ–è¯¯å·®.\n\n### è®¾ç½®æµ‹è¯•é›†çš„æ„ä¹‰\n- å¦‚æœæˆ‘ä»¬å°†æ‰€æœ‰æ•°æ®éƒ½ç”¨æ¥è®­ç»ƒ, æˆ‘ä»¬å°±æ²¡æ³•ç›‘æ§æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›\n\n\t- æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å‘ç°æŸäº›æ¨¡å¼ï¼Œ è¿™äº›æ¨¡å¼æ•æ‰åˆ°äº†æˆ‘ä»¬è®­ç»ƒé›†æ½œåœ¨æ€»ä½“çš„è§„å¾‹ã€‚ å¦‚æœæˆåŠŸåšåˆ°äº†è¿™ç‚¹ï¼Œå³ä½¿æ˜¯å¯¹ä»¥å‰ä»æœªé‡åˆ°è¿‡çš„ä¸ªä½“ï¼Œ æ¨¡å‹ä¹Ÿå¯ä»¥æˆåŠŸåœ°è¯„ä¼°é£é™©ã€‚ **å¦‚ä½•å‘ç°å¯ä»¥æ³›åŒ–çš„æ¨¡å¼æ˜¯æœºå™¨å­¦ä¹ çš„æ ¹æœ¬é—®é¢˜**ã€‚\n\n\n### å¾ˆå¤šæ—¶å€™, æ•°æ®æ˜¯ä¸å¤Ÿç”¨çš„\næˆ‘ä»¬å¯ä»¥é€šè¿‡[Cross Validation](notes/2021/2021.12/Cross%20Validation.md), æ¥å°½é‡å¢åŠ éªŒè¯é›†çš„å¤§å°","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-21-%E6%A8%A1%E5%9E%8B%E5%AE%B9%E9%87%8F":{"title":"D2L-21-æ¨¡å‹å®¹é‡","content":"# æ¨¡å‹å®¹é‡(å¤æ‚åº¦)\n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #DeepLearning \n\nLink: [Part.17_Overfitting_Underfitting(ML_Andrew.Ng.)](notes/2021/2021.8/Part.17_Overfitting_Underfitting(ML_Andrew.Ng.).md)\n\n## æ¦‚å¿µ\n\n- æ¨¡å‹å®¹é‡å°±æ˜¯æ¨¡å‹çš„å¤æ‚åº¦, ä¹Ÿå°±æ˜¯ä¸€ä¸ªæ¨¡å‹çš„Variance.\n- æ¨¡å‹å®¹é‡å’Œæ•°æ®çš„å¤æ‚åº¦åº”è¯¥å¯¹åº”, ä¸¤è€…çš„ä¸åŒ¹é…å®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆé—®é¢˜\n![](notes/2022/2022.2/assets/img_2022-10-15-11.png)\n- ä¸‹å›¾æ˜¯ä¸¤ç§æŸå¤±éšç€æ¨¡å‹å¤æ‚åº¦çš„å˜åŒ–(æ³¨æ„æ¨ªè½´ä»£è¡¨çš„æ˜¯ä¸åŒå¤æ‚åº¦çš„æ¨¡å‹, ä¸è¦å’Œè®­ç»ƒçš„Lossæ›²çº¿ææ··).\n\t![](notes/2022/2022.2/assets/capacity-vs-error.svg)\n\t- å¯ä»¥çœ‹åˆ°å¯¹äºåŒä¸€ä¸ªæ•°æ®é›†, è¿‡äºå¤æ‚çš„æ¨¡å‹è™½ç„¶æœ‰ç€æ›´å°çš„è®­ç»ƒæŸå¤±, ä½†æ˜¯æœ‰äº†æ›´å¤§çš„æ³›åŒ–æŸå¤±, åˆ™è¯´æ˜**æ¨¡å‹è¿‡åˆ†å¥‘åˆè®­ç»ƒé›†äº†**, å­¦ä¹ åˆ°äº†è®­ç»ƒé›†çš„ä¸€äº›è¯¯å·®ç­‰ç­‰, å¤ªè¿‡äºçµæ´»(High variance), å‡ºç°äº†è¿‡æ‹Ÿåˆ\n\t\t- è€Œå¦‚æœæ¨¡å‹è¿‡äºç®€å•, åˆ™è®­ç»ƒæŸå¤±å’Œæ³›åŒ–æŸå¤±éƒ½å¾ˆé«˜, è¯´æ˜æ¨¡å‹èƒ½åŠ›ä¸å¤Ÿ, å­¦ä¹ ä¸åˆ°è¶³å¤Ÿçš„çŸ¥è¯†, æ¨¡å‹å¯¹äºæ•°æ®çš„åè§(Bias)å¤ªé«˜äº†\n\n## æ¨¡å‹å®¹é‡\n### ä¼°è®¡æ¨¡å‹å®¹é‡\n- æˆ‘ä»¬å¾ˆéš¾æ¯”è¾ƒä¸åŒç±»å‹æ¨¡å‹çš„å®¹é‡å·®åˆ«: æ¯”å¦‚æ ‘æ¨¡å‹å’Œç¥ç»ç½‘ç»œ.\n- **å½±å“æ¨¡å‹å®¹é‡çš„ä¸¤ä¸ªå› ç´ :**\n\t- å‚æ•°çš„**æ•°é‡**\n\t- å‚æ•°**å€¼çš„å˜åŒ–èŒƒå›´**\n\n### æ¨¡å‹å®¹é‡çš„è¯„ä»·æ ‡å‡†\n- [VCç»´](notes/2022/2022.2/VCç»´-VC_Dimension.md)æ˜¯å¯¹ä¸€ä¸ªå¯å­¦ä¹ åˆ†ç±»å‡½æ•°ç©ºé—´çš„èƒ½åŠ›ï¼ˆå¤æ‚åº¦ï¼Œè¡¨ç¤ºèƒ½åŠ›ç­‰ï¼‰çš„è¡¡é‡ã€‚\n- å®ƒå®šä¹‰ä¸ºç®—æ³•èƒ½â€œæ‰“æ•£â€çš„ç‚¹é›†çš„åŠ¿çš„æœ€å¤§å€¼ã€‚\n\n## æ•°æ®å¤æ‚åº¦\nè¯„ä»·æ•°æ®å¤æ‚åº¦çš„ä¸€äº›æ–¹é¢: \n- æ ·æœ¬çš„ä¸ªæ•°\n- ä¸€ä¸ªæ ·æœ¬å…ƒç´ çš„ä¸ªæ•°\n- æ—¶é—´, ç©ºé—´ç»“æ„\n- æ ·æœ¬åˆ†ç±»çš„å¤šæ ·æ€§\n\n\n\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-22-%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F":{"title":"D2L-22-æƒé‡è¡°å‡","content":"# æƒé‡è¡°å‡\n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #Regularization #DeepLearning \n\n- **æƒé‡è¡°å‡**å°±æ˜¯åˆ©ç”¨ $\\ell_{2}$ èŒƒæ•°è¿›è¡Œ [æ­£åˆ™åŒ–](notes/2022/2022.2/Regularization-æ­£åˆ™åŒ–.md), é¿å…è¿‡æ‹Ÿåˆ\n\t- æƒé‡è¡°å‡æ˜¯é€šè¿‡å‡å°ç›®æ ‡å‚æ•°(weights)çš„å¤§å°æ¥å®ç°æ­£åˆ™åŒ–çš„, è¿™ä¹Ÿæ˜¯å…¶åç§°çš„ç”±æ¥.\n\t- å‚æ•°çš„èŒƒæ•°ä»£è¡¨äº†ä¸€ç§æœ‰ç”¨çš„ç®€å•æ€§åº¦é‡ã€‚[^5]\n\n\u003e Links:\n\u003e -  [Part.18_Regularization_Intuition(ML_Andrew.Ng.)](notes/2021/2021.9/Part.18_Regularization_Intuition(ML_Andrew.Ng.).md)\n\u003e -  [Part.19_Regularized_Linear_Regression(ML_Andrew.Ng.)](notes/2021/2021.9/Part.19_Regularized_Linear_Regression(ML_Andrew.Ng.).md)\n\n## Intuition\n[Norm in Regularization - Intuition](notes/2022/2022.2/Norm%20in%20Regularization%20-%20Intuition.md)\n\n---\n- **è¿™é¡¹æŠ€æœ¯é€šè¿‡å‡½æ•°ä¸é›¶çš„è·ç¦»æ¥è¡¡é‡å‡½æ•°çš„å¤æ‚åº¦**ï¼Œ å› ä¸ºåœ¨æ‰€æœ‰å‡½æ•° $f$ ä¸­ï¼Œå‡½æ•° $f=0$ ï¼ˆæ‰€æœ‰è¾“å…¥éƒ½å¾—åˆ°å€¼ $0$ï¼‰ åœ¨æŸç§æ„ä¹‰ä¸Šæ˜¯æœ€ç®€å•çš„ã€‚ ä½†æ˜¯æˆ‘ä»¬åº”è¯¥å¦‚ä½•ç²¾ç¡®åœ°æµ‹é‡ä¸€ä¸ªå‡½æ•°å’Œé›¶ä¹‹é—´çš„è·ç¦»å‘¢ï¼Ÿ æ²¡æœ‰ä¸€ä¸ªæ­£ç¡®çš„ç­”æ¡ˆã€‚ äº‹å®ä¸Šï¼Œå‡½æ•°åˆ†æå’Œå·´æ‹¿èµ«ç©ºé—´ç†è®ºçš„ç ”ç©¶ï¼Œéƒ½åœ¨è‡´åŠ›äºå›ç­”è¿™ä¸ªé—®é¢˜ã€‚[^1]\n\n## æ¨å¯¼[^2]\nå¯¹äºä»¥ä¸‹æŸå¤±å‡½æ•°: \n$$L(\\mathbf{w}, b)=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{2}\\left(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}+b-y^{(i)}\\right)^{2}$$\n\n- ä¸ºäº†æƒ©ç½šæƒé‡å‘é‡çš„å¤§å°ï¼Œ æˆ‘ä»¬å¿…é¡»ä»¥æŸç§æ–¹å¼åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ $â€–\\mathbf wâ€–^2$ï¼Œ ä½†æ˜¯æ¨¡å‹åº”è¯¥å¦‚ä½•å¹³è¡¡è¿™ä¸ªæ–°çš„é¢å¤–æƒ©ç½šçš„æŸå¤±ï¼Ÿ å®é™…ä¸Šï¼Œæˆ‘ä»¬é€šè¿‡ **æ­£åˆ™åŒ–å¸¸æ•°** $Î»$ æ¥æè¿°è¿™ç§æƒè¡¡ï¼Œ è¿™æ˜¯ä¸€ä¸ªéè´Ÿè¶…å‚æ•°ï¼Œæˆ‘ä»¬ä½¿ç”¨éªŒè¯æ•°æ®æ‹Ÿåˆï¼š\n\n\t$$L(\\mathbf{w}, b)+\\frac{\\lambda}{2}\\|\\mathbf{w}\\|^{2}$$\n\n\t- å…¶ä¸­ $1/2$ æ˜¯ä¸ºäº†æ±‚å¯¼åå…¬å¼çš„ç®€æ´.\n\n- ä½ å¯èƒ½ä¼šæƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨å¹³æ–¹èŒƒæ•° $\\mathbf{\\|w\\|}_2^2$ è€Œä¸æ˜¯æ ‡å‡†èŒƒæ•° $\\mathbf{\\|w\\|}_2$ ï¼ˆå³æ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰ï¼Ÿ \n\t- æˆ‘ä»¬è¿™æ ·åšæ˜¯ä¸ºäº†ä¾¿äºè®¡ç®—ã€‚ é€šè¿‡å¹³æ–¹ $L_2$ èŒƒæ•°ï¼Œæˆ‘ä»¬å»æ‰å¹³æ–¹æ ¹ï¼Œç•™ä¸‹æƒé‡å‘é‡æ¯ä¸ªåˆ†é‡çš„å¹³æ–¹å’Œã€‚ è¿™ä½¿å¾—æƒ©ç½šçš„å¯¼æ•°å¾ˆå®¹æ˜“è®¡ç®—ï¼šå¯¼æ•°çš„å’Œç­‰äºå’Œçš„å¯¼æ•°ã€‚\n\t\n- $L_2$æ­£åˆ™åŒ–å›å½’çš„å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™æ›´æ–°å¦‚ä¸‹å¼ï¼š\n\n$$\\mathbf{w} \\leftarrow(1-\\eta \\lambda) \\mathbf{w}-\\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\mathbf{x}^{(i)}\\left(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}+b-y^{(i)}\\right)$$\n\n- æˆ‘ä»¬æ ¹æ®ä¼°è®¡å€¼ä¸è§‚æµ‹å€¼ä¹‹é—´çš„å·®å¼‚æ¥æ›´æ–°$\\mathbf w$ã€‚ ç„¶è€Œï¼Œæˆ‘ä»¬åŒæ—¶ä¹Ÿåœ¨è¯•å›¾å°† $\\mathbf w$ çš„å¤§å°ç¼©å°åˆ°é›¶ã€‚ **è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™ç§æ–¹æ³•æœ‰æ—¶è¢«ç§°ä¸º _æƒé‡è¡°å‡_** ã€‚ æˆ‘ä»¬ä»…è€ƒè™‘æƒ©ç½šé¡¹ï¼Œä¼˜åŒ–ç®—æ³•åœ¨è®­ç»ƒçš„æ¯ä¸€æ­¥_è¡°å‡_ æƒé‡ã€‚ \n\t- ä¸ç‰¹å¾é€‰æ‹©ç›¸æ¯”ï¼Œæƒé‡è¡°å‡ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§**è¿ç»­çš„**æœºåˆ¶æ¥è°ƒæ•´å‡½æ•°çš„å¤æ‚åº¦ã€‚ è¾ƒå°çš„ $Î»$ å€¼å¯¹åº”è¾ƒå°‘çº¦æŸçš„ $\\mathbf w$ï¼Œ è€Œè¾ƒå¤§çš„ $Î»$ å€¼å¯¹ $\\mathbf w$ çš„çº¦æŸæ›´å¤§ã€‚\n\n- æ˜¯å¦å¯¹ç›¸åº”çš„åç½® $b^2$ è¿›è¡Œæƒ©ç½šåœ¨ä¸åŒçš„å®è·µä¸­ä¼šæœ‰æ‰€ä¸åŒï¼Œ åœ¨ç¥ç»ç½‘ç»œçš„ä¸åŒå±‚ä¸­ä¹Ÿä¼šæœ‰æ‰€ä¸åŒã€‚ **é€šå¸¸ï¼Œç½‘ç»œè¾“å‡ºå±‚çš„åç½®é¡¹ä¸ä¼šè¢«æ­£åˆ™åŒ–**ã€‚\n\n## ä¸¤ç§é™åˆ¶æ–¹å¼çš„ç­‰ä»·æ€§\n![](notes/2022/2022.2/assets/Pasted%20image%2020220214194009.png)\n![](notes/2022/2022.2/assets/Pasted%20image%2020220214194022.png)\n\n## Tikhonov Regularization\n- L2 æ­£åˆ™åŒ–è¿˜æœ‰ä¸€ä¸ªåå­—å«\"**å‰æ´ªè¯ºå¤«æ­£åˆ™åŒ–**\"[^3]\n\n\t- 1995 å¹´ï¼Œå…‹é‡Œæ–¯æ‰˜å¼—Â·æ¯•æ™“æ™®[^4]è¯æ˜äº†: å…·æœ‰è¾“å…¥å™ªå£°çš„è®­ç»ƒç­‰ä»·äº Tikhonov æ­£åˆ™åŒ– [Bishop, 1995](https://zh-v2.d2l.ai/chapter_references/zreferences.html#bishop-1995)ã€‚ ^c88d1b\n\n## å®ç°\n- ä¼˜åŒ–ç®—æ³•é‡Œé¢çš„ `weight_decay` å°±æ˜¯å®ç°çš„æƒé‡è¡°å‡\n\t- åœ¨æ·±åº¦å­¦ä¹ é‡Œé¢æƒé‡è¡°å‡æ˜¯æ•´åˆåˆ°äº†ä¼˜åŒ–å‡½æ•°é‡Œé¢çš„, æ‰€ä»¥å¯¹äºä»»æ„æŸå¤±æˆ‘ä»¬éƒ½å¯ä»¥è¿›è¡Œè¡°å‡.\n\t- ä¾‹: PyTorché‡Œé¢çš„éšæœºæ¢¯åº¦ä¸‹é™:  [SGD â€” PyTorch 1.10 documentation](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n\t\t- ![](notes/2022/2022.2/assets/Pasted%20image%2020220302193549.png)\n- weight_decayç›¸å¯¹äºDropoutåº”ç”¨é¢æ›´å¹¿[^6]\n\n[^1]: [4.5. æƒé‡è¡°å‡ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/weight-decay.html#id2)\n[^2]: [4.5. æƒé‡è¡°å‡ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/weight-decay.html#id2)\n[^3]: [å‰æ´ªè¯ºå¤«æ­£åˆ™åŒ– - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-hans/%E5%90%89%E6%B4%AA%E8%AF%BA%E5%A4%AB%E6%AD%A3%E5%88%99%E5%8C%96) English:  [Tikhonov regularization - Wikipedia](https://en.wikipedia.org/wiki/Tikhonov_regularization)\n[^4]: å°±æ˜¯å†™ PRML é‚£æœ¬ä¹¦ çš„ Bishop\n[^5]: [4.6. æš‚é€€æ³•ï¼ˆDropoutï¼‰ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/dropout.html#id2)\n[^6]: [13 ä¸¢å¼ƒæ³•ã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ v2ã€‘_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1Y5411c7aY?p=3\u0026t=1196.3)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-23-Dropout-%E4%B8%A2%E5%BC%83%E6%B3%95":{"title":"D2L-23-Dropout-ä¸¢å¼ƒæ³•","content":"# Dropout - ä¸¢å¼ƒæ³•(æš‚é€€æ³•)\n\n\u003cdiv align=\"right\"\u003e 2022-02-14\u003c/div\u003e\n\nTags: #Dropout #Regularization #DeepLearning \n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/drT5_1TCYrk\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n[^1]\n\n- Dropoutå°±æ˜¯åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹è®¡ç®—æ¯ä¸€å†…éƒ¨å±‚çš„åŒæ—¶æ³¨å…¥å™ªå£°, ä»è€Œæé«˜æ¨¡å‹çš„å¹³æ»‘æ€§, å‡å°‘è¿‡æ‹Ÿåˆ.\n\n![](notes/2022/2022.2/assets/dropout2.svg)\n\n## å®ç°æ–¹å¼\n- å®ç°çš„å…³é”®æ˜¯è¦ä»¥ä¸€ç§æ— å(ä¸æ”¹å˜æœŸæœ›)çš„æ–¹å¼æ³¨å…¥å™ªå£°.\n\n- åœ¨æ¯•æ™“æ™®çš„å·¥ä½œä¸­ï¼Œä»–å°†**é«˜æ–¯å™ªå£°**æ·»åŠ åˆ°çº¿æ€§æ¨¡å‹çš„è¾“å…¥ä¸­ã€‚ åœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼Œä»–å°†ä»å‡å€¼ä¸ºé›¶çš„åˆ†å¸ƒ $Ïµâˆ¼\\mathcal{N}(0,Ïƒ^2)$ é‡‡æ ·å™ªå£°æ·»åŠ åˆ°è¾“å…¥ $\\mathbf{x}$ï¼Œ ä»è€Œäº§ç”Ÿæ‰°åŠ¨ç‚¹ $\\mathbf{x^â€²=x}+Ïµ$ï¼Œ é¢„æœŸæ˜¯ $E[\\mathbf{x^â€²}]=\\mathbf{x}$ ã€‚\n\n- ä½†æ˜¯æˆ‘ä»¬æ›´å¸¸ç”¨çš„æ–¹å¼æ˜¯æŒ‰ä¸€å®šæ¦‚å¿µ $p$ å¯¹éšè—å±‚çš„è¾“å‡ºç½®é›¶, æ¢è¨€ä¹‹ï¼Œæ¯ä¸ªä¸­é—´æ´»æ€§å€¼ $h$ ä»¥ _æš‚é€€æ¦‚ç‡_ $p$ ç”±éšæœºå˜é‡ $h^â€²$ æ›¿æ¢ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n$$h^{\\prime}= \\begin{cases}0 \u0026 \\text { æ¦‚ç‡ä¸º } p \\\\ \\frac{h}{1-p} \u0026 \\text { å…¶ä»–æƒ…å†µ }\\end{cases}$$\næ ¹æ®æ­¤æ¨¡å‹çš„è®¾è®¡, å…¶æœŸæœ›å€¼ä¿æŒä¸å˜, å³ $$E\\left[h^{\\prime}\\right]=h$$\n\n- å‰å‘ä¼ æ’­æ—¶, è¾“å‡ºçš„è®¡ç®—ä¸å†ä¾èµ–äºè¢«ä¸¢å¼ƒçš„å˜é‡; åœ¨åå‘ä¼ æ’­æ—¶, è¢«ä¸¢å¼ƒçš„å˜é‡æ¢¯åº¦ä¸º0, ä¸å‚ä¸å‚æ•°çš„ä¼˜åŒ–æ›´æ–°. è¿™ä½¿å¾—è¾“å‡ºå±‚çš„è®¡ç®—ä¸èƒ½è¿‡åˆ†çš„ä¾èµ–äºéšè—å±‚ä¸­çš„ä»»ä½•ä¸€ä¸ªå…ƒç´ .\n\n### æµ‹è¯•æ—¶\n- é€šå¸¸ï¼Œæˆ‘ä»¬åœ¨æµ‹è¯•æ—¶ä¸ç”¨æš‚é€€æ³•ã€‚ ç»™å®šä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹å’Œä¸€ä¸ªæ–°çš„æ ·æœ¬ï¼Œæˆ‘ä»¬ä¸ä¼šä¸¢å¼ƒä»»ä½•èŠ‚ç‚¹ï¼Œå› æ­¤ä¸éœ€è¦æ ‡å‡†åŒ–ã€‚ \n\n- ç„¶è€Œä¹Ÿæœ‰ä¸€äº›ä¾‹å¤–ï¼šä¸€äº›ç ”ç©¶äººå‘˜åœ¨æµ‹è¯•æ—¶ä½¿ç”¨æš‚é€€æ³•ï¼Œ ç”¨äºä¼°è®¡ç¥ç»ç½‘ç»œé¢„æµ‹çš„â€œä¸ç¡®å®šæ€§â€ï¼š å¦‚æœé€šè¿‡è®¸å¤šä¸åŒçš„æš‚é€€æ³•é®ç›–åå¾—åˆ°çš„é¢„æµ‹ç»“æœéƒ½æ˜¯ä¸€è‡´çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è¯´ç½‘ç»œå‘æŒ¥æ›´ç¨³å®šã€‚(æ¢è¨€ä¹‹, å„ä¸ªéƒ¨åˆ†éƒ½æ˜¯ä¸€æ ·é‡è¦çš„, ä¸¢å¼ƒäº†ä»»ä½•ä¸€éƒ¨åˆ†å½±å“éƒ½æ˜¯ä¸€æ ·çš„)[^3]\n\n### é€‚ç”¨å¯¹è±¡\n- Dropoutä¸»è¦åº”ç”¨äºå…¨è¿æ¥å±‚\n\n## Bonus\n- æ—¢ç„¶æ˜¯éšæœºä¸¢å¼ƒ, é‚£ä¹ˆæœ‰æ²¡æœ‰å¯èƒ½æŸä¸€å±‚å…¨éƒ¨è¢«ä¸¢å®Œäº†å‘¢? \n[neural networks - What if all the nodes are dropped when using dropout? - Cross Validated](https://stats.stackexchange.com/questions/302452/what-if-all-the-nodes-are-dropped-when-using-dropout)\n\n- Loss map with drop out - Visualized[^2]\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2PqTW_p1fIs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- Dropoutè¢«Googleç”³è¯·äº†ä¸“åˆ©ğŸ¤.\n\n\n\n[^1]: [Dropout (DEF 0075) - YouTube](https://www.youtube.com/watch?v=drT5_1TCYrk)\n[^2]: [DROP | Dropout variations in weight space | Loss landscape visualization | Deep Learning - YouTube](https://www.youtube.com/watch?v=2PqTW_p1fIs)\n[^3]: [4.6. æš‚é€€æ³•ï¼ˆDropoutï¼‰ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/dropout.html#id5)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-24-%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7":{"title":"D2L-24-æ•°å€¼ç¨³å®šæ€§","content":"# æ·±åº¦å­¦ä¹ é‡Œé¢çš„æ•°å€¼ç¨³å®šæ€§\n\n\u003cdiv align=\"right\"\u003e 2022-02-17\u003c/div\u003e\n\nTags: #DeepLearning #NumericalComputing\n\n## é—®é¢˜çš„ç”±æ¥\n- æ•°å€¼ç¨³å®šæ€§çš„é—®é¢˜å‘ç”Ÿåœ¨åå‘ä¼ æ’­çš„æ—¶å€™. \n- å¯¹äºä¸€ä¸ªå¾ˆæ·±çš„æ¨¡å‹, è®¡ç®—åœ¨æŸå¤± $\\ell$ å…³äºç¬¬ $t$ å±‚æƒé‡ $\\mathbf{W_t}$ çš„æ¢¯åº¦çš„æ—¶å€™, å¦‚æœç¬¬ $t$ å±‚å…³äºè¾“å‡ºè¾ƒè¿œ, åˆ™ç»“æœç”±è®¸å¤šçŸ©é˜µä¹˜æ³•æ„æˆ, è¿™ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–è€…æ¢¯åº¦æ¶ˆå¤±.\n\t- è€ƒè™‘å¦‚ä¸‹æœ‰ $\\mathrm{d}$ å±‚çš„ç¥ç»ç½‘ç»œ\n\t$$\\mathbf{h}^{t}=f_{t}\\left(\\mathbf{h}^{t-1}\\right) \\quad \\text { and } \\quad y=\\ell \\circ f_{d} \\circ \\ldots \\circ f_{1}(\\mathbf{x})$$\n\t\t![400](notes/2022/2022.2/assets/img_2022-10-15-12.png)\n\t- å¯¹äºä¸€ä¸ªä¸€ç™¾å±‚çš„æ¨¡å‹: \n\t$$1.5^{100} \\approx 4 \\times 10^{17} \\quad 0.8^{100} \\approx 2 \\times 10^{-10}$$\n\t- ä¸¤è€…éƒ½è¿œè¿œè¶…å‡ºäº†å¸¸ç”¨çš„16ä½æµ®ç‚¹æ•°èƒ½è¡¨ç¤ºçš„æœ€å¤§å€¼ $65504$ å’Œæœ€å°ç²¾åº¦ $2^{-24}\\approx 6e(-8)$\n\n\n## çŸ©é˜µè¿ä¹˜å¯¼è‡´çš„é—®é¢˜\n- è¿™æ˜¯å¯¼è‡´æ•°å€¼ä¸ç¨³å®šçš„æ ¹æœ¬é—®é¢˜\n- ä¾‹å­: **MLP** (ä¸ºäº†ç®€å•çœç•¥äº†åç§»)\n\t$$\\mathbf{h}^{t}=f_{t}\\left(\\mathbf{h}^{t-1}\\right)=\\sigma\\left(\\mathbf{W}^{t} \\mathbf{h}^{t-1}\\right)$$\n\t- $\\sigma$ æ˜¯æ¿€æ´»å‡½æ•°\n\t$$\\frac{\\partial \\mathbf{h}^{t}}{\\partial \\mathbf{h}^{t-1}}=\\operatorname{diag}\\left(\\sigma^{\\prime}\\left(\\mathbf{W}^{t} \\mathbf{h}^{t-1}\\right)\\right)\\left(\\mathbf{W}^{t}\\right)^{T}$$[^1]\n\t- $\\sigma^{\\prime}$ æ˜¯ $\\sigma$ çš„å¯¼æ•°å‡½æ•°, åˆ™\n\t$$\\prod_{i=t}^{d-1} \\frac{\\partial \\mathbf{h}^{i+1}}{\\partial \\mathbf{h}^{i}}=\\prod_{i=t}^{d-1} \\operatorname{diag}\\left(\\sigma^{\\prime}\\left(\\mathbf{W}^{i} \\mathbf{h}^{i-1}\\right)\\right)\\left(\\mathbf{W}^{i}\\right)^{T}$$\n- æˆ‘ä»¬é€‰æ‹©ReLUä½œä¸ºæ¿€æ´»å‡½æ•°, åˆ™å…¶å¯¼æ•°ä¸º: \n\t- $$\\sigma(x)=\\max (0, x) \\quad \\text { and } \\quad \\sigma^{\\prime}(x)= \\begin{cases}1 \u0026 \\text { if } x\u003e0 \\\\ 0 \u0026 \\text { otherwise }\\end{cases}$$\n\t- åˆ™å‰é¢çš„æ¢¯åº¦ä¸º$$\\prod_{i=t}^{d-1} \\frac{\\partial \\mathbf{h}^{i+1}}{\\partial \\mathbf{h}^{i}}=\\prod_{i=t}^{d-1} \\operatorname{diag}\\left(\\sigma^{\\prime}\\left(\\mathbf{W}^{i} \\mathbf{h}^{i-1}\\right)\\right)\\left(\\mathbf{W}^{i}\\right)^{T}$$\n\t- å…¶ä¸­ $\\operatorname{diag}\\left(\\sigma^{\\prime}\\left(\\mathbf{W}^{i} \\mathbf{h}^{i-1}\\right)\\right)$ æ˜¯å…¨éƒ¨ç”±0å’Œ1æ„æˆçš„å¯¹è§’çŸ©é˜µ. è¿™ä½¿å¾—ç»“æœçš„ä¸€äº›å…ƒç´ æ¥è‡ªäº \n\t\t$$\\prod_{i=t}^{d-1} \\left(W^{i} \\right)^{T}$$\n\t\t\n\t- åœ¨ $d-t$ è¾ƒå¤§çš„æ—¶å€™, å¦‚æœå…¶ä¸­å‡ºç°å¤§äº1çš„æ•°è¿ä¹˜, åˆ™å¾ˆå¯èƒ½å‡ºç°æ¢¯åº¦çˆ†ç‚¸. åŒæ ·, å¦‚æœå…¶ä¸­å‡ºç°å°äº1çš„æ•°è¿ä¹˜, åˆ™å¾ˆå¯èƒ½å‡ºç°æ¢¯åº¦æ¶ˆå¤±.\n\n## æ¿€æ´»å‡½æ•°å¯¼è‡´çš„é—®é¢˜\n- é™¤äº†çŸ©é˜µè¿ä¹˜, æ¿€æ´»å‡½æ•°çš„å¯¼æ•°å€¼ä¹Ÿå¯èƒ½å¯¼è‡´æ•°å€¼é—®é¢˜\n\t- ä¾‹: [$Sigmoid$ Function](notes/2021/2021.8/Sigmoid_Function.md)\n\t\tå®ƒçš„å¯¼å‡½æ•°æ˜¯: $$\\sigma'(x)=\\sigma(x)(1-\\sigma(x))$$\n\t\t![](notes/2022/2022.2/assets/img_2022-10-15-13.png)\n\t- å½“è¾“å…¥è¾ƒå¤§çš„æ—¶å€™, $\\operatorname{diag}\\left(\\sigma^{\\prime}\\left(\\mathbf{W}^{i} \\mathbf{h}^{i-1}\\right)\\right)$ ä¼šå˜å¾—å¾ˆå° ,åˆ™ $$\\prod_{i=t}^{d-1} \\frac{\\partial \\mathbf{h}^{i+1}}{\\partial \\mathbf{h}^{i}}=\\prod_{i=t}^{d-1} \\operatorname{diag}\\left(\\sigma^{\\prime}\\left(\\mathbf{W}^{i} \\mathbf{h}^{i-1}\\right)\\right)\\left(\\mathbf{W}^{i}\\right)^{T}$$ æ˜¯ $d-t$ ä¸ªå°æ•°å€¼çš„ä¹˜ç§¯. è¿™å¾ˆå®¹æ˜“é€ æˆæ¢¯åº¦æ¶ˆå¤±.\n\n## åæœ\n- æœ€ç›´æ¥çš„åæœæ˜¯**æ¢¯åº¦å€¼è¶…å‡ºèŒƒå›´**\n\t- æ¢¯åº¦çˆ†ç‚¸: `inf`, æ¢¯åº¦æ¶ˆå¤±: `0`\n\n- è€Œè¿™ä¼šå¯¼è‡´**è®­ç»ƒçš„æ—¶å€™å¾ˆéš¾é€‰æ‹©å­¦ä¹ ç‡**\n\t- æ¢¯åº¦çˆ†ç‚¸: å­¦ä¹ ç‡è¢«é™åˆ¶åœ¨ä¸€ä¸ªå¾ˆå°çš„èŒƒå›´å†…. å¤ªå¤§äº†ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸, å¤ªå°äº†åˆ™ä¼šå¯¼è‡´è®­ç»ƒç¼“æ…¢. \n\t\t- æˆ‘ä»¬å¯èƒ½éœ€è¦åœ¨è®­ç»ƒæ—¶ä¸æ–­è°ƒæ•´å­¦ä¹ ç‡\n\t- æ¢¯åº¦æ¶ˆå¤±: å­¦ä¹ ç‡æ— è®ºæ€ä¹ˆè°ƒæ•´, è®­ç»ƒéƒ½æ²¡æœ‰è¿›å±•\n\n- å¯¹äº**ç½‘ç»œç»“æ„**, æ¢¯åº¦æ¶ˆå¤±ä¼šä½¿å¾—æ¨¡å‹ä»…ä»…åœ¨é è¿‘è¾“å‡ºçš„ä¸€ç«¯è®­ç»ƒçš„å¾ˆå¥½, è€Œé è¿‘è¾“å…¥çš„ä¸€ç«¯åˆ™ç”±äºæ¢¯åº¦æ¶ˆå¤±, å®Œå…¨å¾—ä¸åˆ°ä¼˜åŒ–.\n\n[^1]: #todo  è¿™é‡Œé¢çš„Diagæ˜¯è¯æ˜æ¥çš„å‘€","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-25-%E8%AE%A9%E8%AE%AD%E7%BB%83%E6%9B%B4%E5%8A%A0%E7%A8%B3%E5%AE%9A-Xavier%E5%88%9D%E5%A7%8B%E5%8C%96":{"title":"D2L-25-è®©è®­ç»ƒæ›´åŠ ç¨³å®š-Xavieråˆå§‹åŒ–","content":"# è®©è®­ç»ƒæ›´åŠ ç¨³å®š\n\n\u003cdiv align=\"right\"\u003e 2022-02-18\u003c/div\u003e\n\nTags: #DeepLearning \n\n## è¦ç‚¹\n- å› ä¸ºæˆ‘ä»¬æ— æ³•æ”¹å˜[æ¢¯åº¦é—®é¢˜çš„æ ¹æœ¬åŸå› ](notes/2022/2022.2/D2L-24-æ•°å€¼ç¨³å®šæ€§.md#é—®é¢˜çš„ç”±æ¥), æ‰€ä»¥æˆ‘ä»¬çš„ç›®æ ‡æ˜¯**å°†æ¢¯åº¦çš„å€¼æ§åˆ¶åœ¨ä¸€ä¸ªåˆç†çš„èŒƒå›´å†…**.  \n\n### æ”¹è¿›æ–¹å‘\n- **å°†ä¹˜æ³•å˜åŠ æ³•**: å¦‚ResNet,  LSTM\n\n- **å½’ä¸€åŒ–**: æ¢¯åº¦å½’ä¸€åŒ–,  [Gradient Clipping-æ¢¯åº¦å‰ªè£](notes/2022/2022.4/D2L-54-Gradient%20Clipping-æ¢¯åº¦å‰ªè£.md)\n\n- **åˆç†åœ°åˆå§‹åŒ–æƒé‡å¹¶é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°**: \n\t- åˆå§‹åŒ–æ–¹æ¡ˆçš„é€‰æ‹©åœ¨ç¥ç»ç½‘ç»œå­¦ä¹ ä¸­èµ·ç€ä¸¾è¶³è½»é‡çš„ä½œç”¨ï¼Œ å®ƒå¯¹ä¿æŒæ•°å€¼ç¨³å®šæ€§è‡³å…³é‡è¦ã€‚\n\t- æ­¤å¤–ï¼Œè¿™äº›åˆå§‹åŒ–æ–¹æ¡ˆçš„é€‰æ‹©å¯ä»¥ä¸éçº¿æ€§æ¿€æ´»å‡½æ•°çš„é€‰æ‹©æœ‰è¶£çš„ç»“åˆåœ¨ä¸€èµ·ã€‚\n\n## æ¢¯åº¦å½’ä¸€åŒ–\n**ç›®æ ‡**: æˆ‘ä»¬å¯ä»¥å°†æ¯å±‚çš„è¾“å‡º $h_i^s$ å’Œæ¢¯åº¦ $\\frac{\\partial \\ell}{\\partial h_{i}^{s}}$ éƒ½çœ‹åšéšæœºå˜é‡, é€šè¿‡è®©å®ƒä»¬çš„å‡å€¼å’Œæ–¹å·®éƒ½ä¿æŒä¸€è‡´, å®ç°å¯¹æ¢¯åº¦çš„å½’ä¸€åŒ–\n\t$$\\begin{gathered}\n\t\\text{æ­£å‘:}\\quad\\mathbb{E}\\left[h_{i}^{s}\\right]=0 \\quad \n\t\\operatorname{Var}\\left[h_{i}^{s}\\right]=a \\\\\\\\\n\t\\text{åå‘:}\\quad\\mathbb{E}\\left[\\frac{\\partial \\ell}{\\partial h_{i}^{s}}\\right]=0 \\quad \\operatorname{Var}\n\t\\left[\\frac{\\partial \\ell}{\\partial h_{i}^{s}}\\right]=b \\quad \\forall i, s\\end{gathered}$$\n\tå…¶ä¸­ $a,b$ å‡ä¸ºå¸¸æ•°.\n\n### æƒé‡åˆå§‹åŒ–\n- æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆç†çš„æƒé‡åˆå§‹åŒ–æ¥è¾¾åˆ°ä¸Šé¢çš„ç›®æ ‡\n![](notes/2022/2022.2/assets/img_2022-10-15-14.png)\n- å¯¹äºä¸€ä¸ªä¸­ç­‰éš¾åº¦çš„é—®é¢˜, æ¡†æ¶é»˜è®¤çš„éšæœºåˆå§‹åŒ–é€šå¸¸å¾ˆæœ‰æ•ˆ(ä¾‹å¦‚ $\\mathcal{N}(0,0.01)$ ), ä½†æ˜¯å¯¹äºå¾ˆæ·±çš„ç¥ç»ç½‘ç»œåˆ™éš¾ä»¥ä¿è¯æ•ˆæœ.\n- ç°åœ¨æ ‡å‡†ä¸”å®ç”¨çš„ä¸€ç§æ–¹æ³•å«åš**Xavieråˆå§‹åŒ–**\n\n#### Xavieråˆå§‹åŒ–[^1]\n[Xavieråˆå§‹åŒ–çš„è¯¦ç»†ä¾‹å­](notes/2022/2022.2/Xavieråˆå§‹åŒ–çš„è¯¦ç»†ä¾‹å­.md)\n\n- ä»ä¾‹å­ä¸­å¯ä»¥çœ‹å‡º, å¦‚æœæ­£å‘åå‘éƒ½è¦ä¿è¯æ–¹å·®ä¸€è‡´, é‚£ä¹ˆéœ€è¦åŒæ—¶æ»¡è¶³ $n_{s}\\gamma_{s}=1$ å’Œ $n_{s-1} \\gamma_{s}=1$, å…¶ä¸­ $\\gamma_s$ æ˜¯ç¬¬ $s$ å±‚æƒé‡çš„æ–¹å·®, $n_{s-1}, n_{s}$ æ˜¯è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦. \n\t- å› ä¸ºéšè—å±‚çš„è¾“å…¥å’Œè¾“å‡ºç»´åº¦å¾ˆå¯èƒ½ä¸ä¸€è‡´, æ‰€ä»¥è¿™å…¶å®æ˜¯å¾ˆéš¾æ»¡è¶³çš„.\n\n- **Xavieråˆå§‹åŒ–**åˆ™ä»¤ $$\\frac{\\gamma_{s}\\left(n_{s-1}+n_{s}\\right)}{2} =1 \\quad \\rightarrow\\quad \\gamma_{s}=\\frac{2}{n_{s-1}+n_{s}}$$\n\t- å°½ç®¡åœ¨ä¸Šè¿°æ•°å­¦æ¨ç†ä¸­ï¼Œâ€œä¸å­˜åœ¨éçº¿æ€§â€çš„å‡è®¾åœ¨ç¥ç»ç½‘ç»œä¸­å¾ˆå®¹æ˜“è¢«è¿åï¼Œ ä½†Xavieråˆå§‹åŒ–æ–¹æ³•åœ¨å®è·µä¸­è¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ã€‚\n\n- **æ­£æ€åˆ†å¸ƒ** $$\\mathcal{N}\\left(0, \\sqrt{\\frac{2}{n_{s-1}+n_{s}}}\\right)$$\n- **å‡åŒ€åˆ†å¸ƒ** $$\\mathscr{U}\\left(-\\sqrt{\\frac{6}{n_{s-1}+n_{s}}}, \\sqrt{\\frac{6}{n_{s-1}+n_{s}}}\\right)$$\n\t- åˆ†å¸ƒ $\\mathscr{U}[-a, a]$ çš„æ–¹å·®æ˜¯ $a^{2} / 3$\n\n- **Bonus Question:** [ä¸ºä»€ä¹ˆå‚æ•°ä¸èƒ½åˆå§‹åŒ–ä¸ºåŒä¸€ä¸ªå¸¸æ•°?](notes/2022/2022.2/ä¸ºä»€ä¹ˆå‚æ•°ä¸èƒ½åˆå§‹åŒ–ä¸ºåŒä¸€ä¸ªå¸¸æ•°.md) \n\n### æŸå¤±å‡½æ•°çš„é€‰æ‹©\n- ç°åœ¨æˆ‘ä»¬å…ˆå‡è®¾æŸå¤±å‡½æ•°æ˜¯ä¸€ä¸ªçº¿æ€§çš„å‡½æ•° $\\sigma(x)=\\alpha x+\\beta$, æ¥çœ‹çœ‹è¾“å…¥å’Œè¾“å‡ºçš„å‡å€¼å’Œæ–¹å·®ç»è¿‡ $\\sigma(x)$ åä¼šæœ‰ä»€ä¹ˆå˜åŒ–.\n\t- ä»¤ $\\mathbf{h}^{\\prime}=\\mathbf{W}^{t} \\mathbf{h}^{t-1} \\quad \\text { and } \\quad \\mathbf{h}^{t}=\\sigma\\left(\\mathbf{h}^{\\prime}\\right)$\n\t- å‰é¢æˆ‘ä»¬å·²ç»çŸ¥é“ $\\mathbf{h}^{s}=\\mathbf{W}^{s} \\mathbf{h}^{s-1}$ æ—¶, $\\mathbb{E}(\\mathbf{h}^{s})=\\mathbb{E}(\\mathbf{h}^{s-1})=0$. ä¸”åå‘ä¹Ÿä¸€æ ·, æ‰€ä»¥æˆ‘ä»¬æ ¹æ®æ–¹å·®çš„æ€§è´¨å¯ä»¥çŸ¥é“: \n\t\t$$\\begin{aligned}\n\t\\mathbb{E}\\left[h_{i}^{t}\\right] \u0026=\\mathbb{E}\\left[\\alpha h_{i}^{\\prime}+\\beta\\right]=\\beta \\\\\n\t\\operatorname{Var}\\left[h_{i}^{t}\\right] \u0026=\\mathbb{E}\\left[\\left(h_{i}^{t}\\right)^{2}\\right]-\\mathbb{E}\\left[h_{i}^{t}\\right]^{2} \\\\\n\t\u0026=\\mathbb{E}\\left[\\left(\\alpha h_{i}^{\\prime}+\\beta\\right)^{2}\\right]-\\beta^{2} \\\\\n\t\u0026=\\mathbb{E}\\left[\\alpha^{2}\\left(h_{i}^{\\prime}\\right)^{2}+2 \\alpha \\beta h_{i}^{\\prime}+\\beta^{2}\\right]-\\beta^{2} \\\\\n\t\u0026=\\alpha^{2} \\operatorname{Var}\\left[h_{i}^{\\prime}\\right]\n\t\\end{aligned}$$\n\tå¦‚æœè¦ä¿æŒå‡å€¼å’Œæ–¹å·®ä¸å˜, åˆ™è¦æ±‚ $\\beta=0, \\alpha=\\pm1$\n\t- åå‘ä¹Ÿç±»ä¼¼\n\t\t![500](notes/2022/2022.2/assets/Pasted%20image%2020220219125913.png)\n\n- ç°åœ¨æˆ‘ä»¬æ¥æ£€æŸ¥å„ä¸ªæ¿€æ´»å‡½æ•°çš„å½¢çŠ¶:\n\t![](notes/2022/2022.2/assets/Pasted%20image%2020220219125956.png)\n- ä½¿ç”¨æ³°å‹’å±•å¼€\n$$\\operatorname{sigmoid}(x)=\\frac{1}{2}+\\frac{x}{4}-\\frac{x^{3}}{48}+O\\left(x^{5}\\right)$$\n$$\\tanh (x)=0+x-\\frac{x^{3}}{3}+O\\left(x^{5}\\right)$$\n$$\\operatorname{ReLU}(x)=0+x \\quad for\\quad  x \\geq 0$$\nå¯ä»¥çœ‹åˆ°, é™¤äº†Sigmoidä»¥å¤–, å…¶ä»–å‡½æ•°åœ¨åŸç‚¹é™„è¿‘éƒ½åŸºæœ¬æ»¡è¶³ $\\alpha=\\pm1, \\beta=0$ çš„æ¡ä»¶.\n- æˆ‘ä»¬å¯ä»¥è§„èŒƒåŒ–Sigmoidå‡½æ•°: \n\t$$\\text{scaled Sigmoid: }=\\quad 4\\times \\operatorname{Sigmoid}(x)-2$$\n\tå‡ $2$ æ˜¯ä¸ºäº†è®©å‡½æ•°å…³äºåŸç‚¹å¯¹ç§°\n\n\n\n\n[^1]: å®ƒä»¥å…¶æå‡ºè€… [Glorot \u0026 Bengio, 2010](https://zh-v2.d2l.ai/chapter_references/zreferences.html#glorot-bengio-2010) ç¬¬ä¸€ä½œè€…çš„åå­—å‘½å","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-26-%E7%8E%AF%E5%A2%83%E5%92%8C%E5%88%86%E5%B8%83%E5%81%8F%E7%A7%BB":{"title":"D2L-26-ç¯å¢ƒå’Œåˆ†å¸ƒåç§»","content":"# Environment and Distribution Shift\n\n\u003cdiv align=\"right\"\u003e 2022-02-19\u003c/div\u003e\n\nTags: #DeepLearning #DistributionShift #CovariateShift\n\n- ç¯å¢ƒæ˜¯å˜åŒ–çš„ï¼Œæ•°æ®ä¹Ÿæ˜¯ã€‚æœ‰æ—¶é€šè¿‡å°†åŸºäºæ¨¡å‹çš„å†³ç­–å¼•å…¥ç¯å¢ƒï¼Œæˆ‘ä»¬å¯èƒ½ä¼šç ´åæ¨¡å‹[^1]ã€‚æˆ‘ä»¬éœ€è¦åˆç†åœ°è°ƒæ•´æ¨¡å‹æ¥é€‚åº”è¿™ç§å¯èƒ½çš„å˜åŒ–ã€‚\n\n## åˆ†å¸ƒåç§»çš„ç±»å‹\n### Covariate Shift - åå˜é‡åç§»\n- é¡¾åæ€ä¹‰ï¼Œå°±æ˜¯è¾“å…¥æ•°æ®ï¼ˆç‰¹å¾ã€åå˜é‡ï¼‰çš„åˆ†å¸ƒå‘ç”Ÿäº†åç§»ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¾“å…¥å˜å¾—ä¸ä¸€æ ·äº†ï¼ŒåŸæ¥æ˜¯çœŸå®çš„çŒ«çŒ«ç‹—ç‹—ï¼Œ ç°åœ¨å˜æˆäº†å¡é€šçš„çŒ«çŒ«ç‹—ç‹—ï¼\n![covariate Shift](notes/2022/2022.2/assets/covariate%20-Shift.png)\n- å½¢å¼åŒ–åœ°è¯´, å°±æ˜¯è¾“å…¥æ•°æ®çš„åˆ†å¸ƒ $P(X)$ å‘ç”Ÿäº†å˜åŒ–, ä½†æ˜¯åœ¨è¾“å…¥ç¡®å®šä¹‹å, æœ€ç»ˆè¾“å‡ºçš„æ ‡ç­¾åˆ†å¸ƒ $P(y\\space |\\space X)$ ä¸å˜.\n\n### Label Shift - æ ‡ç­¾åç§»\n- åå˜é‡åç§»æ˜¯è¾“å…¥çš„åŸå§‹æ•°æ®åˆ†å¸ƒå‘ç”Ÿäº†åç§», è€Œ**æ ‡ç­¾åç§»**åˆ™æ˜¯åŸå§‹æ•°æ®å¯¹åº”çš„æ ‡ç­¾åˆ†å¸ƒå‘ç”Ÿäº†åç§». \n- æ¯”å¦‚åœ¨é¼ ç–«çš„è¯Šæ–­ä¸Š, é¼ ç–«æœ€åˆçš„ç—‡çŠ¶æœ‰å¤´ç—›ã€åŒçœ¼å……è¡€ã€å’³å—½ã€ä»¥åŠæ€ å€¦æ„Ÿï¼Œä¸æ™®é€šå‘¼å¸é“ç–¾ç—…ç›¸ä¼¼ã€‚è™½ç„¶å…¶ç—‡çŠ¶åœ¨åä¸‰ä¸–çºªæ—¶å’Œç°åœ¨éƒ½æ˜¯å·®ä¸å¤šçš„, ä½†æ˜¯éšç€åŒ»å­¦çš„è¿›æ­¥, é¼ ç–«çš„å‘ç—…ç‡å·²ç»å¤§å¤§é™ä½äº†. æ‰€ä»¥ç°åœ¨é¢å¯¹ç›¸åŒçš„ç—‡çŠ¶, è¯Šæ–­ä¸ºå‘¼å¸é“ç–¾ç—…çš„æ¦‚ç‡æ˜¯è¦å¤§äºé¼ ç–«çš„. ä¹Ÿå°±æ˜¯è¯´, åœ¨é¼ ç–«çš„åˆ¤æ–­é—®é¢˜ä¸Šå‘ç”Ÿäº†æ ‡ç­¾åç§».\n![200](notes/2022/2022.2/assets/450px-Yersinia_pestis_fluorescent.jpeg) [^2]\n- å½¢å¼åŒ–åœ°æ¥è¯´, å°±æ˜¯ä¸€ä¸ªæ ‡ç­¾å¯¹åº”çš„ç‰¹å¾åˆ†å¸ƒ $P(X\\space |\\space y)$ ä¸å˜, è€Œæ ‡ç­¾çš„è¾¹ç¼˜æ¦‚ç‡åˆ†å¸ƒ $P(y)$ å‘ç”Ÿäº†å˜åŒ–.\n\n### Concept Shift - æ¦‚å¿µåç§»\n- ç›´è§‚çš„ç†è§£, æ¦‚å¿µåˆ†å¸ƒå°±æ˜¯ä¸€ä¸ªäº‹ç‰©çš„å®šä¹‰(æ¦‚å¿µ)å‘ç”Ÿäº†å˜åŒ–, æ¯”å¦‚ä¸‹å›¾è¡¨ç¤ºäº†ç¾å›½ä¸åŒåœ°åŒºå¯¹äºSoft Drinkçš„ä¸åŒå®šä¹‰:\n![](notes/2022/2022.2/assets/popvssoda.png)\n- å½¢å¼åŒ–åœ°æ¥è¯´, Concept Shiftå°±æ˜¯ $X$ ä¸ $y$ çš„**ç›¸äº’å…³ç³»**å‘ç”Ÿäº†å˜åŒ–[^5], è€Œå®ƒä»¬çš„æ¦‚ç‡åˆ†å¸ƒå¯èƒ½ä¸å˜. \n\n- æ›´å¤šçš„ä¾‹å­: [Environment and Distribution Shift â€” Examples of Distribution Shift](https://d2l.ai/chapter_multilayer-perceptrons/environment.html#examples-of-distribution-shift)\n## åˆ†å¸ƒåç§»: çº æ­£\n### Empirical Risk\nå¯¹äºè®­ç»ƒæ•°æ® $\\left\\{\\left(\\mathbf{x}_{1}, y_{1}\\right), \\ldots,\\left(\\mathbf{x}_{n}, y_{n}\\right)\\right\\}$, æˆ‘ä»¬æœ€å°åŒ–æŸå¤±å‡½æ•°çš„è¿‡ç¨‹å¯ä»¥è¡¨ç¤ºä¸º: $$\\operatorname{minimize} \\frac{1}{n} \\sum_{i=1}^{n} l\\left(f\\left(\\mathbf{x}_{i}\\right), y_{i}\\right)$$\nåœ¨ç»Ÿè®¡çš„è¯­å¢ƒé‡Œé¢, ä¸Šé¢çš„æŸå¤±ä¹Ÿç§°ä¸º **ç»éªŒæŸå¤±** (*Empirical Risk*). ä¹Ÿå°±æ˜¯æŸå¤± $l(f(\\mathbf{x}), y)$ åœ¨æ•´ä¸ªæ•°æ®çš„çœŸå®åˆ†å¸ƒ $p(\\mathbf{x}, y)$ ä¸Šé¢çš„æ•°å­¦æœŸæœ›:\n$$E_{p(\\mathbf{x}, y)}[l(f(\\mathbf{x}), y)]=\\iint l(f(\\mathbf{x}), y) p(\\mathbf{x}, y) d \\mathbf{x} d y$$\nä½†æ˜¯åœ¨å®é™…è¿‡ç¨‹ä¸­æˆ‘ä»¬ä¸çŸ¥é“æ•°æ®çš„çœŸå®åˆ†å¸ƒ $p(\\mathbf{x}, y)$, æ‰€ä»¥æˆ‘ä»¬åªèƒ½è¿‘ä¼¼åœ°å»æœ€å°åŒ–Empirical risk.\n\n### Covariate Shift Correction\n- å‡è®¾ç”±äºCovariate Shift, ç‰¹å¾çš„åˆ†å¸ƒç”± $q(\\mathbf{x})$ åç§»åˆ°äº† $p(\\mathbf{x})$, å¹¶ä¸”æ ‡ç­¾çš„åˆ†å¸ƒæ²¡æœ‰å‘ç”Ÿå˜åŒ–: $q(y \\mid \\mathbf{x})=p(y \\mid \\mathbf{x})$. åˆ™æˆ‘ä»¬å¯ä»¥ç”¨å¦‚ä¸‹ç­‰å¼æ¥å¯¹åŸæ¥çš„æ¨¡å‹è¿›è¡Œä¿®æ­£:\n$$\\iint l(f(\\mathbf{x}), y) p(y \\mid \\mathbf{x}) p(\\mathbf{x}) d \\mathbf{x} d y=\\iint l(f(\\mathbf{x}), y) q(y \\mid \\mathbf{x}) q(\\mathbf{x}) \\textcolor{red}{\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}} d \\mathbf{x} d y$$\n- å¯ä»¥çœ‹åˆ°å…³é”®ä¾¿æ˜¯åˆ©ç”¨ç³»æ•° $\\beta_{i}$ æ¥å¯¹æ¯ä¸€ä¸ªæ ·æœ¬ $\\mathbf{x}_{i}$ è¿›è¡Œä¿®æ­£: $$\\beta_{i} \\stackrel{\\text { def }}{=}\\frac{p\\left(\\mathbf{x}_{i}\\right)}{q\\left(\\mathbf{x}_{i}\\right)}$$\n- æœ€å°åŒ–æŸå¤±å‡½æ•°çš„è¿‡ç¨‹å˜ä¸ºäº† $$\\underset{f}{\\operatorname{minimize}} \\frac{1}{n} \\sum_{i=1}^{n} \\textcolor{red}{\\beta_{i}} l\\left(f\\left(\\mathbf{x}_{i}\\right), y_{i}\\right)$$\n\n#### é‚£ä¹ˆæ€ä¹ˆä¼°è®¡ $\\beta_{i}$ å‘¢?\n- å› ä¸ºè®­ç»ƒæ ·æœ¬æ˜¯å·²çŸ¥çš„, æ‰€ä»¥ $q(\\mathbf{x})$ å¾ˆå¥½è®¡ç®—, ä½†æ˜¯åç§»ä¹‹åçš„ $p(\\mathbf{x})$ åˆ™ä¸æ˜¯å¾ˆå¥½è®¡ç®—. å°½ç®¡æœ‰ä¸€äº›èŠ±å“¨çš„æ–¹æ³•[^3]å¯ä»¥ç”¨æ¥ä¼°è®¡ $\\beta_{i}$ , ä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨ç®€å•çš„ [Logistic_Regression](notes/2021/2021.8/Part.12_Logistic_Regression(ML_Andrew.Ng.).md)æ¥è§£å†³è¿™ä¸ªé—®é¢˜:\n- æˆ‘ä»¬çš„æƒ³æ³•æ˜¯: åˆ©ç”¨Logistic Regressionæ¥è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨, ç”¨æ¥åŒºåˆ† $p(\\mathbf{x})$ å’Œ $q(\\mathbf{x})$. \n\t- å¦‚æœåˆ†ç±»å™¨ä¸èƒ½åŒºåˆ†çš„è¯, è¯´æ˜è¿™ä¸ªæ ·æœ¬æ²¡æœ‰å‘ç”Ÿåç§»; \n\t- å¯¹åº”çš„, è¦æ˜¯åˆ†ç±»å™¨èƒ½å¤ŸåŒºåˆ†çš„è¯, æˆ‘ä»¬ä¾¿åˆ©ç”¨åˆ†ç±»å™¨çš„è¾“å‡ºå¯¹æ ·æœ¬è¿›è¡Œç›¸åº”çš„åŠ æƒ(åˆ©ç”¨Logisticå›å½’çš„è¾“å‡ºæ¥ç”Ÿæˆæƒé‡ $\\beta_{i}$)\n\n- ä¸ºäº†ç®€å•èµ·è§, æˆ‘ä»¬å‡è®¾ $p(\\mathbf{x})$ å’Œ $q(\\mathbf{x})$ æœ‰åŒæ ·æ•°é‡çš„æ ·æœ¬ $X=\\mathbf{\\{x_1,\\cdots, x_n\\}}$ å’Œ $U=\\mathbf{\\{u_1,\\cdots, u_n\\}}$, å¯¹äºä»æ–°çš„åˆ†å¸ƒ $p$ é‡Œé¢é‡‡æ ·çš„æ ·æœ¬, æˆ‘ä»¬ä»¤æ ‡ç­¾ $z=1$, ä»æ—§çš„åˆ†å¸ƒ $q$ é‡Œé¢é‡‡æ ·çš„æ ·æœ¬, æˆ‘ä»¬ä»¤æ ‡ç­¾ $z=-1$, åˆ™å¾—åˆ°æ ·æœ¬é›†åˆ: $$\\left\\{\\left(\\mathbf{x}_{1},-1\\right), \\ldots,\\left(\\mathbf{x}_{n},-1\\right),\\left(\\mathbf{u}_{1}, 1\\right), \\ldots,\\left(\\mathbf{u}_{m}, 1\\right)\\right\\}$$\n\t- å› ä¸ºæœ‰:\n\t$$P(z=1 \\mid \\mathbf{x})=\\frac{p(\\mathbf{x})}{p(\\mathbf{x})+q(\\mathbf{x})} \\text{ and }P(z=-1 \\mid \\mathbf{x})=\\frac{q(\\mathbf{x})}{p(\\mathbf{x})+q(\\mathbf{x})}$$\n\t- ä¸¤å¼ç›¸é™¤: $$ \\frac{P(z=1 \\mid \\mathbf{x})}{P(z=-1 \\mid \\mathbf{x})}=\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}$$\n\t- æˆ‘ä»¬åˆçŸ¥é“ $$P(z=1 \\mid \\mathbf{x})=\\frac{1}{1+\\exp (-h(\\mathbf{x}))}$$\n\t- æ‰€ä»¥æœ‰: $$\\beta_{i}=\\frac{1 /\\left(1+\\exp \\left(-h\\left(\\mathbf{x}_{i}\\right)\\right)\\right)}{\\exp \\left(-h\\left(\\mathbf{x}_{i}\\right)\\right) /\\left(1+\\exp \\left(-h\\left(\\mathbf{x}_{i}\\right)\\right)\\right)}=\\exp \\left(h\\left(\\mathbf{x}_{i}\\right)\\right)$$\n\t- è¿™ä¾¿æ˜¯æƒé‡çš„ä¼°è®¡å€¼, å¦‚æœè€ƒè™‘åˆ°èŒƒå›´è¿˜å¯ä»¥çº¦æŸä¸º $\\beta_{i}=\\min \\left(\\exp \\left(h\\left(\\mathbf{x}_{i}\\right)\\right), c\\right)$, $c$ ä¸ºå¸¸é‡.\n\t- æ³¨æ„ä¸Šé¢çš„ç®—æ³•ä¾èµ–äºä¸€ä¸ªé‡è¦çš„å‡è®¾ï¼š éœ€è¦ç›®æ ‡åˆ†å¸ƒä¸­çš„æ¯ä¸ªæ•°æ®æ ·æœ¬åœ¨è®­ç»ƒæ—¶å‡ºç°çš„æ¦‚ç‡éé›¶(å°±æ˜¯è¯´åç§»åçš„æ•°æ®ä¹Ÿå¾—åœ¨åŸæ¥çš„åˆ†å¸ƒé‡Œé¢å­˜åœ¨: $q(\\mathbf{x})\\neq0$ )ã€‚ å¦‚æœæˆ‘ä»¬æ‰¾åˆ° $p(\\mathbf{x})\u003e0$ ä½† $q(\\mathbf{x})=0$ çš„ç‚¹ï¼Œ é‚£ä¹ˆç›¸åº”çš„æƒé‡ $\\beta_{i}$ ä¼šæ˜¯æ— ç©·å¤§ã€‚\n\n### Label Shift Correction\n- æ ‡ç­¾åç§»çš„çº æ­£æ–¹æ³•å’Œä¸Šé¢å¾ˆç›¸ä¼¼. æˆ‘ä»¬å‡è®¾æ ‡ç­¾çš„åˆ†å¸ƒä» $q(y)$ åç§»åˆ°äº† $p(y)$, åŒæ—¶æ¯ä¸€ä¸ªç±»çš„ç‰¹å¾åˆ†å¸ƒæ˜¯ä¸å˜çš„: $q(\\mathbf{x} \\mid y)=p(\\mathbf{x} \\mid y)$. é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ ¹æ®ä¸‹é¢çš„ç­‰å¼æ¥çº æ­£æ ‡ç­¾åç§»:\n$$\\iint l(f(\\mathbf{x}), y) p(\\mathbf{x} \\mid y) p(y) d \\mathbf{x} d y=\\iint l(f(\\mathbf{x}), y) q(\\mathbf{x} \\mid y) q(y) \\textcolor{red}{\\frac{p(y)}{q(y)}} d \\mathbf{x} d y$$\n- åŒæ ·, ä¿®æ­£çš„æƒé‡å¯ä»¥å®šä¹‰ä¸º: $$\\beta_{i} \\stackrel{\\text { def }}{=} \\frac{p\\left(y_{i}\\right)}{q\\left(y_{i}\\right)}$$\n- è®­ç»ƒæ•°æ®é‡Œé¢çš„æ ‡ç­¾åˆ†å¸ƒ $q(y_{i})$ æ˜¯å·²çŸ¥çš„, æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦ä¼°è®¡ $p(y_{i})$\n#### æ€ä¹ˆä¼°è®¡ $p(y_{i})$ å‘¢\n- å¦‚æœæ ‡ç­¾åç§»çš„ç¨‹åº¦ä¸æ˜¯ç‰¹åˆ«å¤§, æˆ‘ä»¬å…¶å®å¯ä»¥å°†åŸå§‹çš„æ ‡ç­¾ $q(\\mathbf{y})$ è¿›è¡Œçº¿æ€§å˜æ¢æ¥å¾—åˆ°æ–°çš„è¾“å‡º: $p(\\mathbf{y})$\n- è¯¦ç»†çš„æ¥è¯´, æˆ‘ä»¬å¯ä»¥æ„é€ ä¸€ä¸ª $k\\times k$ çš„æ··æ·†çŸ©é˜µ[^4] $C$ ($k$ æ˜¯ç±»åˆ«çš„æ•°ç›®). å…¶ä¸­åˆ—ç´¢å¼•å¯¹åº”Validation setæ•°æ®çš„çœŸå®æ ‡ç­¾, è¡Œç´¢å¼•åˆ™å¯¹åº”æ¨¡å‹çš„è¾“å‡ºæ ‡ç­¾. æ¯ä¸€ä¸ªå…ƒç´  $c_{ij}$ çš„å€¼åˆ™æ˜¯æ•´ä¸ªValidation Seté‡Œé¢, æ¨¡å‹æŠŠç±»åˆ« $j$ é¢„æµ‹ä¸ºç±»åˆ« $i$ çš„æ¦‚ç‡.\n\t- ä¸¾ä¸ªä¾‹å­, è¦æ˜¯æ•°æ®æ²¡æœ‰å‘ç”Ÿåç§», é‚£ä¹ˆCå°±æ˜¯ä¸€ä¸ªå•ä½çŸ©é˜µ. æ¨¡å‹å’Œå•ä½çŸ©é˜µå·®çš„è¶Šå¤š, æ ‡ç­¾åç§»å°±è¶Šä¸¥é‡.\n\n- æˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹å®é™…é¢„æµ‹æ—¶çš„ç»“æœè®°å½•ä¸‹æ¥, å¾—åˆ°è¾“å‡º $\\mu(\\hat{\\mathbf{y}}) \\in \\mathbb{R}^{k}$, å…¶ä¸­ç¬¬ $i$ ä¸ªåˆ†é‡ $\\mu\\left(\\hat{y}_{i}\\right)$ æ˜¯æ¨¡å‹é¢„æµ‹å€¼ä¸º $i$ çš„æ¦‚ç‡.\n- å°†æ‰€æœ‰æ¨¡å‹è¾“å‡ºä¸º $i$ çš„æƒ…å†µç»Ÿè®¡èµ·æ¥,  æœ‰ $$\\sum_{j=1}^{k} c_{i j} p\\left(y_{j}\\right)=\\mu\\left(\\hat{y}_{i}\\right)$$\n- æ‰€ä»¥ $$\\mathbf{C} p(\\mathbf{y})=\\mu(\\hat{\\mathbf{y}})$$\n- åªè¦è¿™ä¸ªåˆ†ç±»å™¨åœ¨ä¸€å¼€å§‹æ˜¯è¶³å¤Ÿå‡†ç¡®çš„, å¹¶ä¸”åç§»çš„ç¨‹åº¦ä¸å¤ªå¤§, é‚£ä¹ˆçŸ©é˜µCå°±æ˜¯å¯é€†çš„, æˆ‘ä»¬ä¾¿èƒ½å¤Ÿæ ¹æ® $C$ å’Œ $\\mu(\\hat{\\mathbf{y}})$ è¿‘ä¼¼å¾—åˆ°æ–°çš„æ ‡ç­¾åˆ†å¸ƒ $p(\\mathbf{y})=C^{-1}\\mu(\\hat{\\mathbf{y}})$\n\n### Concept Shift Correction\n- æ¦‚å¿µåç§»é€šå¸¸æ˜¯å¾ˆéš¾ä¿®æ­£çš„, å› ä¸º\"Xå’Œyç›¸äº’å…³ç³»çš„å˜åŒ–\"é€šå¸¸å¾ˆéš¾è¡¡é‡. ä¸¾ä¸ªæç«¯çš„ä¾‹å­, å°†åˆ†ç±»çŒ«çŒ«ç‹—ç‹—çš„åˆ†ç±»å™¨æ‹¿å»åŒºåˆ†è€è™å’Œå¤§è±¡, æ•ˆæœè‚¯å®šä¸å¥½. è¿™æ—¶å€™é€šå¸¸æˆ‘ä»¬åªèƒ½é‡æ–°æ”¶é›†æ•°æ®è¿›è¡Œè®­ç»ƒ.\n\n\n\n\n\n\n[^1]: Say, for example, that we trained a model to predict who will repay vs. default on a loan, finding that an applicantâ€™s choice of footwear was associated with the risk of default (Oxfords indicate repayment, sneakers indicate default). We might be inclined to thereafter grant loans to all applicants wearing Oxfords and to deny all applicants wearing sneakers.   In this case, our ill-considered leap from pattern recognition to decision-making and our failure to critically consider the environment might have disastrous consequences. For starters, as soon as we began making decisions based on footwear, customers would catch on and change their behavior. Before long, all applicants would be wearing Oxfords, without any coinciding improvement in credit-worthiness. Similar issues abound in many applications of machine learning: by introducing our model-based decisions to the environment, we might break the model. [4.9. Environment and Distribution Shift â€” Dive into Deep Learning 0.17.5 documentation](https://d2l.ai/chapter_multilayer-perceptrons/environment.html#environment-and-distribution-shift)\n\n[^2]: [é¼ ç–« - ç¶­åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨æ›¸](https://zh.wikipedia.org/zh-tw/%E9%BC%A0%E7%96%AB)\n[^3]: [4.9. Environment and Distribution Shift â€” Dive into Deep Learning 0.17.5 documentation](https://d2l.ai/chapter_multilayer-perceptrons/environment.html#covariate-shift-correction)\n[^4]: Confusion Matrix\n[^5]: [machine learning - Difference between distribution shift and data shift, concept drift and model drift - Cross Validated](https://stats.stackexchange.com/questions/548405/difference-between-distribution-shift-and-data-shift-concept-drift-and-model-dr)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-27-Computation-%E5%B1%82%E5%92%8C%E5%9D%97":{"title":"D2L-27-Computation-å±‚å’Œå—","content":"# æ·±åº¦å­¦ä¹ è®¡ç®—: ä½¿ç”¨*å±‚* å’Œ*å—*\n\n\u003cdiv align=\"right\"\u003e 2022-02-19\u003c/div\u003e\n\nTags: #DeepLearning #Computation #PyTorch \n\n- è¿™ä¸€ç« ä¸»è¦ä»‹ç»æ¡†æ¶çš„ä½¿ç”¨ç»†èŠ‚, æœ€å¥½çš„æ–¹æ³•å°±æ˜¯ç»“åˆä»£ç ç¤ºä¾‹, è¾¹è¿è¡Œè¾¹ç†è§£. è¿™é‡Œæˆ‘ä»¬è®°å½•ä¸€äº›å®¹æ˜“å¿½ç•¥çš„è¦ç‚¹.\n\t- [åœ¨çº¿ä»£ç å®ä¾‹: 5.1. å±‚å’Œå—](https://zh-v2.d2l.ai/chapter_deep-learning-computation/model-construction.html#sec-model-construction \"Permalink to this headline\")\n---\n\n## å±‚å’Œå—: å®šä¹‰\n- **\"å±‚\"å…·æœ‰ä¸‰ä¸ªç‰¹å¾:** \n\t1. æ¥å—ä¸€ç»„è¾“å…¥ï¼Œ \n\t2. ç”Ÿæˆç›¸åº”çš„è¾“å‡ºï¼Œ\n\t3. ç”±ä¸€ç»„å¯è°ƒæ•´å‚æ•°æè¿°ã€‚\n\n- äº‹å®è¯æ˜ï¼Œ**ç ”ç©¶è®¨è®ºâ€œæ¯”å•ä¸ªå±‚å¤§â€ä½†â€œæ¯”æ•´ä¸ªæ¨¡å‹å°â€çš„ç»„ä»¶æ›´æœ‰ä»·å€¼**ã€‚ ä¾‹å¦‚ï¼Œåœ¨è®¡ç®—æœºè§†è§‰ä¸­å¹¿æ³›æµè¡Œçš„ResNet-152æ¶æ„å°±æœ‰æ•°ç™¾å±‚ï¼Œ è¿™äº›å±‚æ˜¯ç”± _**å±‚ç»„**_ï¼ˆgroups of layersï¼‰çš„é‡å¤æ¨¡å¼ç»„æˆã€‚\n\t- [æˆ‘ä»¬å¯ä»¥è‡ªå®šä¹‰ä¸€ä¸ªå±‚](notes/2022/2022.2/D2L-29-Computation-è‡ªå®šä¹‰å±‚.md)\n\n\n- ä¸ºäº†å®ç°è¿™äº›å¤æ‚çš„ç½‘ç»œï¼Œæˆ‘ä»¬å¼•å…¥äº†ç¥ç»ç½‘ç»œ _**å—**_ çš„æ¦‚å¿µã€‚ _å—_ï¼ˆblockï¼‰å¯ä»¥æè¿°å•ä¸ªå±‚ã€ç”±å¤šä¸ªå±‚ç»„æˆçš„ç»„ä»¶æˆ–æ•´ä¸ªæ¨¡å‹æœ¬èº«ã€‚\n![](notes/2022/2022.2/assets/blocks.svg)\n## å±‚å’Œå—: å®ç°\n\n- ä»ç¼–ç¨‹çš„è§’åº¦æ¥çœ‹ï¼Œå—ç”± _**ç±»**_ ï¼ˆclassï¼‰è¡¨ç¤ºã€‚ \n\t- å®ƒçš„ä»»ä½•å­ç±»éƒ½å¿…é¡»å®šä¹‰ä¸€ä¸ªå°†å…¶è¾“å…¥è½¬æ¢ä¸ºè¾“å‡ºçš„**å‰å‘ä¼ æ’­å‡½æ•°**`forward()`ï¼Œ å¹¶ä¸”å¿…é¡»å­˜å‚¨ä»»ä½•å¿…éœ€çš„å‚æ•°ã€‚\n\t- åå‘ä¼ æ’­ä¸è‡ªåŠ¨æ±‚å¯¼é€šå¸¸ç”±æ¡†æ¶è‡ªåŠ¨å®Œæˆ.\n\n\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-28-Computation-%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86":{"title":"D2L-28-Computation-å‚æ•°ç®¡ç†","content":"# æ·±åº¦å­¦ä¹ è®¡ç®—: å‚æ•°ç®¡ç†\n\n\u003cdiv align=\"right\"\u003e 2022-02-19\u003c/div\u003e\n\nTags: #DeepLearning #Computation #Parameter #PyTorch \n\n- [åœ¨çº¿ä»£ç å®ä¾‹: 5.2. å‚æ•°ç®¡ç†](https://zh-v2.d2l.ai/chapter_deep-learning-computation/parameters.html#id1 \"Permalink to this headline\")\n---\næœ¬èŠ‚ä¸»è¦æœ‰ä»¥ä¸‹å†…å®¹ï¼š\n-   è®¿é—®å‚æ•°ï¼Œç”¨äºè°ƒè¯•ã€è¯Šæ–­å’Œå¯è§†åŒ–ã€‚\n-   å‚æ•°åˆå§‹åŒ–ã€‚\n-   åœ¨ä¸åŒæ¨¡å‹ç»„ä»¶é—´å…±äº«å‚æ•°ã€‚(ä¿æŒæŸå‡ ä¸ªå±‚çš„å‚æ•°æ˜¯åŒæ­¥çš„)\n\n## å»¶ååˆå§‹åŒ–[Â¶](https://zh-v2.d2l.ai/chapter_deep-learning-computation/deferred-init.html#sec-deferred-init \"Permalink to this headline\")\n- æ·±åº¦å­¦ä¹ æ¡†æ¶æ— æ³•åˆ¤æ–­ç½‘ç»œçš„è¾“å…¥ç»´åº¦æ˜¯ä»€ä¹ˆã€‚ è¿™é‡Œçš„è¯€çªæ˜¯æ¡†æ¶çš„ _å»¶ååˆå§‹åŒ–_ï¼ˆdefers initializationï¼‰ï¼Œ å³ç›´åˆ°æ•°æ®ç¬¬ä¸€æ¬¡é€šè¿‡æ¨¡å‹ä¼ é€’æ—¶ï¼Œæ¡†æ¶æ‰ä¼šåŠ¨æ€åœ°æ¨æ–­å‡ºæ¯ä¸ªå±‚çš„å¤§å°ã€‚\n- è¿™ä¸ªåœ¨MXNET å’Œ Tensorflow é‡Œé¢æœ‰, PyTorchè¿˜ä¸å¤ªå®Œå–„, ä¸è¿‡LazyLinearå¯ä»¥è¾¾åˆ°ç±»ä¼¼çš„åŠŸèƒ½","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-29-Computation-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82":{"title":"D2L-29-Computation-è‡ªå®šä¹‰å±‚","content":"# æ·±åº¦å­¦ä¹ è®¡ç®—: è‡ªå®šä¹‰ä¸€ä¸ªå±‚\n\n\u003cdiv align=\"right\"\u003e 2022-02-19\u003c/div\u003e\n\nTags: #DeepLearning #Computation #PyTorch \n\n - [åœ¨çº¿ä»£ç å®ä¾‹: 5.4. è‡ªå®šä¹‰å±‚](https://zh-v2.d2l.ai/chapter_deep-learning-computation/custom-layer.html#id1 \"Permalink to this headline\")\n---\n-   æˆ‘ä»¬å¯ä»¥é€šè¿‡åŸºæœ¬å±‚ç±»è®¾è®¡è‡ªå®šä¹‰å±‚ã€‚è¿™å…è®¸æˆ‘ä»¬å®šä¹‰çµæ´»çš„æ–°å±‚ã€‚\n-   åœ¨è‡ªå®šä¹‰å±‚å®šä¹‰å®Œæˆåï¼Œæˆ‘ä»¬å°±å¯ä»¥åœ¨ä»»æ„ç¯å¢ƒå’Œç½‘ç»œæ¶æ„ä¸­è°ƒç”¨è¯¥è‡ªå®šä¹‰å±‚ã€‚\n-   å±‚å¯ä»¥æœ‰å±€éƒ¨å‚æ•°ï¼Œè¿™äº›å‚æ•°å¯ä»¥é€šè¿‡å†…ç½®å‡½æ•°åˆ›å»ºã€‚","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-30-Computation-%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6":{"title":"D2L-30-Computation-è¯»å†™æ–‡ä»¶","content":"# æ·±åº¦å­¦ä¹ è®¡ç®—: è¯»å†™æ–‡ä»¶\n\n\u003cdiv align=\"right\"\u003e 2022-02-19\u003c/div\u003e\n\nTags: #DeepLearning #Computation #PyTorch \n\n - [åœ¨çº¿ä»£ç å®ä¾‹: 5.5. è¯»å†™æ–‡ä»¶](https://zh-v2.d2l.ai/chapter_deep-learning-computation/read-write.html#id1 \"Permalink to this headline\")\n---\n- æˆ‘ä»¬å¯ä»¥ä¿å­˜ä¸€ä¸ªå¼ é‡, æˆ–è€…å¼ é‡çš„å­—å…¸å’Œåˆ—è¡¨\n- æˆ‘ä»¬å¯ä»¥é€šè¿‡**å‚æ•°å­—å…¸**ä¿å­˜å’ŒåŠ è½½ç½‘ç»œçš„å…¨éƒ¨å‚æ•°, ä½†æ˜¯Pytorchä¸­, æ¨¡å‹çš„å®šä¹‰éœ€è¦ç”¨å…¶ä»–æ–¹æ³•æ¥ä¿å­˜.\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-31-Computation-%E8%B4%AD%E4%B9%B0%E4%B8%8E%E4%BD%BF%E7%94%A8GPU":{"title":"D2L-31-Computation-è´­ä¹°ä¸ä½¿ç”¨GPU","content":"# æ·±åº¦å­¦ä¹ è®¡ç®—: è´­ä¹°ä¸ä½¿ç”¨GPU\n\n\u003cdiv align=\"right\"\u003e 2022-02-19\u003c/div\u003e\n\nTags: #DeepLearning #Computation #PyTorch #GPU\n\n- è´­ä¹°ä¸æ­å»ºè®¡ç®—å¹³å°: [16.4. é€‰æ‹©æœåŠ¡å™¨å’ŒGPU](https://zh-v2.d2l.ai/chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html#gpu \"Permalink to this headline\")\n\n- Pytorchä½¿ç”¨GPU: [5.6. GPU â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ](https://zh-v2.d2l.ai/chapter_deep-learning-computation/use-gpu.html)\n\t- Tesla GPU å’Œé©¬æ–¯å…‹æ²¡å•¥å…³ç³»: \n\t\u003e NVIDIAæä¾›ä¸¤ç§ç±»å‹çš„GPUï¼Œé’ˆå¯¹ä¸ªäººç”¨æˆ·ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡GTXå’ŒRTXç³»åˆ—ï¼‰å’Œ**ä¼ä¸šç”¨æˆ·ï¼ˆé€šè¿‡å…¶Teslaç³»åˆ—ï¼‰**","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-32-Convolution-%E5%8D%B7%E7%A7%AF":{"title":"D2L-32-Convolution-å·ç§¯","content":"# å·ç§¯ - Convolution\n\n\u003cdiv align=\"right\"\u003e 2022-02-26\u003c/div\u003e\n\nTags: #DeepLearning #Convolution \n\n**å…³é”®ç‚¹:**\n- Convolution Determines the Output of a System for any Input[^2]\n\n- ä»æ•°å­¦çš„è§’åº¦ç†è§£, å·ç§¯æ˜¯é€šè¿‡ä¸¤ä¸ªå‡½æ•°  ($f$ å’Œ $g$ ) ç”Ÿæˆç¬¬ä¸‰ä¸ªå‡½æ•° ($f*g$) çš„ä¸€ç§æ•°å­¦ç®—å­, å·ç§¯å‡½æ•° $f*g$ è¡¨ç¤ºäº†ä¸¤ä¸ªå‡½æ•°ç›¸äº’å½±å“çš„ç»“æœ. \n\n## å·ç§¯: ç›´è§‚ç†è§£\n### å·ç§¯å¯ä»¥è¡¡é‡è®¸å¤šç¬æ—¶è¾“å…¥çš„ç´¯è®¡å½±å“\n- [The Motivation of Convolution è¿™æ˜¯ä¸€ä¸ªäº¤äº’çš„ä¾‹å­, å¼ºçƒˆå»ºè®®ç‚¹è¿›å»](https://lpsa.swarthmore.edu/Convolution/sbh.html)\n\n\t- ä»¥å®¤å¤–æ¸©åº¦å¯¹å®¤å†…æ¸©åº¦çš„å½±å“ä¸ºä¾‹, å‡è®¾æŸä¸€å¤©çš„æ°”æ¸©å¯¹äºä»¥åå‡ å¤©çš„å®¤å†…æ¸©åº¦çš„å½±å“å‘ˆå¦‚ä¸‹æŒ‡æ•°åˆ†å¸ƒ: \n\t![impulse-response-ht-vs-t|350](notes/2022/2022.2/assets/impulse-response-ht-vs-t.svg)\n\t- æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å½±å“éšç€æ—¶é—´çš„å¢é•¿è¡°å‡çš„å¾ˆå¿«. \n\t- æ˜¾ç„¶å®¤å¤–æ¸©åº¦å˜åŒ–æ˜¯ä¸€ä¸ªè¿ç»­çš„å‡½æ•°, å¦‚ä¸‹é¢è“è‰²æ›²çº¿æ‰€ç¤º. è€Œè¿™ä¸ªè“è‰²æ›²çº¿ä¸Šæ¯ä¸€ç‚¹å¯¹å®¤å†…æ°”æ¸©çš„å½±å“çš„å˜åŒ–, éƒ½æ˜¯ä¸Šæ–¹çš„çº¢è‰²æ›²çº¿. \n\t\t![flambda-ext-t-and-ht-lam|350](notes/2022/2022.2/assets/flambda-ext-t-and-ht-lam.svg)\n\t- æˆ‘ä»¬æ€æ ·è¡¡é‡ä»Šå¤©ä»¥å‰**æ‰€æœ‰çš„å®¤å¤–æ°”æ¸©**å¯¹ä»Šæ—¥æ°”æ¸©çš„æ€»å½±å“å‘¢? è¿™å°±è¦æ±‚æˆ‘ä»¬è®¡ç®—æ— æ•°ä¸ªç¬æ—¶è¾“å…¥çš„ç´¯è®¡å½±å“, è€Œå·ç§¯å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹: \n\t\t- æˆ‘ä»¬è®¡ç®— $f(\\lambda)\\cdot h(t-\\lambda)$ ç›¸å¯¹äº $\\lambda$ çš„å˜åŒ–æ›²çº¿: \n\t\t![flambdamiddotht-lambda-v|350](notes/2022/2022.2/assets/flambdamiddotht-lambda-v.svg)\n\t\t- è¿™å°±æ˜¯ $t$ æ—¶åˆ», æ‰€æœ‰å½±å“åœ¨æ—¶é—´ä¸Šçš„åˆ†å¸ƒ, ä¸ºäº†è®¡ç®—ç´¯è®¡å½±å“, æˆ‘ä»¬éœ€è¦å¯¹è¿™ä¸ªå‡½æ•°å…³äº $\\lambda$ è¿›è¡Œç§¯åˆ†: $$y(t)=\\int_{-\\infty}^{+\\infty} h(t-\\lambda) \\cdot f(\\lambda) \\cdot d \\lambda$$\n\t\t- ä¸Šå¼å°±æ˜¯å·ç§¯ $y(t)=h*f$ çš„å®šä¹‰, é€šè¿‡è¡¡é‡è¾“å…¥ $f$ åœ¨ $t$ æ—¶åˆ»ä»¥å‰çš„æ‰€æœ‰å½±å“ $h$, æˆ‘ä»¬å¾—åˆ°äº†ç´¯è®¡å½±å“éšç€æ—¶é—´çš„å˜åŒ– $y(t)$\n\t\t![external-and-internal-te|350](notes/2022/2022.2/assets/external-and-internal-te.svg)\n\n- **Some minor points**\n\t- å› ä¸ºè¡¡é‡çš„æ˜¯ $t$ æ—¶åˆ»ä»¥å‰çš„ç´¯è®¡å½±å“, æ‰€ä»¥æˆ‘ä»¬éœ€è¦\"ç¿»è½¬\"å½±å“å‡½æ•° $h$ å†è¿›è¡Œ\"æ»‘åŠ¨\".\n\t- å¯¹äºæ¯ä¸€ä¸ªæ—¶åˆ» $t$, æˆ‘ä»¬éƒ½éœ€è¦è®¡ç®—æ•´ä¸ªåæ ‡è½´ä¸Šé¢æ‰€æœ‰ç‚¹å¯¹äº $t$ æ—¶åˆ»çš„å½±å“, è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆ $y(t)$ çš„å®šä¹‰é‡Œé¢æœ‰ä¸€ä¸ªç§¯åˆ†ç¬¦å·.\n\t- [Live Demo](https://lpsa.swarthmore.edu/Convolution/CI.html)\n\n### å…¶ä»–ç†è§£\n- ä¸‹é¢æ˜¯ä¸¤ä¸ªä»ç¦»æ•£å˜é‡è§’åº¦æ¥ç†è§£çš„ä¾‹å­\n\u003ciframe width=\"560\" height=\"315\" src=\" https://www.youtube.com/embed/MQm6ZP1F6ms?start=32\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ciframe width=\"560\" height=\"315\" src=\" https://www.youtube.com/embed/aEGboJxmq-w\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- è¿™æ˜¯å·ç§¯åœ¨å›¾åƒå¤„ç†æ—¶çš„åº”ç”¨.\n\u003ciframe width=\"560\" height=\"315\" src=\" https://www.youtube.com/embed/8rrHTtUzyZA\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n## å·ç§¯çš„æ•°å­¦å®šä¹‰\n$$(f * g)(t):=\\int_{-\\infty}^{\\infty} f (\\tau) g (t-\\tau) d \\tau$$\n\n### ä¸€äº›æ€§è´¨[^3]\n- **äº¤æ¢å¾‹Commutativity:** æ—¢ç„¶å¯ä»¥ $g$ æ»‘åŠ¨ $f$ ä¸åŠ¨, é‚£ä¹ˆè‚¯å®šä¹Ÿå¯ä»¥ $f$ æ»‘åŠ¨ $g$ ä¸åŠ¨, å®ƒä»¬é‡å çš„é¢ç§¯è‚¯å®šæ˜¯ä¸ä¼šå˜çš„, è¿™å°±æœ‰äº†äº¤æ¢å¾‹:\n\t$$(f * g)(t)=\\int_{-\\infty}^{\\infty} f (\\tau) g (t-\\tau) d \\tau=\\int_{-\\infty}^{\\infty} f (t-\\tau) g (\\tau) d \\tau$$\n\tin short: $$f * g=g * f$$\n- **ç»“åˆå¾‹Associativity:** å‡è®¾æœ‰å‡½æ•° $f,g,h$, é‚£ä¹ˆå¯ä»¥å…ˆå åŠ  $f$ å’Œ $g$ çš„å½±å“, å†å åŠ  $h$ çš„å½±å“, ä¹Ÿå¯ä»¥ç›¸å åŠ  $g$ å’Œ $h$ çš„å½±å“, å†å åŠ  $f$ çš„å½±å“, ç»“æœè‚¯å®šæ˜¯ä¸å˜çš„. \n\t$$f *(g * h)=(f * g) * h$$\n\t\n- **åˆ†é…å¾‹Distributivity:**\n\t$$f *(g+h)=(f * g)+(f * h)$$\n\n## å·ç§¯ä¸äº¤å‰ç›¸å…³ Convolution \u0026 Cross-Correlation\n![](notes/2022/2022.2/assets/Comparison_convolution_correlation.svg)æ¥æº: [^1]\n\n### å•¥æ˜¯äº¤å‰ç›¸å…³\n- [Cross-correlation - Wikipedia](https://en.wikipedia.org/wiki/Cross-correlation)\n\tå®æ•°åŸŸä¸Š, äº¤å‰ç›¸å…³æ˜¯\n\t$$(f \\star g)(t) := \\int_{-\\infty}^{\\infty} f(\\tau) g(t+\\tau) d \\tau$$\n\täº¤å‰ç›¸å…³å’Œå·ç§¯å°±å·®äº†ä¸€ä¸ªæ­£è´Ÿå·\n\t- In signal processing, cross-correlation is **a measure of similarity of two series (åºåˆ—)** as a function of the displacement of one relative to the other.\n\n- äº¤å‰ç›¸å…³ç”¨äº**è¡¡é‡å›¾ç‰‡ç›¸ä¼¼åº¦**çš„ä¸€ä¸ªä¾‹å­\n\u003ciframe width=\"560\" height=\"315\" src=\" https://www.youtube.com/embed/MQm6ZP1F6ms?start=424\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- ä¸¤è€…çš„å·®åˆ«ä¸å¤§, å«ä¹‰éƒ½æ˜¯ç±»ä¼¼çš„.\n\n- åœ¨è®¡ç®—å·ç§¯æ ¸çš„æ—¶å€™, å®é™…ä¸Šæˆ‘ä»¬è®¡ç®—çš„æ˜¯**äº¤å‰ç›¸å…³**, è¿™æ˜¯æ·±åº¦å­¦ä¹ é‡Œé¢çš„ä¸€ä¸ªæœ¯è¯­è¯¯ç”¨.\n\t- [19 å·ç§¯å±‚ã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ v2ã€‘](https://www.bilibili.com/video/BV1L64y1m7Nh?p=2\u0026t=415.1)\n\t- [Convolution vs Cross Correlation - YouTube](https://youtu.be/C3EEy8adxvc)\n\t\t![](notes/2022/2022.2/assets/Pasted%20image%2020220226172550.png)\n\n## æ•°å€¼è®¡ç®—: å·ç§¯ä¸å‚…é‡Œå¶å˜æ¢\n- å·ç§¯çš„è®¡ç®—å¤æ‚åº¦æ˜¯å¾ˆé«˜çš„, æ‰€ä»¥æˆ‘ä»¬æƒ³è¦æ‰¾åˆ°ä¸€ä¸ªé«˜æ•ˆçš„æ–¹æ³•æ¥è®¡ç®—å·ç§¯, å¹¸è¿çš„æ˜¯, å·ç§¯ä¸å‚…é‡Œå¶å˜æ¢æœ‰ä»¥ä¸‹è”ç³» (Convolution Theorem): \n\t$$\\mathcal{F}(f*g)=\\mathcal{F}(f)\\mathcal{F}(g)$$\n\tä¹Ÿå°±æ˜¯è¯´\n\t$$f*g=\\mathcal{F}^{-1}\\left(\\mathcal{F}(f)\\mathcal{F}(g)\\right)$$\n\tæˆ‘ä»¬å¯ä»¥ç”¨å‚…é‡Œå¶å˜æ¢æ¥ä»£æ›¿å·ç§¯è¿ç®—.\n\t\n- æ¨å¯¼: \n\t\u003ciframe width=\"560\" height=\"315\" src=\" https://www.youtube.com/embed/mOiY1fOROOg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- å¯¹äºCross-Correlationä¹Ÿæ˜¯ä¸€æ ·çš„, åªä¸è¿‡æ˜¯åœ¨æ¨å¯¼çš„æ—¶å€™æŠŠ $t-\\tau$ å˜æˆ $t+\\tau$\n\n- Fast Fourier transfer (FFT) reduces the complexity of convolution from  $ğ‘‚(ğ‘›^2)$ to $ğ‘‚(ğ‘›\\logğ‘›)$\n- GPU-accelerated FFT implementations perform up to 10 times faster than CPU only alternatives. (e.g. NVIDIA CUDA libraries) .\n\n- ä¸€ä¸ªæ›´è¯¦ç»†çš„å®ä¾‹è§£é‡Š\n\t\u003ciframe width=\"560\" height=\"315\" src=\" https://www.youtube.com/embed/8rrHTtUzyZA?start=1568\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n---\nä¸‹ä¸€éƒ¨åˆ†è°ˆè®ºå·ç§¯ç¥ç»ç½‘ç»œ\n\n\n[^1]: [Convolution - Wikipedia](https://en.wikipedia.org/wiki/Convolution#/media/File:Comparison_convolution_correlation.svg)\n[^2]: [The Convolution as A Sum of Impulse Responses](https://lpsa.swarthmore.edu/Convolution/Convolution.html)\n[^3]: [Convolution - Wikipedia](https://en.wikipedia.org/wiki/Convolution#Properties)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-33-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN":{"title":"D2L-33-å·ç§¯ç¥ç»ç½‘ç»œCNN","content":"# Convolutional Neural Network - å·ç§¯ç¥ç»ç½‘ç»œ\n\n\u003cdiv align=\"right\"\u003e 2022-02-26\u003c/div\u003e\n\nTags: #CNN #DeepLearning #Convolution \n\n## MLPçš„ä¸è¶³\néšç€å›¾åƒåˆ†è¾¨ç‡çš„æé«˜, MLPæ˜¾éœ²å‡ºä»¥ä¸‹ä¸è¶³: \n- å‡è®¾æˆ‘ä»¬çš„å›¾åƒåˆ†è¾¨ç‡ä¸º $1920\\times 1080$, é‚£ä¹ˆä¸€å¼ å›¾ç‰‡å°±æœ‰ $2,073,600$ ä¸ªåƒç´ ç‚¹, å‡è®¾å’Œè¾“å…¥å±‚ç›¸è¿çš„éšè—å±‚æœ‰ $1000$ ä¸ªå•å…ƒ, é‚£ä¹ˆå…‰æ˜¯ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚å°±æœ‰å¤§çº¦ $2\\times10^9$ ($20$ äº¿) ä¸ªå‚æ•°, è®­ç»ƒè¿™æ ·çš„ç½‘ç»œæ˜¯éš¾ä»¥æƒ³è±¡çš„, å†µä¸”è¿™è¿˜åªæ˜¯ç½‘ç»œçš„ç¬¬ä¸€å±‚.\n\n- ä¸ºäº†å‡å°‘ç½‘ç»œå‚æ•°çš„å¤§å°, æˆ‘ä»¬éœ€è¦æƒ³åŠæ³•ç¼©å‡å‚æ•°çš„å¤§å°.\n\n## ä»å…¨è¿æ¥å±‚åˆ°å·ç§¯ - From Fully-Connected Layers to Convolutions\n### MLPæ¨å¹¿åˆ°äºŒç»´ï¼šæƒé‡å˜æˆäº†å››ç»´å¼ é‡\nä¹‹å‰ MLP çš„è¾“å…¥è¾“å‡ºéƒ½æ˜¯ä¸€ç»´çš„ï¼š\n![mlp](notes/2022/2022.2/assets/mlp.svg)\nå›¾åƒå¯ä»¥çœ‹ä½œåƒç´ ç‚¹æ„æˆçš„äºŒç»´çŸ©é˜µã€‚å¦‚æœç½‘ç»œè¾“å…¥è¾“å‡ºçš„å½¢çŠ¶éƒ½æ˜¯äºŒç»´çš„çŸ©é˜µçš„è¯, é‚£ä¹ˆç½‘ç»œæ¯ä¸€å±‚çš„æƒé‡ä¼šå˜æˆä¸€ä¸ªå››ç»´å¼ é‡:\n![å››ç»´æƒé‡](notes/2022/2022.2/assets/å››ç»´æƒé‡.svg)\nè§„èŒƒåœ°è¯´, å°±æ˜¯: $$h_{i, j}=\\sum_{k, l} w_{i, j, k, l} x_{k, l}$$\nå…¶ä¸­ç´¢å¼• $k,l$ çš„ä½œç”¨æ˜¯å¯¹äºæ¯ä¸€ä¸ªéšè—å•å…ƒ, éå†æ‰€æœ‰è¾“å…¥ $X$; ç´¢å¼• $i,j$ çš„ä½œç”¨æ˜¯éå†æ‰€æœ‰çš„éšè—å•å…ƒï¼ˆ$H_h\\times H_w$ï¼‰.\n\n### å¹³ç§»ä¸å˜æ€§  Translation Invariance\n![400](notes/2022/2022.2/assets/Translation_of_a_set.svg)[^1]\n\n- åœ¨ä¸€å¼ å›¾ç‰‡é‡Œé¢å¹³ç§»ä¸€ä¸ªç‰©ä½“, è¿™ä¸ªç‰©ä½“çš„å½¢çŠ¶åº”è¯¥æ˜¯ä¸å˜çš„. æ‰€ä»¥æˆ‘ä»¬æƒ³, èƒ½ä¸èƒ½åˆ©ç”¨è¿™ç§ç›¸ä¼¼æ€§æ¥å‡å°‘å‚æ•°çš„å¤§å°å‘¢?\n![400](notes/2022/2022.2/assets/Pasted%20image%2020220227105222.png)\n- **Parameter Sharing :** æ—¢ç„¶ç‰©ä½“åœ¨å›¾åƒå“ªé‡Œçš„å½¢çŠ¶éƒ½ä¸€æ ·, é‚£ä¹ˆåœ¨å›¾åƒä»»æ„ä½ç½®è¯†åˆ«è¿™ä¸ªç‰©ä½“çš„æƒé‡ä¹Ÿå¤§è‡´ç›¸ä¼¼. ä¹Ÿå°±æ˜¯è¯´, æˆ‘ä»¬å¯ä»¥åœ¨å„ä¸ªéšè—å•å…ƒä¹‹é—´\"åˆ†äº«æƒé‡\".\n- æ•°å­¦ä¸Šè¯´, å°±æ˜¯: $$h_{i, j}=\\sum_{k, l} w_{k, l} x_{k, l}$$ æƒé‡ä¸å†å’Œéšè—å•å…ƒçš„ç´¢å¼• $i,j$ ç›¸å…³äº†, æ‰€æœ‰éšè—å•å…ƒçš„æƒé‡éƒ½æ˜¯åŒä¸€ä¸ªçŸ©é˜µ. è¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„è¿›æ­¥!\n![å‡å°‘äº†å¾ˆå¤šå‚æ•°](notes/2022/2022.2/assets/å‡å°‘äº†å¾ˆå¤šå‚æ•°.svg)\n\n- å¹³ç§»ä¸å˜æ€§è¿˜æ„å‘³ç€è¾“å…¥ä¸­\"ç‰©ä½“çš„å¹³ç§»\"å°†å¯¼è‡´è¾“å‡ºä¸­\"æ¿€æ´»çš„å¹³ç§»\"\n\n### å±€éƒ¨æ€§ Local Connectivity\n![](notes/2022/2022.2/assets/Pasted%20image%2020220227114101.png)\n- ä¸€å¼ å›¾åƒå¯ä»¥çœ‹ä½œä¸€å›¢åƒç´ ç‚¹, è€Œå›¾åƒä¸­ç›¸éš”è¾ƒè¿œçš„åƒç´ ç‚¹å¾€å¾€è”ç³»ä¸å¤§. æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ç§\"é‡è¦æ€§çš„è¡°å‡\"æ¥è¿›ä¸€æ­¥ç¼©å‡å‚æ•°çš„å¤§å°.\n- è¦ç¼©å‡æˆ‘ä»¬å…³æ³¨åƒç´ ç‚¹çš„èŒƒå›´, è‡ªç„¶éœ€è¦å‡å°æƒé‡çŸ©é˜µçš„å¤§å°, ä¸ºäº†æ–¹ä¾¿æ•°å­¦ä¸Šçš„è¡¨ç¤º, æˆ‘ä»¬å¯¹ç´¢å¼• $k,l$ è¿›è¡Œä»¥ä¸‹å˜æ¢:\n\t$$\\begin{aligned}h_{i, j}\u0026=\\sum_{k, l} w_{k, l} x_{k, l}\\\\\n\t\u0026=\\sum_{a, b} v_{a, b} x_{i+a, j+b}\n\t\\end{aligned}$$\n\t- å…¶ä¸­ $w_{k,l}=v_{i+a, j+b}$ , å¦‚æœ $x$ ä¸‹æ ‡çš„èŒƒå›´ä¸å˜, è¿™å°±æ„å‘³ç€ $a\\in[-i,k-i],$  $b\\in[-j,l-j]$, å…¶å®å°±ç›¸å½“äº\"ä»¥ $(i, j)$ ä¸ºä¸­å¿ƒå¼€å§‹è®¡ç®— $h_{i, j}$ \"\n- ç¼©å‡å‚æ•°çš„èŒƒå›´æ„å‘³ç€è¦ä¸¢å¼ƒè·ç¦» $(i, j)$ å¤ªè¿œçš„æƒé‡, ä¹Ÿå°±æ˜¯è¯´ï¼š\n\tå½“ $|a|,|b|\u003e\\Delta$ æ—¶, ä½¿å¾— $v_{a, b}=0$\n\t$$h_{i, j}=\\sum_{a=-\\Delta}^{\\Delta} \\sum_{b=-\\Delta}^{\\Delta} v_{a, b} x_{i+a, j+b}$$\n\t\n### å·ç§¯æ˜¯ä¸€ç§ç‰¹æ®Šçš„å…¨è¿æ¥\n- å¹³ç§»ä¸å˜æ€§å’Œå±€éƒ¨æ€§æ˜¯æˆ‘ä»¬å¯¹å…¨è¿æ¥å±‚çš„è¿›ä¸€æ­¥çº¦æŸ, ä¹Ÿå°±æ˜¯è¯´: **å·ç§¯æ˜¯ä¸€ç§ç‰¹æ®Šçš„å…¨è¿æ¥å±‚**.\n\n- ç›¸æ¯”å…¨è¿æ¥å±‚ (FC Layer), å·ç§¯å±‚æœ‰æ›´å°‘çš„å‚æ•°, è‡ªç„¶æœ‰ç€æ›´å¿«çš„è¿ç®—é€Ÿåº¦ä¸æ›´å°çš„å­˜å‚¨å¼€é”€\n\t![400](notes/2022/2022.2/assets/Pasted%20image%2020220227120249.png)\n#### æ„Ÿå—é‡çš„å¢é•¿\n![400](notes/2022/2022.2/assets/Pasted%20image%2020220227120443.png)\n- å±€éƒ¨æ€§æ˜¯å¦æ„å‘³ç€æ·±åº¦ç¥ç»ç½‘ç»œåªæ³¨æ„ç»†èŠ‚è€Œ\"ä¸è§‚å¤§å±€\"å‘¢?\n- å…¶å®æ·±åº¦ç¥ç»ç½‘ç»œé‡Œé¢è¾ƒæ·±çš„å±‚é€šå¸¸èƒ½é—´æ¥åœ° (Indirectly) å…³è”æ›´å¤šçš„è¾“å…¥, è¿™ä½¿å¾—ç¥ç»ç½‘ç»œèƒ½å¤Ÿä»ç®€å•è€Œç¨€ç–çš„å…³ç³»ä¸­ç»„åˆå‡ºå¤æ‚çš„ç»“æ„.\n- ä¾‹å¦‚, ä¸Šå›¾ä¸­ç¬¬äºŒå±‚çš„ $h_i$ åªå…³è”äº†3ä¸ªè¾“å…¥, è€Œ $g_3$ å…³è”äº†æ‰€æœ‰äº”ä¸ªè¾“å…¥. \n\n### å·ç§¯å±‚çš„ [å½’çº³åç½® Inductive bias](notes/2022/2022.2/å½’çº³åç½®-Inductive%20bias%20-%20learning%20bias.md)\n- å·ç§¯å±‚ä¸­æ‰€æœ‰çš„æƒé‡å­¦ä¹ éƒ½å°†ä¾èµ–äºå½’çº³åç½®(å³å±€éƒ¨æ€§å’Œå¹³ç§»ä¸å˜æ€§)ã€‚å½“è¿™ç§åç½®ä¸ç°å®ç›¸ç¬¦æ—¶ï¼Œæˆ‘ä»¬å°±èƒ½å¾—åˆ°æ ·æœ¬æœ‰æ•ˆçš„æ¨¡å‹ï¼Œå¹¶ä¸”è¿™äº›æ¨¡å‹èƒ½å¾ˆå¥½åœ°æ³›åŒ–åˆ°æœªçŸ¥æ•°æ®ä¸­ã€‚\n- ä½†å¦‚æœè¿™åç½®ä¸ç°å®ä¸ç¬¦æ—¶ï¼Œæ¯”å¦‚å½“å›¾åƒä¸æ»¡è¶³å¹³ç§»ä¸å˜æ—¶ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯èƒ½éš¾ä»¥æ‹Ÿåˆæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ã€‚\n\u003e **ä¸€ä¸ªä¾‹å­**: We build a face detector. It works well on all benchmarks. Unfortunately it fails on test dataâ€”the offending examples are close-ups where the face fills the entire image (no such data were in the training set).[^4]\n\n## è¿›ä¸€æ­¥æ‹“å±•: Channels - é€šé“\n- ä¸Šé¢æˆ‘ä»¬åªæ˜¯å•çº¯åœ°å°†å›¾åƒçœ‹ä½œåƒç´ ç‚¹çš„äºŒç»´çŸ©é˜µ, ä½†æ˜¯å®é™…ä¸Šå½©è‰²å›¾åƒæœ‰RGBä¸‰ä¸ªé€šé“ (Channel). ä¹Ÿå°±æ˜¯è¯´: å›¾åƒä¸æ˜¯äºŒç»´å¼ é‡ï¼Œè€Œæ˜¯ä¸€ä¸ªç”±é«˜åº¦ã€å®½åº¦å’Œé¢œè‰²ç»„æˆçš„ä¸‰ç»´å¼ é‡.\n- å› æ­¤ï¼Œæˆ‘ä»¬å°† $X$ ç´¢å¼•ä¸º $x_{i, j, k}$ . å¯¹äºå›¾åƒçš„ä¸åŒé€šé“, æˆ‘ä»¬å•ç‹¬è®¾ç½®ä¸€ä¸ªæƒé‡çŸ©é˜µ $v_{a,\\space b,\\space i}$, ç”±æ­¤å·ç§¯ç›¸åº”åœ°è°ƒæ•´ä¸º $v_{a,\\space b,\\space c}$ , æœ€åæˆ‘ä»¬å°†ä¸åŒè¾“å…¥é€šé“çš„å·ç§¯ç»“æœç›¸åŠ :\n\t$$h_{i, j}=\\sum_{a=-\\Delta}^{\\Delta} \\sum_{b=-\\Delta}^{\\Delta}\\sum_c v_{a,\\space b,\\space c}\\space x_{i+a,\\space j+b,\\space c}$$\n\t- ç°åœ¨æˆ‘ä»¬å°†ä¸€ä¸ªä¸‰ç»´çš„å›¾åƒ $X_{ijk}$ å˜æ¢ä¸ºäº†ä¸€ä¸ªäºŒç»´çš„å›¾åƒ $H_{ij}$, æƒé‡å˜æˆäº†ä¸€ä¸ªä¸‰ç»´çš„å¼ é‡ $v_{a,\\space b,\\space c}$\n\t\t![](notes/2022/2022.2/assets/conv-multi-in.svg)\n\n- ç±»æ¯”å›¾åƒçš„é¢œè‰²é€šé“, æˆ‘ä»¬çš„éšè—è¡¨ç¤º $H$ èƒ½å¦ä¹Ÿé‡‡ç”¨ä¸‰ç»´å¼ é‡å‘¢?  \n\t- å®è·µè¡¨æ˜è¿™æ ·æ˜¯å¯ä»¥å¢å¼ºç½‘ç»œçš„è¡¨ç°èƒ½åŠ›çš„[^2], è¿™äº›é€šé“æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸º_ç‰¹å¾æ˜ å°„_ï¼ˆfeature mapsï¼‰ï¼Œå› ä¸ºæ¯ä¸ªé€šé“éƒ½å‘åç»­å±‚æä¾›ä¸€ç»„ç©ºé—´åŒ–çš„å­¦ä¹ ç‰¹å¾ã€‚ \n\t- ç›´è§‚ä¸Šä½ å¯ä»¥æƒ³è±¡åœ¨é è¿‘è¾“å…¥çš„åº•å±‚ï¼Œä¸€äº›é€šé“ä¸“é—¨è¯†åˆ«è¾¹ç¼˜ï¼Œè€Œä¸€äº›é€šé“ä¸“é—¨è¯†åˆ«çº¹ç†ã€‚æ¢å¥è¯è¯´ï¼Œå¯¹äºæ¯ä¸€ä¸ªç©ºé—´ä½ç½®ï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ç»„è€Œä¸æ˜¯ä¸€ä¸ªéšè—è¡¨ç¤ºã€‚\n\t ![300](notes/2022/2022.2/assets/Pasted%20image%2020220227122429.png)[^3]\n\n- ä¸ºäº†æ”¯æŒè¾“å…¥ $X$ å’Œéšè—è¡¨ç¤º $H$ ä¸­çš„å¤šä¸ªé€šé“ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æƒé‡ $V$ ä¸­æ·»åŠ ç¬¬å››ä¸ªåæ ‡ï¼Œå³ $v_{a,\\space b,\\space c,\\space d}$  , ç»¼ä¸Šæ‰€è¿°:\n\t$$h_{i,\\space j,\\space d}=\\sum_{a=-\\Delta}^{\\Delta} \\sum_{b=-\\Delta}^{\\Delta}\\sum_c v_{a,\\space b,\\space c,\\space d}\\space x_{i+a,\\space j+b,\\space c}$$\n\t- å¤šä¸ªéšè—å±‚é€šé“æ„å‘³ç€æ¯ä¸€å±‚æœ‰è®¸å¤š\"å—\"ä¸åŒçš„å·ç§¯æ ¸.\n\t\t![å·ç§¯å±‚æƒé‡å¤§å°çš„è®¡ç®—](notes/2022/2022.2/assets/å·ç§¯å±‚æƒé‡å¤§å°çš„è®¡ç®—.svg)\n---\n- CNNå°±æ˜¯Kernelå­¦ä¹ æœºå™¨:\n\t- CNNå­¦ä¹ åˆ°Kernel, ç”¨è¿™äº›Kernelå¤„ç†è¾“å…¥, å¾—åˆ°éšè—å±‚é‡Œé¢ä¸åŒçš„ç‰¹å¾:\n\t\t![](notes/2022/2022.2/assets/Pasted%20image%2020220227152750.png)\n\t[âœ‚ï¸ From Kernel to CNN - YouTube](https://youtube.com/clip/UgkxpFJvCStGs-5uA7ay8H6_LLSE7Z8HzX_a)\n\n\n\n[^1]: [Translational symmetry - Wikipedia](https://en.wikipedia.org/wiki/Translational_symmetry#/media/File:Translation_of_a_set.svg)\n[^2]: æˆ‘è‡ªå·±ç¼–çš„ Reference Needed\n[^3]: [CNN Explainer](https://poloclub.github.io/cnn-explainer/)\n[^4]: [4.9. Environment and Distribution Shift â€” Dive into Deep Learning 0.17.5 documentation](https://d2l.ai/chapter_multilayer-perceptrons/environment.html#more-anecdotes)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-34-%E5%8D%B7%E7%A7%AF%E5%B1%82-%E5%A1%AB%E5%85%85-Padding":{"title":"D2L-34-å·ç§¯å±‚ - å¡«å…… - Padding","content":"# Padding - å¡«å……\n\n\u003cdiv align=\"right\"\u003e 2022-02-27\u003c/div\u003e\n\nTags: #DeepLearning #CNN #Padding\n\n- It's always nice to have an interactive example: \n\t- [Convolution Visualizer](https://ezyang.github.io/convolution-visualizer/index.html)\n\t- [CNN Explainer](https://poloclub.github.io/cnn-explainer/)\n\n- å·ç§¯æ“ä½œä¼šä½¿å›¾åƒå°ºå¯¸å˜å°, å¡«å…… (Padding) å¯ä»¥**å‡ç¼“**è¿™ä¸ªè¿‡ç¨‹.\n\n![300](notes/2022/2022.2/assets/img_2022-10-15-3.gif)\n## å°ºå¯¸å˜åŒ–: å®šé‡è®¡ç®—\n- æˆ‘ä»¬å‡è®¾è¾“å…¥çš„å¤§å°ä¸º $x_h\\times x_w$, å·ç§¯æ ¸çš„å¤§å°ä¸º $k_h\\times k_w$\n\n- ä¸å¸¦Paddingçš„å·ç§¯: $$x_h\\times x_w \\quad\\stackrel{conv}{\\longrightarrow}\\quad \\left (x_{h}-k_{h}+1\\right) \\times\\left (x_{w}-k_{w}+1\\right)$$\n\n- å‡è®¾Paddingå¤§å°ä¸º $p_h\\times p_w$, å…¶ä¸­ $p_h$ ä»£è¡¨å¯¹heightçš„å¡«å……ï¼ˆå¤§çº¦ä¸€åŠåœ¨é¡¶éƒ¨ï¼Œä¸€åŠåœ¨åº•éƒ¨ï¼‰, $p_w$ ä»£è¡¨å¯¹widthçš„å¡«å……ï¼ˆå¤§çº¦ä¸€åŠåœ¨å·¦ä¾§ï¼Œä¸€åŠåœ¨å³ä¾§ï¼‰\n\t- æ³¨æ„è¿™é‡Œçš„å¡«å……å’ŒPytorché‡Œé¢çš„paddingæœ‰ä¸€ç‚¹ä¸åŒ: Pytorché‡Œé¢çš„ `Padding=(4, 2)` æ˜¯æŒ‡heightä¸­, ä¸Šé¢å¡«å……4æ’, ä¸‹é¢ä¹Ÿå¡«å……å››æ’, widthåŒç†.\n\t\n\t- å¡«å……åå›¾åƒå¤§å°å¢åŠ ç›¸åº”çš„å€¼:\n\t$$x_h\\times x_w \\quad\\stackrel{conv}{\\longrightarrow}\\quad \\left (x_{h}-k_{h}+1+p_{h}\\right) \\times\\left (x_{w}-k_{w}+1+p_{w}\\right)$$\n\n## å¡«å……å¤§å°çš„é€‰å–\n- åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½® $p_h=k_hâˆ’1$ å’Œ $p_w=k_wâˆ’1$ï¼Œä½¿è¾“å…¥å’Œè¾“å‡ºå…·æœ‰ç›¸åŒçš„é«˜åº¦å’Œå®½åº¦ ($x_{h}-k_{h}+1+k_hâˆ’1=x_h$)ã€‚\n\n- å‡è®¾ $k_h$ æ˜¯å¥‡æ•°ï¼Œæˆ‘ä»¬å°†åœ¨é«˜åº¦çš„ä¸¤ä¾§å¡«å…… $p_h/2$ è¡Œã€‚ ä½†æ˜¯å¦‚æœ $k_h$ æ˜¯å¶æ•°ï¼Œåˆ™ä¸€ç§å¯èƒ½æ€§æ˜¯åœ¨è¾“å…¥é¡¶éƒ¨å¡«å…… $âŒˆp_h/2âŒ‰$ è¡Œï¼Œåœ¨åº•éƒ¨å¡«å…… $âŒŠp_h/2âŒ‹$ è¡Œ,å®½åº¦åŒç†ã€‚\n\t- æ‰€ä»¥å·ç§¯ç¥ç»ç½‘ç»œä¸­å·ç§¯æ ¸çš„é«˜åº¦å’Œå®½åº¦é€šå¸¸ä¸ºå¥‡æ•°ï¼Œä¾‹å¦‚1ã€3ã€5æˆ–7ã€‚è¿™æ ·ä¿æŒç©ºé—´ç»´åº¦çš„åŒæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨é¡¶éƒ¨å’Œåº•éƒ¨å¡«å……**ç›¸åŒæ•°é‡**çš„è¡Œï¼Œåœ¨å·¦ä¾§å’Œå³ä¾§å¡«å……ç›¸åŒæ•°é‡çš„åˆ—ã€‚\n\n\n## [æœ€å…¨é¢çš„å¤§å°è®¡ç®—å…¬å¼](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)\n![](notes/2022/2022.2/assets/img_2022-10-15-15.png)\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-35-%E5%8D%B7%E7%A7%AF%E5%B1%82-%E6%AD%A5%E5%B9%85-Stride":{"title":"D2L-35-å·ç§¯å±‚ - æ­¥å¹… - Stride","content":"# Stride - æ­¥å¹…\n\n\u003cdiv align=\"right\"\u003e 2022-02-27\u003c/div\u003e\n\nTags: #DeepLearning #CNN #Stride\n\n- It's always nice to have an interactive example: \n\t- [Convolution Visualizer](https://ezyang.github.io/convolution-visualizer/index.html)\n\t- [CNN Explainer](https://poloclub.github.io/cnn-explainer/)\n\n- å·ç§¯æ“ä½œä¼šä½¿å›¾åƒå°ºå¯¸å˜å°, å¢å¤§æ­¥å¹… (Stride) å¯ä»¥**åŠ å¿«**è¿™ä¸ªè¿‡ç¨‹.\n\n![](notes/2022/2022.2/assets/img_2022-10-15-4.gif)\n- ä¸ºäº†é«˜æ•ˆè®¡ç®—æˆ–æ˜¯ç¼©å‡é‡‡æ ·æ¬¡æ•°ï¼Œå·ç§¯çª—å£å¯ä»¥è·³è¿‡ä¸­é—´ä½ç½®ï¼Œæ¯æ¬¡æ»‘åŠ¨å¤šä¸ªå…ƒç´ ã€‚è€Œæ¯æ¬¡æ»‘åŠ¨å…ƒç´ çš„æ•°é‡å°±ç§°ä¸º_æ­¥å¹…_ï¼ˆ*stride*ï¼‰\n\n## å°ºå¯¸å˜åŒ–: å®šé‡è®¡ç®—\n- é€šå¸¸, å½“å‚ç›´æ­¥å¹…ä¸º $s_{h}$  (height) ã€æ°´å¹³æ­¥å¹…ä¸º $s_{w}$ æ—¶ (width) , è¾“å‡ºå½¢çŠ¶ä¸º\n$$\n\\left\\lfloor\\frac{x_{h}-k_{h}+p_{h}+s_{h}}{s_{h}}\\right\\rfloor \\times\\left\\lfloor\\frac{x_{w}-k_{w}+p_{w}+s_{w}}{s_{w}}\\right\\rfloor\n$$\n\n- å¦‚æœæˆ‘ä»¬è®¾ç½®äº† $p_{h}=k_{h}-1$ å’Œ $p_{w}=k_{w}-1$, åˆ™è¾“å‡ºå½¢çŠ¶å°†ç®€åŒ–ä¸º $$\\left\\lfloor\\frac{x_{h}+s_{h}-1}{s_{h}}\\right\\rfloor \\times\\left\\lfloor\\frac{x_{w}+s_{w}-1}{s_{w}}\\right\\rfloor$$ \n\n- æ›´è¿›ä¸€æ­¥, å¦‚æœè¾“å…¥çš„é«˜åº¦å’Œå®½åº¦å¯ä»¥è¢«å‚ç›´å’Œæ°´å¹³æ­¥å¹…æ•´é™¤, åˆ™è¾“å‡ºå½¢çŠ¶å°†ä¸º $$\\left(\\frac{x_{h}}{s_{h}}\\right) \\times\\left(\\frac{x_{w}} {s_{w}}\\right)$$ ","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-36-1x1%E5%8D%B7%E7%A7%AF%E5%B1%82":{"title":"D2L-36-1x1å·ç§¯å±‚","content":"# $1Ã—1$ å·ç§¯å±‚\n\n\u003cdiv align=\"right\"\u003e 2022-02-27\u003c/div\u003e\n\nTags: #CNN #DeepLearning #Convolution \n\n- $1Ã—1$ å·ç§¯ï¼Œå³ $k_h=k_w=1$ï¼Œå®ƒè™½ç„¶ä¸èƒ½æå–ç›¸å…³ç‰¹å¾, ä½†æ˜¯å´èƒ½**èåˆå›¾åƒçš„ä¸åŒé€šé“**, ä¹Ÿæ˜¯ä¸€ç§å¾ˆå—æ¬¢è¿çš„ç½‘ç»œç»“æ„.\n\n- å®ƒç›¸å½“äºè¾“å…¥å½¢çŠ¶ä¸º $n_{h} n_{w} \\times c_{i}$ , æƒé‡ä¸º $c_{o} \\times c_{i}$ çš„**å…¨è¿æ¥å±‚** \n\n\t![](notes/2022/2022.2/assets/conv-1x1.svg)\n\n- åœ¨ä¸Šé¢è¿™å¼ å›¾é‡Œé¢, æ ¸å‡½æ•°çš„é¢œè‰²ä»£è¡¨è¾“å‡ºçš„é€šé“, å¯ä»¥çœ‹åˆ°è¿™ä¸ªå·ç§¯å°†3ä¸ªé€šé“çš„è¾“å…¥å˜æˆäº†ä¸¤ä¸ªé€šé“çš„è¾“å‡º, å›¾åƒçš„å¤§å°ä¸å˜.\n\n-  $1Ã—1$ å·ç§¯å±‚ç›¸å½“äºå¯¹äºå•ä¸ªåƒç´ åšMLP\n\t![NiN_PixelMLP](notes/2022/2022.3/assets/NiN_PixelMLP.svg)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-37-CNN%E7%9A%84%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6":{"title":"D2L-37-CNNçš„è®¡ç®—å¤æ‚åº¦","content":"# CNNçš„è®¡ç®—å¤æ‚åº¦\n\n\u003cdiv align=\"right\"\u003e 2022-02-27\u003c/div\u003e\n\nTags: #DeepLearning #CNN #ComputationalComplexity \n\n- å‰é¢æˆ‘ä»¬æåˆ°è¿‡åˆ©ç”¨å‚…é‡Œå¶å˜æ¢å¯ä»¥å¿«é€Ÿåœ°è®¡ç®—å·ç§¯: [æ•°å€¼è®¡ç®— å·ç§¯ä¸å‚…é‡Œå¶å˜æ¢](notes/2022/2022.2/D2L-32-Convolution-å·ç§¯.md#æ•°å€¼è®¡ç®—%20å·ç§¯ä¸å‚…é‡Œå¶å˜æ¢)\n\n- åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ é‡Œé¢ç»™å‡ºäº†ä¸€ä¸ªä¾‹å­, è¯´æ˜å·ç§¯çš„è®¡ç®—å¤æ‚åº¦å…¶å®è¿˜æ˜¯å¾ˆé«˜çš„, åªæ˜¯å‚æ•°çš„å­˜å‚¨å¼€é”€è¾ƒå°.\n![](notes/2022/2022.2/assets/img_2022-10-15-16.png)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-38-%E6%B1%A0%E5%8C%96%E5%B1%82-Pooling_Layer":{"title":"D2L-38-æ± åŒ–å±‚-Pooling_Layer","content":"# æ± åŒ–å±‚/æ±‡èšå±‚ - Pooling Layer\n\n\u003cdiv align=\"right\"\u003e 2022-02-27\u003c/div\u003e\n\nTags: #PoolingLayer #DeepLearning #CNN \n\n## é¦–å…ˆï¼Œæ± åŒ–å±‚ä¸ºä»€ä¹ˆå«â€œæ± åŒ–å±‚â€\n\u003e  [Collins Dictionary - Pool](https://www.collinsdictionary.com/dictionary/english/pool)   7. verb\n\u003e - If a group of people or organizations *pool* their money, knowledge, or equipment, they share it or put it together so that it can be used for a particular purpose.\n\u003e\t -\tWe *pooled* ideas and information. \n\u003e\t - Philip and I *pooled* our savings to start up my business. \n\u003e\n\u003e - **Synonyms:** combine, share, merge, put together \n\n- ä»å­—é¢ä¸Šç†è§£, Poolä½œä¸ºåŠ¨è¯çš„æ—¶å€™æœ‰\"æ±‡é›†è®¸å¤šä¸ªä½“\"çš„å«ä¹‰, è¿™å’Œæ± åŒ–å±‚çš„æ“ä½œæ¯”è¾ƒç›¸ä¼¼\n\n![](notes/2022/2022.2/assets/img_2022-10-15-5.gif)\n[^1]\n\n## Poolingçš„ä½œç”¨\n- CNNå¯¹äºç‰©ä½“çš„ä½ç½®å®é™…ä¸Šæ˜¯å¾ˆæ•æ„Ÿçš„, ç›®æ ‡ç‰©ä½“ä¸€ç‚¹ç‚¹çš„å˜åŒ–å°±ä¼šå¯¼è‡´å·ç§¯å±‚çš„è¾“å‡ºå‘ç”Ÿå¯¹åº”çš„å˜åŒ–. \n- è€ŒCNNæœ€ç»ˆè§£å†³çš„é—®é¢˜å…¶å®æ˜¯å’Œæ•´ä¸ªå›¾åƒç›¸å…³çš„ (ä¾‹å¦‚: å›¾åƒé‡Œé¢æœ‰æ²¡æœ‰å°ä¼é¹…?) è¿™å°±è¦æ±‚ç½‘ç»œçš„æœ€åä¸€å±‚çš„æ„Ÿå—é‡è¦è¦†ç›–æ•´ä¸ªè¾“å…¥å›¾åƒ. æ•´ä¸ªè¿‡ç¨‹ç›¸å½“äºæ˜¯åœ¨é€æ¸èšåˆä¿¡æ¯ (aggregating information), ç”Ÿæˆè¶Šæ¥è¶Šç²—ç³™çš„æ˜ å°„ (coarser and coarser maps) , æ—¢åœ¨ç½‘ç»œçš„ä¸­æ®µå……åˆ†åˆ©ç”¨å·ç§¯å±‚çš„ä¼˜åŠ¿ (å¹³ç§»ä¸å˜æ€§, å±€éƒ¨æ€§ç­‰), åˆèƒ½è¾“å‡ºæˆ‘ä»¬æƒ³è¦çš„å…¨å±€ä¿¡æ¯. \n\n- Poolingå±‚çš„ä½œç”¨å°±æ˜¯\"è®©æ˜ å°„å…·æœ‰ç²—ç³™æ€§\", æˆ–è€…è¯´, è®©Short-sightedçš„å·ç§¯å±‚æœ‰\"å…¨å±€è§‚\", å¯¹ç›®æ ‡çš„ä½ç½®ä¸é‚£ä¹ˆæ•æ„Ÿ.\n- æ­¤å¤–, æ± åŒ–å±‚è¿˜æœ‰**ä¸‹é‡‡æ ·**çš„ä½œç”¨ (è®©å›¾åƒå˜å°), è¿™å¯ä»¥åŠ å¿«è¿ç®—.\n\t- _Pooling layers_ serve the dual purposes of mitigating the sensitivity of convolutional layers to location and of spatially downsampling representations.[^2]\n\n- å› ä¸ºæ± åŒ–å±‚çš„ä½œç”¨å’Œå·ç§¯ç´§å¯†ç›¸å…³, æ‰€ä»¥æ± åŒ–å±‚ä¸€èˆ¬æ˜¯è·Ÿåœ¨å·ç§¯ä¹‹åçš„.\n\n- å´æ©è¾¾è¯´æ± åŒ–å±‚çš„ä½œç”¨æ˜¯å®è·µå‡ºæ¥çš„, åº”è¯¥æ²¡æœ‰äººèƒ½è¯´æ¸…æ¥šå…¶ä¸­çš„é—¨é“.\n\t[âœ‚ï¸ Andrew Ng Explain Max Pooling - YouTube](https://youtube.com/clip/UgkxKiNbvqiUlN91gNNwPUcFR-0oCOwmR2uk)\n\t\n### ä¸¾å‡ ä¸ªä¾‹å­åŠ æ·±ç†è§£\n![](notes/2022/2022.2/assets/img_2022-10-15-17.png)\n- å¦‚æœä¸Šå›¾ä¸­çš„è¾“å‡ºå€¼ä»£è¡¨æ£€æµ‹åˆ°ç›®æ ‡çš„å¯èƒ½æ€§, é‚£ä¹ˆæ± åŒ–å±‚ç»¼åˆè€ƒè™‘äº†å››ä¸ªå·ç§¯æ“ä½œçš„ç»“æœ, ç”¨\"åˆ†æ²»\"çš„æ€æƒ³æ¥åˆ¤æ–­å“ªä¸ªåŒºåŸŸå­˜åœ¨ç›®æ ‡.\n- ä¸‹å›¾ä¹Ÿæ˜¯è¿™ä¸ªæ„æ€, æ— è®ºä¸‰ä¸ªfilteré‡Œé¢çš„å“ªä¸€ä¸ªè¯†åˆ«åˆ°äº†æ•°å­—äº”, max pooléƒ½ä¼šè¾“å‡ºæ­£ç¡®çš„ç»“æœ.  è¿™ä¹Ÿå’ŒPoolçš„å­—é¢æ„æ€ä¸è°‹è€Œåˆ: ç»¼åˆè®¸å¤šäººçš„ç»“æœ/èµ„æº.\n![](notes/2022/2022.2/assets/img_2022-10-15-18.png)\n- ä¸‹å›¾æ¼”ç¤ºäº†æ± åŒ–å±‚å¯ä»¥å¢å¼ºå·ç§¯å¯¹å¾®å°å¹³ç§»çš„é²æ£’æ€§. å› ä¸ºæˆ‘ä»¬å¾€å¾€æ›´å…³æ³¨å›¾ä¸­æ˜¯å¦å­˜åœ¨ç›®æ ‡, è€Œä¸æ˜¯ç›®æ ‡å‡ºç°åœ¨äº†å“ªä¸ªç²¾ç¡®çš„ä½ç½®.\n![](notes/2022/2022.2/assets/img_2022-10-15-19.png)\n- ä»ä¸Šå›¾å¯ä»¥çœ‹å‡º, å°½ç®¡æ‰€æœ‰çš„è¾“å…¥éƒ½å‘ç”Ÿäº†å˜åŒ–, ä½†åªæœ‰ä¸€åŠçš„Poolè¾“å‡ºå‘ç”Ÿäº†å˜åŒ–. è¿™æ˜¯å› ä¸ºMax Poolåªå…³å¿ƒå®ƒèƒ½çœ‹åˆ°çš„æœ€å¤§å€¼, è€Œä¸æ˜¯æœ€å¤§å€¼å‡ºç°çš„ä½ç½®.\n\n## ä¸¤ç§æ± åŒ–\n- å’Œå·ç§¯å±‚ç±»ä¼¼, æ± åŒ–å±‚ä¹Ÿæ˜¯é€šè¿‡ä¸€ä¸ªæ»‘åŠ¨çš„çª—å£æ¥è¿›è¡Œæ± åŒ–è¿ç®—çš„, è‡ªç„¶ä¹Ÿå¯ä»¥é€šè¿‡è¿›è¡Œ[å¡«å……](notes/2022/2022.2/D2L-34-å·ç§¯å±‚%20-%20å¡«å……%20-%20Padding.md) å’Œè®¾ç½®[æ­¥å¹…](notes/2022/2022.2/D2L-35-å·ç§¯å±‚%20-%20æ­¥å¹…%20-%20Stride.md) æ¥è°ƒæ•´è¾“å‡ºçš„å°ºå¯¸. \n- å’Œå·ç§¯ä¸åŒçš„æ˜¯, æ± åŒ–å±‚æ²¡æœ‰Kernel, æ± åŒ–å±‚åªèƒ½è¿›è¡Œå›ºå®šçš„ä¸¤ç§è¿ç®—: Max æˆ– Avg. è¿™ä¹Ÿæ„å‘³ç€æ± åŒ–å±‚æ˜¯æ²¡æœ‰å‚æ•°å¯ä»¥è¿›è¡Œå­¦ä¹ çš„.\n\n\t- æ± åŒ–å±‚è¿˜èƒ½è¿›è¡Œp-normè¿ç®—, å…·ä½“ä½œç”¨æˆ‘æ²¡æœ‰æ·±å…¥äº†è§£\n\n![400](notes/2022/2022.2/assets/img_2022-10-15-20.png)\n\n![400](notes/2022/2022.2/assets/img_2022-10-15-21.png)\n## å¤šé€šé“çš„æƒ…å†µ: é€ä¸ªPooling\n- æ± åŒ–å±‚å’Œå·ç§¯å±‚çš„å¦ä¸€ä¸ªä¸åŒåœ¨äº: **æ± åŒ–å±‚ä¸æ”¹å˜è¾“å…¥çš„é€šé“æ•°, å¯¹æ¯ä¸€ä¸ªé€šé“å•ç‹¬è¿›è¡Œæ± åŒ–æ“ä½œ**. \n\t- ç›¸å, å·ç§¯å°†è¾“å…¥çš„å¤šä¸ªé€šé“æ ¹æ®å·ç§¯æ ¸è½¬æ¢ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªè¾“å‡ºé€šé“.\n\n![Pooling-NoChangeInChannels](notes/2022/2022.2/assets/Pooling-NoChangeInChannels.svg)\n\n\n\n\n[^1]: [Comprehensive Guide to Different Pooling Layers in Deep Learning](https://analyticsindiamag.com/comprehensive-guide-to-different-pooling-layers-in-deep-learning/)\n[^2]: [6.5. Pooling â€” Dive into Deep Learning 0.17.2 documentation](https://d2l.ai/chapter_convolutional-neural-networks/pooling.html#pooling)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-39-LeNet":{"title":"D2L-39-LeNet","content":"# LeNet\n\n\u003cdiv align=\"right\"\u003e 2022-03-01\u003c/div\u003e\n\nTags: #LeNet #DeepLearning #CNN #NeuralNetwork \n\n## æ¶æ„\n![](notes/2022/2022.2/assets/lenet.svg)[^1]\n- æ€»ä½“æ¥çœ‹ï¼ŒLeNetï¼ˆLeNet-5ï¼‰ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼š\n\t-   **å·ç§¯ç¼–ç å™¨**ï¼šç”±ä¸¤ä¸ªå·ç§¯å±‚ç»„æˆ;\n\t-   **å…¨è¿æ¥å±‚å¯†é›†å—**ï¼šç”±ä¸‰ä¸ªå…¨è¿æ¥å±‚ç»„æˆã€‚\n\n- æ¯ä¸ªå·ç§¯å—ä¸­çš„åŸºæœ¬å•å…ƒæ˜¯**ä¸€ä¸ªå·ç§¯å±‚**(å«**ä¸€ä¸ªsigmoidæ¿€æ´»å‡½æ•°**) å’Œä¸€ä¸ª**Avg Pooling å±‚**ã€‚\n\t- è¯·æ³¨æ„ï¼Œè™½ç„¶ReLUå’Œæœ€å¤§æ±‡èšå±‚(Max Pooling)æ›´æœ‰æ•ˆï¼Œä½†å®ƒä»¬åœ¨20ä¸–çºª90å¹´ä»£è¿˜æ²¡æœ‰å‡ºç°ã€‚\n\n- æ¯ä¸ªå·ç§¯å±‚ä½¿ç”¨ $5Ã—5$ å·ç§¯æ ¸[^1]å’Œä¸€ä¸ªsigmoidæ¿€æ´»å‡½æ•°ã€‚è¿™äº›å±‚å°†è¾“å…¥æ˜ å°„åˆ°å¤šä¸ªäºŒç»´ç‰¹å¾è¾“å‡ºï¼Œé€šå¸¸åŒæ—¶å¢åŠ é€šé“çš„æ•°é‡ã€‚\n\t- ç¬¬ä¸€å·ç§¯å±‚æœ‰6ä¸ªè¾“å‡ºé€šé“ï¼Œè€Œç¬¬äºŒä¸ªå·ç§¯å±‚æœ‰16ä¸ªè¾“å‡ºé€šé“ã€‚æ¯ä¸ª $2Ã—2$ æ± æ“ä½œï¼ˆæ­¥éª¤2, Stride=2ï¼‰é€šè¿‡ç©ºé—´ä¸‹é‡‡æ ·å°†ç»´æ•°å‡å°‘4å€ (æŒ‡é¢ç§¯, ç›¸å½“äºè¾¹é•¿å‡åŠ)ã€‚\n\n- ä¸ºäº†å°†å·ç§¯å—çš„è¾“å‡ºä¼ é€’ç»™ç¨ å¯†å—ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨ç¬¬äºŒä¸ªPoolingåä¸­å±•å¹³æ¯ä¸ªæ ·æœ¬ã€‚(16x5x5=400), LeNetçš„ç¨ å¯†å—æœ‰ä¸‰ä¸ªå…¨è¿æ¥å±‚ï¼Œåˆ†åˆ«æœ‰120ã€84å’Œ10ä¸ªè¾“å‡ºã€‚(æ‰€ä»¥æ˜¯ $400\\rightarrow 120\\rightarrow 84\\rightarrow 10$ å› ä¸ºæˆ‘ä»¬åœ¨æ‰§è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œæ‰€ä»¥è¾“å‡ºå±‚çš„10ç»´å¯¹åº”äºæœ€åè¾“å‡ºç»“æœçš„æ•°é‡ã€‚\n\n- ç›¸æ¯”åŸå§‹æ¨¡å‹ï¼Œæˆ‘ä»¬å»æ‰äº†æœ€åä¸€å±‚çš„é«˜æ–¯æ¿€æ´»ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿™ä¸ªç½‘ç»œä¸æœ€åˆçš„LeNet-5ä¸€è‡´ã€‚\n![](notes/2022/2022.2/assets/lenet-vert.svg)\n\n## Origin\n- LeNetæ˜¯**æœ€æ—©å‘å¸ƒçš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€**ï¼Œå› å…¶åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§èƒ½è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ è¿™ä¸ªæ¨¡å‹æ˜¯ç”±AT\u0026Tè´å°”å®éªŒå®¤çš„ç ”ç©¶å‘˜**Yann LeCunåœ¨1989å¹´æå‡º**çš„ï¼ˆå¹¶**ä»¥å…¶å‘½å**ï¼‰ï¼Œç›®çš„æ˜¯è¯†åˆ«å›¾åƒä¸­çš„**æ‰‹å†™æ•°å­—(MNIST)**ã€‚ \n- ä¸€ç¹å¤§ä½¬çœŸå®¹:\n\tYann LeCun(æ¨ç«‹æ˜†) \n\t![150](notes/2022/2022.2/assets/Pasted%20image%2020220301203532.png)\n- Paper: PDF(zotero://select/items/@lecun1998gradient) Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, â€œGradient-based learning applied to document recognition,â€ _Proceedings of the IEEE_, vol. 86, no. 11, pp. 2278â€“2324, 1998, doi: [10.1109/5.726791](https://doi.org/10.1109/5.726791) .\n\n\n[^1]: å›¾é‡Œé¢çš„åƒç´ å¤§å°æœ‰ç‚¹ä¸å¯¹, å·ç§¯æ ¸æ˜¯5x5çš„","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-40-AlexNet":{"title":"D2L-40-AlexNet","content":"# AlexNet\n\n\u003cdiv align=\"right\"\u003e 2022-03-02\u003c/div\u003e\n\nTags: #DeepLearning #AlexNet #CNN #ImageNet \n\n![](notes/2022/2022.2/assets/alexnet.svg)\n\n## æ¨¡å‹è§£æ\n\n### å¯¹æ¯”LeNet\n- æœ€é‡è¦çš„æ˜¯, AlexNetå¯¼è‡´äº†**è®¡ç®—æœºè§†è§‰æ–¹æ³•è®ºçš„æ”¹å˜**: ä»æ ¸æ–¹æ³•åˆ°æ·±åº¦ç¥ç»ç½‘ç»œ, å¼€å¯äº†ç¥ç»ç½‘ç»œçš„ç¬¬äºŒæ¬¡çƒ­æ½®\n\t- ![](notes/2022/2022.2/assets/Pasted%20image%2020220302193907.png)[^5]\n- å¯¹æ¯”LeNet, AlexNetçš„ä¸»è¦ç‰¹ç‚¹æœ‰: \n\t- è¾“å…¥å›¾ç‰‡æ›´ **\"å¤§\"**, ç½‘ç»œç»“æ„æ›´ **\"æ·±\"**, æ¯å±‚é€šé“æ›´ **\"å¤š\"**, æ»‘åŠ¨çª—å£æ›´ **\"å¤§\"**(æ ¸å‡½æ•°å’Œæ± åŒ–å±‚) \n\t- ä½¿ç”¨äº†**ReLU**ä½œä¸ºæ¿€æ´»å‡½æ•°\n\t- æ± åŒ–å±‚é‡‡ç”¨äº†**Max Pooling**\n\t- ä½¿ç”¨äº†**ä¸¢å¼ƒæ³•(Dropout)** ä½œä¸ºæ­£åˆ™åŒ–æ–¹æ³•[^4], è€Œ LeNetåªé‡‡ç”¨äº† [æƒé‡è¡°å‡](notes/2022/2022.2/D2L-22-æƒé‡è¡°å‡.md)\n\t- AlexNetåœ¨è®­ç»ƒå‰è¿›è¡Œäº†**æ•°æ®å¢å¼º**\n\n\n![](notes/2022/2022.2/assets/AlexNet.png) [^3]\n### ç½‘ç»œç»“æ„çš„æ”¹è¿›\n- ImageNetæ•°æ®é›†çš„å°ºå¯¸æ›´å¤§äº†, ç¡¬ä»¶æ¡ä»¶ä¹Ÿæ›´å¥½äº†, è¿™ä¹Ÿæ¨åŠ¨AlexNetçš„è¾“å…¥å¢å¤§åˆ°äº† $224\\times224$.[^6] (ç›¸æ¯”ä¹‹ä¸‹ [LeNet](notes/2022/2022.2/D2L-39-LeNet.md) çš„MNISTåªæœ‰ $28\\times28$)\n- å›¾åƒå¤§äº†, éœ€è¦æ•è·çš„ç›®æ ‡ä¹Ÿå˜å¤§äº†, å·ç§¯æ ¸($11\\times11$)å’Œæ± åŒ–å±‚çš„çª—å£($3\\times3$)è‡ªç„¶ä¹Ÿå¢å¤§äº†, Strideä¹Ÿç›¸åº”å¢åŠ .\n- å›¾åƒå¤§äº†, æ•°æ®é›†æ›´å¤§äº†, ä¿¡æ¯ä¹Ÿæ›´å¤šäº†, è¿™ä½¿å¾—AlexNetçš„é€šé“æ•°å‡ ä¹æ˜¯LeNetçš„åå€\n- æ–°å¢åŠ çš„ä¸‰ä¸ªå·ç§¯å±‚è®©AlexNetæ¯”LeNetæ›´æ·±\n- åœ¨æœ€åä¸€ä¸ªå·ç§¯å±‚åæœ‰ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œåˆ†åˆ«æœ‰4096ä¸ªè¾“å‡ºã€‚ è¿™ä¸¤ä¸ªå·¨å¤§çš„å…¨è¿æ¥å±‚æ‹¥æœ‰å°†è¿‘1GBçš„æ¨¡å‹å‚æ•°ã€‚\n![](notes/2022/2022.2/assets/AlexNet2.png) [^3]\n### æ¿€æ´»å‡½æ•°\n- æ­¤å¤–ï¼ŒAlexNetå°†Sigmoidæ¿€æ´»å‡½æ•°æ”¹ä¸ºæ›´ç®€å•çš„ReLUæ¿€æ´»å‡½æ•°ã€‚ \n\t- ä¸€æ–¹é¢ï¼ŒReLUæ¿€æ´»å‡½æ•°çš„è®¡ç®—æ›´ç®€å•ï¼Œå®ƒä¸éœ€è¦å¦‚sigmoidæ¿€æ´»å‡½æ•°é‚£èˆ¬å¤æ‚çš„æ±‚å¹‚è¿ç®—ã€‚ \n\t- å¦ä¸€æ–¹é¢ï¼Œå½“ä½¿ç”¨ä¸åŒçš„å‚æ•°åˆå§‹åŒ–æ–¹æ³•æ—¶ï¼ŒReLUæ¿€æ´»å‡½æ•°ä½¿è®­ç»ƒæ¨¡å‹æ›´åŠ å®¹æ˜“ã€‚ \n\t\t- å½“sigmoidæ¿€æ´»å‡½æ•°çš„è¾“å‡ºéå¸¸æ¥è¿‘äº0æˆ–1æ—¶ï¼Œè¿™äº›åŒºåŸŸçš„æ¢¯åº¦å‡ ä¹ä¸º0ï¼Œå› æ­¤åå‘ä¼ æ’­æ— æ³•ç»§ç»­æ›´æ–°ä¸€äº›æ¨¡å‹å‚æ•°ã€‚ ç›¸åï¼ŒReLUæ¿€æ´»å‡½æ•°åœ¨æ­£åŒºé—´çš„æ¢¯åº¦æ€»æ˜¯1ã€‚ å› æ­¤ï¼Œå¦‚æœæ¨¡å‹å‚æ•°æ²¡æœ‰æ­£ç¡®åˆå§‹åŒ–ï¼Œsigmoidå‡½æ•°å¯èƒ½åœ¨æ­£åŒºé—´å†…å¾—åˆ°å‡ ä¹ä¸º0çš„æ¢¯åº¦ï¼Œä»è€Œä½¿æ¨¡å‹æ— æ³•å¾—åˆ°æœ‰æ•ˆçš„è®­ç»ƒã€‚[^7]\n\n![](notes/2022/2022.2/assets/Pasted%20image%2020220302145051.png) [^1]\n\n### å®¹é‡æ§åˆ¶å’Œé¢„å¤„ç†\n- AlexNeté€šè¿‡Dropoutæ§åˆ¶å…¨è¿æ¥å±‚çš„æ¨¡å‹å¤æ‚åº¦ï¼Œè€ŒLeNetåªä½¿ç”¨äº†æƒé‡è¡°å‡ã€‚ \n```py\nnet = nn.Sequential(\n...\n    # è¿™é‡Œï¼Œå…¨è¿æ¥å±‚çš„è¾“å‡ºæ•°é‡æ˜¯LeNetä¸­çš„å¥½å‡ å€ã€‚ä½¿ç”¨dropoutå±‚æ¥å‡è½»è¿‡æ‹Ÿåˆ\n    nn.Linear(6400, 4096), nn.ReLU(),\n    nn.Dropout(p=0.5),\n    nn.Linear(4096, 4096), nn.ReLU(),\n    nn.Dropout(p=0.5),\n...\n)\n```\n- åŒæ—¶ä¸ºäº†è¿›ä¸€æ­¥æ‰©å……æ•°æ®ï¼ŒAlexNetåœ¨è®­ç»ƒæ—¶å¢åŠ äº†å¤§é‡çš„å›¾åƒå¢å¼ºæ•°æ®ï¼Œå¦‚ç¿»è½¬ã€è£åˆ‡å’Œå˜è‰²ã€‚ è¿™ä½¿å¾—æ¨¡å‹æ›´å¥å£®ï¼Œæ›´å¤§çš„æ ·æœ¬é‡æœ‰æ•ˆåœ°å‡å°‘äº†è¿‡æ‹Ÿåˆã€‚\n![](notes/2022/2022.2/assets/Pasted%20image%2020220302200454.png)\n\n## Side Notes\n- å—é™äºå½“æ—¶çš„ç¡¬ä»¶æ¡ä»¶, AlexNetçš„åŸå§‹æ¨¡å‹ä½¿ç”¨äº†ä¸¤ä¸ªGPUåŒæ—¶è®¡ç®—, åœ¨ç½‘ç»œæ¶æ„å›¾é‡Œè¡¨ç¤ºä¸ºåŒæ•°æ®æµè®¾è®¡: \n\t![](notes/2022/2022.2/assets/Pasted%20image%2020220302143910.png)[^2]\n\t- æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†ä¸¤æ¡è·¯åˆå¹¶, ç²¾ç®€ä¸ºåªä½¿ç”¨ä¸€ä¸ªGPUçš„æ¨¡å‹.\n\n## ä¸è¶³\n- è™½ç„¶AlexNetè¯æ˜æ·±å±‚ç¥ç»ç½‘ç»œå“æœ‰æˆæ•ˆï¼Œä½†å®ƒæ²¡æœ‰æä¾›ä¸€ä¸ªé€šç”¨çš„æ¨¡æ¿æ¥æŒ‡å¯¼åç»­çš„ç ”ç©¶äººå‘˜è®¾è®¡æ–°çš„ç½‘ç»œã€‚ \n- åœ¨åé¢çš„ä¸€äº›ç ”ç©¶é‡Œé¢, æˆ‘ä»¬é€æ¸æ€»ç»“å‡ºä¸€äº›å¸¸ç”¨äºè®¾è®¡æ·±å±‚ç¥ç»ç½‘ç»œçš„å¯å‘å¼æ¦‚å¿µã€‚\n\t- æ¨¡å—åŒ–: [VGG](notes/2022/2022.2/D2L-41-VGG.md)\n\t- å»é™¤å…¨è¿æ¥å±‚: [NiN](notes/2022/2022.3/D2L-42-NiN.md)\n\t- å¹¶è¡Œè¿æ¥ä¸ç¨€ç–æ€§: [GoogLeNet(Inception)](notes/2022/2022.3/D2L-43-GoogLeNet(Inception).md)\n\t- æ®‹å·®è¿æ¥: [ResNet](notes/2022/2022.3/D2L-45-ResNet.md)\n\n\n## Origin\n- AlexNet is named after Alex Krizhevsky\n![250](notes/2022/2022.2/assets/Pasted%20image%2020220302135107.png)\n- **Paper**: PDF(zotero://select/items/@krizhevsky2012imagenet) A. Krizhevsky, I. Sutskever, and G. E. Hinton, â€œImagenet classification with deep convolutional neural networks (AlexNet),â€ _Advances in neural information processing systems_, vol. 25, 2012.\n\n[^1]: [GitHub - ishanExtreme/AlexNet-Visualization: Visualizing layer output of AlexNet model trained on cifar-10 dataset](https://github.com/ishanExtreme/AlexNet-Visualization)\n[^2]: [CNN ëª¨ë¸](https://chacha95.github.io/2019-10-05-Efficient-DL1/)\n[^3]: [5 Advanced CNN architectures Â· Deep Learning for Vision Systems](https://livebook.manning.com/book/grokking-deep-learning-for-computer-vision/chapter-5/115) \n[^4]: Dropoutå¹¶ä¸æ˜¯åœ¨è¿™ç¯‡æ–‡ç« é‡Œé¢æå‡ºæ¥çš„, ä½†æ˜¯çš„ç¡®æ˜¯åŒä¸€å¸®äººæå‡ºæ¥çš„\n[^5]: [24 æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ AlexNetã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ v2ã€‘å“”å“©å“”å“©bilibili](https://www.bilibili.com/video/BV1h54y1L7oe?p=1)\n[^6]:AlexNetçš„è¾“å…¥å¤§å°å¥½åƒæœ‰ç‚¹ä¸ç»Ÿä¸€, åœ¨è®ºæ–‡é‡Œé¢æ˜¯ $224\\times224$ , ä½†æ˜¯å¦‚æœPadding=1, Stride=4çš„è¯, ä¸‹ä¸€ä¸ªå·ç§¯å±‚çš„å¤§å°æ˜¯ $54.5$, ä¸æ˜¯ä¸€ä¸ªæ•´æ•°, éœ€è¦å‘ä¸‹å–æ•´å¾—åˆ°54. æ‰€ä»¥æœ‰çš„åœ°æ–¹å°±æŠŠè¾“å…¥æ”¹æˆäº†227, è¿™æ ·ç®—å‡ºæ¥å°±åˆšå¥½æ˜¯54.\n[^7]: [7.1. æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_convolutional-modern/alexnet.html#id13)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/D2L-41-VGG":{"title":"D2L-41-VGG","content":"# VGG\n\n\u003cdiv align=\"right\"\u003e 2022-03-03\u003c/div\u003e\n\nTags: #DeepLearning #VGG #CNN \n\n![](notes/2022/2022.2/assets/img_2022-10-15-22.png)\n- **æ¨¡å—åŒ–**æ˜¯VGGç½‘ç»œæœ€é‡è¦çš„æ€æƒ³.\n- æ¨¡å—åŒ–è¿›ä¸€æ­¥å¸¦æ¥äº†**è‡ªç”±æ€§**, ä¸åŒçš„å—é…ç½®å¯ä»¥å¸¦æ¥ä¸åŒçš„æ¨¡å‹è¡¨ç°.\n\n![](notes/2022/2022.2/assets/img_2022-10-15-23.png)\n\n## è§„èŒƒåŒ– - æ¨¡å—åŒ–\n- ä¸èŠ¯ç‰‡è®¾è®¡ä¸­å·¥ç¨‹å¸ˆä»æ”¾ç½®æ™¶ä½“ç®¡åˆ°é€»è¾‘å…ƒä»¶å†åˆ°é€»è¾‘å—çš„è¿‡ç¨‹ç±»ä¼¼ï¼Œç¥ç»ç½‘ç»œæ¶æ„çš„è®¾è®¡ä¹Ÿé€æ¸å˜å¾—æ›´åŠ æŠ½è±¡ã€‚ç ”ç©¶äººå‘˜å¼€å§‹ä»å•ä¸ªç¥ç»å…ƒçš„è§’åº¦æ€è€ƒé—®é¢˜ï¼Œå‘å±•åˆ°æ•´ä¸ªå±‚ï¼Œç°åœ¨åˆè½¬å‘å—ï¼Œé‡å¤å±‚çš„æ¨¡å¼ã€‚\n- ä½¿ç”¨å—çš„è®¾è®¡åŒæ ·è®©æ¨¡å‹æ›´åŠ ç®€æ´.\n\n### VGGå—\n![](notes/2022/2022.2/assets/img_2022-10-15-24.png)\n- VGGå°† [AlexNet](notes/2022/2022.2/D2L-40-AlexNet.md) é‡Œé¢ä¸‰å±‚è¿ç»­çš„å·ç§¯æ‹¿å‡ºæ¥, æŠ½è±¡æˆVGGå—, ä½œä¸ºæ„å»ºç½‘ç»œçš„åŸºç¡€æ¨¡å¼.\n\n- VGGå—æ˜¯å¯å˜çš„, è¶…å‚æ•°å˜é‡ `conv_arch` æŒ‡å®šäº†æ¯ä¸ªVGGå—é‡Œ**å·ç§¯å±‚ä¸ªæ•°**å’Œ**è¾“å‡ºé€šé“æ•°**ã€‚\n\t- ![ä¸€ä¸ªVGGå—](notes/2022/2022.2/assets/ä¸€ä¸ªVGGå—.svg)\n\tæ–¹å—æ¨¡å‹è§£é‡Š: \n\t![æ–¹å—æ¨¡å‹è¡¨ç¤º](notes/2022/2022.2/assets/æ–¹å—æ¨¡å‹è¡¨ç¤º.svg)\n\t- ä¸è¦æƒ³å½“ç„¶åœ°æŠŠåŒä¸€ä¸ªå¤§å°çš„å±‚ä½œä¸ºä¸€ä¸ªå—, VGGå—åœ¨å¢å¤§Channelæ•°åœ°åŒæ—¶å‡åŠè¾“å‡ºå°ºå¯¸. ä¸‹å›¾æ˜¯VGG 16çš„ç¤ºæ„å›¾, 16æ˜¯æŒ‡ç½‘ç»œé‡Œé¢æœ‰13ä¸ªå·ç§¯å±‚åŠ 3ä¸ªå…¨è¿æ¥å±‚.\n\t![](notes/2022/2022.2/assets/VGG16.png)\nVGG19: [^2]\n![](notes/2022/2022.2/assets/vgg19.jpg)\n- **VGGå—çš„å‚æ•°**\n\t![](notes/2022/2022.2/assets/img_2022-10-15-24.png)\n\t- ä¸ºäº†ä¿æŒå·ç§¯è¾“å…¥è¾“å‡º**å°ºå¯¸ä¸å˜**, å·ç§¯å±‚é‡‡ç”¨äº† $3\\times3$ çš„æ ¸åŠ ä¸Š $1$ çš„Padding.\n\t- VGGçš„Poolingçª—å£å¤§å°ä¸º $2\\times2$, Stride=2, æ‰€ä»¥è¾“å‡ºå›¾åƒçš„å°ºå¯¸å‡åŠ. (ä¸‹é‡‡æ ·åˆ°1/4çš„åˆ†è¾¨ç‡)\n\n- **ä¸ºä»€ä¹ˆä¸æ·»åŠ å…¨è¿æ¥å±‚æ¥åŠ æ·±ç½‘ç»œå‘¢?**\n\t- ä¸ºäº†ä½¿ç½‘ç»œæ›´æ·±, æˆ‘ä»¬å¯ä»¥æ·»åŠ æ›´å¤šçš„å…¨è¿æ¥å±‚(FC)æˆ–è€…å·ç§¯å±‚(Conv), ä½†æ˜¯å› ä¸ºå…¨è¿æ¥å±‚è¿‡äºæ˜‚è´µ(å‚æ•°æ•°é‡åºå¤§), æˆ‘ä»¬é€šå¸¸é€‰æ‹©æ·»åŠ æ›´å¤šçš„å·ç§¯å±‚.\n\n- **ä¸ºä»€ä¹ˆä¸ç”¨å¤§ä¸€ç‚¹çš„å·ç§¯æ ¸?**\n\t- åœ¨VGGè®ºæ–‡ä¸­ï¼ŒSimonyanå’ŒZisermanå°è¯•äº†å„ç§æ¶æ„ã€‚ç‰¹åˆ«æ˜¯ä»–ä»¬å‘ç°æ·±å±‚ä¸”çª„çš„å·ç§¯ï¼ˆå³ $3Ã—3$ ï¼‰æ¯”è¾ƒæµ…å±‚ä¸”å®½çš„å·ç§¯æ›´æœ‰æ•ˆã€‚[^1]\n\t- ä½†æ˜¯ä¸ºä»€ä¹ˆæ›´å¤§çš„å·ç§¯æ ¸, æ›´æ·±çš„ç½‘ç»œ, æ•ˆæœæ›´å¥½?\n\t\t- ä¸€ä¸ªå¯èƒ½çš„åŸå› æ˜¯: å…·æœ‰ç›¸åŒæ„ŸçŸ¥é‡çš„æ¡ä»¶ä¸‹ï¼Œå°çš„å·ç§¯æ ¸æå‡äº†ç½‘ç»œçš„æ·±åº¦\n\t\t\t- [[notes/2022/2022.2/2ä¸ª3x3å·ç§¯æ ¸å †å åç­‰ä»·äºä¸€ä¸ª5x5å·ç§¯æ ¸]]\n\t\t- é‚£ä¸ºä»€ä¹ˆæ·±çš„ç½‘ç»œæ•ˆæœå¥½? #todo \n\n## è‡ªç”±æ€§ - æ¨¡å‹çš„å¤šæ ·æ€§\n![](notes/2022/2022.2/assets/VGG%20Variations.png)\n## Origin\n- VGGç”±ç‰›æ´¥å¤§å­¦çš„ [è§†è§‰å‡ ä½•ç»„ï¼ˆvisualgeometry groupï¼‰](http://www.robots.ox.ac.uk/~vgg/) æå‡º.\n![](notes/2022/2022.2/assets/Pasted%20image%2020220303152941.png)\n\n\n[^1]: [7.2. ä½¿ç”¨å—çš„ç½‘ç»œï¼ˆVGGï¼‰ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_convolutional-modern/vgg.html#id5)\n[^2]: [Image Classification on CIFAR-10 Dataset Â· Image Classification](https://rishabhjain.xyz/ml-class-project/)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Entropy-%E7%86%B5":{"title":"Entropy-ç†µ","content":"# Entropy - ç†µ\n\n2022-02-11\u003c/div\u003e\n\nTags: #InformationTheory\n\n## ç†è§£\n\n- ç†µæ˜¯Surpriseçš„æœŸæœ›\n[Entropy (for data science) Clearly Explained!!! - YouTube](https://www.youtube.com/watch?v=YtebGVx-Fxw)\n\n- ç†µæ˜¯å¯¹äº‹ä»¶å¤æ‚åº¦çš„è¡¡é‡, å³æˆ‘ä»¬æœ€å°‘éœ€è¦å¤šå°‘ä¿¡æ¯æ‰èƒ½å®Œæ•´åœ°æè¿°è¿™ä¸ªäº‹ä»¶\n[Intuitively Understanding the Shannon Entropy - YouTube](https://www.youtube.com/watch?v=0GCGaw0QOhA)\n\n- æ¢å¥è¯è¯´, ç†µçš„å¤§å°æ˜¯ç¼–ç ä¸€ä¸ªéšæœºäº‹ä»¶æ‰€éœ€è¦çš„**æœ€çŸ­å¹³å‡ç¼–ç é•¿åº¦**\n\n**è”ç³»:**  ä¸€ä¸ªäº‹ä»¶è¶Šå¤æ‚, é‚£ä¹ˆå°±éœ€è¦æ›´å¤šçš„ä¿¡æ¯æ¥æè¿°è¿™ä¸ªäº‹ä»¶, è¿™ä¸ªäº‹ä»¶çš„å¹³å‡\"æƒŠè®¶ç¨‹åº¦\"å°±è¶Šé«˜, è¿™ä¸ªäº‹ä»¶çš„ç†µå°±è¶Šé«˜.\n\n## å…¬å¼\n\n$$\\text { Entropy }=-\\sum p(x) \\log (p(x))$$\nor\n$$\\text { Entropy }=\\sum p(x) \\log \\left(\\frac{1}{p(x)}\\right)$$\n(The Average *Surprise*)\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Inanimate-Whose":{"title":"Inanimate Whose","content":"# Inanimate Whose\n\n\u003cdiv align=\"right\"\u003e 2022-03-04\u003c/div\u003e\n\nTags: #English \n\n- **æˆ‘ä»¬å¯ä»¥ç”¨WhoseæŒ‡ä»£ä¸æ˜¯äººçš„åŠ¨ç‰©, ä¹Ÿå¯ä»¥ç”¨äºéç”Ÿå‘½çš„ç‰©ä½“(Inanimate Whose[^1]å°±æ˜¯è¿™ç§æƒ…å†µ).**\n\t- ä¾‹å¥: \n\t\tThat's the car _whose_ alarm keeps waking us up at night.\n\n- **å¦‚æœä¸æƒ³ç”¨Whose, ä¹Ÿæœ‰ä»¥ä¸‹æ–¹æ³•æ¥ç­‰ä»·ä»£æ¢:** \n\t- ä½¿ç”¨ *of which*\n\t\t\u003e - He was watching the movie *whose* title I couldnâ€™t remember earlier.\n\t\t\u003e - He was watching the movie, the title *of which* I couldnâ€™t remember earlier.  \n\t\t\u003e - The car *whose* windshield is cracked is his.  \n\t\t\u003e - The car, the windshield *of which* is cracked, is his.\n\t\t- ç„¶è€Œè¿™æ ·çš„å¥å­è¯»èµ·æ¥clumsy or stilted.\n\t\n\t- ä¹Ÿå¯ä»¥é¿å…ä½¿ç”¨æ‰€æœ‰æ ¼, æ¯”å¦‚ä½¿ç”¨*with*\n\t\t\u003e - He was watching the movie with the title that I couldn't remember earlier. \n\t\t\u003e - The car with the cracked windshield is his.\n\n- ç„¶è€Œåœ¨**ç–‘é—®å¥é‡Œé¢**, ä½¿ç”¨WhoseæŒ‡ä»£éç”Ÿå‘½çš„ç‰©ä½“ä¼šå¸¦æ¥æ­§ä¹‰: \n\t- \"*Whose* lid is this?\"\n\t- \"*Which* container does this lid *belong to*?\"\n\n- Ref: è¿™ç¯‡æ–‡ç« å†™çš„å¾ˆå¥½: [Using 'Whose' for Objects and Things | Merriam-Webster](https://www.merriam-webster.com/words-at-play/whose-used-for-inanimate-objects)\n\n\n[^1]: [Inanimate whose - Wikipedia](https://en.wikipedia.org/wiki/Inanimate_whose) ","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/KL_Divergence-KL%E6%95%A3%E5%BA%A6":{"title":"KL_Divergence-KLæ•£åº¦","content":"# Kullbackâ€“Leibler divergence\n\n\u003cdiv align=\"right\"\u003e 2022-02-11\u003c/div\u003e\n\nTags: #Math/Probability #DeepLearning \n\n![](notes/2022/2022.2/assets/img_2022-10-15-25.png)[^3]\n- KLæ•£åº¦å¯ä»¥è¡¡é‡**ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„ç›¸ä¼¼æ€§**\n\n- KLæ•£åº¦ä¹Ÿç§°ä¸ºç›¸å¯¹ç†µ\n\n\u003e - Wikipedia: In mathematical statistics, the **Kullbackâ€“Leibler divergence**, $D _{KL} ( P âˆ¥ Q )$ (also called **relative entropy**), is a statistical distance: a measure of how one probability distribution Q is different from a second, reference probability distribution P.\n\n- è¦ç†è§£ç›¸å¯¹ç†µæ˜¯æ€æ ·è¡¡é‡æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚çš„, è¯·çœ‹ä¸‹é¢è¿™ä¸ªè§†é¢‘:\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/SxGYPqCgJWM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n[^1]\n\n- åœ¨æœºå™¨å­¦ä¹ é‡Œé¢,  $D _{KL} ( P âˆ¥ Q )$ ä¹Ÿè¢«ç§°ä¸ºä»Qåˆ‡æ¢åˆ°Pçš„**ä¿¡æ¯å¢ç›Š**.\n- äº¤å‰ç†µè¶Šå°, è¯´æ˜ä¸¤ä¸ªæ¦‚å¿µè¶Šç›¸ä¼¼, ä¹Ÿå°±æ˜¯PQä¹‹é—´åˆ‡æ¢çš„ä¿¡æ¯å¢ç›Šè¶Šå°.\n\n## å…¬å¼\n- å¯¹äºç›¸åŒæ¦‚ç‡ç©ºé—´ $\\mathcal{X}$ é‡Œé¢çš„ç¦»æ•£æ¦‚ç‡åˆ†å¸ƒ $P$ å’Œ $Q$,  $P$ç›¸å¯¹äº$Q$çš„**ç›¸å¯¹ç†µ**å®šä¹‰å¦‚ä¸‹:\n$$\nD_{\\mathrm{KL}}(P \\| Q)=\\sum_{x \\in \\mathcal{X}} P(x) \\log \\left(\\frac{P(x)}{Q(x)}\\right) .\n$$\nä¹Ÿå¯ä»¥æä¸€ä¸ªè´Ÿå·å‡ºæ¥: \n$$\nD_{\\mathrm{KL}}(P \\| Q)=-\\sum_{x \\in \\mathcal{X}} P(x) \\log \\left(\\frac{Q(x)}{P(x)}\\right)\n$$\n\n## æ€§è´¨[^2]\n- ç›¸å¯¹ç†µçš„å€¼ä¸ºéè´Ÿæ•°ï¼š\n\t$$D_{\\mathrm{KL}}(P \\| Q) \\geq 0,$$\n\t- ç”±å‰å¸ƒæ–¯ä¸ç­‰å¼å¯çŸ¥ï¼Œå½“ä¸”ä»…å½“ $P=Q$ æ—¶ $D_{K L}(P \\| Q)$ ä¸ºé›¶ã€‚è¿™æ—¶ä¸¤ä¸ªåˆ†å¸ƒå…·æœ‰ç›¸åŒçš„ä¿¡æ¯é‡.\n\n- **KLæ•£åº¦ä¸å…·æœ‰å¯¹ç§°æ€§**: ä»åˆ†å¸ƒ $P$ åˆ° $Q$ çš„è·ç¦»é€šå¸¸å¹¶ä¸ç­‰äºä» $Q$ åˆ° $P$ çš„è·ç¦»ã€‚\n\t$$D_{\\mathrm{KL}}(P \\| Q) \\neq D_{\\mathrm{KL}}(Q \\| P)$$\n\t- åŸå› å¾ˆç®€å•, ä¸€ä¸ªæ˜¯$P(x)$åœ¨$log$å¤–é¢, å¦å¤–ä¸€ä¸ªæ˜¯$Q(x)$åœ¨$log$å¤–é¢\n\t- å°½ç®¡ä»ç›´è§‰ä¸Š KL æ•£åº¦æ˜¯ä¸ªåº¦é‡æˆ–è·ç¦»å‡½æ•°, ä½†æ˜¯å®ƒå®é™…ä¸Šå¹¶ä¸æ˜¯ä¸€ä¸ªçœŸæ­£çš„åº¦é‡æˆ–è·ç¦»ã€‚\n\t- \n\n\n[^1]: [Intuitively Understanding the KL Divergence - YouTube](https://www.youtube.com/watch?v=SxGYPqCgJWM)\n[^2]: [ç›¸å¯¹ç†µ - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/wiki/%E7%9B%B8%E5%AF%B9%E7%86%B5)\n[^3]: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#/media/File:KL-Gauss-Example.png","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Likelihood_Function-%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0":{"title":"Likelihood_Function-ä¼¼ç„¶å‡½æ•°","content":"# Likelihood Function - ä¼¼ç„¶å‡½æ•°\n\n\u003cdiv align=\"right\"\u003e 2022-02-11\u003c/div\u003e\n\nTags: #Math/Statistics #MachineLearning \n\nå¯¹äºæŸä¸ª(æŸç»„)éšæœºå˜é‡ $X$, æˆ‘ä»¬é€šè¿‡é‡‡æ ·è·å¾—äº†æ•°æ®é›† $x$ :\n- ä¼¼ç„¶å‡½æ•°$\\mathcal{L}(\\theta \\mid x)$å°±æ˜¯åœ¨æŸä¸ªå‚æ•°(parameter) $\\theta$ ä¸‹, ç°æœ‰æ•°æ® $x$ å‡ºç°çš„æ¦‚ç‡å¤§å°, ä¹Ÿå°±æ˜¯è¯´: \n$$\\mathcal{L}(\\theta \\mid x) = P(X=x\\mid\\theta)$$\n$P(X=x\\mid\\theta)$ ä¹Ÿå¸¸å¸¸å†™ä½œ $p_{\\theta}(x)=P_{\\theta}(X=x)=P(X=x\\space ;\\theta)$\n\n- å› ä¸ºæ•°æ®é›†æœ‰è®¸å¤šæ ·æœ¬ç‚¹, æ‰€ä»¥ä¼¼ç„¶å‡½æ•°æ˜¯ä¸€ä¸ªè”åˆæ¦‚ç‡åˆ†å¸ƒ(Joint Probability)\n\n\u003e - **The likelihood function** (often simply called **the likelihood**) describes the *joint probability* of the observed data as *a function of the parameters* of the chosen statistical model. \n\u003e \n\u003e - For each specific parameter value $Î¸$ in the parameter space, the likelihood function $p ( X | Î¸ )$ therefore assigns a probabilistic prediction to the observed data $X$. \n\u003e \n\u003e - It is essentially the product of sampling densities.[^1]\n\n- [Maximum_Likelihood_Estimation-æå¤§ä¼¼ç„¶ä¼°è®¡](notes/2021/2021.12/Maximum_Likelihood_Estimation-æå¤§ä¼¼ç„¶ä¼°è®¡.md)\n\n[^1]:[Likelihood function - Wikipedia](https://en.wikipedia.org/wiki/Likelihood_function) ","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Logit":{"title":"Logit","content":"# Logit: a confusing term\n\n\u003cdiv align=\"right\"\u003e 2022-02-11\u003c/div\u003e\n\nTags: #Math #DeepLearning #SoftmaxRegression \n\nRef: [machine learning - What is the meaning of the word logits in TensorFlow? - Stack Overflow](https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow)\n- Logits is an overloaded term which can mean many different things:\n\n## ç†è§£[^1]\n- æˆ‘ä»¬å¯ä»¥æŠŠLogitç†è§£æˆ\"å¯¹æ•°å‡ ç‡/æ¦‚ç‡\", ä¹Ÿå°±æ˜¯æ¦‚ç‡çš„å¯¹æ•°:  $\\log p_i$.\n\t- Logitè¾“å…¥åˆ°Softmaxä¹‹åè¿˜åŸæˆåŸæ¥çš„æ¦‚ç‡: $p_i$  : $$\\frac{\\exp(\\log p_i)}{\\sum_K \\exp(\\log p_i)}=p_i$$ \n\n## In Math\n- **In Math**, [Logit](https://en.wikipedia.org/wiki/Logit) is a function that maps probabilities (`[0, 1]`) to R (`(-inf, inf)`)\n\n\t![enter image description here](https://i.stack.imgur.com/zto5q.png)\n\n\t- Probability of 0.5 corresponds to a logit of 0. Negative logit correspond to probabilities less than 0.5, positive to \u003e 0.5.\n\n## In ML\n- **For Tensorflow**: It's a name that it is thought to imply that this Tensor is the quantity that is being mapped to probabilities by the Softmax.\n\n- **Logits Layer**: In context of deep learning the [logits layer](https://www.tensorflow.org/tutorials/estimators/cnn#logits_layer) means the layer that feeds in to Softmax (or other such normalization). \n\t- The output of the softmax are the probabilities for the classification task and its input is **logits layer**. The logits layer typically produces values from -infinity to +infinity and the softmax layer transforms it to values from 0 to 1.\n\n## Historical Context\nWhere does this term comes from? \n\n- In 1930s and 40s, several people were trying to adapt linear regression to the problem of predicting probabilities. However linear regression produces output from -infinity to +infinity while for probabilities our desired output is 0 to 1. \n\n- One way to do this is by somehow mapping the probabilities 0 to 1 to -infinity to +infinity and then use linear regression as usual. One such mapping is cumulative normal distribution that was used by Chester Ittner Bliss in 1934 and he called this \"probit\" model, short for \"probability unit\".\n\n- However this function is computationally expensive while lacking some of the desirable properties for multi-class classification. In 1944 Joseph Berkson used the function `log(p/(1-p))` to do this mapping and called it logit, short for \"logistic unit\". The term logistic regression derived from this as well.\n\n## The Confusion\nUnfortunately the term logits is abused in deep learning. \n- From pure mathematical perspective logit is a _function_ that performs above mapping. In deep learning people started calling the layer \"logits layer\" that feeds in to logit function. Then people started calling the output _values_ of this layer \"logit\" creating the confusion with logit _the function_.\n\n**TensorFlow Code**\n- Unfortunately TensorFlow code further adds in to confusion by names like `tf.nn.softmax_cross_entropy_with_logits`. \n\n- What does logits mean here? It just means the input of the function is supposed to be the output of last neuron layer as described above. The `_with_logits` suffix is [redundant, confusing and pointless](https://github.com/tensorflow/tensorflow/issues/6531). \n\n- Functions should be named without regards to such very specific contexts because they are simply mathematical operations that can be performed on values derived from many other domains. In fact TensorFlow has another similar function `sparse_softmax_cross_entropy` where they fortunately forgot to add `_with_logits` suffix creating inconsistency and adding in to confusion. \n\n- PyTorch on the other hand simply names its function without these kind of suffixes.\n\n**Reference**\n\n- [Logit/Probit lecture slides](http://www.columbia.edu/~so33/SusDev/Lecture_9.pdf)  \n- [Wikipedia article](https://en.wikipedia.org/wiki/Logit) \n\n\n\n\n\n[^1]: [7.3. ç½‘ç»œä¸­çš„ç½‘ç»œï¼ˆNiNï¼‰ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_convolutional-modern/nin.html#id3)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Norm-in-Regularization-Intuition":{"title":"Norm in Regularization - Intuition","content":"# Norm in Regularization - Intuition\n\n\u003cdiv align=\"right\"\u003e 2022-02-14\u003c/div\u003e\n\nTags: #Norm #Regularization #DeepLearning #MachineLearning \n\n\n![](notes/2022/2022.2/assets/img_2022-10-15-31.png)\n### L2 Norm $\\ell_{2}$ in Regularization\n- L2 Norm çš„ç­‰é«˜çº¿æ˜¯åœ†å½¢çš„\n- ä½¿ç”¨$L_2$èŒƒæ•°çš„ä¸€ä¸ªåŸå› æ˜¯å®ƒå¯¹æƒé‡å‘é‡çš„å¤§åˆ†é‡æ–½åŠ äº†å·¨å¤§çš„æƒ©ç½šã€‚ è¿™ä½¿å¾—æˆ‘ä»¬çš„å­¦ä¹ ç®—æ³•åå‘äºåœ¨å¤§é‡ç‰¹å¾ä¸Šå‡åŒ€åˆ†å¸ƒæƒé‡çš„æ¨¡å‹ã€‚ åœ¨å®è·µä¸­ï¼Œè¿™å¯èƒ½ä½¿å®ƒä»¬å¯¹å•ä¸ªå˜é‡ä¸­çš„è§‚æµ‹è¯¯å·®æ›´ä¸ºç¨³å®šã€‚[^2]\n- ä½¿ç”¨L2æ­£è§„åŒ–åœ¨è®­ç»ƒæ—¶\"æ›´ç¨³å®š\".\n\t ![](notes/2022/2022.2/assets/img_2022-10-15-32.png)\n\t - å› ä¸ºåœ¨è¿›è¡Œ[å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™](notes/2022/2022.1/D2L-10-å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™.md)çš„æ—¶å€™, æ¯æ¬¡è®­ç»ƒè·å¾—çš„æ•°æ®å…·æœ‰ä¸€å®šéšæœºæ€§, ä»ä¸Šå›¾ä¸­å¯ä»¥çœ‹åˆ°, L2æ­£åˆ™é¡¹åœ¨ $J(\\theta)$ å‡ºç°å˜åŒ–çš„æ—¶å€™æ¢¯åº¦å˜åŒ–æ›´å°, è€ŒL1æ­£åˆ™é¡¹å˜åŒ–è¾ƒå¤§[^1]\n\n- [GeoGebraçš„ç›´è§‚äº’åŠ¨ä¾‹å­](https://www.geogebra.org/m/jgq2yu36)\n\t![400](notes/2022/2022.2/assets/img_2022-10-15-33.png)\n\n\n### L1 Norm $\\ell_{2}$ in Regularization\n- L1 Normçš„ç­‰é«˜çº¿æ˜¯æ–¹å½¢çš„, åœ¨æ­£æ–¹å½¢ä¸Šé¢æ¯ä¸€ç‚¹çš„å–å€¼ç›¸åŒ.\n- L1 èŒƒæ•°å½¢çŠ¶æ›´\"å°–é”\", ä»å›¾å½¢ä¸­å¯ä»¥çœ‹å‡ºæ­£æ–¹å½¢çš„å››ä¸ªè§’éƒ½åœ¨åæ ‡è½´ä¸Š, è¿™ä½¿å¾—L1èŒƒæ•°æ‰¾åˆ°çš„\"å¹³è¡¡ç‚¹\"å¾ˆå¯èƒ½å°†æƒé‡é›†ä¸­åœ¨ä¸€å°éƒ¨åˆ†ç‰¹å¾ä¸Šï¼Œ è€Œå°†å…¶ä»–æƒé‡æ¸…é™¤ä¸ºé›¶, ä¹Ÿå°±æ˜¯è¯´, [L1èŒƒæ•°çº¦æŸåçš„è§£å¾ˆ\"ç¨€ç–\", è¿™åœ¨ç‰¹å¾é€‰æ‹©æ—¶æ˜¯å¾ˆæœ‰ç”¨çš„](notes/2021/2021.8/Why_do_cost_functions_use_the_square_error.md#^269677)\n\n\t- è¿™ä¸ªè§†é¢‘å°†L1èŒƒæ•°ä¸ç¨€ç–æ€§çš„å…³ç³»è®²çš„å¾ˆå¥½: \n\t\t\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/76B5cMEZA4Y\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- [GeoGebraçš„ç›´è§‚äº’åŠ¨ä¾‹å­](https://www.geogebra.org/m/abbbqute)\n\t![400](notes/2022/2022.2/assets/img_2022-10-15-34.png)\n\n### L1 L2 èŒƒæ•°çº¦æŸä¸‹çš„çº¿æ€§å›å½’: LASSOå›å½’ ä¸ å²­å›å½’\n- çº¿æ€§å›å½’åŠ ä¸ŠL2èŒƒæ•°è¿›è¡Œæ­£åˆ™åŒ–å°±æ˜¯å²­å›å½’, å²­å›å½’é€šå¸¸åœ¨æ ·æœ¬ç‰¹å¾ä¹‹é—´ç›¸å…³æ€§å¾ˆé«˜çš„æ—¶å€™ä½¿ç”¨, \"è®©å‚æ•°çš„æ–¹å·®å˜å°\", è·å¾—æ¯”è¾ƒç¨³å®šçš„è§£.\n\n- çº¿æ€§å›å½’åŠ ä¸ŠL1èŒƒæ•°è¿›è¡Œæ­£åˆ™åŒ–åˆ™å«åšLASSOå›å½’(**Least Absolute Shrinkage and Selection Operator**,  å¥—ç´¢å›å½’), LASSOçš„ä¸»è¦æ€æƒ³æ˜¯æ„é€ ä¸€ä¸ªä¸€é˜¶æƒ©ç½šå‡½æ•°è·å¾—ä¸€ä¸ªç²¾ç‚¼çš„æ¨¡å‹, é€šè¿‡æœ€ç»ˆç¡®å®šä¸€äº›å˜é‡çš„ç³»æ•°ä¸º0è¿›è¡Œç‰¹å¾ç­›é€‰ã€‚[^3]\n\nä¸‹é¢çš„æ–‡ç« å¯ä»¥è¿›ä¸€æ­¥äº†è§£è¿™ä¸¤ç§æ–¹æ³•: \n- [æœºå™¨å­¦ä¹ ç®—æ³•å®è·µ-å²­å›å½’å’ŒLASSO - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/30535220)\n- [ã€æœºå™¨å­¦ä¹ ã€‘ä¸€æ–‡è¯»æ‡‚çº¿æ€§å›å½’ã€å²­å›å½’å’ŒLassoå›å½’ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/88698511)\n- [å²­å›å½’å’Œæœ€å°äºŒä¹˜æ³•çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿä»€ä¹ˆæ—¶å€™æ¯”è¾ƒé€‚åˆç”¨å²­å›å½’ï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/28221429)\n\n[^1]: [ä»€ä¹ˆæ˜¯ L1 L2 æ­£è§„åŒ– æ­£åˆ™åŒ– Regularization (æ·±åº¦å­¦ä¹  deep learning) - YouTube](https://www.youtube.com/watch?v=TmzzQoO8mr4)\n[^2]: [4.5. æƒé‡è¡°å‡ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/weight-decay.html#id2)\n[^3]: [æœºå™¨å­¦ä¹ ç®—æ³•å®è·µ-å²­å›å½’å’ŒLASSO - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/30535220)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Passage_Paragraph-Difference":{"title":"Passage_Paragraph-Difference","content":"# Passage Paragraph éƒ½æ˜¯\"æ®µè½\", æœ‰ä»€ä¹ˆåŒºåˆ«å—?\n\n\u003cdiv align=\"right\"\u003e 2022-02-22\u003c/div\u003e\n\nTags: #English \n\n- *Paragraph* is a section of a document that is usually indicated by an indent on the left hand side of the paper. It ends with the last sentence before the next indent. It is very clear where a paragraph starts and where it ends.  \n  \n- A *passage* is any excerpt from a larger work. It could be a few sentences or three pages. A passage could also be a paragraph ;)[^1]\n\n\n[^1]: [\"\"paragraph\"\" å’Œ \"\"passage\"\" å’Œæœ‰ä»€ä¹ˆä¸ä¸€æ ·ï¼Ÿ | HiNative](https://zh.hinative.com/questions/311732)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Regularization-%E6%AD%A3%E5%88%99%E5%8C%96":{"title":"Regularization-æ­£åˆ™åŒ–","content":"# Regularization\n\n\u003cdiv align=\"right\"\u003e 2022-02-14\u003c/div\u003e\n\nTags: #Regularization #DeepLearning \n\n## Definition\n- **Regularization**: any modification we make to a learning algorithm that is intended to reduce its *generalization error* but **not** its *training error*.[^1]\n\t- å¯¹å­¦ä¹ ç®—æ³•çš„ä¿®æ”¹â€”â€”æ—¨åœ¨å‡å°‘æ³›åŒ–è¯¯å·®è€Œä¸æ˜¯è®­ç»ƒè¯¯å·®\n\t- è¿™æ˜¯ä¸€ä¸ªå¾ˆå®½æ³›çš„æ¦‚å¿µ, \n\n- Many strategies used in machine learning are explicitly designed to reduce the test error, possibly at the expense of increased training error. These strategies are known collectively as **regularization**.[^1]\n\n- æ­£åˆ™åŒ–åªåœ¨è®­ç»ƒä¸­ä½¿ç”¨. ä¹Ÿå°±æ˜¯è¯´, åœ¨æ¨¡å‹å®é™…ç”¨æ¥æ¨ç†å¾—ç»“æœçš„æ—¶å€™ä¸ä½¿ç”¨æ­£åˆ™åŒ–.\n\t- å¯¹äº L2 æ­£åˆ™åŒ–, è¿™ä¸ªæ²¡å•¥å½±å“, ä½†æ˜¯å¯¹äº Dropout æ¥è¯´, æ„å‘³ç€ $\\mathbf{h}=\\operatorname{dropout}(\\mathbf{h})$\n\n## Links\n- [Part.18_Regularization_Intuition(ML_Andrew.Ng.)](notes/2021/2021.9/Part.18_Regularization_Intuition(ML_Andrew.Ng.).md)\n- [D2L-22-æƒé‡è¡°å‡](notes/2022/2022.2/D2L-22-æƒé‡è¡°å‡.md)\n- [Part.19_Regularized_Linear_Regression(ML_Andrew.Ng.)](notes/2021/2021.9/Part.19_Regularized_Linear_Regression(ML_Andrew.Ng.).md)\n- [Part.20_Regularized_Logistic_Regression(ML_Andrew.Ng.)](notes/2021/2021.9/Part.20_Regularized_Logistic_Regression(ML_Andrew.Ng.).md)\n- \n\n\n\n\n\n\n\n[^1]:I. Goodfellow, Y. Bengio, and A. Courville, _Deep learning_. MIT Press, 2016.(zotero://select/items/@Goodfellow-et-al-2016)","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Relation_between_Softmax_and_Logistic_Regression":{"title":"Relation_between_Softmax_and_Logistic_Regression","content":"# Softmax ä¸ Logistic å›å½’çš„è”ç³»\n\n\u003cdiv align=\"right\"\u003e 2022-02-11\u003c/div\u003e\n\nTags: #SoftmaxRegression #LogisticRegression #Classification #MulticlassClassification \n\nRef: [Unsupervised Feature Learning and Deep Learning Tutorial](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)\n\n- äºŒåˆ†ç±»çš„[Softmaxå›å½’](notes/2022/2022.2/D2L-13-Softmax_Regression.md)å½¢å¼å¦‚ä¸‹: \n$$h_{\\theta}(x)=\\frac{1}{\\exp \\left(\\theta^{(1) \\top} x\\right)+\\exp \\left(\\theta^{(2) \\top} x^{(i)}\\right)}\\left[\\begin{array}{c}\n\\exp \\left(\\theta^{(1) \\top} x\\right) \\\\\n\\exp \\left(\\theta^{(2) \\top} x\\right)\n\\end{array}\\right]$$\n\n- æ ¹æ®: [Softmax_Regression_is_Over-parameterized](notes/2022/2022.2/Softmax_Regression_is_Over-parameterized.md), æˆ‘ä»¬å¯ä»¥è®©å‚æ•°åŒæ—¶å‡å» $\\psi=\\theta^{(2)}$, å¾—åˆ°: \n\n$$\\begin{aligned}\nh(x) \u0026=\\frac{1}{\\exp \\left(\\left(\\theta^{(1)}-\\theta^{(2)}\\right)^{\\top} x^{(i)}\\right)+\\exp \\left(\\overrightarrow{0}^{\\top} x\\right)}\\left[\\exp \\left(\\left(\\theta^{(1)}-\\theta^{(2)}\\right)^{\\top} x\\right) \\exp \\left(\\overrightarrow{0}^{\\top} x\\right)\\right] \\\\\n\u0026=\\left[\\begin{array}{l}\n\\frac{1}{1+\\exp \\left(\\left(\\theta^{(1)}-\\theta^{(2)}\\right)^{\\top} x^{(i)}\\right)} \\\\\n\\frac{\\exp \\left(\\left(\\theta^{(1)}-\\theta^{(2)}\\right)^{\\top} x\\right)}{1+\\exp \\left(\\left(\\theta^{(1)}-\\theta^{(2)}\\right)^{\\top} x^{(i)}\\right)}\n\\end{array}\\right] \\\\\n\u0026=\\left[\\begin{array}{c}\n\\frac{1}{1+\\exp \\left(\\left(\\theta^{(1)}-\\theta^{(2)}\\right)^{\\top}\nx^{(i)}\\right)}\\\\\n{1-\\frac{1}{1+\\exp \\left(\\left(\\theta^{(1)}-\\theta^{(2)}\\right)^{\\top} x^{(i)}\\right)}}\n\\end{array}\\right]\n\\end{aligned}$$\n\né€šè¿‡å°† $\\theta^{(2)}-\\theta^{(1)}$ æ›¿æ¢ä¸º $\\theta'$, å¾—åˆ°\n$$\\begin{bmatrix}\n\\frac{1}{1+\\exp \\left(-(\\theta')^{\\top}\nx^{(i)}\\right)}\\\\\n{1-\\frac{1}{1+\\exp \\left(-(\\theta')^{\\top} x^{(i)}\\right)}}\n\\end{bmatrix}$$\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‡½æ•°é¢„æµ‹ç¬¬ä¸€ä¸ªç±»çš„æ¦‚ç‡ä¸º: \n$$\\frac{1}{1+\\exp \\left(-(\\theta')^{\\top}\nx^{(i)}\\right)}$$\nå°±æ˜¯[Logisticå›å½’](notes/2021/2021.8/Part.12_Logistic_Regression(ML_Andrew.Ng.).md)çš„æƒ…å½¢.\n\nç¬¬äºŒä¸ªç±»çš„æ¦‚ç‡ä¸º\n$${1-\\frac{1}{1+\\exp \\left(-(\\theta')^{\\top} x^{(i)}\\right)}}$$\nä¹Ÿå°±æ˜¯logisticå›å½’æ²¡æœ‰è¡¨è¿°å‡ºæ¥çš„æƒ…å†µ.","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Softmax%E5%87%BD%E6%95%B0":{"title":"Softmaxå‡½æ•°","content":"## Softmaxå‡½æ•°\n\n### ç›´è§‚ç†è§£\n\n\u003e Softmaxå‡½æ•°çš„ä½œç”¨éšè—åœ¨å®ƒå…³äºåŸŸçš„æ˜ å°„å…³ç³»é‡Œ:\n\u003e $$\\sigma: \\mathbb{R}^{K} \\rightarrow(0,1)^{K}$$\n\u003e å¯ä»¥çœ‹åˆ°, Softmaxå‡½æ•°å°† $K$ ç»´å‘é‡ä¸­æ¯ä¸€ä¸ªå…ƒç´ çš„å–å€¼èŒƒå›´ç”± $\\mathbb{R}$ å‹ç¼©åˆ° $(0,1)$ , å¹¶ä¸”è¿˜ä¿è¯äº†æ‰€æœ‰å…ƒç´ åŠ èµ·æ¥ç­‰äº $1$, è¿™å°±æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å°†æ¯ä¸€ä¸ªå…ƒç´ çœ‹ä½œä¸€ä¸ªæ¦‚ç‡.\n\nä¹Ÿå°±æ˜¯è¯´:\n\n- Softmax çš„ä½œç”¨æ˜¯æŠŠ ä¸€ä¸ªåºåˆ—ï¼Œå˜æˆæ¦‚ç‡ã€‚\n$$\\left[\\begin{array}{c}\n\\sigma(\\mathbf{z})_{1} \\\\\n\\vdots \\\\\n\\sigma(\\mathbf{z})_{K}\n\\end{array}\\right]=\\frac{1}{\\sum_{i=1}^{K} e^{z_{i}}}\\left[\\begin{array}{c}\ne^{z_{1}} \\\\\n\\vdots \\\\\ne^{z_{K}}\n\\end{array}\\right]=\n\\left[\\begin{array}{c}\nP(t=1 \\mid \\mathbf{z}) \\\\\n\\vdots \\\\\nP(t=K \\mid \\mathbf{z})\n\\end{array}\\right]$$\n\n### å®šä¹‰\n\næ ‡å‡†Softmaxå‡½æ•° $\\sigma: \\mathbb{R}^{K} \\rightarrow(0,1)^{K}$ çš„å®šä¹‰å¦‚ä¸‹æ‰€ç¤º:\n\n- å¯¹äº $i=1, \\ldots, K$ and $\\mathbf{z}=\\left(z_{1}, \\ldots, z_{K}\\right) \\in \\mathbb{R}^{K}$\n $$\\sigma(\\mathbf{z})_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{K} e^{z_{j}}}$$\n  - å…¶ä¸­$K$ä»£è¡¨ç±»åˆ«æ•°, ä¸”$K\u003e1$ (å¤šåˆ†ç±»)\n\nå¦ä¸€ç§è¡¨ç¤ºæ–¹æ³•æ˜¯:\n$$\\sigma(\\mathbf{z})_{i}=\\frac{\\exp(z_{i})}{\\sum_{j=1}^{K} \\exp(z_{j})} \\quad$$\n\n### æ€§è´¨\n\n- å®¹æ˜“çŸ¥é“, è¾“å‡ºå‘é‡ $\\sigma(\\mathbf{z})_{i}$ çš„æ‰€æœ‰å…ƒç´ å‡å±äº $(0,1)$ åŒºé—´ã€‚\n- è¾“å‡ºå‘é‡ä¸­ï¼Œæ‰€æœ‰åˆ†é‡ç›¸åŠ ä¹‹å’Œç­‰äº1 $$\\sum_{i=1}^K\\sigma(\\mathbf{z})_{i}=\\frac{\\sum_{i=1}^K e^{z_{i}}}{\\sum_{j=1}^{K} e^{z_{j}}}=1$$\n- $\\mathbf{z}=\\left(z_{1}, \\ldots, z_{K}\\right)$, å•ç‹¬æ”¹å˜æŸä¸€ä¸ª $z_i$çš„å€¼, åˆ™ $\\sigma(\\mathbf{z})_{i}$ çš„å˜åŒ–ç¬¦åˆSigmoidå‡½æ•°æ›²çº¿.\n  - \u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ytbYRIN0N4g?start=157\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n- å¦‚æœ $\\mathbf{z}$ ä¸­æ‰€æœ‰å…ƒç´ åŒæ—¶åŠ å‡ç›¸åŒçš„å€¼, æ¯”å¦‚: $\\mathbf{z}=\\left(z_{1}, \\ldots, z_{K}\\right)\\rightarrow\\mathbf{z}=\\left(z_{1}+1, \\ldots, z_{K}+1\\right)$ , åˆ™æ ¹æ®å®šä¹‰, ç›¸å½“äºåˆ†å­åˆ†æ¯åŒæ—¶ä¹˜ä»¥ä¸€ä¸ªç³»æ•° $e^i$, ç»“æœä¸å˜.\n  - è¿™å¼•å‡ºäº†ä¸€ä¸ªæœ‰è¶£çš„ç‚¹: Softmaxå›å½’çš„å‚æ•°æ˜¯ \"over-parameterized\", æ„å‘³ç€åŒæ ·çš„ç»“æœ, Softmaxçš„å‚æ•°å¯èƒ½ä¸å”¯ä¸€: [[notes/2022/2022.2/Softmax_Regression_is_Over-parameterized]]\n- åŒæ ·, å¦‚æœæ‰€æœ‰å…ƒç´ ä¹˜ä»¥ä¸€ä¸ªç³»æ•°, åˆ™ä¼šæ”¹å˜ç»“æœå‘é‡çš„\"çªèµ·ç¨‹åº¦\":\n  - \u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ytbYRIN0N4g?start=288\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n  - å¦‚æœç³»æ•°å¤§äº1, ä¼šå¢åŠ ç»“æœå‘é‡å†…éƒ¨çš„å·®å¼‚\n  - å¦‚æœç³»æ•°å°äº1, åˆ™ä¼šå‡å°ç»“æœå‘é‡å†…éƒ¨çš„å·®å¼‚(å˜å¾—æ›´å¹³ç¼“)\n\n### å¯¼æ•°\n\n- åœ¨åå‘ä¼ æ’­æ—¶æˆ‘ä»¬éœ€è¦è®¡ç®—Softmaxå‡½æ•°çš„æ¢¯åº¦.\n- æˆ‘ä»¬å®šä¹‰ $\\Sigma_{K}=\\sum_{i=1}^{K} e^{z_{i}}$ , for $c=1, \\cdots, K$. æ‰€ä»¥ $y_{i}=e^{z_{i}} / \\Sigma_{K}$.\n- é‚£ä¹ˆè¾“å‡º $\\mathbf{y}$ å…³äºè¾“å…¥ $\\mathbf{z}$ çš„å¯¼æ•° $\\partial y_{i} / \\partial z_{j}$  ä¸º: (éœ€è¦åˆ†æƒ…å†µè®¨è®º)\n$$\\begin{aligned}\n\u0026\\text { if } i=j: \\frac{\\partial y_{i}}{\\partial z_{i}}=\\frac{\\partial \\frac{e^{z_{i}}}{\\Sigma_{K}}}{\\partial z_{i}}=\\frac{e^{z_{i}} \\Sigma_{K}-e^{z_{i}} e^{z_{i}}}{\\Sigma_{K}^{2}}=\\frac{e^{z_{i}}}{\\Sigma_{K}} \\frac{\\Sigma_{K}-e^{z_{i}}}{\\Sigma_{K}}=\\frac{e^{z_{i}}}{\\Sigma_{K}}\\left(1-\\frac{e^{z_{i}}}{\\Sigma_{K}}\\right)=y_{i}\\left(1-y_{i}\\right) \\\\\n\u0026\\text { if } i \\neq j: \\frac{\\partial y_{i}}{\\partial z_{j}}=\\frac{\\partial \\frac{e^{z_{i}}}{\\Sigma_{K}}}{\\partial z_{j}}=\\frac{0-e^{z_{i}} e^{z_{j}}}{\\Sigma_{K}^{2}}=-\\frac{e^{z_{i}}}{\\Sigma_{K}} \\frac{e^{z_{j}}}{\\Sigma_{K}}=-y_{i} y_{j}\n\\end{aligned}$$\næ³¨æ„: å¦‚æœ $i=j$ é‚£ä¹ˆè¿™ä¸ªå¯¼æ•°å’Œ[Sigmoid_Function](notes/2021/2021.8/Sigmoid_Function.md)çš„å¯¼æ•°å¾ˆç›¸ä¼¼.\n\n- Funny Version: [The SoftMax Derivative, Step-by-Step!!! - YouTube](https://www.youtube.com/watch?v=M59JElEPgIg)\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Softmax_Regression_is_Over-parameterized":{"title":"Softmax_Regression_is_Over-parameterized","content":"# Softmax Regression is Over-parameterized\n\n\u003cdiv align=\"right\"\u003e 2022-02-11\u003c/div\u003e\n\nTags: #SoftmaxRegression\n\nRef: [Unsupervised Feature Learning and Deep Learning Tutorial](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)\n\n- å°†Softmaxå›å½’é‡Œé¢çš„å‚æ•°å…¨éƒ¨å˜åŒ–ä¸€ä¸ªç›¸åŒçš„å€¼, ç»“æœä¸å˜:\n$$\\begin{aligned}\nP\\left(y^{(i)}=k \\mid x^{(i)} ; \\theta\\right) \u0026=\\frac{\\exp \\left(\\left(\\theta^{(k)}-\\psi\\right)^{\\top} x^{(i)}\\right)}{\\sum_{j=1}^{K} \\exp \\left(\\left(\\theta^{(j)}-\\psi\\right)^{\\top} x^{(i)}\\right)} \\\\\n\u0026=\\frac{\\exp \\left(\\theta^{(k) \\top} x^{(i)}\\right) \\exp \\left(-\\psi^{\\top} x^{(i)}\\right)}{\\sum_{j=1}^{K} \\exp \\left(\\theta^{(j) \\top} x^{(i)}\\right) \\exp \\left(-\\psi^{\\top} x^{(i)}\\right)} \\\\\n\u0026=\\frac{\\exp \\left(\\theta^{(k) \\top} x^{(i)}\\right)}{\\sum_{j=1}^{K} \\exp \\left(\\theta^{(j) \\top} x^{(i)}\\right)}\n\\end{aligned}$$\n\n- è¿™å°±æ„å‘³ç€ä¸€ä¸ªHypothesiså¯èƒ½å¯¹åº”å¤šä¸ªä¸åŒçš„å‚æ•°ç»„åˆ $\\theta$\n- å– $\\psi=\\theta^{(K)}$, æˆ‘ä»¬å¯ä»¥æ¶ˆå»ä»»æ„å‚æ•° $\\theta^{(K)}$.\n\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/VC%E7%BB%B4-VC_Dimension":{"title":"VCç»´-VC_Dimension","content":"# Vapnikâ€“Chervonenkis dimension\n\n\u003cdiv align=\"right\"\u003e 2022-02-12\u003c/div\u003e\n\nTags: #DeepLearning #StatisticalLearning\n\n- åœ¨VCç†è®ºä¸­ï¼ŒVCç»´æ˜¯å¯¹ä¸€ä¸ªå¯å­¦ä¹ åˆ†ç±»å‡½æ•°ç©ºé—´çš„èƒ½åŠ›ï¼ˆå¤æ‚åº¦ï¼Œè¡¨ç¤ºèƒ½åŠ›ç­‰ï¼‰çš„è¡¡é‡ã€‚å®ƒå®šä¹‰ä¸ºç®—æ³•èƒ½â€œæ‰“æ•£â€çš„ç‚¹é›†çš„åŠ¿çš„æœ€å¤§å€¼ã€‚\n\n- å¯¹äºçº¿æ€§åˆ†ç±»å™¨: \n\n![](notes/2022/2022.2/assets/img_2022-10-15-30.png)\n\n- VCç»´å¯ä»¥è¡¡é‡è®­ç»ƒè¯¯å·®å’Œæ³›åŒ–è¯¯å·®çš„é—´éš”, ä½†æ˜¯åœ¨æ·±åº¦å­¦ä¹ ä¸­, æˆ‘ä»¬å¾ˆéš¾è®¡ç®—ä¸€ä¸ªæ¨¡å‹çš„VCç»´","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.2/Xavier%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BE%8B%E5%AD%90":{"title":"Xavieråˆå§‹åŒ–çš„è¯¦ç»†ä¾‹å­","content":"ä»¥MLPä¸ºä¾‹\n\n- å‡è®¾:\n  - $w_{i, j}^{s}$ æ˜¯ i.i.d, é‚£ä¹ˆ $\\mathbb{E}\\left[w_{i, j}^{s}\\right]=0, \\operatorname{Var}\\left[w_{i, j}^{s}\\right]=\\gamma_{s}$\n  - $h_{i}^{s-1}$ ç‹¬ç«‹äº $w_{i, j}^{s}$\n  - å‡è®¾æ²¡æœ‰æ¿€æ´»å‡½æ•°, å³: $$\\mathbf{h}^{s}=\\mathbf{W}^{s} \\mathbf{h}^{s-1}, \\text { è¿™é‡Œ } \\mathbf{W}^{s} \\in \\mathbb{R}^{n_{s} \\times n_{s-1}}$$\n\n##### æ­£å‘å‡å€¼\n\n$$\\mathbb{E}\\left[h_{i}^{s}\\right]=\\mathbb{E}\\left[\\sum_{j} w_{i, j}^{s} h_{j}^{s-1}\\right]=\\sum_{j} \\mathbb{E}\\left[w_{i, j}^{s}\\right] \\mathbb{E}\\left[h_{j}^{s-1}\\right]=0$$\n\n##### æ­£å‘æ–¹å·®\n\n$$\\begin{aligned}\n\\operatorname{Var}\\left[h_{i}^{s}\\right] \u0026=\\mathbb{E}\\left[\\left(h_{i}^{s}\\right)^{2}\\right]-\\mathbb{E}\\left[h_{i}^{s}\\right]^{2}\\\\\n\u0026=\\mathbb{E}\\left[\\left(\\sum_{j} w_{i, j}^{s} h_{j}^{s-1}\\right)^{2}\\right] \\\\\n\u0026=\\mathbb{E}\\left[\\sum_{j}\\left(w_{i, j}^{s}\\right)^{2}\\left(h_{j}^{s-1}\\right)^{2}+\\sum_{j \\neq k} w_{i, j}^{s} w_{i, k}^{s} h_{j}^{s-1} h_{k}^{s-1}\\right] \\\\\n(\\text{because i.i.d, covariance is 0} )\n\u0026=\\mathbb{E}\\left[\\sum_{j}\\left(w_{i, j}^{s}\\right)^{2}\\left(h_{j}^{s-1}\\right)^{2}\\right] \\\\\n\u0026=\\sum_{j} \\mathbb{E}\\left[\\left(w_{i, j}^{s}\\right)^{2}\\right] \\mathbb{E}\\left[\\left(h_{j}^{s-1}\\right)^{2}\\right] \\\\\n(\\text{because }\\mathbb{E}\\left[h_{j}^{s-1}\\right]^{2}, \\mathbb{E}\\left[w_{i,j}^{s}\\right]^{2}\\space is\\space 0)\n\u0026=\\sum_{j} \\operatorname{Var}\\left[w_{i, j}^{s}\\right] \\operatorname{Var}\\left[h_{j}^{s-1}\\right]\\\\\n\\left(\\mathbf{W}^{s} \\in \\mathbb{R}^{n_{s} \\times n_{s-1}}\\right)\n\u0026=n_{s-1} \\gamma_{s} \\operatorname{Var}\\left[h_{j}^{s-1}\\right]\n\\end{aligned}$$\n\n- è¿™æ„å‘³ç€å¦‚æœè¾“å…¥å±‚è¾“å‡ºå±‚è¦æ–¹å·®ä¸å˜, åˆ™å¿…é¡»æœ‰ $$n_{s-1} \\gamma_{s}=1$$\n\n##### åå‘éƒ¨åˆ†\n\né¦–å…ˆ, å› ä¸º $\\mathbf{h}^{s}=\\mathbf{W}^{s} \\mathbf{h}^{s-1}$, æ‰€ä»¥ $$\\begin{aligned}\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s-1}}\n\u0026=\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s}}\n\\frac{\\partial\\mathbf{h}^{s}}{\\partial\\mathbf{h}^{s-1}}\\\\\n\u0026=\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s}}\n\\frac{\\partial\\mathbf{W}^{s} \\mathbf{h}^{s-1}}{\\partial\\mathbf{h}^{s-1}}\\\\\n\u0026=\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s}}\n\\mathbf{W}^{s}\\end{aligned}$$\n\nä¸ºäº†å’Œä¸Šé¢æ­£å‘çš„æ­¥éª¤ç›¸ä¼¼, æˆ‘ä»¬åŒæ—¶å–ä¸€ä¸ªè½¬ç½®, å¾—åˆ°:\n$$\\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s-1}}\\right)^T\n=\\left(\\mathbf{W}^{s}\\right)^T\\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s}}\\right)^T$$\n\n##### åå‘å‡å€¼\n\n$$\\mathbb{E}\\left[\\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s-1}}\\right)^T_i\\right]\n=\\mathbb{E}\\left[\\sum_{j} w_{j, i}^{s} \\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right]\n=\\sum_{j} \\mathbb{E}\\left[w_{j, i}^{s}\\right] \\mathbb{E}\\left[\\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right]=0$$\n\n##### åå‘æ–¹å·®\n\n$$\\begin{aligned}\n\\operatorname{Var}\\left[\\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s-1}}\\right)^T_i\\right]\n\u0026=\\mathbb{E}\\left[\\left(\\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s-1}}\\right)^T_i\\right)^{2}\\right]-\\mathbb{E}\\left[\\left(\\frac{\\partial\\ell}{\\partial\\mathbf{h}^{s-1}}\\right)^T_i\\right]^{2}\\\\\n\u0026=\\mathbb{E}\\left[\\left(\\sum_{j} w_{j, i}^{s} \\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right)^{2}\\right] \\\\\n\u0026=\\mathbb{E}\\left[\\sum_{j}\\left(w_{j, i}^{s}\\right)^{2}\\left(\\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right)^{2}+\\sum_{j \\neq k} w_{j, i}^{s} w_{k, i}^{s} \\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{j} \\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{k}\\right] \\\\\n\u0026=\\mathbb{E}\\left[\\sum_{j}\\left(w_{j, i}^{s}\\right)^{2}\\left(\\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right)^{2}\\right] \\\\\n\u0026=\\sum_{j} \\mathbb{E}\\left[\\left(w_{j, i}^{s}\\right)^{2}\\right] \\mathbb{E}\\left[\\left(\\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right)^{2}\\right] \\\\\n\u0026=\\sum_{j} \\operatorname{Var}\\left[w_{j, i}^{s}\\right] \\operatorname{Var}\\left[\\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right]\\\\\n\\left(\\mathbf{W}^{s} \\in \\mathbb{R}^{n_{s} \\times n_{s-1}}\\right)\n\u0026=n_{s} \\gamma_{s} \\operatorname{Var}\\left[\\left(\\frac{\\partial\\ell}\n{\\partial\\mathbf{h}^{s}}\\right)^T_{j}\\right]\n\\end{aligned}$$\n\n- è¿™æ„å‘³ç€å¦‚æœè¾“å…¥å±‚è¾“å‡ºå±‚è¦æ–¹å·®ä¸å˜, åˆ™å¿…é¡»æœ‰ $$n_{s} \\gamma_{s}=1$$\n","lastmodified":"2023-11-19T19:19:34.242469258Z","tags":null},"/notes/2022/2022.3/D2L-42-NiN":{"title":"D2L-42-NiN","content":"# Network in Network - NiN\n\n\u003cdiv align=\"right\"\u003e 2022-03-04\u003c/div\u003e\n\nTags: #DeepLearning #NiN #CNN \n\n![NiN_PixelMLP](notes/2022/2022.3/assets/NiN_PixelMLP.svg)\n## ç”¨å·ç§¯ä»£æ›¿å…¨è¿æ¥\n### åŠ¨æœº\n#### å…¨è¿æ¥å±‚å¾ˆè´µ (å‚æ•°å¾ˆå¤š)\n- ä¸€å±‚å·ç§¯å±‚éœ€è¦çš„å‚æ•°ä¸º: \n\t- ![å·ç§¯å±‚æƒé‡å¤§å°çš„è®¡ç®—](notes/2022/2022.2/assets/å·ç§¯å±‚æƒé‡å¤§å°çš„è®¡ç®—.svg) \n\t- [å·ç§¯å±‚å‚æ•°å¤§å°çš„è®¡ç®—](notes/2022/2022.2/å·ç§¯å±‚å‚æ•°å¤§å°çš„è®¡ç®—.md)\n\n- å·ç§¯å±‚åé¢ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚çš„å‚æ•°ä¸º: $$in\\_Channel\\times in\\_Height\\times in\\_Width\\times num\\_of\\_Hidden\\_Units$$\n\n- **å¯¹æ¯” :**\n\t- ä¸€ä¸ª $C_{in}=512, C_{out}=4096$ å·ç§¯æ ¸å¤§å°ä¸º3çš„å·ç§¯å±‚[^2], å‚æ•°è§„æ¨¡æ˜¯ $$512\\times4096\\times3\\times3\\approx 18M$$\n\t- ä¸€ä¸ªè¾“å…¥é€šé“æ•°ä¸º512, éšè—å•å…ƒä¸º4096, è¾“å…¥å°ºå¯¸ä¸º $7\\times7$ çš„å…¨è¿æ¥å±‚çš„å‚æ•°è§„æ¨¡æ˜¯[^3] :  $$512\\times7\\times7\\times4096\\approx 102M$$\n\n#### å…¨è¿æ¥å±‚æŸå¤±äº†ç©ºé—´ä¿¡æ¯\n- è¿™ä¸€ç‚¹å¾ˆå¥½ç†è§£:  ç”±å·ç§¯å±‚è½¬åŒ–åˆ°å…¨è¿æ¥å±‚, éœ€è¦å°†å·ç§¯è¾“å‡ºå…¨éƒ¨Flattenä¸ºä¸€ä¸ªä¸€ç»´å‘é‡. è€Œè¿™æ„å‘³ç€æ”¾å¼ƒäº†å·ç§¯å±‚é‡Œé¢çš„ç©ºé—´ä¿¡æ¯.\n\n### 1x1 å·ç§¯ç›¸å½“äº(å•åƒç´ ä¸Šçš„)å…¨è¿æ¥\n [D2L-36-1x1å·ç§¯å±‚](notes/2022/2022.2/D2L-36-1x1å·ç§¯å±‚.md)\n \n![NiN_PixelMLP](notes/2022/2022.3/assets/NiN_PixelMLP.svg)\n\n## ç½‘ç»œç»“æ„\n- äº¤æ›¿ä½¿ç”¨NiNå—å’Œæ­¥å¹…ä¸º2çš„æœ€å¤§æ± åŒ–å±‚\n\t- é€æ­¥å‡å°é«˜å®½å’Œå¢å¤§é€šé“æ•°\n![](notes/2022/2022.3/assets/nin.svg)\n### åˆ†å—\n- å’ŒVGGä¸€æ ·, NiNç½‘ç»œä¹Ÿé‡‡ç”¨äº†åˆ†å—çš„è§„èŒƒåŒ–ç½‘ç»œç»“æ„, ä¸€ä¸ªNiNå—åŒ…æ‹¬ä¸€ä¸ªæ™®é€šå·ç§¯å±‚ä¸ä¸¤ä¸ªè¿ç»­çš„ $1\\times1$ å·ç§¯å±‚.\n\t```python\n\tdef nin_block(in_channels, out_channels, kernel_size, strides, padding):\n\t\treturn nn.Sequential(\n\t\t\tnn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n\t\t\tnn.ReLU(),\n\t\t\tnn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),\n\t\t\tnn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())\n\t```\n\t- è¶…å‚æ•°ä¸»è¦è°ƒèŠ‚çš„æ˜¯ç¬¬ä¸€ä¸ªå·ç§¯å±‚, åé¢ä¸¤ä¸ª$1\\times1$çš„å·ç§¯å±‚ä¸æ”¹å˜é€šé“æ•°.\n\n### å…¨å±€å¹³å‡æ± åŒ–å±‚ global average pooling layer\n- å…¶ä»–ç½‘ç»œé‡Œé¢é€šå¸¸å°†æœ€åä¸€å±‚çš„éšè—å±‚è¾“å‡ºä½œä¸º [Logit](notes/2022/2022.2/Logit.md) è¾“å…¥åˆ°Softmaxé‡Œé¢å¾—åˆ°é¢„æµ‹æ¦‚ç‡, **ä½†æ˜¯NiNæ²¡æœ‰å…¨è¿æ¥å±‚, åˆæ€ä¹ˆå¾—åˆ°è¾“å‡ºæ ‡ç­¾å‘¢?**\n- NiNç½‘ç»œå°†æ¯ä¸€ä¸ªé€šé“çš„æ‰€æœ‰åƒç´ å–å¹³å‡å€¼, ä½œä¸ºæœ€åçš„è¾“å‡º. è¿™å°±ç›¸å½“äºä¸€ä¸ªçª—å£å¤§å°æ˜¯æ•´ä¸ªè¾“å…¥çš„å¹³å‡æ± åŒ–å±‚, ä¹Ÿç§° **å…¨å±€å¹³å‡æ± åŒ–å±‚(Global Average Pooling layer)**\n- æ‰€ä»¥NiNç½‘ç»œæœ€åè¾“å‡ºçš„é€šé“æ•°ç­‰äºé¢„æµ‹çš„ç±»åˆ«æ•°, é€šè¿‡ä¸€ä¸ªå…¨å±€å¹³å‡æ± åŒ–å±‚(GAP)æ¥å¾—åˆ°æ¯ä¸ªç±»åˆ«çš„åŸå§‹è¾“å‡º.\n\n- è¿™ä¹Ÿæ˜¯ä¸ºäº†é¿å…ä½¿ç”¨å…¨è¿æ¥å±‚, å‡å°‘å‚æ•°æ•°é‡çš„ä¸€ä¸ªæ“ä½œ. å½“ç„¶ä¹ŸåŒæ—¶å‡å°‘äº†è®¡ç®—é‡, é˜²æ­¢è¿‡æ‹Ÿåˆ\n\n### ä¸AlexNetç›¸ä¼¼çš„è¶…å‚æ•°\n- æœ€åˆçš„NiNç½‘ç»œæ˜¯åœ¨AlexNetåä¸ä¹…æå‡ºçš„ï¼Œæ˜¾ç„¶ä»ä¸­å¾—åˆ°äº†ä¸€äº›å¯ç¤ºã€‚ NiNä½¿ç”¨çª—å£å½¢çŠ¶ä¸º11Ã—11ã€5Ã—5å’Œ3Ã—3çš„å·ç§¯å±‚ï¼Œè¾“å‡ºé€šé“æ•°é‡ä¸AlexNetä¸­çš„ç›¸åŒã€‚ æ¯ä¸ªNiNå—åæœ‰ä¸€ä¸ªæœ€å¤§æ±‡èšå±‚ï¼Œæ±‡èšçª—å£å½¢çŠ¶ä¸º3Ã—3ï¼Œæ­¥å¹…ä¸º2ã€‚[^5]\n\n![](notes/2022/2022.3/assets/å›¾ç‰‡1.jpg)\n## æ¨¡å‹çš„ç‰¹æ€§\n- å‚æ•°å°‘, æ¨¡å‹ä¸å®¹æ˜“è¿‡æ‹Ÿåˆ, åŒæ—¶ä¹Ÿå‡å°‘äº†è®¡ç®—é‡.\n- ä½†æ˜¯ç”±äºå¢åŠ äº†å¤§é‡çš„1x1å·ç§¯, NiNçš„è®­ç»ƒæ—¶é—´æ›´é•¿, æ€»çš„è®¡ç®—é‡ä¹Ÿå¹¶æ²¡æœ‰æ¯”AlexNetå°‘.\n\n\n[^2]: è¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„å·ç§¯å±‚äº†\n[^3]: è¿™å°±æ˜¯VGGçš„ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚\n[^5]: [7.3. ç½‘ç»œä¸­çš„ç½‘ç»œï¼ˆNiNï¼‰ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_convolutional-modern/nin.html#id3)","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-43-GoogLeNetInception":{"title":"D2L-43-GoogLeNet(Inception)","content":"# GoogLeNet\n\n\u003cdiv align=\"right\"\u003e 2022-03-05\u003c/div\u003e\n\nTags: #DeepLearning #CNN #GoogLeNet-Inception\n![](notes/2022/2022.3/assets/img_2022-10-15.jpg)\n- GoogLeNetæ˜¯ä¸€ä¸ª**å«å¹¶è¡Œè¿ç»“**çš„ç½‘ç»œ, å…¶æ ¸å¿ƒç»„æˆéƒ¨åˆ†ä¸º\"**Inceptionå—**\".\n- Inceptionå—ç»„åˆä½¿ç”¨äº†ä¸åŒå¤§å°çš„å·ç§¯æ ¸, è¯•å›¾ç”¨ç°æœ‰çš„ç¨ å¯†ç»“æ„(Dense Components)æ¥æ„å»ºä¸€ä¸ª\"**æœ€ä½³çš„å±€éƒ¨ç¨€ç–ç½‘ç»œ**\".\n\t- **å±€éƒ¨:** å¤šä¸ªInceptionå—æ‹¼æ¥æ„æˆæœ€åçš„GoogLeNet\n\t- **ç¨€ç–:** ä¹Ÿå°±æ˜¯å…·æœ‰éšæœºæ€§çš„ç»“æ„[^1]\n\n- GoogLeNetè¿˜å…·æœ‰**è¾ƒé«˜çš„è®¡ç®—æ•ˆç‡**, è¿™ä¸»è¦å¾—ç›ŠäºInceptionå—é‡Œé¢ä¸å«å…¨è¿æ¥å±‚.\n\n## Inception Block\n![](notes/2022/2022.3/assets/inception.svg)\n\n- GoogLeNetçš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ç§°ä¸º**Inceptionå—**ï¼ˆ**Inception block**ï¼‰ã€‚è¿™å¾—åäºç”µå½±ã€Šç›—æ¢¦ç©ºé—´ã€‹ï¼ˆInceptionï¼‰[^2].\n\n- Inceptionå—ç”±å››æ¡å¹¶è¡Œè·¯å¾„ç»„æˆã€‚ å‰ä¸‰æ¡è·¯å¾„ä½¿ç”¨çª—å£å¤§å°ä¸º $1Ã—1$ã€$3Ã—3$ å’Œ $5Ã—5$ çš„å·ç§¯å±‚ï¼Œä»ä¸åŒç©ºé—´å¤§å°ä¸­æå–ä¿¡æ¯ã€‚ ä¸­é—´çš„ä¸¤æ¡è·¯å¾„åœ¨è¾“å…¥ä¸Šæ‰§è¡Œ $1Ã—1$ å·ç§¯ï¼Œä»¥å‡å°‘é€šé“æ•°ï¼Œä»è€Œé™ä½æ¨¡å‹çš„å¤æ‚æ€§ã€‚\n\n### å¹¶è¡Œè¿ç»“: ä¸åŒå·ç§¯æ ¸çš„ç»„åˆ\n- Inceptionå¹¶è¡Œä½¿ç”¨äº†ä¸åŒå¤§å°çš„å·ç§¯å±‚, å¯ä»¥**ä»ä¸åŒçš„å±‚é¢æŠ½å–ä¿¡æ¯**.\n- å°½ç®¡çª—å£å¤§å°æ˜¯ä¸åŒçš„, æˆ‘ä»¬ä¹Ÿå¯ä»¥è°ƒèŠ‚Strideå’ŒPaddingæ¥ä½¿**è¾“å…¥å’Œè¾“å‡ºé«˜å®½ç›¸ç­‰**\n- ä¸åŒè·¯å¾„çš„è¾“å‡ºåœ¨é€šé“ä¸Šè¿›è¡Œæ‹¼æ¥(å°†é€šé“æ•°ç›¸åŠ ).\n\t- ä¸åŒè·¯å¾„çš„é€šé“æ•°å æ¯”æ˜¯ä¸ä¸€æ ·çš„\n\t![](notes/2022/2022.3/assets/Pasted%20image%2020220305210148.png) [^4]\n\n### Add Sparsity using Dense Building Blocks\n- æå‡ç½‘ç»œæ€§èƒ½çš„ä¸€ä¸ªç®€å•æ–¹æ³•å°±æ˜¯å¢å¤§ç½‘ç»œçš„è§„æ¨¡, ä½†æ˜¯è§„æ¨¡çš„å¢é•¿ä¼šå¸¦æ¥ç½‘ç»œä½“ç§¯ä¸è®¡ç®—å¼€é”€çš„å‰§çƒˆå¢é•¿. ä½œè€…è®¤ä¸ºè‹¥è¦ä»æ ¹æœ¬ä¸Šè§£å†³è¿™ä¸€é—®é¢˜, æˆ‘ä»¬éœ€è¦èˆå¼ƒç¨ å¯†çš„ç»“æ„(æ¯”å¦‚å…¨è¿æ¥å±‚å’Œå·ç§¯), é‡‡ç”¨**æ›´ä¸ºç¨€ç–çš„ç½‘ç»œæ¶æ„**. \n\t- ä¸€äº›ç†è®ºæ€§çš„å·¥ä½œ[^1]ä¹Ÿé˜è¿°äº†ä¸€ç§æœ€ä¼˜çš„ç¥ç»ç½‘ç»œç»“æ„: å¯¹é«˜åº¦ç›¸å…³çš„è¾“å‡ºè¿›è¡Œé€å±‚èšç±». è¿™åŒæ—¶ä¹Ÿå’Œç¥ç»ç§‘å­¦é‡Œé¢çš„Herbbian principleå¾ˆç±»ä¼¼: \"Neurons that fire together, wire together.\"\n- ä¸ºäº†æ„å»ºç¨€ç–çš„(å…·æœ‰éšæœºæ€§çš„)ç½‘ç»œ, åŒæ—¶åˆ©ç”¨å¥½ç°æœ‰ç¡¬ä»¶å¯¹äºå¯†é›†çŸ©é˜µçš„é«˜è®¡ç®—æ€§èƒ½, ä½œè€…æå‡ºäº†Inceptionå—.\n\n- ä¸‹å›¾è¡¨ç¤ºäº†Inceptionçš„åŸå§‹è®¾è®¡: \n![](notes/2022/2022.3/assets/Inception%20Naive%20Version.jpg)\n- åŒæ—¶å¯¹ä¸Šå›¾åšä»¥ä¸‹è¯´æ˜ï¼š[^3]\n\t- é‡‡ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸æ„å‘³ç€ä¸åŒå¤§å°çš„æ„Ÿå—é‡ï¼Œæœ€åæ‹¼æ¥æ„å‘³ç€ä¸åŒå°ºåº¦ç‰¹å¾çš„èåˆï¼›\n\t- ä¹‹æ‰€ä»¥å·ç§¯æ ¸å¤§å°é‡‡ç”¨1ã€3å’Œ5ï¼Œä¸»è¦æ˜¯ä¸ºäº†æ–¹ä¾¿å¯¹é½ã€‚è®¾å®šå·ç§¯æ­¥é•¿stride=1ä¹‹åï¼Œåªè¦åˆ†åˆ«è®¾å®špad=0ã€1ã€2ï¼Œé‚£ä¹ˆå·ç§¯ä¹‹åä¾¿å¯ä»¥å¾—åˆ°ç›¸åŒç»´åº¦çš„ç‰¹å¾ï¼Œç„¶åè¿™äº›ç‰¹å¾å°±å¯ä»¥ç›´æ¥æ‹¼æ¥åœ¨ä¸€èµ·äº†ï¼›\n\t- æ–‡ç« è¯´å¾ˆå¤šåœ°æ–¹éƒ½è¡¨æ˜poolingæŒºæœ‰æ•ˆï¼Œæ‰€ä»¥Inceptioné‡Œé¢ä¹ŸåµŒå…¥äº†ã€‚\n\t- ç½‘ç»œè¶Šåˆ°åé¢ï¼Œç‰¹å¾è¶ŠæŠ½è±¡ï¼Œè€Œä¸”æ¯ä¸ªç‰¹å¾æ‰€æ¶‰åŠçš„æ„Ÿå—é‡ä¹Ÿæ›´å¤§äº†ï¼Œå› æ­¤éšç€å±‚æ•°çš„å¢åŠ ï¼Œ3x3å’Œ5x5å·ç§¯çš„æ¯”ä¾‹ä¹Ÿè¦å¢åŠ ã€‚\n\n### 1x1å·ç§¯: å‡å°‘é€šé“çš„æ•°é‡\n- ä½†æ˜¯ $3Ã—3$ å’Œ $5Ã—5$ çš„å·ç§¯ä¾ç„¶æ˜¯æ˜‚è´µçš„.  ä¸ºæ­¤ï¼Œæ–‡ç« å€Ÿé‰´ [NiN](notes/2022/2022.3/D2L-42-NiN.md)ï¼Œé‡‡ç”¨**1x1å·ç§¯æ¥å‡å°‘é€šé“æ•°**. \n![](notes/2022/2022.3/assets/Inception%20with%20dimension%20reduction.jpg)\n- é¢å¤–å¢åŠ çš„1x1å·ç§¯è¿˜ä¸ºç½‘ç»œå¢åŠ äº†**é¢å¤–çš„éçº¿æ€§æ€§(Non-linearity)**. ä½œè€…è¯´ [1x1å·ç§¯å±‚](notes/2022/2022.2/D2L-36-1x1å·ç§¯å±‚.md) çš„é€šé“èåˆæ•ˆæœä¹Ÿä½¿å¾—ä¹‹åçš„å·ç§¯æ“ä½œèƒ½å¤Ÿåœ¨èåˆåçš„å›¾åƒä¸Šé¢è¿›è¡Œç‰¹å¾æå–æ“ä½œ, è¿™æˆ–è®¸èƒ½å¤Ÿæ”¹è¿›æ•ˆæœ.\n\n### Computational Efficiency\n![](notes/2022/2022.3/assets/Pasted%20image%2020220305210203.png)[^4]\n\n## GoogLeNet\n![200](notes/2022/2022.3/assets/LargeGoogLeNet_1.jpg)\n- å°†å¤šä¸ªInceptionå—ç»„åˆèµ·æ¥, æˆ‘ä»¬ä¾¿å¾—åˆ°äº†GoogLeNet, åŒ…å«5æ®µ9ä¸ªInceptionå—\n\t- GoogLeNetå¹¶æ²¡æœ‰ä¸€å¼€å§‹å°±ä½¿ç”¨Inceptionå—, ä½œè€…è®¤ä¸ºè¿™æ ·ä¹Ÿè®¸æ›´å¥½, ä½†ä¹Ÿä¸æ˜¯ä¸€å®šçš„\n\t- ç½‘ç»œçš„æœ€åé‡‡ç”¨äº†ç±»ä¼¼äºNiNçš„å…¨å±€å¹³å‡æ± åŒ–å±‚, ä½†æ˜¯ä¸ºäº†ä¾¿äºè¿ç§»å­¦ä¹ ä¸å‚æ•°è°ƒæ•´, æœ€åè¿˜æ˜¯åŠ ä¸Šäº†ä¸€ä¸ªå…¨è¿æ¥å±‚.\n\t- æ¯ä¸€ä¸ªInceptionå—éƒ½æœ‰é€šé“æ•°é‡ä¸Šçš„ç»†å¾®å·®åˆ«, é™¤äº†ä¸Šé¢æåˆ°çš„è°ƒæ•´æ–¹å‘ä»¥å¤–, è¿™äº›å‚æ•°å…¶å®å¾ˆéš¾åˆç†è§£é‡Š.\n- åœ¨ä¸åŒçš„Inceptionå—ä¹‹é—´æœ‰æ—¶è¿˜æœ‰3x3æ± åŒ–å±‚ç”¨äºå‡å°å›¾åƒå°ºå¯¸.\n\n![](notes/2022/2022.3/assets/inception-full.svg)\n\n- GoogLeNetä¸€å…±æœ‰ 22 å±‚\n- Only 5 million parameters!\n\t- 12x less than AlexNet\n\t- 27x less than VGG-16\n- ILSVRCâ€™14 classification winner (6.7% top 5 error)\n### Auxiliary Networks: Not Important\n- åŸå§‹çš„ç½‘ç»œé‡Œé¢ä¸ºäº†é¿å…æ¢¯åº¦æ¶ˆå¤±ï¼Œç½‘ç»œé¢å¤–å¢åŠ äº†2ä¸ªè¾…åŠ©çš„softmaxç”¨äºå‘å‰ä¼ å¯¼æ¢¯åº¦ã€‚ä½†æ˜¯ç°åœ¨æœ‰äº†æ›´å¥½çš„è®­ç»ƒæ–¹æ³•ï¼Œè¿™äº›ç‰¹æ€§ä¸æ˜¯å¿…è¦çš„ã€‚\n![](notes/2022/2022.3/assets/Pasted%20image%2020220305211135.png)\n\n## Future Improvements\n- Inception-BN (v2) - ä½¿ç”¨ batch normalization\n- Inception-V3 - ä¿®æ”¹äº†Inceptionå—\n\t- æ›¿æ¢ $5 \\times 5$ ä¸ºå¤šä¸ª $3 \\times 3$ å·ç§¯å±‚\n\t- æ›¿æ¢ $5 \\times 5$ ä¸º $1 \\times 7$ å’Œ $7 \\times 1$ å·ç§¯å±‚\n\t- æ›¿æ¢ $3 \\times 3$ ä¸º $1 \\times 3$ å’Œ $3 \\times 1$ å·ç§¯å±‚\n\t- æ›´æ·±\n- Inception-V4 - ä½¿ç”¨æ®‹å·®è¿æ¥\n\n![Inceptionå˜ç§](notes/2022/2022.3/assets/Inceptionå˜ç§.pdf)\n\n\n[^1]: S. Arora, A. Bhaskara, R. Ge, and T. Ma, â€œProvable bounds for learning some deep representations,â€ in _International conference on machine learning_, 2014, pp. 584â€“592. PDF(zotero://select/items/@arora2014provable)\n[^2]: knowyourmeme.com/memes/we-need-to-go-deeper ç”µå½±ä¸­æœ‰è¿™ä¹ˆä¸€å¥è¯: â€œWe need to go deeperâ€ã€‚\n[^3]: [GoogLeNetç³»åˆ—è§£è¯»_shuzfançš„ä¸“æ -CSDNåšå®¢_googlenet](https://blog.csdn.net/shuzfan/article/details/50738394)\n[^4]: [27 å«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œ GoogLeNet / Inception V3ã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ v2ã€‘å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1b5411g7Xo?p=1)","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-44-Batch_Normalization-%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96":{"title":"D2L-44-Batch_Normalization-æ‰¹é‡å½’ä¸€åŒ–","content":"# Batch Normalization\n\n\u003cdiv align=\"right\"\u003e 2022-03-05\u003c/div\u003e\n\nTags: #BatchNormalization #Normalization #DeepLearning #Regularization \n\n- æ‰¹é‡å½’ä¸€åŒ–æ˜¯ä¸€ç§**åŠ é€Ÿæ”¶æ•›**çš„æ–¹æ³•.\n- æ‰¹é‡å½’ä¸€åŒ–ä½œç”¨äºæ¯ä¸€ä¸ªmini-Batch, å…ˆå°†è¿™ä¸ªBatchå½’ä¸€åŒ–, ç„¶åå†åšä¸€ä¸ªç»Ÿä¸€çš„åç§»ä¸æ‹‰ä¼¸. \n\t- æœ€åè¿™ä¸ªåç§»å’Œæ‹‰ä¼¸çš„é‡æ˜¯ä¸€ä¸ªå¯ä»¥å­¦ä¹ çš„è¶…å‚æ•°\n\n- å¯¹äºå…¨è¿æ¥å±‚, BNä½œç”¨äºæ¯ä¸€ä¸ªç‰¹å¾\n- å¯¹äºå·ç§¯å±‚, BNä½œç”¨äºæ¯ä¸€ä¸ªé€šé“. \n\n## Motivation\n- è™½ç„¶BatchNormæ•ˆæœå¾ˆå¥½, ä½†å…¶å®Batch Normalizationæ•ˆæœå¥½çš„åŸå› å¹¶ä¸æ˜æœ—, ä¸‹é¢çš„åŸå› ä¹Ÿéƒ½æ˜¯äº‹åçš„æ¨æµ‹.\n- åŸä½œè€…è®¤ä¸ºBatch Normèƒ½å¤Ÿå‡å°‘ç½‘ç»œå†…éƒ¨çš„\"åå˜é‡åç§»\", ä¹Ÿå°±æ˜¯è¯´ç½‘ç»œå†…éƒ¨çš„ç‰¹å¾åˆ†å¸ƒå¯èƒ½å‘ç”Ÿå˜åŒ–. BatchNormèƒ½å¤Ÿå‡å¼±è¿™ç§å˜åŒ–\n- ä½†æ˜¯ä¸”ä¸è¯´ä½œè€…è¯¯ç”¨äº†\"åå˜é‡åç§»\"è¿™ä¸ªè¯, ä¸€äº›ç ”ç©¶è¡¨æ˜Batch Normå¹¶æ²¡æœ‰æ”¹å˜ç½‘ç»œå†…éƒ¨çš„å˜é‡åˆ†å¸ƒ, è€Œæ˜¯ä½¿æŸå¤±å‡½æ•°æ›´åŠ å¹³æ»‘äº†.\n\n- ä»æƒé‡ç¨³å®šæ€§çš„è§’åº¦åˆ™å¯ä»¥è¿™æ ·ç†è§£: \n![](notes/2022/2022.3/assets/img_2022-10-15-1.png)\n\n\n## Batch Normalization Layer\nBNå±‚å¯ä»¥ä½œç”¨åœ¨å…¨è¿æ¥å±‚æˆ–è€…å·ç§¯å±‚çš„è¾“å‡ºä¹‹å‰å’Œè¾“å…¥ä¹‹å,  å¹¶ä¸”åœ¨æ¿€æ´»å‡½æ•°ä¹‹å‰.\n### å…¨è¿æ¥å±‚\n- å¯¹äºå…¨è¿æ¥å±‚, BNä½œç”¨äºæ¯ä¸€ä¸ªç‰¹å¾\n$$\\mathbf{h}=\\phi(\\mathbf{B N}(\\mathbf{W} \\mathbf{x}+\\mathbf{b}))$$\n\n### å·ç§¯å±‚\n- å¯¹äºå·ç§¯å±‚, BNä½œç”¨äºæ¯ä¸€ä¸ªé€šé“. \n- ä¹Ÿå°±æ˜¯è¯´, å‡è®¾æ¯ä¸€ä¸ªBatchæœ‰ $n$ ä¸ªæ ·æœ¬ $X_1, X_2, \\cdots, X_n$,  è¿™äº›æ ·æœ¬ç»è¿‡å·ç§¯ä¹‹åå¾—åˆ° $n$ ä¸ªè¾“å‡º $O_1, O_2, \\cdots, O_n$, æ¯ä¸€ä¸ªè¾“å‡ºæœ‰ $c$ ä¸ªé€šé“ $O_i^{(1)}, O_i^{(2)}, \\cdots, O_i^{(c)}$, é€šé“çš„å¤§å°ä¸º $h\\times w$\n- BatchNormå°†æ¯ä¸€ä¸ªè¾“å‡º $O_i$ é‡Œé¢çš„ç¬¬ $k$ ä¸ªé€šé“ $O_i^{(k)}$ å–å‡ºæ¥, å…¨éƒ¨å±•å¼€æ‹‰æˆä¸€æ¡å‘é‡(Flatten), é‡Œé¢ä¸€å…±æœ‰ $n\\times h\\times w$ ä¸ªå…ƒç´  , ç„¶åè®¡ç®—è¿™ä¸ªé•¿æ¡æ‰€æœ‰å…ƒç´ çš„å¹³å‡å€¼ $\\mu_k$ å’Œæ–¹å·® $\\sigma_k$. \n\t- æ¥ä¸‹æ¥ç”¨å‡å€¼ $\\mu_k$ å’Œæ–¹å·® $\\sigma_k$ å¯¹æ¯ä¸€ä¸ªå…ƒç´ è¿›è¡Œå½’ä¸€åŒ–. \n\t- è¿›ä¸€æ­¥, åˆ©ç”¨å‚æ•° $\\beta_k$ å’Œ $\\gamma_k$ å¯¹æ‰€æœ‰å…ƒç´ è¿›è¡Œæ‹‰ä¼¸å’Œå¹³ç§».\n\t- æœ€åå°†æ‰€æœ‰å…ƒç´ æ‹¼æˆåŸæ¥çš„å½¢çŠ¶, å¡å›åŸæ¥çš„ä½ç½®[^2]\n\t\n\t![](notes/2022/2022.3/assets/img_2022-10-15-2.png)\n\t[^1]\n- æ¯ä¸€ä¸ªé€šé“å¯¹åº”ä¸€å¯¹ $\\beta_k$ å’Œ $\\gamma_k$ ,  $\\beta_k$ å’Œ $\\gamma_k$ éƒ½æ˜¯å¯ä»¥å­¦ä¹ çš„å‚æ•°.\n\n![Batchnorm](notes/2022/2022.3/assets/Batchnorm.svg)\n\n## è§„èŒƒåŒ–å®šä¹‰\n- ä»å½¢å¼ä¸Šæ¥è¯´, ç”¨ $\\mathbf{x} \\in \\mathcal{B}$ è¡¨ç¤ºä¸€ä¸ªæ¥è‡ªå°æ‰¹é‡ $\\mathcal{B}$ çš„è¾“å…¥ï¼Œæ‰¹é‡è§„èŒƒåŒ–BNå¯¹ $\\mathbf{x}$ çš„ä½œç”¨å¯ä»¥è¡¨ç¤ºä¸º:\n\t$$\\operatorname{BN}(\\mathbf{x})=\\gamma \\odot \\frac{\\mathbf{x}-\\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}}}{\\hat{\\boldsymbol{\\sigma}}_{\\mathcal{B}}}+\\boldsymbol{\\beta}$$\n\t- ä¸Šå¼ä¸­ $\\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}}$ æ˜¯å°æ‰¹é‡ $\\mathcal{B}$ çš„æ ·æœ¬å‡å€¼, $\\hat{\\boldsymbol{\\sigma}}_{\\mathcal{B}}$ æ˜¯å°æ‰¹é‡ $\\mathcal{B}$ çš„æ ·æœ¬æ ‡å‡†å·®ã€‚\n\t- åº”ç”¨æ ‡å‡†åŒ–å, ç”Ÿæˆçš„å°æ‰¹é‡çš„å¹³å‡å€¼ä¸º 0 å’Œå•ä½æ–¹å·®ä¸º 1 ã€‚\n\t- å°†è¾“å‡ºè¿›è¡Œè¿™æ ·çš„æ ‡å‡†åŒ–æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¼ºçš„çº¦æŸ, è¿™å¹¶ä¸æ€»æ˜¯åˆç†çš„, å› æ­¤æˆ‘ä»¬é€šå¸¸åŒ…å« æ‹‰ä¼¸å‚æ•°ï¼ˆscaleï¼‰ $\\gamma$ å’Œåç§»å‚æ•°ï¼ˆshiftï¼‰ $\\boldsymbol{\\beta}$, å®ƒä»¬çš„å½¢çŠ¶ä¸ $\\mathbf{x}$ ç›¸åŒã€‚\n\t- è¯·æ³¨æ„, $\\gamma$ å’Œ $\\boldsymbol{\\beta}$ æ˜¯éœ€è¦ä¸å…¶ä»–æ¨¡å‹å‚æ•°ä¸€èµ·å­¦ä¹ çš„å‚æ•°ã€‚\n\n- è¯·æ³¨æ„ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•ä½¿ç”¨å¤§å°ä¸º1çš„å°æ‰¹é‡åº”ç”¨æ‰¹é‡è§„èŒƒåŒ–ï¼Œæˆ‘ä»¬å°†æ— æ³•å­¦åˆ°ä»»ä½•ä¸œè¥¿ã€‚ è¿™æ˜¯å› ä¸ºåœ¨å‡å»å‡å€¼ä¹‹åï¼Œæ¯ä¸ªéšè—å•å…ƒå°†ä¸º0ã€‚ æ‰€ä»¥ï¼Œåªæœ‰ä½¿ç”¨è¶³å¤Ÿå¤§çš„å°æ‰¹é‡ï¼Œæ‰¹é‡è§„èŒƒåŒ–è¿™ç§æ–¹æ³•æ‰æ˜¯æœ‰æ•ˆä¸”ç¨³å®šçš„ã€‚ è¯·æ³¨æ„ï¼Œæ‰¹é‡å¤§å°çš„é€‰æ‹©åœ¨æœ‰BNæ—¶æ¯”æ²¡æœ‰BNæ—¶æ›´é‡è¦ã€‚\n\n- æ¯ä¸€ä¸ªæ‰¹é‡çš„å‡å€¼ $\\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}}$ å’Œæ–¹å·® $\\hat{\\boldsymbol{\\sigma}}_{\\mathcal{B}}$ çš„è®¡ç®—å¦‚ä¸‹æ‰€ç¤º:\n\t$$\\begin{aligned}\n\t\\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}} \u0026=\\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} \\mathbf{x} \\\\\n\t\\hat{\\boldsymbol{\\sigma}}_{\\mathcal{B}}^{2} \u0026=\\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}}\\left(\\mathbf{x}-\\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}}\\right)^{2}+\\epsilon\n\t\\end{aligned}$$\n\t- è¯·æ³¨æ„, æˆ‘ä»¬åœ¨æ–¹å·®ä¼°è®¡å€¼ä¸­æ·»åŠ ä¸€ä¸ªå°çš„å¸¸é‡ $\\epsilon\u003e0$, ä»¥ç¡®ä¿å³ä½¿æ–¹å·®å¾ˆå°, æˆ‘ä»¬ä¹Ÿæ°¸è¿œä¸ä¼šé™¤ä»¥é›¶ã€‚\n\t- ä¼°è®¡å€¼ $\\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}}$ å’Œ $\\hat{\\boldsymbol{\\sigma}}_{\\mathcal{B}}$ ä¸Batchçš„éšæœºæ€§å¯†åˆ‡ç›¸å…³, ä¹Ÿå°±æ˜¯è¯´, åœ¨å¯¹è¾“å…¥è¿›è¡Œå½’ä¸€åŒ–çš„åŒæ—¶å…¶å®æ˜¯ä¼šå¼•å…¥å™ªå£°çš„, ã€‚ä½ å¯èƒ½ä¼šè®¤ä¸ºè¿™ç§å™ªå£°æ˜¯ä¸€ä¸ªé—®é¢˜, è€Œäº‹å®ä¸Šå®ƒæ˜¯æœ‰ç›Šçš„ã€‚\n\t\t- This turns out to be a recurring theme in deep learning. For reasons that are not yet well-characterized theoretically, various sources of noise in optimization often lead to faster training and less overfitting: this variation appears to act as a form of regularization. In some preliminary research, [Teye et al., 2018](https://d2l.ai/chapter_references/zreferences.html#teye-azizpour-smith-2018 ) and [Luo et al., 2018](https://d2l.ai/chapter_references/zreferences.html#luo-wang-shao-ea-2018 ) relate the properties of batch normalization to Bayesian priors and penalties respectively. In particular, this sheds some light on the puzzle of why batch normalization works best for moderate minibatches sizes in the 50âˆ¼100 range.[^3]\n\n## å…¶ä»–ç›¸ä¼¼çš„Normalization\n- è¿™é‡Œé¢Næ˜¯æ ·æœ¬çš„ä¸ªæ•°, Dæ˜¯ç‰¹å¾æ•°\n\n![Stanford CS231n BN](notes/2022/2022.3/assets/Stanford%20CS231n%20BN.pdf)\n\n## é¢„æµ‹ä¸è®­ç»ƒçš„ä¸åŒ\n- è®­ç»ƒçš„æ—¶å€™æ˜¯ä»¥Batchè¿›è¡Œçš„, è€Œé¢„æµ‹çš„æ—¶å€™æˆ‘ä»¬é€šå¸¸è¾“å…¥çš„æ˜¯å•å¼ å›¾ç‰‡, é‚£æˆ‘ä»¬æ€ä¹ˆè®¡ç®—å‡å€¼å’Œæ–¹å·®å‘¢? \n\t- æˆ‘ä»¬ä½¿ç”¨è®­ç»ƒæ ·æœ¬æ•´ä½“çš„å‡å€¼å’Œæ–¹å·®æ¥ä»£æ›¿\n\n\n[^1]: è¿™ä¸ªå›¾å±…ç„¶æ˜¯Drawioç”»çš„, å¯æƒœåŸä½œè€…çš„é“¾æ¥æ²¡äº† [calculation of mean and variance in batch normalization in convolutional neural network - Stack Overflow](https://stackoverflow.com/questions/65613694/calculation-of-mean-and-variance-in-batch-normalization-in-convolutional-neural) \n![](notes/2022/2022.3/assets/BatchNormFull.png)\n\n[^2]: åªæ˜¯ä¸ºäº†è§£é‡Šçš„æ¸…æ¥š, å®é™…è®¡ç®—çš„æ—¶å€™å¹¶ä¸æ˜¯æˆ‘è¯´çš„è¿™æ ·çš„\n[^3]: [7.5. Batch Normalization â€” Dive into Deep Learning 0.17.2 documentation](https://d2l.ai/chapter_convolutional-modern/batch-norm.html?highlight=scaling%20issue#training-deep-networks)","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-45-ResNet":{"title":"D2L-45-ResNet","content":"# ResNet æ®‹å·®ç½‘ç»œ\n\n\u003cdiv align=\"right\"\u003e 2022-03-06\u003c/div\u003e\n\nTags: #ResNet #CNN #DeepLearning \n\n- ResNetåœ¨ç½‘ç»œä¸­å¼•å…¥äº†**æ®‹å·®è¿æ¥**çš„æ€æƒ³, ç®€å•çš„æ”¹å˜å¸¦æ¥äº†å¾ˆæ£’çš„æ•ˆæœ.\n\n- æ®‹å·®è¿æ¥è®©æ¯ä¸€å±‚**å¾ˆå®¹æ˜“åœ°åŒ…å«äº†åŸå§‹å‡½æ•°**[^5], è¿™æ ·èƒ½ä¿è¯æ–°å¢åŠ çš„æ¯ä¸€å±‚éƒ½èƒ½åŒ…å«åŸæ¥çš„æœ€ä¼˜è§£, è¿›ä¸€æ­¥åœ¨åŸæ¥çš„åŸºç¡€ä¸Šç»§ç»­æ”¹è¿›.\n\n## Motivation\n### å‡½æ•°ç±»çš„è§’åº¦\n- æˆ‘ä»¬å®šä¹‰ $\\mathcal{F}$ æ˜¯**æŸä¸ªæ¨¡å‹èƒ½å¤Ÿæ‹Ÿåˆçš„æ‰€æœ‰å‡½æ•°**æ„æˆçš„å‡½æ•°ç±».  å³å¯¹äº $\\forall f\\in \\mathcal{F}$,  éƒ½å­˜åœ¨ä¸€ç»„å‚æ•°ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ‹Ÿåˆåˆ° $f$. \n- å‡è®¾å¯¹äºæŸä¸ªé—®é¢˜å­˜åœ¨æœ€ä¼˜çš„å‡½æ•° $f^*$. \n\t- å¦‚æœ $f^*\\in\\mathcal{F}$, é‚£ä¹ˆç½‘ç»œå¾ˆå®¹æ˜“å°±èƒ½æ‰¾åˆ°æœ€ä¼˜è§£. \n\t- ä½†æ˜¯ç”Ÿæ´»æ€»æ˜¯å……æ»¡äº†è‰°è¾›, æˆ‘ä»¬é€šå¸¸éƒ½åªèƒ½å§”æ›²æ±‚å…¨, åœ¨ $\\mathcal{F}$ é‡Œé¢å¯»æ‰¾ä¸€ä¸ªæœ€ä¼˜è¿‘ä¼¼ $f^*_{\\mathcal{F}}$.\n\n- å½¢å¼åŒ–çš„è¯´, æˆ‘ä»¬è®­ç»ƒç½‘ç»œçš„è¿‡ç¨‹å°±æ˜¯åœ¨å¯»æ‰¾: $$f_{\\mathcal{F}}^{*} \\stackrel{\\text { def }}{=} \\underset{f}{\\operatorname{argmin}} L(\\mathbf{X}, \\mathbf{y}, f) \\text { subject to } f \\in \\mathcal{F}$$\n\t- å…¶ä¸­ $L$ æ˜¯æŸå¤±å‡½æ•°.\n\n- ä¸ºäº†æ‰¾åˆ°æ›´å¥½çš„è¿‘ä¼¼è§£, æˆ‘ä»¬éœ€è¦æ”¹è¿›æˆ‘ä»¬çš„æ¨¡å‹: $\\mathcal{F}\\rightarrow \\mathcal{F}'$. ä½†æ˜¯æ–°çš„è¿‘ä¼¼è§£ $f^*_{\\mathcal{F'}}$ æ€»æ˜¯æ›´å¥½çš„å—? \n\t![](notes/2022/2022.3/assets/functionclasses.svg)\n\t- è¦æ˜¯ $\\mathcal{F}\\notin \\mathcal{F}'$, é‚£ä¹ˆæ–°çš„è§£å¯èƒ½è¿˜ä¸å¦‚åŸæ¥çš„è§£. å°±åƒä¸Šå›¾ä¸­è¡¨ç¤ºçš„é‚£æ ·: æˆ‘ä»¬ä¸æ–­åœ°æ”¹è¿›æ¨¡å‹, å‡½æ•°ç±»å´ç¦»æœ€ä¼˜è§£è¶Šæ¥è¶Šè¿œ, æ¨¡å‹çš„è¡¨ç°è¶Šæ¥è¶Šå·®. \n\n\t- ä¸ºäº†ä¿è¯æˆ‘ä»¬èƒ½å¤Ÿè„šè¸å®åœ°å‘ç€ç›®æ ‡å‰è¿›, æˆ‘ä»¬å°±å¿…é¡»è¦ä¿è¯ $\\mathcal{F}\\in \\mathcal{F}'$, è¿™æ ·æ¯ä¸€æ­¥éƒ½æ˜¯åœ¨å‰ä¸€æ¬¡æœ€å¥½ç»“æœçš„åŸºç¡€ä¸Šæ”¹è¿›çš„. \n\t\t- åŠ äº†ä¸€å±‚ç½‘ç»œ, å³ä½¿æ²¡æœ‰å˜å¥½, ä½†è‡³å°‘ä¸ä¼šå˜å·®.\n\n- æ€ä¹ˆè®© $\\mathcal{F}\\in \\mathcal{F}'$ å‘¢? æˆ‘ä»¬å¯ä»¥è®©æ–°çš„ç»“æ„å°½å¯èƒ½ç®€å•åœ°åŒ…å«åŸå§‹å‡½æ•°, æˆ–è€…è¯´è¦è®©æ–°çš„å‡½æ•°å¾ˆå®¹æ˜“å˜æˆæ’ç­‰æ˜ å°„. \n\t- æœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯è®©ç½‘ç»œèƒ½å¤Ÿç›´æ¥è·³è¿‡æ–°çš„ç»“æ„ $f(\\mathbf{x})$\n\t- ä¹Ÿå°±æ˜¯è¯´, è®©ç½‘ç»œçš„è¾“å‡º $g(\\mathbf x)=f(\\mathbf{x})+\\mathbf{x}$. è¿™æ ·åªéœ€è¦è®©æ–°ç»“æ„ $f(\\mathbf{x})$ çš„å‚æ•°å˜æˆ0, å°±èƒ½æ¢å¤åŸæ¥ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›. è¿™å°±æ˜¯æ„å»ºResidual Blockçš„åŸºæœ¬ç›´è§‰.\n\t\t![](notes/2022/2022.3/assets/residual-block.svg)\n### æ·±å±‚ç½‘ç»œçš„è®­ç»ƒå›°å¢ƒ\n- ç°åœ¨è®©æˆ‘ä»¬ä»å¦ä¸€ä¸ªè§’åº¦æ¥è€ƒè™‘æ®‹å·®è¿æ¥çš„æœ‰æ•ˆæ€§. \n- ä¸€æ˜§çš„åŠ æ·±ç¥ç»ç½‘ç»œå¹¶ä¸èƒ½å¸¦æ¥æ¨¡å‹æ€§èƒ½çš„æå‡. è¿™æœ‰æ—¶å€™æ˜¯å› ä¸º [æ¨¡å‹å®¹é‡](notes/2022/2022.2/D2L-21-æ¨¡å‹å®¹é‡.md) ä¸æ•°æ®é›†ä¸åŒ¹é…å¯¼è‡´äº† [è¿‡æ‹Ÿåˆ](notes/2021/2021.8/Part.17_Overfitting_Underfitting(ML_Andrew.Ng.).md), æœ‰æ—¶åˆ™æ˜¯å› ä¸ºè¿‡æ·±çš„ç½‘ç»œé€ æˆäº†æ¢¯åº¦çˆ†ç‚¸æˆ–è€…æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜. \n\t- å¯¹äº [åä¸€ç§é—®é¢˜](notes/2022/2022.2/D2L-24-æ•°å€¼ç¨³å®šæ€§.md),  è°¨æ…åœ°åˆå§‹åŒ–å‚æ•°å¯èƒ½ä¼šæœ‰ä¸€äº›å¸®åŠ©, ä½†æ˜¯è¿™å¹¶ä¸èƒ½ä»æ ¹æœ¬ä¸Šè§£å†³é—®é¢˜. è€Œæ®‹å·®è¿æ¥æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯: ç”¨åŠ æ³•ä»£æ›¿ä¹˜æ³•.[^1]\n\t![LargeGoogLeNet 1|200](notes/2022/2022.3/assets/LargeGoogLeNet%201.jpg)\n- ä¸ºäº†ç®€å•èµ·è§, æˆ‘ä»¬å°†é è¿‘è¾“å…¥çš„ç½‘ç»œæŠ½è±¡ä¸º $f(\\mathbf x)$, é è¿‘è¾“å‡ºçš„ç½‘ç»œè¡¨ç¤ºä¸º $g(\\mathbf x)$. \n\t- å¦‚æœæˆ‘ä»¬å°†å‰ä¸€å±‚ç½‘ç»œçš„è¾“å‡ºä½œä¸ºä¸‹ä¸€å±‚ç½‘ç»œçš„è¾“å…¥, åˆ™æ¨¡å‹è¡¨ç¤ºä¸º $$g\\left(f(\\mathbf x)\\right)$$\n\t\t![SimpleNetAbstract](notes/2022/2022.3/assets/SimpleNetAbstract.svg)\n\t- åµŒå¥—ç½‘ç»œåœ¨ $f(\\mathbf x)$ å±‚çš„æ¢¯åº¦ä¸º: \n\t\t$$\\begin{aligned}\n\t\t\\frac{\\partial}{\\partial\\mathbf{w}}g\\left(f(\\mathbf x)\\right)\u0026=\\frac{\\partial g\\left(f(\\mathbf x)\\right)}{\\partial f(\\mathbf x)}\\frac{\\partial f(\\mathbf x)}{\\partial \\mathbf w}\n\t\t\\end{aligned}$$\n\t\t- å› ä¸ºæ¢¯åº¦æ˜¯åå‘ä¼ æ’­çš„, å¦‚æœç½‘ç»œæ¯”è¾ƒæ·±, è¿™ä¸ªæ¢¯åº¦ä¼šå› ä¸ºçŸ©é˜µè¿ä¹˜å˜å¾—è¾ƒå°[^2] . è¿™è¿›ä¸€æ­¥ä¼šå¯¼è‡´ç½‘ç»œæ·±å±‚çš„æ›´æ–°è¾ƒæ…¢, ç”šè‡³å› ä¸ºæ¢¯åº¦æ¶ˆå¤±è€Œä¸æ”¶æ•›. \n\t\t- ä¸‹å›¾æ˜¯è®ºæ–‡é‡Œé¢æä¾›çš„ä¸€ä¸ªä¾‹å­. å¯ä»¥çœ‹åˆ°æ›´æ·±çš„ç½‘ç»œçš„è®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®éƒ½æ›´é«˜, è¿™è¯´æ˜ç½‘ç»œ\"å­¦ä¸åŠ¨äº†\".\n\t\t\t![](notes/2022/2022.3/assets/Pasted%20image%2020220306200938.png)\n- æˆ‘ä»¬æ¥çœ‹çœ‹æ®‹å·®é“¾æ¥æ˜¯æ€æ ·è§£å†³è¿™ä¸ªé—®é¢˜çš„, å¯¹äºå«æ®‹å·®è¿æ¥çš„ç½‘ç»œ, å¯ä»¥å½¢è±¡åŒ–çš„è¡¨ç¤ºä¸º $$g(\\left(f(\\mathbf x)\\right) +f(\\mathbf x)$$\n\t![ResidualNetAbstract](notes/2022/2022.3/assets/ResidualNetAbstract.svg)\n\t- è¿™ä¸ªç½‘ç»œåœ¨ $f(\\mathbf x)$ å±‚çš„æ¢¯åº¦ä¸º: \n\t\t$$\\begin{aligned}\n\t\t\\frac{\\partial}{\\partial\\mathbf{w}}\\left(g\\left(f(\\mathbf x)\\right)+f(\\mathbf x)\\right)\u0026=\\frac{\\partial g\\left(f(\\mathbf x)\\right)}{\\partial \\mathbf w}+\\frac{\\partial f(\\mathbf x)}{\\partial \\mathbf w}\n\t\t\\end{aligned}$$\n\t\t- å°½ç®¡å‰é¢é‚£éƒ¨åˆ†ä¾ç„¶æœ‰æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜, ä½†æ˜¯åé¢çš„ $\\frac{\\partial f(\\mathbf x)}{\\partial \\mathbf w}$ ä¾ç„¶èƒ½ä¿è¯è®­ç»ƒçš„ç»§ç»­è¿›è¡Œ.\n\n## ç½‘ç»œæ¶æ„\n### æ®‹å·®å—\n![](notes/2022/2022.3/assets/residual-block%201.svg)\n- éµå¾ªä¸Šé¢çš„è®¾è®¡æ€è·¯, ResNetæ®‹å·®å—çš„åŸºæœ¬ç»“æ„å¦‚ä¸Šæ‰€ç¤º\n\n- ResNetæ²¿ç”¨äº†VGGå®Œæ•´çš„ $3Ã—3$ å·ç§¯å±‚è®¾è®¡ã€‚ æ®‹å·®å—é‡Œé¦–å…ˆæœ‰2ä¸ªæœ‰ç›¸åŒè¾“å‡ºé€šé“æ•°çš„ $3Ã—3$ å·ç§¯å±‚ã€‚ æ¯ä¸ªå·ç§¯å±‚åæ¥ä¸€ä¸ªæ‰¹é‡å½’ä¸€åŒ–å±‚(BN)å’ŒReLUæ¿€æ´»å‡½æ•°ã€‚ \n- æ®‹å·®é€šè·¯(Shortcut) åˆ™è·³è¿‡è¿™2ä¸ªå·ç§¯è¿ç®—ï¼Œå°†è¾“å…¥ç›´æ¥åŠ åœ¨æœ€åçš„ReLUæ¿€æ´»å‡½æ•°å‰ã€‚ \n\t- å› ä¸ºéœ€è¦å°†å·ç§¯åçš„è¾“å‡ºä¸æ®‹å·®é€šè·¯ç›¸åŠ , æ‰€ä»¥è¿™æ ·çš„è®¾è®¡è¦æ±‚å·ç§¯å±‚çš„è¾“å…¥è¾“å‡ºå½¢çŠ¶ä¸€æ ·ã€‚ \n\t- å¦‚æœæƒ³æ”¹å˜é€šé“æ•°ï¼Œå°±éœ€è¦å¼•å…¥ä¸€ä¸ªé¢å¤–çš„ $1Ã—1$ å·ç§¯å±‚æ¥å°†è¾“å…¥å˜æ¢æˆéœ€è¦çš„å½¢çŠ¶åå†åšç›¸åŠ è¿ç®—ã€‚ \n\t- æ®‹å·®å—çš„å®ç°å¦‚ä¸‹ï¼š\n\t![](notes/2022/2022.3/assets/resnet-block.svg)\n### ä¸¤ç§ä¸åŒçš„æ®‹å·®å—\n- ResNetéµå¾ªäº†VGGçš„æ¨¡å—æ€æƒ³, å¹¶ä¸”è¿›ä¸€æ­¥ä¸ºä¸åŒè§„æ¨¡çš„æ¨¡å‹æ„å»ºäº†ä¸¤ç§ä¸åŒçš„Building Block:\n\t![](notes/2022/2022.3/assets/Pasted%20image%2020220306204258.png) [^3]\n\t- æ·±å±‚çš„ç½‘ç»œè¾“å…¥é€šé“ä¼šæ›´å¤š, å› æ­¤ResNetå…ˆåˆ©ç”¨ $1\\times1$ çš„å·ç§¯å°†è¾“å…¥é€šé“è¿›è¡Œèåˆ, åœ¨å·ç§¯åå†è¿˜åŸåŸæ¥çš„é€šé“æ•°ç›®.[^4] \n\t- ä¸‹å›¾æ˜¯ä¸åŒè§„æ¨¡ResNetçš„åŸºæœ¬æ¶æ„, å¯ä»¥çœ‹å‡º50å±‚å¾€ä¸Šçš„ResNetéƒ½é‡‡ç”¨äº†ç¬¬äºŒç§æ¶æ„.\n![](notes/2022/2022.3/assets/Pasted%20image%2020220306204536.png) [^3]\n\n### æ‹¼æ¥æ®‹å·®å—: å¤šé˜¶æ®µçš„æ¨¡å‹\n![](notes/2022/2022.3/assets/resnet18.svg)\n- GoogLeNetåœ¨åé¢æ¥äº†4ä¸ªç”±Inceptionå—ç»„æˆçš„æ¨¡å—ã€‚ ResNetåˆ™ä½¿ç”¨4ä¸ªç”±æ®‹å·®å—ç»„æˆçš„æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—ä½¿ç”¨è‹¥å¹²ä¸ªåŒæ ·è¾“å‡ºé€šé“æ•°çš„æ®‹å·®å—ã€‚\n- æ›´è¯¦ç»†çš„æ¨¡å‹å®ç°å‚è§æ•™æ(ResNet18): \n\t[7.6. æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰ ResNetæ¨¡å‹](https://zh-v2.d2l.ai/chapter_convolutional-modern/resnet.html#id4) \n\n\n[^1]: [29.2 ResNetä¸ºä»€ä¹ˆèƒ½è®­ç»ƒå‡º1000å±‚çš„æ¨¡å‹ã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ v2ã€‘ å“”å“©å“”å“© bilibili](https://www.bilibili.com/video/BV1554y157E3)\n[^2]: [D2L-24-æ•°å€¼ç¨³å®šæ€§](notes/2022/2022.2/D2L-24-æ•°å€¼ç¨³å®šæ€§.md) . è¿˜æœ‰å¦‚æœ $g(\\mathbf x)$ å·²ç»å­¦ä¹ çš„è¾ƒå¥½äº†, æ¢¯åº¦ä¹Ÿå¯èƒ½å˜å¾—è¾ƒå°. (åœ¨æŸå¤±å‡½æ•°å–å¾—æ°å½“çš„æ—¶å€™,  ä¸€èˆ¬æ˜¯è¿™æ ·çš„. ä¸€ä¸ªä¾‹å­æ˜¯ [ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE](notes/2022/2022.2/ä¸ºä»€ä¹ˆSoftmaxå›å½’ä¸ç”¨MSE.md))\n[^3]: K. He, X. Zhang, S. Ren, and J. Sun, â€œDeep residual learning for image recognition,â€ in _Proceedings of the IEEE conference on computer vision and pattern recognition_, 2016, pp. 770â€“778. PDF(zotero://select/items/@he2016deep)\n[^4]: è¿™ä½“ç°äº†[D2L-43-GoogLeNet(Inception)](notes/2022/2022.3/D2L-43-GoogLeNet(Inception).md) å’Œ [D2L-42-NiN](notes/2022/2022.3/D2L-42-NiN.md) çš„æ€æƒ³\n[^5]: å¦ä¸€ä¸ªè¯´æ³•æ˜¯å¾ˆå®¹æ˜“è®©ä¸€å±‚ç½‘ç»œå˜æˆæ’ç­‰å‡½æ•° Identity Function","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-46-DenseNet":{"title":"D2L-46-DenseNet","content":"# DenseNet\n\n\u003cdiv align=\"right\"\u003e 2022-03-07\u003c/div\u003e\n\nTags: #DenseNet #DeepLearning #CNN \n![](notes/2022/2022.3/assets/img_2022-10-15-3.png)\n\n- ResNetæå¤§åœ°æ”¹å˜äº†å¦‚ä½•å‚æ•°åŒ–æ·±å±‚ç½‘ç»œä¸­å‡½æ•°çš„è§‚ç‚¹ã€‚ ç¨ å¯†è¿æ¥ç½‘ç»œï¼ˆDenseNetï¼‰åœ¨æŸç§ç¨‹åº¦ä¸Šæ˜¯**ResNetçš„é€»è¾‘æ‰©å±•**ã€‚\n\n- PDF(zotero://select/items/@huang2017densely) \n\n## æ•°å­¦ç›´è§‰: ä»ResNetåˆ°DenseNet\n- æŸä¸ªå‡½æ•°åœ¨ $x=0$ å¤„çš„æ³°å‹’å±•å¼€ä¸º: \n\t$$f(x)=f(0)+f^{\\prime}(0) x+\\frac{f^{\\prime \\prime}(0)}{2 !} x^{2}+\\frac{f^{\\prime \\prime \\prime}(0)}{3 !} x^{3}+\\ldots$$\n\t- è¿™å…¶ä¸­çš„æ€æƒ³æ˜¯: æŠŠäº‹ç‰©åˆ†è§£ä¸ºå¤æ‚åº¦ä¸æ–­é€’å¢çš„é¡¹\n\t- ResNetå…¶å®ä¹Ÿä½“ç°äº†è¿™ç§æ€æƒ³: $$f(\\mathbf{x})=\\mathbf{x}+g(\\mathbf{x})$$\n\t\tå®ƒå°† $f(\\mathbf{x})$ åˆ†è§£ä¸ºäº†ç®€å•çš„çº¿æ€§é¡¹ $\\mathbf{x}$ ä¸å¤æ‚çš„éçº¿æ€§é¡¹ $g(\\mathbf{x})$.\n\n- æˆ‘ä»¬å¯ä»¥æ€æ ·å°†è¿™ç§æ€æƒ³è¿›ä¸€æ­¥æ¨å¹¿å‘¢?  \n\t- æˆ‘ä»¬éœ€è¦åˆ›å»ºæ›´å¤æ‚çš„è¿æ¥\n\t![ResNet2DenseNet|300](notes/2022/2022.3/assets/ResNet2DenseNet.svg)\n\t- è¿›ä¸€æ­¥, æˆ‘ä»¬ä½¿ç”¨\"æ‹¼æ¥\"(_concatenation_)ä»£æ›¿åŠ æ³•.\n\t![](notes/2022/2022.3/assets/densenet-block.svg)\n\t- æ–°çš„è¿æ¥ä½¿å¾—æœ€åçš„è¾“å‡ºæ˜¯å„ç§ä¸åŒå¤æ‚åº¦çš„é¡¹çš„èšåˆ: \n\t\t$$\\mathbf{x} \\rightarrow\\left[\n\t\\textcolor[RGB]{157, 72, 68}{\\mathbf{x}}, \n\t\\textcolor[RGB]{255, 116, 109}{f_{1}(\\mathbf{x})}, \n\t\\textcolor[RGB]{255, 154, 109}{f_{2}\\left(\\left[\\mathbf{x}, f_{1}(\\mathbf{x})\\right]\\right)}, \n\t\\textcolor[RGB]{255, 211, 109}{f_{3}\\left(\\left[\\mathbf{x}, f_{1}(\\mathbf{x}), f_{2}\\left(\\left[\\mathbf{x}, f_{1}(\\mathbf{x})\\right]\\right)\\right]\\right)},\n\t\\ldots\\right]$$\n\t![](notes/2022/2022.3/assets/densenet.svg)\n\t- å¯ä»¥çœ‹åˆ°å‡½æ•°ä¾èµ–å›¾å˜å¾—ååˆ†çš„\"ç¨ å¯†\"(Dense), è¿™ä¹Ÿæ˜¯DenseNetåå­—çš„ç”±æ¥.\n- ä¸ºäº†ä½¿ç½‘ç»œä¸ä¼šè¿‡äºå¤æ‚, æˆ‘ä»¬ä½¿ç”¨1x1å·ç§¯æ ¸æ± åŒ–æ¥æ§åˆ¶é€šé“çš„æ•°é‡.\n\n## ç½‘ç»œæ¶æ„\n- DenseNetç”±ç›¸äº’åˆ¶çº¦çš„ä¸¤ä¸ªç»„ä»¶æ„æˆ: **ç¨ å¯†å—**(*Dense Block*)å’Œ**è¿‡æ¸¡å±‚**(*Transition Layer*). \n\t- å‰è€…å®šä¹‰å¦‚ä½•è¿æ¥è¾“å…¥å’Œè¾“å‡ºï¼Œè€Œåè€…åˆ™æ§åˆ¶é€šé“æ•°é‡ï¼Œä½¿å…¶ä¸ä¼šå¤ªå¤æ‚ã€‚\n\n### ç¨ å¯†å—\n- DenseNetä½¿ç”¨äº†ResNetæ”¹è‰¯ç‰ˆçš„â€œæ‰¹é‡è§„èŒƒåŒ–ã€æ¿€æ´»å’Œå·ç§¯â€æ¶æ„.[^1]\n- ä¸€ä¸ª_ç¨ å¯†å—_ç”±å¤šä¸ªå·ç§¯å—ç»„æˆï¼Œæ¯ä¸ªå·ç§¯å—ä½¿ç”¨ç›¸åŒæ•°é‡çš„è¾“å‡ºé€šé“ã€‚ åœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œæˆ‘ä»¬ä¸å†å°†å¤šè·¯è¾“å‡ºç›¸åŠ , è€Œæ˜¯ç›´æ¥åœ¨é€šé“ä¸Šç›¸è¿(Concatenate).\n\n- è¯¦ç»†å®ç°å‚è§ : [7.7. Densely Connected Networks (DenseNet) â€” Dense Block](https://d2l.ai/chapter_convolutional-modern/densenet.html#dense-blocks)\n### è¿‡æ¸¡å±‚\n- ç”±äºæ¯ä¸ªç¨ å¯†å—éƒ½ä¼šå¸¦æ¥é€šé“æ•°çš„å¢åŠ ï¼Œä½¿ç”¨è¿‡å¤šåˆ™ä¼šè¿‡äºå¤æ‚åŒ–æ¨¡å‹ã€‚ è€Œè¿‡æ¸¡å±‚å¯ä»¥ç”¨æ¥æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚ å®ƒé€šè¿‡1Ã—1å·ç§¯å±‚æ¥å‡å°é€šé“æ•°ï¼Œå¹¶ä½¿ç”¨æ­¥å¹…ä¸º2çš„å¹³å‡æ±‡èšå±‚å‡åŠé«˜å’Œå®½ï¼Œä»è€Œè¿›ä¸€æ­¥é™ä½æ¨¡å‹å¤æ‚åº¦ã€‚\n\n- è¯¦ç»†å®ç°å‚è§ : [7.7. Densely Connected Networks (DenseNet) â€”Transition Layer](https://d2l.ai/chapter_convolutional-modern/densenet.html#transition-layers)\n\n### DenseNet\n- DenseNeté¦–å…ˆä½¿ç”¨åŒResNetä¸€æ ·çš„å•å·ç§¯å±‚å’Œæœ€å¤§æ±‡èšå±‚ã€‚\n- æ¥ä¸‹æ¥ï¼Œç±»ä¼¼äºResNetä½¿ç”¨çš„4ä¸ªæ®‹å·®å—ï¼ŒDenseNetä½¿ç”¨çš„æ˜¯4ä¸ªç¨ å¯†å—ã€‚ ä¸ResNetç±»ä¼¼ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®æ¯ä¸ªç¨ å¯†å—ä½¿ç”¨å¤šå°‘ä¸ªå·ç§¯å±‚ã€‚\n- åœ¨æ¯ä¸ªæ¨¡å—ä¹‹é—´ï¼ŒResNeté€šè¿‡æ­¥å¹…ä¸º2çš„æ®‹å·®å—å‡å°é«˜å’Œå®½ï¼ŒDenseNetåˆ™ä½¿ç”¨è¿‡æ¸¡å±‚æ¥å‡åŠé«˜å’Œå®½ï¼Œå¹¶å‡åŠé€šé“æ•°ã€‚\n\n- ä¸ResNetç±»ä¼¼ï¼Œæœ€åæ¥ä¸Šå…¨å±€æ±‡èšå±‚å’Œå…¨è¿æ¥å±‚æ¥è¾“å‡ºç»“æœã€‚\n\n- è¯¦ç»†å®ç°å‚è§ : [7.7. Densely Connected Networks (DenseNet) â€” DenseNet](https://d2l.ai/chapter_convolutional-modern/densenet.html#densenet-model)\n\n[^1]: He, K., Zhang, X., Ren, S., \u0026 Sun, J. (2016). Identity mappings in deep residual networks. _European conference on computer vision_ (pp.Â 630â€“645).","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-47-%E5%BA%8F%E5%88%97%E4%BF%A1%E6%81%AF":{"title":"D2L-47-åºåˆ—ä¿¡æ¯","content":"# åºåˆ—ä¿¡æ¯\n\n\u003cdiv align=\"right\"\u003e 2022-03-07\u003c/div\u003e\n\nTags: #SequentialData\n\n## æ•°æ®åˆ†å¸ƒçš„ä¸åŒ\n- å¯¹äºå›¾åƒæˆ–è€…è¡¨æ ¼æ•°æ®ï¼Œ æˆ‘ä»¬é€šå¸¸éƒ½å‡è®¾æ‰€æœ‰æ ·æœ¬æ˜¯**ç‹¬ç«‹åŒåˆ†å¸ƒ**çš„[^1]ã€‚ ç„¶è€Œï¼Œå¤§å¤šæ•°çš„æ•°æ®éƒ½æœ‰åºåˆ—æ€§ã€‚ \n\t- ä¾‹å¦‚ï¼Œæ–‡ç« ä¸­çš„å•è¯æ˜¯æŒ‰é¡ºåºå†™çš„ï¼Œå¦‚æœé¡ºåºè¢«éšæœºåœ°é‡æ’ï¼Œå°±å¾ˆéš¾ç†è§£æ–‡ç« åŸå§‹çš„æ„æ€ã€‚ åŒæ ·ï¼Œè§†é¢‘ä¸­çš„å›¾åƒå¸§ã€å¯¹è¯ä¸­çš„éŸ³é¢‘ä¿¡å·ä»¥åŠç½‘ç«™ä¸Šçš„æµè§ˆè¡Œä¸ºéƒ½æ˜¯æœ‰é¡ºåºçš„ã€‚ å› æ­¤ï¼Œé’ˆå¯¹æ­¤ç±»æ•°æ®è€Œè®¾è®¡ç‰¹å®šæ¨¡å‹ï¼Œå¯èƒ½æ•ˆæœä¼šæ›´å¥½ã€‚\n\n## å®é™…æƒ…æ™¯\n- åœ¨æ¥æ”¶ä¸€ä¸ªåºåˆ—ä½œä¸ºè¾“å…¥çš„æ—¶å€™ï¼Œ æˆ‘ä»¬é€šå¸¸æœŸæœ›çŒœæµ‹è¿™ä¸ªåºåˆ—çš„åç»­ã€‚ \n\t- ä¾‹å¦‚é¢„æµ‹è‚¡å¸‚çš„æ³¢åŠ¨ã€ æ‚£è€…çš„ä½“æ¸©æ›²çº¿æˆ–è€…èµ›è½¦æ‰€éœ€çš„åŠ é€Ÿåº¦ã€‚ æˆ‘ä»¬éœ€è¦èƒ½å¤Ÿå¤„ç†è¿™äº›æ•°æ®çš„ç‰¹å®šæ¨¡å‹ã€‚\n\n## ç›¸å…³æ¨¡å‹\n- å¦‚æœè¯´å·ç§¯ç¥ç»ç½‘ç»œå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ç©ºé—´ä¿¡æ¯ï¼Œ é‚£ä¹ˆ _å¾ªç¯ç¥ç»ç½‘ç»œ_ï¼ˆrecurrent neural networkï¼ŒRNNï¼‰åˆ™å¯ä»¥æ›´å¥½åœ°å¤„ç†åºåˆ—ä¿¡æ¯ã€‚ \n\n#todo \n\n\n[^1]: è¿™çœŸçš„åˆç†å—ï¼Ÿ","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-48-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B-Sequence_Models":{"title":"D2L-48-åºåˆ—æ¨¡å‹-Sequence_Models","content":"# åºåˆ—æ¨¡å‹ - Sequence Models\n\n\u003cdiv align=\"right\"\u003e 2022-03-07\u003c/div\u003e\n\nTags: #SequenceModel #SequentialData\n\n- ä¸¤ç§æµè¡Œçš„åºåˆ—æ¨¡å‹æ˜¯**è‡ªå›å½’æ¨¡å‹**å’Œ**éšå˜é‡è‡ªå›å½’æ¨¡å‹**\n\n## é¢„æµ‹é—®é¢˜\n![](notes/2022/2022.3/assets/img_2022-10-15-4.png)\n- å‡è®¾æˆ‘ä»¬æƒ³è¦æ ¹æ®å‰ $t-1$ å¤©çš„è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ä»Šå¤©çš„è‚¡ç¥¨ä»·æ ¼ $x_t$, è¿™ä¸ªé—®é¢˜å¯ä»¥æŠ½è±¡ä¸ºï¼š $$x_{t} \\sim P\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{1}\\right)$$\n\t- é—®é¢˜çš„å…³é”®åœ¨äºä¼°è®¡ $P\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{1}\\right)$\n\n- ä¸€ä¸ªç®€å•çš„æƒ³æ³•æ˜¯ä½¿ç”¨**å›å½’**æ¨¡å‹æ¥ä¼°è®¡æ¦‚ç‡ã€‚ä½†æ˜¯æˆ‘ä»¬é¦–å…ˆéœ€è¦è§£å†³è¿™ä¹ˆä¸€ä¸ªé—®é¢˜ï¼š éšç€æ—¶é—´çš„æµé€ï¼Œæ¨¡å‹çš„è¾“å…¥ $x_1, \\cdotsï¼Œx_{t-1}$ ä¼šä¸æ–­å¢åŠ ï¼Œè®¡ç®—ä¼šå˜å¾—è¶Šæ¥è¶Šå›°éš¾ï¼Œç›´åˆ°ä¸å¯æ¥å—ã€‚\n- åŸºäºä¸åŒçš„å‡è®¾ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸¤ç§æ¨¡å‹ï¼š**è‡ªå›å½’æ¨¡å‹** å’Œ **éšå˜é‡è‡ªå›å½’æ¨¡å‹**\n\n## è‡ªå›å½’æ¨¡å‹ Autoregressive Models\n- è‡ªå›å½’æ¨¡å‹çš„å‡è®¾æ˜¯ï¼š åªæœ‰**æœ€è¿‘ä¸€æ®µæ—¶é—´çš„æ•°æ®**æ˜¯æœ‰ç”¨çš„ï¼Œè¿™è¢«ç§°ä¸ºé©¬å°”å¯å¤«æ¡ä»¶(Markov condition)ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦è€ƒè™‘ä¸€ä¸ªæ—¶é—´è·¨åº¦ $\\tau$ é‡Œé¢çš„æ‰€æœ‰æ•°æ®: $x_{t-1}, \\ldots, x_{t-\\tau}$.\n\t- å› ä¸ºè¾“å…¥çš„é•¿åº¦æ˜¯ä¸å˜çš„ï¼Œæ‰€ä»¥æ¨¡å‹çš„å‚æ•°ä¹Ÿæ˜¯ä¸å˜çš„. \n\n- å› ä¸ºæ¨¡å‹æ ¹æ® $x_{t-1}, \\ldots, x_{t-\\tau}$ é¢„æµ‹ $x_t$,  ç›¸å½“äºæ˜¯åœ¨å¯¹å˜é‡ $x$ è‡ªèº«è¿›è¡Œå›å½’. æ•…ç§°æ¨¡å‹ä¸º\"è‡ªå›å½’æ¨¡å‹\".\n\n- å¦‚æœå°†æ¨¡å‹è¡¨ç¤ºä¸º $f(x)$, åˆ™è‡ªå›å½’æ¨¡å‹å¯ä»¥æŠ½è±¡ä¸º: $$p\\left(x_{t} \\mid x_{t-1}, \\ldots x_{1}\\right)=p\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{t-\\tau}\\right)=p\\left(x_{t} \\mid f\\left(x_{t-1}, \\ldots, x_{t-\\tau}\\right)\\right)$$\n\n\n### é©¬å°”å¯å¤«æ¨¡å‹\n- æ»¡è¶³é©¬å°”å¯å¤«æ¡ä»¶çš„æ¨¡å‹ç§°ä¸º**é©¬å°”å¯å¤«æ¨¡å‹**(Markov Model). æ ¹æ® $\\tau$ çš„ä¸åŒå–å€¼, æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸åŒ\"é˜¶æ•°\"çš„æ¨¡å‹:\n\t- $\\tau=1$ : ä¸€é˜¶é©¬å°”å¯å¤«æ¨¡å‹ $$P\\left(x_{1}, \\ldots, x_{T}\\right)=\\prod_{t=1}^{T} P\\left(x_{t} \\mid x_{t-1}\\right) \\text { å½“ } P\\left(x_{1} \\mid x_{0}\\right)=P\\left(x_{1}\\right)$$\n\t\t- å½“ $x_i$ å–ç¦»æ•£å€¼çš„æ—¶å€™, ä¸€é˜¶é©¬å°”å¯å¤«æ¨¡å‹å¯ä»¥ä½¿ç”¨**åŠ¨æ€è§„åˆ’**å¯ä»¥æ²¿ç€é©¬å°”å¯å¤«é“¾ç²¾ç¡®åœ°è®¡ç®—ç»“æœ. æ¯”å¦‚: $$\\begin{aligned}\n\t\tP\\left(x_{t+1} \\mid x_{t-1}\\right) \u0026=\\frac{\\sum_{x_{t}} P\\left(x_{t+1}, x_{t}, x_{t-1}\\right)}{P\\left(x_{t-1}\\right)} \\\\\n\t\t\u0026=\\frac{\\sum_{x_{t}} \\textcolor{red}{P\\left(x_{t+1} \\mid x_{t}, x_{t-1}\\right)} P\\left(x_{t}, x_{t-1}\\right)}{P\\left(x_{t-1}\\right)} \\\\\n\t\t\u0026=\\sum_{x_{t}} \\textcolor{red}{P\\left(x_{t+1} \\mid x_{t}\\right)} P\\left(x_{t} \\mid x_{t-1}\\right)\n\t\t\\end{aligned}$$\n\t\t- çº¢è‰²çš„éƒ¨åˆ†åˆ©ç”¨äº†é©¬å°”å¯å¤«æ¡ä»¶, æˆ‘ä»¬ä¸éœ€è¦è€ƒè™‘ $x_{t-1}$ å³å¯æ±‚å¾—ç»“æœ.\n\n## éšå˜é‡è‡ªå›å½’æ¨¡å‹ Latent Autoregressive Models\n- è¿™ä¸ªæ¨¡å‹çš„å‡è®¾æ˜¯: \"ä¹‹å‰æ‰€æœ‰è¾“å…¥éƒ½å¯ä»¥æ€»ç»“ä¸ºéšå˜é‡ $h_{t}$ \", æˆ‘ä»¬å¯ä»¥æ ¹æ®éšå˜é‡æ¥é¢„æµ‹ $x_t$ \n\t![](notes/2022/2022.3/assets/sequence-model.svg)\n\t- å¦‚ä¸Šå›¾æ‰€ç¤º, æˆ‘ä»¬ä¿ç•™ä¸€äº›å¯¹è¿‡å»è§‚æµ‹çš„æ€»ç»“ $h_{t}$ , åŒæ—¶æ›´æ–°é¢„æµ‹ $\\hat{x}_{t}$ å’Œæ€»ç»“ $h_{t}$ ã€‚ä¹Ÿå°±æ˜¯åŸºäº $\\hat{x}_{t}=P\\left(x_{t} \\mid h_{t}\\right)$ æ¥ä¼°è®¡ $x_{t}$ .\n\n- æœ‰æ—¶ä¹Ÿå¯ä»¥å†™æˆè¿™æ ·: æ ¹æ®ä¸Šä¸€æ¬¡è¾“å‡ºä¸æ½œå˜é‡ä¸€èµ·å†³å®šè¿™ä¸€æ¬¡çš„è¾“å‡º.\n![](notes/2022/2022.3/assets/Pasted%20image%2020220308193240.png)\n\n\n## Stationary Dynamics\n- å‡è®¾ä¸Šé¢çš„æ¨¡å‹èƒ½å¤ŸæˆåŠŸåœ°é¢„æµ‹è‚¡ä»·, æˆ‘ä»¬çš„æ¨¡å‹åˆ°åº•å­¦åˆ°äº†ä»€ä¹ˆå‘¢? \n\t- æ¨¡å‹çš„è¾“å‡ºæ˜¯åœ¨ä¸æ–­åœ°å˜åŒ–çš„, è€Œæˆ‘ä»¬çš„æ¨¡å‹å­¦ä¹ åˆ°çš„åº”è¯¥æ˜¯è¿™ç§å˜åŒ–èƒŒåçš„è§„å¾‹(Dynamics). å¦‚æœè¿™ä¸ªè§„å¾‹ä¸ä¼šå˜åŒ–, æˆ‘ä»¬å°±ç§°å…¶ä¸º\"é™æ­¢çš„\"è§„å¾‹ (Dynamics, åŠ¨åŠ›å­¦).\n\n## å› æœå…³ç³» Causality\n- æˆ‘ä»¬å¯ä»¥è¿™æ ·è¡¨ç¤ºä¸€ä¸ªåºåˆ—çš„æ€»æ¦‚ç‡: \n\t$$P\\left(x_{1}, \\ldots, x_{T}\\right)=\\prod_{t=1}^{T} P\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{1}\\right)$$ ^973ecf\n- ä½†æ˜¯, æ•°å­¦ä¸Šæˆ‘ä»¬å®Œå…¨ä¹Ÿå¯ä»¥åè¿‡æ¥å†™: \n\t$$P\\left(x_{1}, \\ldots, x_{T}\\right)=\\prod_{t=T}^{1} P\\left(x_{t} \\mid x_{t+1}, \\ldots, x_{T}\\right)$$\n\t- ä½†æ˜¯è¿™æ„å‘³ç€ç°åœ¨çš„äº‹ä»¶å½±å“äº†è¿‡å»çš„äº‹ä»¶! ä½†æ˜¯è¿™æœ‰æ„ä¹‰å—?\n\t- åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ•°æ®å­˜åœ¨ä¸€ä¸ªè‡ªç„¶çš„æ–¹å‘ï¼Œå³åœ¨æ—¶é—´ä¸Šæ˜¯å‰è¿›çš„ã€‚ å¾ˆæ˜æ˜¾ï¼Œæœªæ¥çš„äº‹ä»¶ä¸èƒ½å½±å“è¿‡å»ã€‚ å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æ”¹å˜ $x_t$ï¼Œå¯èƒ½ä¼šå½±å“æœªæ¥å‘ç”Ÿçš„äº‹æƒ… $x_{t+1}$ ï¼Œä½†ä¸èƒ½åè¿‡æ¥ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœæˆ‘ä»¬æ”¹å˜ $x_t$ ï¼ŒåŸºäºè¿‡å»äº‹ä»¶å¾—åˆ°çš„åˆ†å¸ƒä¸ä¼šæ”¹å˜ã€‚ å› æ­¤ï¼Œè§£é‡ŠP $(x_{t+1}âˆ£x_t)$ åº”è¯¥æ¯”è§£é‡Š $P(x_tâˆ£x_{t+1})$ æ›´å®¹æ˜“ã€‚  ^f8bb86\n\n\t\t- ä¾‹å¦‚ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯¹äºæŸäº›å¯åŠ æ€§å™ªå£° $Ïµ$ï¼Œ æ˜¾ç„¶æˆ‘ä»¬å¯ä»¥æ‰¾åˆ° $x_{t+1}=f(x_t)+Ïµ$ï¼Œ è€Œåä¹‹åˆ™ä¸è¡Œ [Hoyer et al., 2009](https://zh-v2.d2l.ai/chapter_references/zreferences.html#hoyer-janzing-mooij-ea-2009 )ã€‚ è¿™æ˜¯ä¸ªå¥½æ¶ˆæ¯ï¼Œå› ä¸ºè¿™ä¸ªå‰è¿›æ–¹å‘é€šå¸¸ä¹Ÿæ˜¯æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ–¹å‘ã€‚\n\n## kæ­¥é¢„æµ‹\n- å¯¹äºç›´åˆ°æ—¶é—´æ­¥ $t$ çš„è§‚æµ‹åºåˆ—ï¼Œå…¶åœ¨æ—¶é—´æ­¥ $t+k$ çš„é¢„æµ‹è¾“å‡ºæ˜¯â€œ $k$ æ­¥é¢„æµ‹â€ã€‚\n- ä¾‹å¦‚5æ­¥é¢„æµ‹å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹: \n$$\\begin{aligned}\n\u0026\\textcolor{blue}{\\hat{x}_{5}}=f\\left(x_{1}, x_{2}, x_{3}, x_{4}\\right) \\\\\n\u0026\\textcolor{blue}{\\hat{x}_{6}}=f\\left(x_{2}, x_{3}, x_{4}, \\textcolor{blue}{\\hat{x}_{5}}\\right) \\\\\n\u0026\\textcolor{blue}{\\hat{x}_{7}}=f\\left(x_{3}, x_{4}, \\textcolor{blue}{\\hat{x}_{5}}, \\textcolor{blue}{\\hat{x}_{6}}\\right) \\\\\n\u0026\\textcolor{blue}{\\hat{x}_{8}}=f\\left(x_{4}, \\textcolor{blue}{\\hat{x}_{5}}, \\textcolor{blue}{\\hat{x}_{6}}, \\textcolor{blue}{\\hat{x}_{7}}\\right) \\\\\n\u0026\\textcolor{blue}{\\hat{x}_{9}}=f\\left(\\textcolor{blue}{\\hat{x}_{5}}, \\textcolor{blue}{\\hat{x}_{6}}, \\textcolor{blue}{\\hat{x}_{7}}, \\textcolor{blue}{\\hat{x}_{8}}\\right)\n\\end{aligned}$$\n- ä½†æ˜¯éšç€æˆ‘ä»¬å¯¹é¢„æµ‹æ—¶é—´ $k$ å€¼çš„å¢åŠ ï¼Œä¼šé€ æˆè¯¯å·®çš„å¿«é€Ÿç´¯ç§¯å’Œé¢„æµ‹è´¨é‡çš„æ€¥é€Ÿä¸‹é™ã€‚\n\t![](notes/2022/2022.3/assets/kStepPredict.svg)","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-49-%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86-Text-Preprocessing":{"title":"D2L-49-æ–‡æœ¬é¢„å¤„ç†-Text Preprocessing","content":"# æ–‡æœ¬é¢„å¤„ç†\n\n\u003cdiv align=\"right\"\u003e 2022-03-08\u003c/div\u003e\n\nTags: #Preprocessing \n\n- åŠ¨æ‰‹æ˜¯æœ€å¥½çš„å­¦ä¹ : [8.2. æ–‡æœ¬é¢„å¤„ç† â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/text-preprocessing.html)\n\n- ä¸€äº›å¸¸è§çš„æ“ä½œ:\n\t1.  å°†æ–‡æœ¬ä½œä¸ºå­—ç¬¦ä¸²åŠ è½½åˆ°å†…å­˜ä¸­ã€‚\n\t2.  å°†å­—ç¬¦ä¸²æ‹†åˆ†ä¸ºè¯å…ƒï¼ˆå¦‚å•è¯å’Œå­—ç¬¦ï¼‰ã€‚Tokenize\n\t3.  å»ºç«‹ä¸€ä¸ªè¯è¡¨ï¼Œå°†æ‹†åˆ†çš„è¯å…ƒæ˜ å°„åˆ°æ•°å­—ç´¢å¼•ã€‚\n\t4.  å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—ç´¢å¼•åºåˆ—ï¼Œæ–¹ä¾¿æ¨¡å‹æ“ä½œã€‚\n\n- è¯­æ–™ in English: corpus\n\n- è¯­æ–™åº“ä¸­ä¸å­˜åœ¨æˆ–å·²åˆ é™¤çš„ä»»ä½•è¯å…ƒéƒ½å°†æ˜ å°„åˆ°ä¸€ä¸ªç‰¹å®šçš„æœªçŸ¥è¯å…ƒ `\u003cunk\u003e` ã€‚ æˆ‘ä»¬å¯ä»¥é€‰æ‹©å¢åŠ ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºä¿å­˜é‚£äº›è¢«ä¿ç•™çš„è¯å…ƒï¼Œ ä¾‹å¦‚ï¼šå¡«å……è¯å…ƒï¼ˆ `\u003cpad` \u003eï¼‰ï¼› åºåˆ—å¼€å§‹è¯å…ƒï¼ˆ `\u003cbos\u003e` ï¼‰ï¼› åºåˆ—ç»“æŸè¯å…ƒï¼ˆ `\u003ceos\u003e` ï¼‰ã€‚\n\t- å°–æ‹¬å·é€šå¸¸ç”¨æ¥è¡¨ç¤ºç‰¹æ®Šå­—ç¬¦\n\n","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-50-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-%E4%BC%A0%E7%BB%9F%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8D%E8%B6%B3":{"title":"D2L-50-è¯­è¨€æ¨¡å‹-ä¼ ç»Ÿæ¨¡å‹çš„ä¸è¶³","content":"# è¯­è¨€æ¨¡å‹\n\n\u003cdiv align=\"right\"\u003e 2022-03-08\u003c/div\u003e\n\nTags: #LanguageModel\n\n## ä¼ ç»Ÿæ¨¡å‹\n- è¯­è¨€æ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ä¸ªæ–‡æœ¬åºåˆ—: $$x_{t},\\space x_{t-1},\\space \\ldots\\space ,\\space x_{1}$$\n\t- ä¸ºäº†ç”Ÿæˆæœ‰æ„ä¹‰çš„åºåˆ—, æˆ‘ä»¬å¸Œæœ›æ¨¡æ‹Ÿè¯­æ–™åº“é‡Œé¢çš„è¯­å¥, ç”Ÿæˆæ¦‚ç‡ $P\\left(x_{1}, x_{2}, \\ldots, x_{T}\\right)$ æœ€é«˜çš„è¯­å¥.\n\n![](notes/2022/2022.3/D2L-48-åºåˆ—æ¨¡å‹-Sequence_Models.md#^973ecf)\n\n- ä¸€ä¸ªä¾‹å­æ˜¯ $$\\begin{aligned}\u0026P(deep, learning, is, fun)=\\\\\u0026P(deep) P(learning\\mid deep ) P( is  \\mid  deep, learning ) P( fun  \\mid  deep, learning, is )\\end{aligned}$$\n\n- ä¸ºäº†ä¼°è®¡è¿™ä¸ªå¥å­çš„æ¦‚ç‡, æˆ‘ä»¬éœ€è¦è®¡ç®—é‡Œé¢çš„æ¯ä¸€ä¸ªéƒ¨åˆ†, ä¸€ä¸ªæƒ³æ³•æ˜¯ç”¨é¢‘ç‡ä»£æ›¿æ¦‚ç‡: $$\\hat{P}(\\text { learning } \\mid \\text { deep })=\\frac{n(\\text { deep }, \\text { learning })}{n(\\text { deep })}$$\n- ä½†æ˜¯: \n\u003e ä¸å¹¸çš„æ˜¯ï¼Œç”±äºè¿ç»­å•è¯å¯¹â€œdeep learningâ€çš„å‡ºç°é¢‘ç‡è¦ä½å¾—å¤šï¼Œ æ‰€ä»¥ä¼°è®¡è¿™ç±»å•è¯æ­£ç¡®çš„æ¦‚ç‡è¦å›°éš¾å¾—å¤šã€‚ ç‰¹åˆ«æ˜¯å¯¹äºä¸€äº›ä¸å¸¸è§çš„å•è¯ç»„åˆï¼Œè¦æƒ³æ‰¾åˆ°è¶³å¤Ÿçš„å‡ºç°æ¬¡æ•°æ¥è·å¾—å‡†ç¡®çš„ä¼°è®¡å¯èƒ½éƒ½ä¸å®¹æ˜“ã€‚ è€Œå¯¹äºä¸‰ä¸ªæˆ–è€…æ›´å¤šçš„å•è¯ç»„åˆï¼Œæƒ…å†µä¼šå˜å¾—æ›´ç³Ÿã€‚ è®¸å¤šåˆç†çš„ä¸‰ä¸ªå•è¯ç»„åˆå¯èƒ½æ˜¯å­˜åœ¨çš„ï¼Œä½†æ˜¯åœ¨æ•°æ®é›†ä¸­å´æ‰¾ä¸åˆ°ã€‚ é™¤éæˆ‘ä»¬æä¾›æŸç§è§£å†³æ–¹æ¡ˆï¼Œæ¥å°†è¿™äº›å•è¯ç»„åˆæŒ‡å®šä¸ºéé›¶è®¡æ•°ï¼Œ å¦åˆ™å°†æ— æ³•åœ¨è¯­è¨€æ¨¡å‹ä¸­ä½¿ç”¨å®ƒä»¬ã€‚ å¦‚æœæ•°æ®é›†å¾ˆå°ï¼Œæˆ–è€…å•è¯éå¸¸ç½•è§ï¼Œé‚£ä¹ˆè¿™ç±»å•è¯å‡ºç°ä¸€æ¬¡çš„æœºä¼šå¯èƒ½éƒ½æ‰¾ä¸åˆ°ã€‚[^1]\n\n### æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘\n- ä¸€ç§å¸¸è§çš„ç­–ç•¥æ˜¯æ‰§è¡Œ **æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘**ï¼ˆLaplace smoothingï¼‰ï¼Œ å…·ä½“æ–¹æ³•æ˜¯åœ¨æ‰€æœ‰è®¡æ•°ä¸­æ·»åŠ ä¸€ä¸ªå°å¸¸é‡ã€‚ ç”¨ $n$ è¡¨ç¤ºè®­ç»ƒé›†ä¸­çš„å•è¯æ€»æ•°ï¼Œç”¨ $m$ è¡¨ç¤ºå”¯ä¸€å•è¯çš„æ•°é‡ã€‚ æ­¤è§£å†³æ–¹æ¡ˆæœ‰åŠ©äºå¤„ç†å•å…ƒç´ é—®é¢˜ï¼Œä¾‹å¦‚é€šè¿‡ï¼š\n$$\\begin{aligned}\n\\hat{P}(x) \u0026=\\frac{n(x)+\\epsilon_{1} / m}{n+\\epsilon_{1}} \\\\\n\\hat{P}\\left(x^{\\prime} \\mid x\\right) \u0026=\\frac{n\\left(x, x^{\\prime}\\right)+\\epsilon_{2} \\hat{P}\\left(x^{\\prime}\\right)}{n(x)+\\epsilon_{2}} \\\\\n\\hat{P}\\left(x^{\\prime \\prime} \\mid x, x^{\\prime}\\right) \u0026=\\frac{n\\left(x, x^{\\prime}, x^{\\prime \\prime}\\right)+\\epsilon_{3} \\hat{P}\\left(x^{\\prime \\prime}\\right)}{n\\left(x, x^{\\prime}\\right)+\\epsilon_{3}} .\n\\end{aligned}$$\n- å…¶ä¸­ï¼Œ$Ïµ_1$, $Ïµ_2$ å’Œ $Ïµ_3$ æ˜¯è¶…å‚æ•°ã€‚ ä»¥ $Ïµ_1$ ä¸ºä¾‹ï¼šå½“ $Ïµ_1=0$ æ—¶ï¼Œä¸åº”ç”¨å¹³æ»‘ï¼› å½“ $Ïµ_1$ æ¥è¿‘æ­£æ— ç©·å¤§æ—¶ï¼Œ$\\hat P(x)$ æ¥è¿‘å‡åŒ€æ¦‚ç‡åˆ†å¸ƒ $1/m$ã€‚ ä¸Šé¢çš„å…¬å¼æ˜¯ [Wood et al., 2011](https://zh-v2.d2l.ai/chapter_references/zreferences.html#wood-gasthaus-archambeau-ea-2011 ) çš„ä¸€ä¸ªç›¸å½“åŸå§‹çš„å˜å½¢ã€‚[^2]\n\n#### ç¼ºç‚¹\n- ç„¶è€Œï¼Œè¿™æ ·çš„æ¨¡å‹å¾ˆå®¹æ˜“å¤±æ•ˆï¼ŒåŸå› å¦‚ä¸‹ï¼š \n\t- é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å­˜å‚¨æ‰€æœ‰çš„è®¡æ•°ï¼› \n\t- å…¶æ¬¡ï¼Œè¿™å®Œå…¨å¿½ç•¥äº†å•è¯çš„æ„æ€ã€‚ ä¾‹å¦‚ï¼Œâ€œçŒ«â€ï¼ˆcatï¼‰å’Œâ€œçŒ«ç§‘åŠ¨ç‰©â€ï¼ˆfelineï¼‰å¯èƒ½å‡ºç°åœ¨ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œ ä½†æ˜¯æƒ³æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´è¿™ç±»æ¨¡å‹å…¶å®æ˜¯ç›¸å½“å›°éš¾çš„ã€‚ \n\t- æœ€åï¼Œé•¿å•è¯åºåˆ—å¤§éƒ¨åˆ†æ˜¯æ²¡å‡ºç°è¿‡çš„ï¼Œ å› æ­¤ä¸€ä¸ªæ¨¡å‹å¦‚æœåªæ˜¯ç®€å•åœ°ç»Ÿè®¡å…ˆå‰â€œçœ‹åˆ°â€çš„å•è¯åºåˆ—é¢‘ç‡ï¼Œ é‚£ä¹ˆæ¨¡å‹é¢å¯¹è¿™ç§é—®é¢˜è‚¯å®šæ˜¯è¡¨ç°ä¸ä½³çš„ã€‚\n\n\n[^1]: [8.3. è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›† â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html)\n[^2]: [8.3. è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›† â€” å­¦ä¹ è¯­è¨€æ¨¡å‹](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html#id2)","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-51-%E8%AF%AD%E8%A8%80%E7%9A%84%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81":{"title":"D2L-51-è¯­è¨€çš„ç»Ÿè®¡ç‰¹å¾","content":"# è¯­è¨€çš„ç»Ÿè®¡ç‰¹å¾\n\n\u003cdiv align=\"right\"\u003e 2022-03-08\u003c/div\u003e\n\nTags: #Zipf_Law \n\n## nå…ƒè¯­æ³• n-gram\n- æˆ‘ä»¬å°†æ¶‰åŠä¸€ä¸ªã€ä¸¤ä¸ªå’Œä¸‰ä¸ªå˜é‡çš„æ¦‚ç‡å…¬å¼çš„æ¨¡å‹åˆ†åˆ«ç§°ä¸º â€œä¸€å…ƒè¯­æ³•â€ï¼ˆunigramï¼‰ã€â€œäºŒå…ƒè¯­æ³•â€ï¼ˆbigramï¼‰å’Œâ€œä¸‰å…ƒè¯­æ³•â€ï¼ˆtrigramï¼‰æ¨¡å‹.\n\t$$\\begin{aligned}\n\t\u0026P\\left(x_{1}, x_{2}, x_{3}, x_{4}\\right)=P\\left(x_{4}\\right) P\\left(x_{3}\\right) P\\left(x_{2}\\right) P\\left(x_{1}\\right) \\\\\n\t\u0026P\\left(x_{1}, x_{2}, x_{3}, x_{4}\\right)=P\\left(x_{4} \\mid x_{3}\\right) P\\left(x_{3} \\mid x_{2}\\right) P\\left(x_{2} \\mid x_{1}\\right) P\\left(x_{1}\\right) \\\\\n\t\u0026P\\left(x_{1}, x_{2}, x_{3}, x_{4}\\right)=P\\left(x_{4} \\mid x_{2}, x_{3}\\right)P\\left(x_{3} \\mid x_{1}, x_{2}\\right) P\\left(x_{2} \\mid x_{1}\\right) P\\left(x_{1}\\right) \\end{aligned}$$\n\t\n\t- ä¾‹å¦‚, ä¸€é˜¶é©¬å°”å¯å¤«æ¨¡å‹çš„ä¾èµ–å…³ç³»ä¸º $P\\left(x_{t} \\mid x_{t-1}\\right)$, å¯¹åº”äºŒå…ƒè¯­æ³•.\n\n\n## é½æ™®å¤«å®šå¾‹\n- åœ¨è‡ªç„¶è¯­è¨€çš„è¯­æ–™åº“é‡Œï¼Œä¸€ä¸ªå•è¯å‡ºç°çš„é¢‘ç‡ä¸å®ƒåœ¨é¢‘ç‡è¡¨é‡Œçš„æ’åæˆåæ¯”ã€‚[^1]\n- ç¬¬ $i$ ä¸ªæœ€å¸¸ç”¨å•è¯çš„é¢‘ç‡ $n_{i}$ ä¸ºï¼š\n$$n_{i} \\propto \\frac{1}{i^\\alpha}$$ ç­‰ä»·äº$$\\log n_{i}=-\\alpha \\log i+c$$\n- åœ¨åŒå¯¹æ•°æ›²çº¿ä¸Šå¯ä»¥è¡¨ç¤ºä¸º: \n\t![](notes/2022/2022.3/assets/Zipf.svg)\n- æœ‰è¶£çš„æ˜¯, å³ä½¿æ˜¯å¤šå…ƒè¯­æ³•çš„è¯åºåˆ—ä¹Ÿç¬¦åˆZipf's Law: \n\t![](notes/2022/2022.3/assets/ZipfALL.svg)\n\t- è¿™å¼ å›¾éå¸¸ä»¤äººæŒ¯å¥‹ï¼é¦–å…ˆï¼Œé™¤äº†ä¸€å…ƒè¯­æ³•è¯ï¼Œ**å•è¯åºåˆ—**ä¼¼ä¹ä¹Ÿéµå¾ªé½æ™®å¤«å®šå¾‹ï¼Œ å¹¶ä¸”å…¬å¼ä¸­çš„æŒ‡æ•° $Î±$ æ›´å° ï¼ˆæŒ‡æ•°çš„å¤§å°å—åºåˆ—é•¿åº¦çš„å½±å“ï¼‰ã€‚ \n\t- å…¶æ¬¡ï¼Œè¯è¡¨ä¸­ $n$ å…ƒç»„çš„æ•°é‡å¹¶æ²¡æœ‰é‚£ä¹ˆå¤§ï¼Œ**è¿™è¯´æ˜è¯­è¨€ä¸­å­˜åœ¨ç›¸å½“å¤šçš„ç»“æ„**ï¼Œ è¿™äº›ç»“æ„ç»™äº†æˆ‘ä»¬åº”ç”¨æ¨¡å‹çš„å¸Œæœ›ã€‚ (è¦æ˜¯è¯­è¨€ä¸­æ²¡æœ‰å¤ªå¤šè§„å¾‹, åˆ™nå…ƒç»„ä¼šæ›´éšæœº, ç§ç±»ä¹Ÿä¼šæ›´å¤š)\n\n- ç¬¬ä¸‰ï¼Œå¾ˆå¤šnå…ƒç»„å¾ˆå°‘å‡ºç°ï¼Œè¿™ä½¿å¾— [æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘](notes/2022/2022.3/D2L-50-è¯­è¨€æ¨¡å‹-ä¼ ç»Ÿæ¨¡å‹çš„ä¸è¶³.md#æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘) éå¸¸ä¸é€‚åˆè¯­è¨€å»ºæ¨¡ã€‚ ä½œä¸ºä»£æ›¿ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åŸºäºæ·±åº¦å­¦ä¹ çš„æ¨¡å‹ã€‚\n\n[^1]: [é½æ™®å¤«å®šå¾‹ Zipf's law - é›†æ™ºç™¾ç§‘ - å¤æ‚ç³»ç»Ÿ|äººå·¥æ™ºèƒ½|å¤æ‚ç§‘å­¦|å¤æ‚ç½‘ç»œ|è‡ªç»„ç»‡](https://wiki.swarma.org/index.php/%E9%BD%90%E6%99%AE%E5%A4%AB%E5%AE%9A%E5%BE%8B_Zipf%27s_law)","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/D2L-52-%E8%AF%BB%E5%8F%96%E9%95%BF%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95":{"title":"D2L-52-è¯»å–é•¿åºåˆ—æ•°æ®çš„ä¸¤ç§æ–¹æ³•","content":"# è¯»å–é•¿åºåˆ—æ•°æ®çš„ä¸¤ç§æ–¹æ³•\n\n\u003cdiv align=\"right\"\u003e 2022-03-08\u003c/div\u003e\n\nTags:  #SequentialData #DataPreprocessing\n\n- å°½ç®¡åºåˆ—æ•°æ®æœ¬è´¨ä¸Šæ˜¯è¿ç»­çš„, æˆ‘ä»¬åœ¨å¤„ç†æ•°æ®çš„æ—¶å€™ä¹Ÿå¸Œæœ›å°†å…¶åˆ†ä¸ºå°æ‰¹é‡, æ–¹ä¾¿æ¨¡å‹è¯»å–ã€‚\n- è®¾æˆ‘ä»¬å°†ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œ æ¨¡å‹ä¸­çš„ç½‘ç»œä¸€æ¬¡å¤„ç†å…·æœ‰é¢„å®šä¹‰é•¿åº¦ ï¼ˆä¾‹å¦‚nä¸ªæ—¶é—´æ­¥ï¼‰çš„ä¸€ä¸ªå°æ‰¹é‡åºåˆ—ã€‚\n![](notes/2022/2022.3/assets/timemachine-5gram.svg)\n- æˆ‘ä»¬åº”è¯¥ä»ä¸Šå›¾ä¸­é€‰æ‹©å“ªä¸€ä¸ªåºåˆ—å‘¢ï¼Ÿ äº‹å®ä¸Šï¼Œä»–ä»¬éƒ½ä¸€æ ·å¥½ã€‚ \n\t- ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬åªé€‰æ‹©ä¸€ä¸ªåç§»é‡ï¼Œ é‚£ä¹ˆç”¨äºè®­ç»ƒç½‘ç»œçš„ã€æ‰€æœ‰å¯èƒ½çš„å­åºåˆ—çš„è¦†ç›–èŒƒå›´å°†æ˜¯æœ‰é™çš„ã€‚ \n\t- å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä»éšæœºåç§»é‡å¼€å§‹åˆ’åˆ†åºåˆ—ï¼Œ ä»¥åŒæ—¶è·å¾—è¦†ç›–æ€§ï¼ˆcoverageï¼‰å’Œéšæœºæ€§ï¼ˆrandomnessï¼‰ã€‚ ä¸‹é¢ï¼Œæˆ‘ä»¬å°†æè¿°å¦‚ä½•å®ç°éšæœºé‡‡æ ·ï¼ˆrandom samplingï¼‰å’Œ é¡ºåºåˆ†åŒºï¼ˆsequential partitioningï¼‰ç­–ç•¥ã€‚\n\n## éšæœºé‡‡æ ·\nä¸‹å›¾ä¸­ `Batchsize=2`, ä¹Ÿå°±æ˜¯è¯´æ¯ä¸ªBatché‡Œé¢æœ‰ä¸¤ä¸ªåºåˆ—, ä¸€ä¸ªçº¢è‰²çš„, ä¸€ä¸ªè“è‰²çš„.\n\n![éšæœºé€‰å–](notes/2022/2022.3/assets/éšæœºé€‰å–.svg)\n- æ¯ä¸ªæ ·æœ¬éƒ½æ˜¯åœ¨åŸå§‹çš„é•¿åºåˆ—ä¸Šä»»æ„æ•è·çš„å­åºåˆ—ã€‚ \n- åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œæ¥è‡ªä¸¤ä¸ªç›¸é‚»çš„ã€éšæœºçš„ã€å°æ‰¹é‡ä¸­çš„å­åºåˆ—ä¸ä¸€å®šåœ¨åŸå§‹åºåˆ—ä¸Šç›¸é‚»ã€‚ \n\t- æ³¨æ„, å³ä½¿é‡‡ç”¨äº†éšæœºé‡‡æ ·, æˆ‘ä»¬ä¹ŸåŒæ ·è¦†ç›–äº†æ•´ä¸ªæ–‡æœ¬åºåˆ—.\n- å¯¹äºè¯­è¨€å»ºæ¨¡ï¼Œç›®æ ‡æ˜¯åŸºäºåˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬çœ‹åˆ°çš„è¯å…ƒæ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒï¼Œ å› æ­¤æ ‡ç­¾æ˜¯ç§»ä½äº†ä¸€ä¸ªè¯å…ƒçš„åŸå§‹åºåˆ—ã€‚\n\n\n## é¡ºåºåˆ†åŒº\n\n![é¡ºåºé€‰å–](notes/2022/2022.3/assets/é¡ºåºé€‰å–.svg)\n- ä¸¤ä¸ªç›¸é‚»çš„å°æ‰¹é‡ä¸­çš„å­åºåˆ—åœ¨åŸå§‹åºåˆ—ä¸Šä¹Ÿæ˜¯ç›¸é‚»çš„","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/Latex-Colored-Text":{"title":"Latex Colored Text","content":"![](notes/2022/2022.3/assets/img_2022-10-15-5.png)\n\n- ä½¿ç”¨é¢œè‰²å\n$$\\textcolor{red}{Sample}$$\n\n```latex\n\\textcolor{red}{Sample}\n```\n\n- ä½¿ç”¨ `rgb`\n$$\\textcolor[rgb]{0.5,0.2,0.8}{text}$$\n\n```latex\n\\textcolor[rgb]{r,g,b}{text}\n```\n\nå…¶ä¸­{r,g,b}ä»£è¡¨redã€greenå’Œblueä¸‰ç§é¢œè‰²çš„ç»„åˆï¼Œå–å€¼èŒƒå›´ä¸º[0-1]\n\n- ä½¿ç”¨ `RGB`\n$$\\textcolor[RGB]{123,234,099}{text}$$\n\n```latex\n\\textcolor[RGB]{R,G,B}{text}\n```\n\nå…¶ä¸­{R,G,B}ä»£è¡¨redã€greenå’Œblueä¸‰ç§é¢œè‰²çš„ç»„åˆï¼Œå–å€¼èŒƒå›´ä¸º[0-255]\n\n#### æ¯”è¾ƒå¥½çœ‹çš„é¢œè‰²\n\n$\\textcolor{forestgreen}{forestgreen}$\n$\\textcolor{royalblue}{royalblue}$\n$\\textcolor{darkorchid}{darkorchid}$\n$\\textcolor{orangered}{orangered}$\n$\\textcolor{salmon}{salmon}$\n$\\textcolor{darkorange}{darkorange}$\n","lastmodified":"2023-11-19T19:19:34.330470693Z","tags":null},"/notes/2022/2022.3/cmd_powershell_bash-Comparison":{"title":"cmd_powershell_bash-Comparison","content":"# CMD / Powershell / bash: Comparison\n\n\u003cdiv align=\"right\"\u003e 2022-03-18\u003c/div\u003e\n\nTags: #Terminal #OperatingSystem \n\n![](notes/2022/2022.3/assets/img_2022-10-15.png)\n\n- Bashæ˜¯Unixç³»ç»Ÿçš„, è€Œå‰ä¸¤ä¸ªæ˜¯Windowsçš„\n- Powershellæ˜¯CMDçš„å‡çº§ç‰ˆ\n\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/%E5%87%B8%E7%BB%84%E5%90%88-Convex-Combination":{"title":"å‡¸ç»„åˆ - Convex Combination","content":"# Convex Combination \n\n\u003cdiv align=\"right\"\u003e 2022-04-18\u003c/div\u003e\n\nTags: #NonlinearProgreamming #Math #ConvexCombination\n\n![](notes/2022/2022.4/assets/img_2022-10-15-1.png)\n\n- A *convex combination* of points $\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\ldots, \\mathbf{x}^{(k)} \\in \\mathbb{R}^{n}$ is a \"weighted average\": a linear combination\n$$\n\\lambda_{1} \\mathbf{x}^{(1)}+\\lambda_{2} \\mathbf{x}^{(2)}+\\cdots+\\lambda_{k} \\mathbf{x}^{(k)}\n$$\n\twhere $\\lambda_{1}+\\lambda_{2}+\\cdots+\\lambda_{k}=1$ and $\\lambda_{1}, \\ldots, \\lambda_{k} \\geq 0$\n\n- The *convex hull* $\\operatorname{conv}(S)$ of a set of points $S$ is sometimes defined as the set of all convex combinations of points from $S$.\n\n- In the plane, you can visualize $\\operatorname{conv}(S)$ as the interior of a rubber band stretched around points in $S$.\n\n![](notes/2022/2022.4/assets/img_2022-10-15-2.png)\n\nRef: Original File(@ConvexCombination)\n\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.4/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CFeedforward-neural-network":{"title":"å‰é¦ˆç¥ç»ç½‘ç»œ(Feedforward neural network)","content":"# å‰é¦ˆç¥ç»ç½‘ç»œ: Feedforward Neural Network\n\n\u003cdiv align=\"right\"\u003e 2022-04-12\u003c/div\u003e\n\nTags: #FeedforwardNeuralNetwork\n\n- å¤šå±‚å‰é¦ˆç¥ç»ç½‘ç»œçš„ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š \n\t- æ¯å±‚ç¥ç»å…ƒä¸ä¸‹ä¸€å±‚ç¥ç»å…ƒå…¨éƒ¨äº’è¿ \n\t- åŒå±‚ç¥ç»å…ƒä¹‹é—´ä¸å­˜åœ¨è¿æ¥ \n\t- è·¨å±‚ç¥ç»å…ƒä¹‹é—´ä¹Ÿä¸å­˜åœ¨è¿æ¥\n\n![](notes/2022/2022.4/assets/img_2022-10-15.jpg)\n\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.4/%E6%B1%89%E5%AD%97%E6%8E%92%E6%A3%80%E6%B3%95":{"title":"æ±‰å­—æ’æ£€æ³•","content":"# æ±‰å­—æ’æ£€æ³•\n\n\u003cdiv align=\"right\"\u003e 2022-04-02\u003c/div\u003e\n\nTags: #ChineseCharacters\n\n- æ±‰å­—ä½œä¸ºè±¡å½¢æ–‡å­—, åœ¨ä¿¡æ¯åŒ–çš„è¿‡ç¨‹ä¸­é¢ä¸´ç€å…ˆå¤©çš„å›°éš¾. \n\n- å…¶å®é™¤äº†æ‹¼éŸ³, æ±‰å­—æ˜¯æœ‰è®¸å¤šç´¢å¼•æ–¹å¼çš„, è¿™äº›æ–¹æ³•ç»Ÿç§°æ±‰å­—æ’æ£€æ³•. æ¯”å¦‚è¿‡å»çš„å››è§’å·ç æ£€å­—æ³•.\n\t- å…¶å®ç›¸æ¯”**åŸºäºè¯­éŸ³**çš„æ‹¼éŸ³, å››è§’å·ç å°±åƒäº”ç¬”ä¸€æ ·, ä½ å³ä½¿è®¤ä¸åˆ°è¿™ä¸ªå­—, ä¹Ÿå¯ä»¥è¾“å…¥, è¿™æ˜¯**åŸºäºå­—å½¢**çš„æ£€ç´¢æ–¹æ³•çš„ä¼˜åŠ¿.\n\n\n\n- [æ±‰å­—æ’æ£€æ³•_ç™¾åº¦ç™¾ç§‘](https://baike.baidu.com/item/%E6%B1%89%E5%AD%97%E6%8E%92%E6%A3%80%E6%B3%95/9979589)\n- [å››è§’å·ç æŸ¥å­—æ³•_ç™¾åº¦ç™¾ç§‘](https://baike.baidu.com/item/%E5%9B%9B%E8%A7%92%E5%8F%B7%E7%A0%81%E6%9F%A5%E5%AD%97%E6%B3%95/144844?fromtitle=%E5%9B%9B%E8%A7%92%E5%8F%B7%E7%A0%81%E6%A3%80%E5%AD%97%E6%B3%95\u0026fromid=2783996)\n\n\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E5%8D%8F%E8%AE%AE%E4%BF%A1%E9%81%93%E5%88%A9%E7%94%A8%E7%8E%87%E5%88%86%E6%9E%90":{"title":"æ»‘åŠ¨çª—å£åè®®ä¿¡é“åˆ©ç”¨ç‡åˆ†æ","content":"# æ»‘åŠ¨çª—å£åè®®ä¿¡é“åˆ©ç”¨ç‡åˆ†æ \n## Link Utilization of Sliding Window Protocols\n\u003cdiv align=\"right\"\u003e 1953184 å‚…é©°åŸ\u003c/div\u003e\n\u003cdiv align=\"right\"\u003e 2022-04-25\u003c/div\u003e\n\nTags: #ComputerNetwork #Course \n\n- æˆ‘ä»¬å‡è®¾æŸä¸€å¸§å‡ºé”™çš„æ¦‚ç‡ç›¸ç­‰ä¸”ç‹¬ç«‹, å¹¶ä¸”éƒ½ä¸º $P$\n\n## 1Bitæ»‘åŠ¨çª—å£\n- è¿™å…¶å®æ˜¯ä¸€ç§çª—å£å¤§å°ä¸º $1$, å¸§åºå·ä½æ•°ä¹Ÿä¸º $1$ çš„ç‰¹æ®Šå›é€€ $N$ åè®®.\n- å‡è®¾å‘é€ä¸€ä¸ªæ•°æ®å¸§èŠ±è´¹çš„æ—¶é—´ä¸º $t_{frame}$, æ•°æ®ä¼ è¾“æ—¶å»¶ä¸º $t_{trans}$, åˆ™ä¿¡é“åˆ©ç”¨ç‡å¯ä»¥è¡¨ç¤ºä¸º: $$U_1=(1-P)\\frac{t_{frame}}{t_{frame}+2t_{trans}}$$\n\t- å¦‚æœä»¤ $$\\alpha=\\frac{t_{trans}}{t_{frame}}$$ åˆ™æœ‰: $$U_1=(1-P)\\frac{1}{1+2\\alpha}$$\n## é€‰æ‹©é‡ä¼ åè®®\n- åœ¨ä¹‹å‰çš„åŸºç¡€ä¸Š, è¿›ä¸€æ­¥è€ƒè™‘å‘é€ $W$ ä¸ªæ•°æ®å¸§çš„æ—¶é—´, å°±å¾—åˆ°é€‰æ‹©é‡ä¼ åè®®çš„ä¿¡é“åˆ©ç”¨ç‡ä¸º:\n\t- $W\u003c1+2\\alpha$ æ—¶:\n\t\t$$U_2=\\frac{W(1-P)}{1+2\\alpha}$$\n\t- $W\\geq1+2\\alpha$ æ—¶\n\t$$U_2=1-P$$\n\n## å›é€€ $N$ æ»‘åŠ¨çª—å£\n- åœ¨ä¹‹å‰çš„åŸºç¡€ä¸Š, å†è¿›ä¸€æ­¥è€ƒè™‘å¹³å‡é‡ä¼  $W\\times P$ ä¸ªæŸåæ•°æ®å¸§çš„æ—¶é—´, å°±å¾—åˆ°å›é€€ $N$ æ»‘åŠ¨çª—å£åè®®çš„ä¿¡é“åˆ©ç”¨ç‡ä¸º:\n\t- $W\u003c1+2\\alpha$ æ—¶:\n\t$$U_2=\\frac{W(1-P)}{(1+2\\alpha)(1-P+WP)}$$\n\t- $W\\geq1+2\\alpha$ æ—¶\n\t$$U_2=\\frac{1-P}{1+2\\alpha P}$$\n## æ€§èƒ½åˆ†æ\n- ä½œå›¾åˆ†æ, å¯ä»¥å½¢è±¡çš„çœ‹å‡º:\n\t- çª—å£æ›´å¤§æ›´æœ‰åˆ©äºæé«˜ä¿¡é“åˆ©ç”¨ç‡\n\t- åœ¨çª—å£æ›´å¤§çš„æ—¶å€™, é€‰æ‹©é‡ä¼ è¦æ›´æœ‰ä¼˜åŠ¿(è¿™æ—¶å€™å›é€€ $N$ æ­¥çš„ä»£ä»·å¤ªå¤§äº†)\n\t![](notes/2022/2022.4/assets/img_2022-10-15.png)\n\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.4/%E9%80%92%E6%8E%A8%E5%85%AC%E5%BC%8F-a_tb_t+c_ta_t-1-%E8%BD%AC%E9%80%9A%E9%A1%B9%E5%85%AC%E5%BC%8F":{"title":"é€’æ¨å…¬å¼ $a_{t}=b_{t}+c_{t}a_{t-1}$ è½¬é€šé¡¹å…¬å¼","content":"# é€’æ¨å…¬å¼ $a_{t}=b_{t}+c_{t}a_{t-1}$ è½¬é€šé¡¹å…¬å¼\n\n\u003cdiv align=\"right\"\u003e 2022-04-02\u003c/div\u003e\n\nTags: #Math \n\n\n$$\\begin{aligned}\na_{t}=b_{t} \u0026+c_{t} a_{t-1} \\\\\n\u0026+ c_{t}\\left(b_{t-1}+c_{t-1} a_{t-2}\\right) \\\\\n\u0026\\hspace{4.25em}+c_{t-1}\\left(b_{t-2}+c_{t-2} a_{t-3}\\right) \\\\\n\u0026\\hspace{13em}\\vdots \\\\\n\u0026\\hspace{12.5em}+c_{2}\\left(b_{1}+c_{1} a_{0}\\right) \\\\\n\u0026\\hspace{17.5em}\\uparrow\\\\\n\u0026\\hspace{17.8em}0\\\\\n\\end{aligned}$$\nå³è¾¹:\n$$\\begin{aligned}\n\u0026\\textcolor{blue}{b_{t}}+\\textcolor{darkorange}{c_{t}}(\\textcolor{blue}{b_{t-1}}+\\cdots \\textcolor{darkorange}{c_{4}}(\\textcolor{blue}{b_{3}}+\\textcolor{darkorange}{c_{3}}(\\textcolor{blue}{b_{2}}+\\textcolor{darkorange}{c_{2}} \\textcolor{blue}{b_{1}})))\\\\\n=\u0026\\textcolor{darkorange}{c_{t}c_{t-1}\\cdots c_{4}c_{3}c_{2}}\\textcolor{blue}{b_{1}}+\\textcolor{darkorange}{c_{t}c_{t-1}\\cdots c_{4}c_{3}}\\textcolor{blue}{b_{2}}+\\textcolor{darkorange}{c_{t}c_{t-1}\\cdots c_{4}}\\textcolor{blue}{b_{3}}+\\cdots+\\textcolor{darkorange}{c_{t}}\\textcolor{blue}{b_{t-1}}+\\textcolor{blue}{b_{t}}\n\\\\=\u0026\\textcolor{blue}{b_{t}}+\\textcolor{blue}{\\sum_{i=1}^{t-1}}\\left(\\textcolor{darkorange}{\\prod_{j=i+1}^{t}c_{j}}\\right)\\textcolor{blue}{b_{i}}\n\\\\=\u0026b_{t}+\\sum_{i=1}^{t-1}\\left(\\prod_{j=i+1}^{t}c_{j}\\right)b_{i}\n\\end{aligned}$$\næ•…\n$$a_{t}=b_{t}+\\sum_{i=1}^{t-1}\\left(\\prod_{j=i+1}^{t}c_{j}\\right)b_{i}$$\n\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.4/D2L-53-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN":{"title":"D2L-53-å¾ªç¯ç¥ç»ç½‘ç»œRNN","content":"# Recurrent Neural Networks\n\n\u003cdiv align=\"right\"\u003e 2022-04-01\u003c/div\u003e\n\nTags: #RNN #DeepLearning #NeuralNetwork \n\n## Motivation\n- åŸºäºé©¬å°”å¯å¤«å‡è®¾çš„Nå…ƒè¯­æ³•ï¼ˆ*n-gram*ï¼‰éœ€è¦å­˜å‚¨å¤§é‡çš„å‚æ•°ã€‚åœ¨ $n$ é€æ¸å¢å¤§çš„è¿‡ç¨‹ä¸­ï¼Œ*n-gram*æ¨¡å‹çš„å‚æ•°å¤§å° $|W|$ ä¸åºåˆ—é•¿åº¦ $n$ æ˜¯æŒ‡æ•°å…³ç³»ï¼š$$|W|=|\\mathcal{V}|^n $$ ($|\\mathcal{V}|$ æ˜¯å•è¯çš„æ•°ç›®)\n- å› æ­¤, æˆ‘ä»¬å°†ç›®å…‰è½¬å‘äº† [éšå˜é‡è‡ªå›å½’æ¨¡å‹](notes/2022/2022.3/D2L-48-åºåˆ—æ¨¡å‹-Sequence_Models.md#éšå˜é‡è‡ªå›å½’æ¨¡å‹%20Latent%20Autoregressive%20Models). éšçŠ¶æ€ $h_{t-1}$ èƒ½å¤Ÿ(è¿‘ä¼¼åœ°)å­˜å‚¨å½“å‰æ—¶é—´æ­¥ä¹‹å‰æ‰€æœ‰è¾“å…¥çš„ç»¼åˆå½±å“:\n\t$$P\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{1}\\right) \\approx P\\left(x_{t} \\mid h_{t-1}\\right)$$\n\t- è¿›è€Œ, æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å½“å‰çš„è¾“å…¥å’Œä¸Šä¸€ä¸ªéšçŠ¶æ€æ¥ç”Ÿæˆå½“å‰çš„éšçŠ¶æ€:\n\t$$h_{t}=f\\left(x_{t}, h_{t-1}\\right)$$\n\tåªè¦å‡½æ•° $f$ è¶³å¤Ÿå¼ºå¤§, å°±èƒ½å°†æ‰€æœ‰ä¿¡æ¯éƒ½ç»¼åˆåˆ° $h_t$ é‡Œé¢, ä¸ä¸¢å¤±ä»»ä½•ä¿¡æ¯. å½“ç„¶, è¿™æ ·çš„å¼€é”€ä¹Ÿæ˜¯å¾ˆå¤§çš„.\n\t\n![](notes/2022/2022.3/assets/img_2022-10-15-6.png)\n- _Recurrent neural networks_ (RNNs)å°±æ˜¯å¸¦æœ‰éšçŠ¶æ€çš„ç¥ç»ç½‘ç»œ.\n\n## ä»MLPåˆ°RNN\n- RNNå’Œ [MLP](notes/2022/2022.2/D2L-17-MLP-å¤šå±‚æ„ŸçŸ¥æœº.md) å…¶å®æ˜¯éå¸¸ç›¸ä¼¼çš„, å®ƒä»¬å”¯ä¸€çš„åŒºåˆ«å°±æ˜¯æœ‰æ²¡æœ‰éšçŠ¶æ€ $h_{t}$\n- **MLP**\n\t$$\\begin{aligned}\n\t\\mathbf{H}\u0026=\\phi\\left(\\mathbf{X} \\mathbf{W}_{x h}+\\mathbf{b}_{h}\\right)\\\\\n\t\\mathbf{O}\u0026=\\mathbf{H} \\mathbf{W}_{h q}+\\mathbf{b}_{q}\\end{aligned}$$\n- **RNN**\n$$\\begin{aligned}\n\t\\mathbf{H}_t\u0026=\\phi\\left(\\textcolor[RGB]{255, 83, 61}{\\mathbf{H}_{t-1}\\mathbf{W}_{h h}}+\\mathbf{X} \\mathbf{W}_{x h}+\\mathbf{b}_{h}\\right)\\\\\n\t \\mathbf{O}\u0026=\\mathbf{H} \\mathbf{W}_{h q}+\\mathbf{b}_{q}\\end{aligned}$$\n- æ³¨æ„åœ¨åŠ ä¸Šåç½®çš„æ—¶å€™è§¦å‘äº†PyTorchçš„å¹¿æ’­æœºåˆ¶(Broadcasting, see [Section 2.1.3](https://d2l.ai/chapter_preliminaries/ndarray.html#subsec-broadcasting)) \n- ä¸‹é¢æ˜¯ä¸€äº›å›¾ä¾‹:\n![](notes/2022/2022.3/assets/img_2022-10-15-7.png)\n\n![](notes/2022/2022.3/assets/img_2022-10-15-8.png)\n\n- å€¼å¾—æ³¨æ„çš„ä¸€ç‚¹æ˜¯, å› ä¸ºæˆ‘ä»¬åœ¨æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½ä½¿ç”¨çš„æ˜¯åŒä¸€ä¸ªå‚æ•°çŸ©é˜µ $\\mathbf{W}_{hh}$, æ‰€ä»¥RNNçš„å‚æ•°å¤§å°å¹¶ä¸ä¼šéšç€æ—¶é—´æ­¥çš„å¢é•¿è€Œå¢é•¿.\n### Hidden States\n![Hidden States](notes/2022/2022.4/Hidden%20States.svg)\n\n### ä¸ºä»€ä¹ˆå«\"Recurrent\" Neural Network\n- å°½ç®¡æ¯ä¸€æ¬¡è®¡ç®—éƒ½éœ€è¦åˆ©ç”¨ä¸Šä¸€æ¬¡çš„ $\\mathbf H_{t-1}$, ä½†æ˜¯ä½¿ç”¨çš„å‚æ•° $\\mathbf{W}_{hh}$ éƒ½æ˜¯ä¸€æ ·çš„. ä¹Ÿå°±æ˜¯è¯´, æ¯ä¸€å±‚çš„éšçŠ¶æ€çš„è®¡ç®—æ–¹å¼æ˜¯å®Œå…¨ä¸€æ ·çš„, è¿™ä¸€æ¬¡çš„è¾“å‡ºå°±æ˜¯ä¸‹ä¸€æ¬¡çš„è¾“å…¥, æ˜¯ä¸€ä¸ª*é€’å½’*çš„å…³ç³», è¿™ä¹Ÿæ˜¯Recurrentçš„å«ä¹‰.\n\n\t- é€’å½’è®¡ç®—éšçŠ¶æ€çš„å±‚è‡ªç„¶å°±å«åš\"**é€’å½’å±‚**(*recurrent layer*)\" \n\n![](notes/2022/2022.4/assets/R5nRD.jpg)\n\n### $\\mathbf{H}_{t-1}\\mathbf{W}_{h h}+\\mathbf{X} \\mathbf{W}_{x h}$ å®é™…çš„è®¡ç®—æ–¹å¼\n- å…¬å¼é‡Œé¢æ˜¯:\n![Matrix Mutiplication Trick A](notes/2022/2022.4/assets/Matrix%20Mutiplication%20Trick%20A.svg)\n\n- å®é™…ä¸Šå¯ä»¥ç®€åŒ–æˆ:\n![Matrix Mutiplication Trick B](notes/2022/2022.4/assets/Matrix%20Mutiplication%20Trick%20B.svg)\n\n- RNNçš„è®¡ç®—å¯ä»¥è¡¨ç¤ºä¸º:\n![](notes/2022/2022.4/assets/rnn.svg)\n ^ba5f9a\n- å› ä¸ºRNNçš„é€’å½’å±‚å­˜åœ¨ç¯è·¯, æ‰€ä»¥RNNä¸å±äº[[notes/2022/2022.4/å‰é¦ˆç¥ç»ç½‘ç»œ(Feedforward neural network)]].\n\n## RNNçš„è¯„ä¼°æŒ‡æ ‡: å›°æƒ‘åº¦ Perplexity\n- Review:  [Cross_Entropy-äº¤å‰ç†µ](notes/2022/2022.2/Cross_Entropy-äº¤å‰ç†µ.md)\n\n- è™½ç„¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ•´ä¸ªå¥å­çš„æ¦‚ç‡ $P\\left(x_{1}, \\ldots, x_{T}\\right)$ æ¥è¯„ä»·æ¨¡å‹çš„è´¨é‡, ä½†ç”±äºçŸ­åºåˆ—çš„æ¦‚ç‡å¾ˆå¯èƒ½æ¯”é•¿åºåˆ—å¤§è®¸å¤š, æˆ‘ä»¬å¾ˆéš¾ç›´è§‚çš„è¯„ä»·æ¨¡å‹çš„å¥½å.\n\n- ä¸€ä¸ªè‡ªç„¶çš„æƒ³æ³•å°±æ˜¯å°†æ•´ä¸ªå¥å­çš„æ¦‚ç‡\"é™¤ä»¥\"å¥å­çš„é•¿åº¦, ç”¨\"æ¯ä¸ªå­—ç¬¦çš„æ¦‚ç‡\"ä½œä¸ºè¯„ä»·æŒ‡æ ‡. åˆ©ç”¨ä¿¡æ¯è®ºçš„çŸ¥è¯†, æˆ‘ä»¬å¯ä»¥ç»“åˆäº¤å‰ç†µçš„æ¦‚å¿µ: ä¸€ä¸ªå¥½çš„é¢„æµ‹æ¨¡å‹åº”è¯¥è¾“å‡ºå’ŒçœŸå®å¥å­å°½å¯èƒ½ç›¸ä¼¼çš„ç»“æœ. æˆ‘ä»¬å¯ä»¥ç”¨äº¤å‰ç†µæ¥è¡¡é‡æ¨¡å‹çš„è¾“å‡ºæ¦‚ç‡ $q(x_i)=P\\left(x_{i} \\mid x_{t-1}, \\ldots, x_{1}\\right)$ å’ŒçœŸå®åºåˆ—åˆ†å¸ƒ $p(x_i)$ çš„å·®è·: \n\t$$\\begin{aligned}\n\tCE(p,q)\u0026=-\\sum_i^{|\\mathcal{V}|}p(x_i)\\log q(x_i)\\\\\n\t(\\text{ç‹¬çƒ­ç¼–ç })\u0026=-\\log q(x_t)\\\\\u0026=-\\log P\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{1}\\right)\\end{aligned}$$\n\t- å…¶ä¸­ $|\\mathcal{V}|$ æ˜¯æ‰€æœ‰å¯èƒ½çš„ $x_i$ ä¸ªæ•°, å› ä¸ºçœŸå®åºåˆ—æ˜¯å·²çŸ¥çš„, ç›¸å½“äºç‹¬çƒ­ç¼–ç , æ‰€ä»¥åªå‰©ä¸‹ $x_i=x_t$ çš„ä¸€é¡¹, å…¶ä¸­ $x_t$ æ˜¯åœ¨æ—¶é—´æ­¥ $t$ ä»è¯¥åºåˆ—ä¸­è§‚å¯Ÿåˆ°çš„å®é™…è¯å…ƒ\n- å°†æ•´ä¸ªåºåˆ—é‡Œé¢æ‰€æœ‰ä½ç½®çš„äº¤å‰ç†µç»¼åˆèµ·æ¥, å†å–å¹³å‡å¾—åˆ°: $$-\\frac{1}{n} \\sum_{t=1}^{n} \\log P\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{1}\\right)$$\n- ç”±äºå†å²åŸå› ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†çš„ç§‘å­¦å®¶æ›´å–œæ¬¢ä½¿ç”¨ä¸€ä¸ªå«åš_å›°æƒ‘åº¦_ï¼ˆperplexityï¼‰çš„é‡ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œå®ƒæ˜¯ä¸Šå¼çš„æŒ‡æ•°ï¼š\n\t$$\\exp \\left(-\\frac{1}{n} \\sum_{t=1}^{n} \\log P\\left(x_{t} \\mid x_{t-1}, \\ldots, x_{1}\\right)\\right)$$\n\t\n\u003e å›°æƒ‘åº¦çš„æœ€å¥½çš„ç†è§£æ˜¯â€œä¸‹ä¸€ä¸ªè¯å…ƒçš„å®é™…é€‰æ‹©æ•°çš„[è°ƒå’Œå¹³å‡æ•°(*Harmonic* mean)](notes/2022/2022.5/Harmonic_Mean-è°ƒå’Œå¹³å‡æ•°.md)â€ã€‚ æˆ‘ä»¬çœ‹çœ‹ä¸€äº›æ¡ˆä¾‹ï¼š\n\u003e - åœ¨æœ€å¥½çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€»æ˜¯å®Œç¾åœ°ä¼°è®¡æ ‡ç­¾è¯å…ƒçš„æ¦‚ç‡ä¸º $1$ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„å›°æƒ‘åº¦ä¸º $1$ã€‚\n\u003e -   åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€»æ˜¯é¢„æµ‹æ ‡ç­¾è¯å…ƒçš„æ¦‚ç‡ä¸º $0$ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›°æƒ‘åº¦æ˜¯æ­£æ— ç©·å¤§ã€‚\n\u003e -   åœ¨åŸºçº¿ä¸Šï¼Œè¯¥æ¨¡å‹çš„é¢„æµ‹æ˜¯è¯è¡¨çš„æ‰€æœ‰å¯ç”¨è¯å…ƒä¸Šçš„å‡åŒ€åˆ†å¸ƒã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›°æƒ‘åº¦ç­‰äºè¯è¡¨ä¸­å”¯ä¸€è¯å…ƒçš„æ•°é‡ $|\\mathcal{V}|$ã€‚ äº‹å®ä¸Šï¼Œå¦‚æœæˆ‘ä»¬åœ¨æ²¡æœ‰ä»»ä½•å‹ç¼©çš„æƒ…å†µä¸‹å­˜å‚¨åºåˆ—ï¼Œ è¿™å°†æ˜¯æˆ‘ä»¬èƒ½åšçš„æœ€å¥½çš„ç¼–ç æ–¹å¼ã€‚ å› æ­¤ï¼Œè¿™ç§æ–¹å¼æä¾›äº†ä¸€ä¸ªé‡è¦çš„ä¸Šé™ï¼Œ è€Œä»»ä½•å®é™…æ¨¡å‹éƒ½å¿…é¡»è¶…è¶Šè¿™ä¸ªä¸Šé™ã€‚[^1]\n\n## RNNä¸­outputå’Œhidden_stateçš„åŒºåˆ«\n[RNNä¸­outputå’Œhidden_stateçš„åŒºåˆ«](notes/2022/2022.4/RNNä¸­outputå’Œhidden_stateçš„åŒºåˆ«.md)\n\n\n[^1]: [8.4. å¾ªç¯ç¥ç»ç½‘ç»œ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/rnn.html)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-54-Gradient-Clipping-%E6%A2%AF%E5%BA%A6%E5%89%AA%E8%A3%81":{"title":"D2L-54-Gradient Clipping-æ¢¯åº¦å‰ªè£","content":"# Gradient Clipping\n\n\u003cdiv align=\"right\"\u003e 2022-04-02\u003c/div\u003e\n\nTags: #GradientClipping\n\n- æ¢¯åº¦å‰ªè£æ˜¯é¢„é˜²æ¢¯åº¦çˆ†ç‚¸çš„ä¸€ç§æ–¹æ³•, å®ƒç›´æ¥ç»™æ¢¯åº¦è®¾ç½®ä¸€ä¸ªä¸Šé™.\n\n$$\\mathbf{g} \\leftarrow \\min \\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}$$\n- ä¸Šé¢çš„å†™æ³•æœ‰ç‚¹ç»•, å› ä¸ºä¸ºäº†ä¿æŒæ¢¯åº¦ $\\mathbf{g}$ çš„æ–¹å‘ä¸å˜, å‰ªè£æ—¶éœ€è¦ä½œç”¨äº $\\mathbf{g}$ çš„æ¯ä¸€ä¸ªåˆ†é‡, æ•´ä½“ä¸Šæ¥è¯´å…¶å®å°±æ˜¯:\n$$\\mathbf{g} \\leftarrow \\min \\left(\\|\\mathbf{g}\\|, \\theta \\frac{\\mathbf{g}}{\\|\\mathbf{g}\\|}\\right)$$\n\n![400](notes/2022/2022.4/assets/img_2022-10-15-3.png)\n- ç›¸æ¯”ç›´æ¥å‡å°å­¦ä¹ ç‡ï¼ŒClippingæ˜¯åˆ†æ®µçš„, å¯ä»¥åªåœ¨æ¢¯åº¦è¾ƒå¤§æ—¶åŠ ä»¥é™åˆ¶.\n\n- æŠ½è±¡ç‰ˆçš„æè¿°è§ï¼šã€€[8.5. Implementation of Recurrent Neural Networks from Scratch â€” Dive into Deep Learning 0.17.5 documentation](https://d2l.ai/chapter_recurrent-neural-networks/rnn-scratch.html#gradient-clipping)\n\n## PyTorch\n[torch.nn.utils.clip_grad_norm_ â€” PyTorch 1.11.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n```python\nnn.utils.clip_grad_norm_(model.parameters(), max_norm=CLIP_GRAD)\n```\n\n## D2l é‡Œé¢çš„ç®€æ˜“å®ç°\n```py\ndef grad_clipping(net, theta):  #@save\n    \"\"\"è£å‰ªæ¢¯åº¦\"\"\"\n    if isinstance(net, nn.Module):\n        params = [p for p in net.parameters() if p.requires_grad]\n    else:\n        params = net.params\n    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n    if norm \u003e theta:\n        for param in params:\n            param.grad[:] *= theta / norm #æ³¨æ„è¿™é‡Œæ˜¯*=\n```","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-55-%E5%9C%A8%E6%97%B6%E9%97%B4%E4%B8%8A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD":{"title":"D2L-55-åœ¨æ—¶é—´ä¸Šåå‘ä¼ æ’­","content":"# Backpropagation Through Time\n\n\u003cdiv align=\"right\"\u003e 2022-04-02\u003c/div\u003e\n\nTags: #Backpropagation #RNN \n\n- å’Œæ­£å‘ä¼ æ’­çš„æ—¶å€™ä¸€æ ·, RNNåœ¨åå‘ä¼ æ’­çš„æ—¶å€™éœ€è¦åœ¨æ—¶é—´æ­¥ä¸Šé¢è¿›è¡Œè¿­ä»£, è¿™å¯èƒ½å¯¼è‡´æ¢¯åº¦é—®é¢˜. \n- ä¸‹é¢æˆ‘ä»¬å…ˆå¤§æ¦‚åˆ†æåœ¨\"æ—¶é—´ä¸Š\"åå‘ä¼ æ’­çš„ä¸åŒä¹‹å¤„, ç„¶åç®€è¦ä»‹ç»ä¸€äº›ç¼“è§£æ¢¯åº¦é—®é¢˜çš„è®­ç»ƒæ–¹æ³•, æœ€å, æˆ‘ä»¬è¯¦ç»†çš„åˆ†æä¸€ä¸‹åœ¨æ—¶é—´ä¸Šåå‘ä¼ æ’­çš„ç»†èŠ‚é—®é¢˜.\n- è¿™ç¯‡ç¬”è®°ä»¥ [8.7. Backpropagation Through Time â€” Dive into Deep Learning](https://d2l.ai/chapter_recurrent-neural-networks/bptt.html) ä¸ºåŸºç¡€. \n\n## åœ¨æ—¶é—´ä¸Šåå‘ä¼ æ’­/RNNçš„åå‘ä¼ æ’­\n### æ¨¡å‹\n - æˆ‘ä»¬å¯ä»¥æŠŠRNNçš„è®¡ç®—ç®€åŒ–ä¸ºä¸¤ä¸ªå‡½æ•°: $f$ æ›´æ–°éšçŠ¶æ€, $o_t$ æ ¹æ®éšçŠ¶æ€ç”Ÿæˆè¾“å‡º:\n$$\\begin{aligned}h_t \u0026= f(x_t, h_{t-1}, w_h),\\\\o_t \u0026= g(h_t, w_o),\\end{aligned}$$\n- å…¶ä¸­:\n\t- $x_t$ æ˜¯ $t$ æ—¶åˆ»çš„è¾“å…¥, æ³¨æ„ä¸‹æ ‡æ˜¯æ—¶é—´æ­¥è€Œä¸æ˜¯åœ¨åºåˆ—é‡Œçš„ä½ç½®\n\t- $h_t$ æ˜¯ $t$ æ—¶åˆ»çš„éšçŠ¶æ€\n\t- $w_h$ æ˜¯éšè—å±‚çš„æƒé‡\n\t- $w_o$ æ˜¯è¾“å‡ºå±‚çš„æƒé‡\n\n![ç®€åŒ–ç‰ˆRNN](notes/2022/2022.4/assets/img_2022-10-15-4.png)\n### æŸå¤±å‡½æ•°\n- æŸå¤±å‡½æ•°é‡Œé¢, æˆ‘ä»¬å°† $x_1, \\ldots, x_T$ è¾“å…¥æ¨¡å‹, å¾—åˆ°è¾“å‡º $o_1, \\ldots, o_T$, å°† $y_1, \\ldots, y_T$ ä¸æ¯ä¸€ä¸ªè¾“å‡ºè¿›è¡Œæ¯”è¾ƒ, å†å–å¹³å‡. å…¶ä¸­ $w_h, w_o$ æ˜¯æˆ‘ä»¬éœ€è¦ä¼˜åŒ–çš„ç›®æ ‡.\n$$L(x_1, \\ldots, x_T, y_1, \\ldots, y_T, w_h, w_o) = \\frac{1}{T}\\sum_{t=1}^T l(y_t, o_t)$$\n\n### æ±‚æ¢¯åº¦: $\\frac{\\partial L}{\\partial w_o}$\n- å¯¹äº $w_o$ çš„æ¢¯åº¦å¾ˆå¥½è®¡ç®—, å› ä¸ºæ¯ä¸€ä¸ªè¾“å‡ºä»…ä¾èµ–äºå½“å‰æ—¶åˆ»çš„éšçŠ¶æ€ $h_t$, ä¸å­˜åœ¨é€’å½’å…³ç³».\n$$\\begin{aligned}\\frac{\\partial L}{\\partial w_o}\u0026 = \\frac{1}{T}\\sum_{t=1}^T \\frac{\\partial l(y_t, o_t)}{\\partial w_o}\\\\\u0026= \\frac{1}{T}\\sum_{t=1}^T \\frac{\\partial l(y_t, o_t)}{\\partial o_t} \\frac{\\partial g(h_t, w_o)}{\\partial w_o}\\end{aligned}$$\n\n### æ±‚æ¢¯åº¦: $\\frac{\\partial L}{\\partial w_h}$\n- åœ¨ä¸‹é¢çš„å¼å­é‡Œé¢, å‰ä¸¤ä¸ªå› å­éƒ½å¾ˆå¥½è®¡ç®—, è€Œé€’å½’å…³ç³»éšè—åœ¨ ${\\partial h_t}/{\\partial w_h}$ é‡Œé¢.\n$$\\begin{aligned}\\frac{\\partial L}{\\partial w_h}\u0026 = \\frac{1}{T}\\sum_{t=1}^T \\frac{\\partial l(y_t, o_t)}{\\partial w_h}\\\\\u0026= \\frac{1}{T}\\sum_{t=1}^T \\frac{\\partial l(y_t, o_t)}{\\partial o_t} \\frac{\\partial g(h_t, w_o)}{\\partial h_t} \\frac{\\partial h_t}{\\partial w_h}\\end{aligned}$$\n- $h_t = f(x_t, h_{t-1}, w_h)$ è€Œ $h_{t-1}$ åŒæ ·ä¾èµ–äº $w_h$, æ‰€ä»¥æ ¹æ®æ±‚å¯¼æ³•åˆ™æœ‰:\n$$\\frac{\\partial h_t}{\\partial w_h}= \\frac{\\partial f(x_{t},h_{t-1},w_h)}{\\partial w_h} +\\frac{\\partial f(x_{t},h_{t-1},w_h)}{\\partial h_{t-1}} \\frac{\\partial h_{t-1}}{\\partial w_h}$$\nç”¨é¢œè‰²æ ‡è¯†å‡ºæ¯éƒ¨åˆ†çš„æ±‚å¯¼å¯¹è±¡:\n$$\\textcolor{red}{\\frac{\\partial h_t}{\\partial w_h}}= \\frac{\\partial f(x_{t},h_{t-1},\\textcolor{blue}{w_h})}{\\textcolor{blue}{\\partial w_h}} +\\frac{\\partial f(x_{t},\\textcolor{green}{h_{t-1}},w_h)}{\\textcolor{green}{\\partial h_{t-1}}} \\textcolor{red}{\\frac{\\partial h_{t-1}}{\\partial w_h}}$$\nå…¶ä¸­çº¢è‰²çš„éƒ¨åˆ†æ„æˆäº†é€’å½’.\n\n- å¯¹äºé€’æ¨å…¬å¼ $a_{t}=b_{t}+c_{t}a_{t-1}$, $a_{0}=0$. æˆ‘ä»¬å¯ä»¥æ±‚å‡ºé€šé¡¹å…¬å¼ä¸º[^1]:\n$$a_{t}=b_{t}+\\sum_{i=1}^{t-1}\\left(\\prod_{j=i+1}^{t}c_{j}\\right)b_{i}$$\n\n- å†è¿›è¡Œæ›¿æ¢:\n$$\\begin{aligned}a_t \u0026= \\textcolor{red}{\\frac{\\partial h_t}{\\partial w_h}},\\\\\nb_t \u0026= \\frac{\\partial f(x_{t},h_{t-1},\\textcolor{blue}{w_h})}{\\textcolor{blue}{\\partial w_h}}, \\\\\nc_t \u0026= \\frac{\\partial f(x_{t},\\textcolor{green}{h_{t-1}},w_h)}{\\textcolor{green}{\\partial h_{t-1}}},\\end{aligned}$$\nå¾—åˆ°:\n$$\\textcolor{red}{\\frac{\\partial h_t}{\\partial w_h}}\n=\\frac{\\partial f(x_{t},h_{t-1},\\textcolor{blue}{w_h})}{\\textcolor{blue}{\\partial w_h}}+\n\\textcolor{blue}{\\sum_{i=1}^{t-1}}\n\\left(\\textcolor{green}{\\prod_{j=i+1}^{t}} \\frac{\\partial f(x_{j},\\textcolor{green}{h_{j-1}},w_h)}{\\textcolor{green}{\\partial h_{j-1}}} \\right) \n\\frac{\\partial f(x_{i},h_{i-1},\\textcolor{blue}{w_h})}{\\textcolor{blue}{\\partial w_h}}.$$\n- åœ¨ä¸Šé¢çš„å¼å­é‡Œé¢, $b_t$ å¯ä»¥ç†è§£ä¸º $w_h$ å¯¹äº $t$ æ—¶åˆ»çš„éšçŠ¶æ€ $h_t$ çš„å½±å“å¼ºåº¦, $c_t$ å¯ä»¥ç†è§£ä¸ºä¸Šä¸€æ—¶åˆ»éšçŠ¶æ€ $h_{t-1}$ å¯¹äºå½“å‰ $h_t$ çš„å½±å“å¼ºåº¦.\n\n## RNNç¼“è§£æ¢¯åº¦é—®é¢˜çš„ä¸€äº›ç­–ç•¥\n- Reveiw:\n\t- [D2L-24-æ•°å€¼ç¨³å®šæ€§](notes/2022/2022.2/D2L-24-æ•°å€¼ç¨³å®šæ€§.md)\n\t- [D2L-25-è®©è®­ç»ƒæ›´åŠ ç¨³å®š](notes/2022/2022.2/D2L-25-è®©è®­ç»ƒæ›´åŠ ç¨³å®š-Xavieråˆå§‹åŒ–.md)\n\n- å¯ä»¥çœ‹åˆ°åœ¨ä¸Šä¸€èŠ‚çš„ç»“è®ºé‡Œ, ç»¿è‰²çš„éƒ¨åˆ†å’Œè“è‰²çš„éƒ¨åˆ†éƒ½ä¼šå¯¼è‡´æ¢¯åº¦é—®é¢˜. å› è€Œæˆ‘ä»¬å¾ˆå°‘ç›´æ¥åˆ©ç”¨ä¸Šå¼è®¡ç®—RNNçš„æ¢¯åº¦.\n\n### Truncating Time Steps\n- ä¸ºäº†é¿å…æ¢¯åº¦çˆ†ç‚¸, æˆ‘ä»¬å¯ä»¥åªè®¡ç®—ä»å½“å‰æ—¶é—´æ­¥å¾€å‰ $\\tau$ ä¸ªæ—¶é—´æ­¥çš„ä¸€å°éƒ¨åˆ†. è¿™ä¼šä½¿æ¢¯åº¦çš„ä¼ å¯¼è·ç¦»å˜çŸ­, è®©æˆ‘ä»¬åªå…³æ³¨å½“å‰æ—¶é—´æ­¥é™„è¿‘çš„ä¸€æ®µåºåˆ—. å®è·µè¡¨æ˜è¿™ç§æ–¹æ³•è¿˜æœ‰ä¸€å®š [æ­£åˆ™åŒ–](notes/2022/2022.2/Regularization-æ­£åˆ™åŒ–.md) çš„ä½œç”¨åœ¨é‡Œé¢, å®ƒå€¾å‘äºè®©æ¨¡å‹å˜å¾—æ›´ç®€å•ç¨³å®š.\n- é€šå¸¸æˆ‘ä»¬å¯ä»¥åœ¨ä¸€å®šæ—¶é—´æ­¥ådetachæ‰ä¸€äº›éƒ¨åˆ†, å°±åƒ[ä¸‹é¢è¿™æ®µä»£ç ](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/rnn-scratch.html#id7)é‡Œé¢ä¸€æ ·:\n```python\ndef train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n\n...\n\n\tfor X, Y in train_iter:\n        if state is None or use_random_iter:\n            # åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æˆ–ä½¿ç”¨éšæœºæŠ½æ ·æ—¶åˆå§‹åŒ–state\n            state = net.begin_state(batch_size=X.shape[0], device=device)\n        else:\n            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n                # stateå¯¹äºnn.GRUæ˜¯ä¸ªå¼ é‡\n                state.detach_()\n            else:\n            # stateå¯¹äºnn.LSTMæˆ–å¯¹äºæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°çš„æ¨¡å‹æ˜¯ä¸ªå¼ é‡\n                for s in state:\n                    s.detach_()\n \n ...\n\n    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n```\n\n### Randomized Truncation\n- æˆ‘ä»¬å¯ä»¥äººä¸ºåœ°è®¾å®š $\\tau$, è‡ªç„¶ä¹Ÿå¯ä»¥è®© $\\tau$ éšæœºå˜åŒ–æ¢¯åº¦ä¼ æ’­è·ç¦». \n- å®šä¹‰éšæœºå˜é‡ $\\xi_t$ , æœ‰ $P(\\xi_t = 0) = 1-\\pi_t$ å’Œ $P(\\xi_t = \\pi_t^{-1}) = \\pi_t$, å…¶ä¸­ $\\pi_t$ æ˜¯äººä¸ºè®¾å®šçš„å‚æ•°ä¸” $0 \\leq \\pi_t \\leq 1$. ä¸Šé¢çš„è§„å®šæ˜¯ä¸ºäº†ä¿è¯ $E[\\xi_t] = 1$, è¿›ä¸€æ­¥ä¿è¯æ•°å€¼ç¨³å®šæ€§[^2]\n\t- ä»è€Œæœ‰:\n\t$$z_t= \\frac{\\partial f(x_{t},h_{t-1},w_h)}{\\partial w_h} +\\xi_t \\frac{\\partial f(x_{t},h_{t-1},w_h)}{\\partial h_{t-1}} \\frac{\\partial h_{t-1}}{\\partial w_h}$$\n\t- åœ¨$\\xi_t=0$æ—¶æ¢¯åº¦åœæ­¢ä¼ æ’­\n\n- åœ¨å®é™…è¿‡ç¨‹ä¸­, éšæœºåŒ–æˆªæ–­çš„æ•ˆæœå¹¶æ²¡æœ‰å®šé•¿æˆªæ–­çš„æ•ˆæœå¥½.[^3]\n\n### æˆªæ–­æ–¹å¼å¯è§†åŒ–\n![](notes/2022/2022.4/assets/truncated-bptt.svg)\nä¸åŒçš„æˆªæ–­æ–¹å¼ä»£è¡¨äº†æ¢¯åº¦ä¸åŒçš„ä¼ æ’­è·ç¦», ä¸Šé¢çš„å›¾è¡¨ç¤ºäº†æ¯ä¸€ä¸ªä½ç½®çš„éšçŠ¶æ€å¯èƒ½çš„å½±å“èŒƒå›´. \n\n## RNNæ¢¯åº¦ä¼ æ’­çš„ç»†èŠ‚é—®é¢˜\n- ä¸‹é¢æˆ‘ä»¬æŠŠ $h_t=f(x_t, h_{t-1}, w_h)$ å’Œ $o_t= g(h_t, w_o)$ å±•å¼€, è®¨è®ºRNNæ¢¯åº¦ä¼ æ’­çš„å®é™…æƒ…å†µ.\n- å°† $f,g$ å±•å¼€åå¾—åˆ°(æˆ‘ä»¬å…ˆå¿½ç•¥æ¿€æ´»å‡½æ•°å’Œåç½®):\n$$\\begin{aligned}\\mathbf{h}_t \u0026= \\mathbf{W}_{hx} \\mathbf{x}_t + \\mathbf{W}_{hh} \\mathbf{h}_{t-1},\\\\\\mathbf{o}_t \u0026= \\mathbf{W}_{qh} \\mathbf{h}_{t},\\end{aligned}$$\n- æ ¹æ®ä¸Šå¼å¯ä»¥ç”»å‡ºä¸‰ä¸ªæ—¶é—´æ­¥å†…çš„è®¡ç®—å›¾:\n\n![](notes/2022/2022.4/assets/rnn-bptt.svg)\n\nå…¶ä¸­åœ†åœˆä»£è¡¨è¿ç®—, æ–¹æ¡†ä»£è¡¨å˜é‡æˆ–å‚æ•°\n\n- åœ¨åå‘ä¼ æ’­æ—¶, æˆ‘ä»¬éœ€è¦è®¡ç®—æŸå¤±å‡½æ•°å…³äºå‚æ•° $\\mathbf{W}_{hx}$, $\\mathbf{W}_{hh}$, å’Œ $\\mathbf{W}_{qh}$ çš„å¯¼æ•°, å³: $\\partial L/\\partial \\mathbf{W}_{hx}$, $\\partial L/\\partial \\mathbf{W}_{hh}$, å’Œ $\\partial L/\\partial \\mathbf{W}_{qh}$. è®¡ç®—å›¾é‡Œé¢é€†ç®­å¤´æŒ‡å‘å‚æ•°çš„è·¯å¾„ä¹Ÿå°±æ˜¯åå‘ä¼ æ’­çš„è·¯å¾„.\n- ä¸ºäº†ç®€åŒ–ç»†èŠ‚, æˆ‘ä»¬ä½¿ç”¨ $\\text{prod}$ è¿ç®—ç¬¦æ¥ä»£è¡¨ä»»æ„å¼ é‡,å‘é‡æˆ–è€…æ ‡é‡ä¹‹é—´çš„\"ä¹˜\"è¿ç®—.[^4]\n\n### Step 1: $\\frac{\\partial L}{\\partial \\mathbf{o}_t}$\n$$L = \\frac{1}{T} \\sum_{t=1}^T l(\\mathbf{o}_t, y_t).$$\n![](notes/2022/2022.4/assets/Pasted%20image%2020220403114646.png)\n$$\\frac{\\partial L}{\\partial \\mathbf{o}_t} =\\frac{1}{T}\\frac{\\partial l (\\mathbf{o}_t, y_t)}{\\partial \\mathbf{o}_t} \\in \\mathbb{R}^q$$\n\n### Step 2: $\\frac{\\partial L}{\\partial \\mathbf{W}_{qh}}$\næ ¹æ®è®¡ç®—å›¾, æŸå¤±å‡½æ•°å¯¹ $\\mathbf{W}_{qh}$ çš„æ¢¯åº¦ä¾èµ–äº $\\mathbf{o}_1, \\ldots, \\mathbf{o}_T$, åˆ©ç”¨é“¾å¼æ³•åˆ™æœ‰:\n$$\\frac{\\partial L}{\\partial \\mathbf{W}_{qh}}\n= \\sum_{t=1}^T \\text{prod}\\left(\\frac{\\partial L}{\\partial \\mathbf{o}_t}, \\frac{\\partial \\mathbf{o}_t}{\\partial \\mathbf{W}_{qh}}\\right)\n= \\sum_{t=1}^T \\frac{\\partial L}{\\partial \\mathbf{o}_t} \\mathbf{h}_t^\\top$$\n![](notes/2022/2022.4/assets/Pasted%20image%2020220403133206.png)\n### Step 3: $\\frac{\\partial L}{\\partial \\mathbf{h}_t}$\næˆ‘ä»¬å…ˆæ¥çœ‹çœ‹å¯¹äºæœ€åä¸€ä¸ªæ—¶é—´æ­¥ $T$ æ¥è¯´, æ¢¯åº¦ $\\frac{\\partial L}{\\partial \\mathbf{h}_T}$ çš„è®¡ç®—:\n$$\\frac{\\partial L}{\\partial \\mathbf{h}_T} = \\text{prod}\\left(\\frac{\\partial L}{\\partial \\mathbf{o}_T}, \\frac{\\partial \\mathbf{o}_T}{\\partial \\mathbf{h}_T} \\right) = \\mathbf{W}_{qh}^\\top \\frac{\\partial L}{\\partial \\mathbf{o}_T}$$\n![](notes/2022/2022.4/assets/Pasted%20image%2020220403133243.png)\nåœ¨ $t\u003cT$ çš„æ—¶å€™è®¡ç®—å˜å¾—å¤æ‚èµ·æ¥, å› ä¸º $h_t$ çš„æ¢¯åº¦åŒæ—¶ä¾èµ–äº $o_t$ å’Œ $h_{t+1}$\n![](notes/2022/2022.4/assets/Pasted%20image%2020220403134004.png)\næ ¹æ®é“¾å¼æ³•åˆ™æœ‰:\n$$\\frac{\\partial L}{\\partial \\mathbf{h}_t} = \\text{prod}\\left(\\frac{\\partial L}{\\partial \\mathbf{h}_{t+1}}, \\frac{\\partial \\mathbf{h}_{t+1}}{\\partial \\mathbf{h}_t} \\right) + \\text{prod}\\left(\\frac{\\partial L}{\\partial \\mathbf{o}_t}, \\frac{\\partial \\mathbf{o}_t}{\\partial \\mathbf{h}_t} \\right) = \\mathbf{W}_{hh}^\\top \\frac{\\partial L}{\\partial \\mathbf{h}_{t+1}} + \\mathbf{W}_{qh}^\\top \\frac{\\partial L}{\\partial \\mathbf{o}_t}$$\nè½¬åŒ–ä¸ºé€šé¡¹å…¬å¼:\n$$\\frac{\\partial L}{\\partial \\mathbf{h}_t}= \\sum_{i=t}^T {\\left(\\mathbf{W}_{hh}^\\top\\right)}^{T-i} \\mathbf{W}_{qh}^\\top \\frac{\\partial L}{\\partial \\mathbf{o}_{T+t-i}}.$$\nå³ä½¿æˆ‘ä»¬çœç•¥äº†æ¿€æ´»å‡½æ•°, ä»ä¸­æˆ‘ä»¬å·²ç»èƒ½å¤Ÿçœ‹åˆ°ä¸€äº›é—®é¢˜:  è¡¨è¾¾å¼é‡Œé¢ $\\mathbf{W}_{hh}^\\top$ çš„æŒ‡æ•°éƒ¨åˆ†å¯èƒ½ä¼šå¾ˆå¤§, åœ¨ $\\mathbf{W}_{hh}^\\top$ é‡Œé¢ç‰¹å¾å€¼å¤§äº $1$ çš„éƒ¨åˆ†ä¼šæ¢¯åº¦çˆ†ç‚¸, è€Œç‰¹å¾å€¼å°äº $1$ çš„éƒ¨åˆ†ä¼šæ¢¯åº¦æ¶ˆå¤±.\nåœ¨å¤šæ¬¡çŸ©é˜µè¿ä¹˜ä»¥å, ä¸€ä¸ªå‘é‡ä¼šè¶Šæ¥è¶Šé è¿‘ç‰¹å¾å€¼æœ€å¤§çš„ç‰¹å¾å‘é‡çš„æ–¹å‘.\n![EigenvalueMatrixPower](notes/2022/2022.4/assets/EigenvalueMatrixPower.gif)[^5]\n### Step 4: $\\partial L / \\partial \\mathbf{W}_{hx}$ and $\\partial L / \\partial \\mathbf{W}_{hh}$,\næœ€åæˆ‘ä»¬åŸºäº$\\frac{\\partial L}{\\partial \\mathbf{h}_t}$è®¡ç®—éšè—å±‚å‚æ•°çš„æ¢¯åº¦: $\\partial L / \\partial \\mathbf{W}_{hx} \\in \\mathbb{R}^{h \\times d}$ å’Œ $\\partial L / \\partial \\mathbf{W}_{hh} \\in \\mathbb{R}^{h \\times h}$,\n$$\n\\begin{aligned}\n\\frac{\\partial L}{\\partial \\mathbf{W}_{hx}}\n\u0026= \\sum_{t=1}^T \\text{prod}\\left(\\frac{\\partial L}{\\partial \\mathbf{h}_t}, \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{W}_{hx}}\\right)\n= \\sum_{t=1}^T \\frac{\\partial L}{\\partial \\mathbf{h}_t} \\mathbf{x}_t^\\top,\\\\\n\\frac{\\partial L}{\\partial \\mathbf{W}_{hh}}\n\u0026= \\sum_{t=1}^T \\text{prod}\\left(\\frac{\\partial L}{\\partial \\mathbf{h}_t}, \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{W}_{hh}}\\right)\n= \\sum_{t=1}^T \\frac{\\partial L}{\\partial \\mathbf{h}_t} \\mathbf{h}_{t-1}^\\top,\n\\end{aligned}\n$$\n- å…¶ä¸­å…¬å…±çš„éƒ¨åˆ† $\\frac{\\partial L}{\\partial \\mathbf{h}_t}$ å¯ä»¥å­˜å‚¨èµ·æ¥, é¿å…é‡å¤è®¡ç®—.\n\t![](notes/2022/2022.4/assets/Pasted%20image%2020220403135844.png)\n- å½±å“æ¢¯åº¦ç¨³å®šæ€§çš„éƒ¨åˆ†ä¸»è¦æ˜¯Step3é‡Œé¢çš„ $\\frac{\\partial L}{\\partial \\mathbf{h}_t}$\n\n\n\n\n[^1]: [[notes/2022/2022.4/é€’æ¨å…¬å¼ $a_{t}=b_{t}+c_{t}a_{t-1}$ è½¬é€šé¡¹å…¬å¼]]\n[^2]: [æ¢¯åº¦å½’ä¸€åŒ–](notes/2022/2022.2/D2L-25-è®©è®­ç»ƒæ›´åŠ ç¨³å®š-Xavieråˆå§‹åŒ–.md#æ¢¯åº¦å½’ä¸€åŒ–)\n[^3]: [8.7. Backpropagation Through Time â€” Dive into Deep Learning 0.17.5 documentation](https://d2l.ai/chapter_recurrent-neural-networks/bptt.html#comparing-strategies)\n[^4]: å…·ä½“çœ‹çœ‹è¿™ä¸€èŠ‚: [D2L-5-æ‹“å±•é“¾å¼æ³•åˆ™](notes/2022/2022.1/D2L-5-æ‹“å±•é“¾å¼æ³•åˆ™.md) åˆ©ç”¨æŠ½è±¡çš„ç¬¦å·å¯ä»¥çœç•¥æ‰å¾ˆå¤šç¹æ‚çš„ç»†èŠ‚\n[^5]: [å¦‚ä½•ç†è§£çŸ©é˜µç‰¹å¾å€¼ï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/21874816/answer/181864044)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-56-%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83GRU":{"title":"D2L-56-é—¨æ§å¾ªç¯å•å…ƒGRU","content":"# Gated Recurrent Units (GRU)\n\n\u003cdiv align=\"right\"\u003e 2022-04-03\u003c/div\u003e\n\nTags: #GRU #RNN #DeepLearning \n\n- GRUåœ¨RNNçš„åŸºç¡€ä¸Šæ·»åŠ äº†\"é—¨\"(*Gate*), é’ˆå¯¹æ€§åœ°è§£å†³äº†RNNé‡Œé¢å­˜åœ¨çš„ä»¥ä¸‹é—®é¢˜:\n\t- **é•¿æœŸä¾èµ–é—®é¢˜**: åºåˆ—æ—©æœŸçš„éƒ¨åˆ†å¯èƒ½å¯¹æœªæ¥æ‰€æœ‰è§‚æµ‹å€¼éƒ½æœ‰éå¸¸é‡è¦çš„å½±å“, æˆ‘ä»¬éœ€è¦èƒ½å¤Ÿä¿ç•™åºåˆ—æ—©æœŸä¿¡æ¯çš„ç½‘ç»œç»“æ„. \n\t\t- GRUé‡Œé¢ä½“ç°åœ¨: **é‡ç½®é—¨**å‡å°‘é‡ç½®, **æ›´æ–°é—¨**æ›´å¤šåœ°ä¿ç•™ä¸Šä¸€ä¸ªéšçŠ¶æ€\n\t- åºåˆ—é‡Œé¢å¯èƒ½æœ‰**å¹²æ‰°ä¿¡æ¯**, æˆ‘ä»¬éœ€è¦èƒ½å¤Ÿè·³è¿‡(é—å¿˜)è¿™äº›ä¿¡æ¯çš„æœºåˆ¶\n\t\t- GRUé‡Œé¢ä½“ç°åœ¨: **æ›´æ–°é—¨**æ›´å¤šåœ°ä¿ç•™ä¸Šä¸€ä¸ªéšçŠ¶æ€\n\t- åºåˆ—é‡Œé¢å¯èƒ½æœ‰**é€»è¾‘ä¸­æ–­**, æ¯”å¦‚ä¸€æœ¬ä¹¦é‡Œé¢ç« èŠ‚çš„å˜åŒ–å¾€å¾€ä¼šå¯¼è‡´ä¸»é¢˜çš„å˜åŒ–. æˆ‘ä»¬éœ€è¦æœ‰é‡ç½®ç½‘ç»œçŠ¶æ€çš„æœºåˆ¶.\n\t\t- GRUé‡Œé¢ä½“ç°åœ¨: **é‡ç½®é—¨**å±è”½æ‰ä¸Šä¸€ä¸ªéšçŠ¶æ€\n\n\n![GRU](notes/2022/2022.4/assets/GRU.svg)\n## Gated Hidden State\n- é—¨æ§å¾ªç¯å•å…ƒä¸æ™®é€šçš„å¾ªç¯ç¥ç»ç½‘ç»œä¹‹é—´çš„å…³é”®åŒºåˆ«åœ¨äºï¼š åè€…ç”¨Gateå¯¹Hidden stateè¿›è¡Œäº†è¿›ä¸€æ­¥çš„æ§åˆ¶ã€‚\n\t- è¿™æ„å‘³ç€æ¨¡å‹æœ‰ä¸“é—¨çš„æœºåˆ¶æ¥ç¡®å®šåº”è¯¥ä½•æ—¶æ›´æ–°éšçŠ¶æ€ï¼Œ ä»¥åŠåº”è¯¥ä½•æ—¶é‡ç½®éšçŠ¶æ€ã€‚ \n\t- è¿™äº›æœºåˆ¶æ˜¯å¯å­¦ä¹ çš„ï¼Œå¹¶ä¸”èƒ½å¤Ÿè§£å†³äº†ä¸Šé¢åˆ—å‡ºçš„é—®é¢˜ã€‚ \n\t\t- ä¾‹å¦‚ï¼Œå¦‚æœç¬¬ä¸€ä¸ªè¯å…ƒéå¸¸é‡è¦ï¼Œ æ¨¡å‹å°†å­¦ä¼šåœ¨ç¬¬ä¸€æ¬¡è§‚æµ‹ä¹‹åä¸æ›´æ–°éšçŠ¶æ€ã€‚ åŒæ ·ï¼Œæ¨¡å‹ä¹Ÿå¯ä»¥å­¦ä¼šè·³è¿‡ä¸ç›¸å…³çš„ä¸´æ—¶è§‚æµ‹ã€‚ æœ€åï¼Œæ¨¡å‹è¿˜å°†å­¦ä¼šåœ¨éœ€è¦çš„æ—¶å€™é‡ç½®éšçŠ¶æ€ã€‚ \n\n- ä¸‹é¢æˆ‘ä»¬è¯¦ç»†è®¨è®ºä¸¤ä¸ªé—¨æ§:\n\n### Reset Gate and Update Gate\n![](notes/2022/2022.4/assets/gru-1.svg)\nè¿™ä¸¤ä¸ªé—¨çš„å…¬å¼éƒ½æ˜¯ä¸€æ ·çš„, ä½¿ç”¨input $\\mathbf{X}_{t}$ å’Œå‰ä¸€ä¸ªéšçŠ¶æ€ $\\mathbf{H}_{t-1}$ ä½œä¸ºè¾“å…¥, åˆ©ç”¨Sigmoidæ˜ å°„åˆ° $(0,1)$ åŒºé—´:\n$$\\begin{aligned}\n\u0026\\mathbf{R}_{t}=\\sigma\\left(\\mathbf{X}_{t} \\mathbf{W}_{x r}+\\mathbf{H}_{t-1} \\mathbf{W}_{h r}+\\mathbf{b}_{r}\\right) \\\\\n\u0026\\mathbf{Z}_{t}=\\sigma\\left(\\mathbf{X}_{t} \\mathbf{W}_{x z}+\\mathbf{H}_{t-1} \\mathbf{W}_{h z}+\\mathbf{b}_{z}\\right)\n\\end{aligned}$$\nä¸åŒçš„æ˜¯ä½¿ç”¨å®ƒä»¬çš„æ–¹å¼: \n- é‡ç½®é—¨ $\\mathbf{R}_{t}$ å°†å’Œä¸Šä¸€ä¸ªéšçŠ¶æ€ $\\mathbf{H}_{t-1}$ æŒ‰å…ƒç´ ç›¸ä¹˜ $\\odot$, ç›¸å½“äºä¸€ä¸ªSoftçš„Mask, å¯ä»¥æ§åˆ¶æœ‰å¤šå°‘ $\\mathbf{H}_{t-1}$ ç”¨äºç”Ÿæˆå€™é€‰éšçŠ¶æ€ $\\tilde{\\mathbf{H}}_{t}$, ä¹Ÿå°±æ˜¯æ§åˆ¶æœ‰å¤šå°‘ $\\mathbf{H}_{t-1}$ è¢«\"é‡ç½®\"æ‰äº†(*Reset*).\n\t- $$\\tilde{\\mathbf{H}}_{t}=\\tanh \\left(\\mathbf{X}_{t} \\mathbf{W}_{x h}+\\left(\\mathbf{R}_{t} \\odot \\mathbf{H}_{t-1}\\right) \\mathbf{W}_{h h}+\\mathbf{b}_{h}\\right)$$\n- æ›´æ–°é—¨$\\mathbf{Z}_{t}$åˆ™è¢«ç”¨äºæ··åˆå€™é€‰éšçŠ¶æ€ $\\tilde{\\mathbf{H}}_{t}$å’Œä¸Šä¸€ä¸ªéšçŠ¶æ€ $\\mathbf{H}_{t-1}$ :\n$$\\mathbf{H}_{t}=\\mathbf{Z}_{t} \\odot \\mathbf{H}_{t-1}+\\left(1-\\mathbf{Z}_{t}\\right) \\odot \\tilde{\\mathbf{H}}_{t}$$\n\t- æ³¨æ„æœ€åçš„ç»“æœ $\\mathbf{H}_{t}$ æ˜¯å€™é€‰éšçŠ¶æ€å’Œä¸Šä¸€ä¸ªéšçŠ¶æ€çš„ [å‡¸ç»„åˆ - Convex Combination](notes/2022/2022.4/å‡¸ç»„åˆ%20-%20Convex%20Combination.md), è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆ $\\mathbf{Z}_{t}$ è¦ç”¨Sigmoidæ¥æŠŠèŒƒå›´æ§åˆ¶åˆ° $(0,1)$ çš„åŸå› \n\n### å€™é€‰éšçŠ¶æ€\né¡¾åæ€ä¹‰, å°±æ˜¯ç”¨æ¥ç”Ÿæˆç»“æœçš„éšçŠ¶æ€, ä½¿ç”¨é‡ç½®é—¨ $\\mathbf{R}_{t}$, input $\\mathbf{X}_{t}$ å’Œå‰ä¸€ä¸ªéšçŠ¶æ€ $\\mathbf{H}_{t-1}$ ä½œä¸ºè¾“å…¥, ä½¿ç”¨tanhæ¿€æ´»å‡½æ•°å°†ç»“æœæ˜ å°„åˆ° $(-1,1)$ åŒºé—´:\n$$\\tilde{\\mathbf{H}}_{t}=\\tanh \\left(\\mathbf{X}_{t} \\mathbf{W}_{x h}+\\left(\\mathbf{R}_{t} \\odot \\mathbf{H}_{t-1}\\right) \\mathbf{W}_{h h}+\\mathbf{b}_{h}\\right)$$\n![](notes/2022/2022.4/assets/gru-2.svg)\n\n### è¾“å‡ºéšçŠ¶æ€\n![](notes/2022/2022.4/assets/gru-3.svg)\n\næ€»ä¹‹ï¼Œé—¨æ§å¾ªç¯å•å…ƒå…·æœ‰ä»¥ä¸‹ä¸¤ä¸ªæ˜¾è‘—ç‰¹å¾ï¼š\n\n-   **é‡ç½®é—¨** $\\mathbf{R}_{t}$ æœ‰åŠ©äºæ•è·åºåˆ—ä¸­çš„**çŸ­æœŸ**ä¾èµ–å…³ç³»ã€‚\n-   **æ›´æ–°é—¨** $\\mathbf{Z}_{t}$ æœ‰åŠ©äºæ•è·åºåˆ—ä¸­çš„**é•¿æœŸ**ä¾èµ–å…³ç³»ã€‚\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-57-LSTM-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C":{"title":"D2L-57-LSTM-é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ","content":"# Long Short-Term Memory\n\n\u003cdiv align=\"right\"\u003e 2022-04-18\u003c/div\u003e\n\nTags: #LSTM #DeepLearning #RNN \n\n- LSTMæ˜¯æœ€æ—©ç”¨äºè§£å†³é•¿æœŸä¾èµ–é—®é¢˜çš„ä¸€ç§RNN. å®ƒæ¯”GRUå¤æ‚, ä½†æ˜¯è®¾è®¡æ€æƒ³æ˜¯ä¸€æ ·çš„. æœ‰è¶£çš„æ˜¯, LSTM(1997)æ¯”GRU(2014)æ—©å‡ºç°è¿‘20å¹´.\n\n- LSTMå’ŒGRUä¸€æ ·, ä½¿ç”¨äº†ä¸åŒçš„é—¨(Gate)æ¥æ§åˆ¶ä¸Šä¸€ä¸ªéšçŠ¶æ€åœ¨ä¸‹ä¸€ä¸ªéšçŠ¶æ€é‡Œé¢çš„å æ¯”, ä¹Ÿå°±æ˜¯æœ‰é€‰æ‹©åœ°æ¥æ··åˆ\"é•¿æœŸè®°å¿†\"å’Œ\"çŸ­æœŸè®°å¿†\", è¿™ä¹Ÿæ˜¯å…¶åç§°çš„ç”±æ¥.\n\n- ç›¸æ¯”GRU(ä¸€ç§éšçŠ¶æ€, 2ä¸ªé—¨), LSTMæœ‰ä¸¤ç§éšçŠ¶æ€: Cell State $\\mathbf{C}_{t}$ å’ŒHidden State $\\mathbf{H}_{t}$, å¹¶ä¸”LSTMå¤šä¸€ä¸ªé—¨(3ä¸ª).\n\n## Cell State\n- ç›¸æ¯”ä¼ ç»Ÿçš„RNN, LSTMè§£å†³é•¿æœŸä¾èµ–çš„å…³é”®éƒ¨åˆ†æ˜¯æ–°åŠ å…¥çš„Cell State:\n![](notes/2022/2022.4/assets/img_2022-10-15-5.png)\n- Cell Stateç±»ä¼¼äºä¸€ä¸ªä¼ é€å¸¦(Conveyor Belt), ä¿¡æ¯åœ¨å…¶ä¸­èƒ½å¤Ÿé¡ºç•…åœ°æµåŠ¨. åœ¨ç©¿è¿‡æ¯ä¸€ä¸ªCellçš„æ—¶å€™, ä¿¡æ¯åªæœ‰å¾®å°çš„æ”¹å˜, è¿™ä½¿å¾—ç½‘ç»œæ‹¥æœ‰äº†é•¿æœŸè®°å¿†çš„èƒ½åŠ›.[^1]\n\n- ä¸è¿‡æ³¨æ„åªæœ‰éšçŠ¶æ€æ‰ä¼šä¼ é€’åˆ°è¾“å‡ºå±‚ï¼Œ è€Œè®°å¿†å…ƒ $\\mathbf{C}_{t}$ ä¸ç›´æ¥å‚ä¸è¾“å‡ºè®¡ç®—ã€‚\n## 3 Gates \u0026 1 Candidate State\n### 3 Gates\n![](notes/2022/2022.4/assets/lstm-0.svg)\n- å’ŒGRUä¸€æ ·, å‰ä¸€ä¸ªéšçŠ¶æ€ $\\mathbf{H}_{t-1}$ å’Œè¾“å…¥ $\\mathbf{X}_{t}$ Concatenateèµ·æ¥, ä¸€èµ·ä½œä¸ºä¸‰ä¸ªé—¨çš„è¾“å…¥, æ¿€æ´»å‡½æ•°ä¸ºSigmoid:\n\t$$\\begin{aligned}\n\\mathbf{I}_{t} \u0026=\\sigma\\left(\\mathbf{X}_{t} \\mathbf{W}_{x i}+\\mathbf{H}_{t-1} \\mathbf{W}_{h i}+\\mathbf{b}_{i}\\right) \\\\\n\\mathbf{F}_{t} \u0026=\\sigma\\left(\\mathbf{X}_{t} \\mathbf{W}_{x f}+\\mathbf{H}_{t-1} \\mathbf{W}_{h f}+\\mathbf{b}_{f}\\right) \\\\\n\\mathbf{O}_{t} \u0026=\\sigma\\left(\\mathbf{X}_{t} \\mathbf{W}_{x o}+\\mathbf{H}_{t-1} \\mathbf{W}_{h o}+\\mathbf{b}_{o}\\right)\n\\end{aligned}$$\n### 1 Candidate State\n- å’ŒGRUä¸ä¸€æ ·çš„æ˜¯: Candidate Cell Stateç›´æ¥æ¥å—å‰ä¸€ä¸ªéšçŠ¶æ€ $\\mathbf{H}_{t-1}$ å’Œè¾“å…¥ $\\mathbf{X}_{t}$ ä½œä¸ºè¾“å…¥, è€Œä¸æ˜¯å…ˆè¿›è¡Œ\"Reset/é—å¿˜\"æ“ä½œ:\n![](notes/2022/2022.4/assets/lstm-1.svg)\n$$\\tilde{\\mathbf{C}}_{t}=\\tanh \\left(\\mathbf{X}_{t} \\mathbf{W}_{x c}+\\mathbf{H}_{t-1} \\mathbf{W}_{h c}+\\mathbf{b}_{c}\\right)$$\n### Update Cell State\n![](notes/2022/2022.4/assets/Pasted%20image%2020220418183027.png)\nå¯¹ä¸Šä¸€ä¸ªCell State $\\mathbf{C}_{t-1}$ çš„æ›´æ–°åˆ†ä¸ºä¸¤æ­¥:\n\n#### Forget using Forget Gate\n$$\\mathbf{C}_{t}=\\textcolor{darkorchid}{\\mathbf{F}_{t} \\odot \\mathbf{C}_{t-1}}+\\mathbf{I}_{t} \\odot \\tilde{\\mathbf{C}}_{t}$$\nä¸Forget GateæŒ‰å…ƒç´ ç›¸ä¹˜ï¼Œå±è”½æ‰éœ€è¦å¿˜è®°çš„å…ƒç´ ã€‚\n\n#### Merge new Candidate State\n$$\\mathbf{C}_{t}=\\mathbf{F}_{t} \\odot \\mathbf{C}_{t-1}\\textcolor{orangered}{+\\mathbf{I}_{t} \\odot \\tilde{\\mathbf{C}}_{t}}$$\nå…ˆå°†å€™é€‰Cell Stateä¸Input GateæŒ‰å…ƒç´ ç›¸ä¹˜å¾—åˆ°éœ€è¦æ›´æ–°çš„ä½ç½®ï¼Œå†å’Œé—å¿˜åçš„ç»“æœç›¸åŠ ã€‚\n\n### Output new Hidden State\nå…¶å® $\\mathbf{H}_{t}$ åªæ˜¯ $\\mathbf{C}_{t}$ çš„é—¨æ§ç‰ˆæœ¬: å…ˆåˆ©ç”¨tanhè°ƒæ•´å¤§å°èŒƒå›´åˆ° $(-1,1)$, å†ä½¿ç”¨Output Gate Maskä¸€é:\n$$\\mathbf{H}_{t}=\\mathbf{O}_{t} \\odot \\tanh \\left(\\mathbf{C}_{t}\\right)$$\n![](notes/2022/2022.4/assets/lstm-3.svg)\n\n## Variants of LSTM\n### Peepholes\nAll gates can have a peep at the cell state $\\mathbf{C}_{t-1}$.\n![](notes/2022/2022.4/assets/LSTM3-var-peepholes.png)\n\n### Convex Combination[^2] (coupled forget and input gates) \nForget to remember, remember to forget. The total amount of information stays the same.\n![](notes/2022/2022.4/assets/LSTM3-var-tied.png)\n### GRU\n[D2L-56-é—¨æ§å¾ªç¯å•å…ƒGRU](notes/2022/2022.4/D2L-56-é—¨æ§å¾ªç¯å•å…ƒGRU.md)\n\n\n\n\n[^1]: [Understanding LSTM Networks -- colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) Many pics in this article is from colah's blog.\n[^2]: [å‡¸ç»„åˆ - Convex Combination](notes/2022/2022.4/å‡¸ç»„åˆ%20-%20Convex%20Combination.md)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-58-%E6%B7%B1%E5%BA%A6%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C":{"title":"D2L-58-æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œ","content":"# Deep Recurrent Neural Networks\n\n\u003cdiv align=\"right\"\u003e 2022-04-18\u003c/div\u003e\n\nTags: #RNN #DeepLearning \n\n![](notes/2022/2022.4/assets/deep-rnn.svg)\n\n- å’ŒMLPä¸CNNä¸­ä¸€æ ·, æˆ‘ä»¬å¯ä»¥é€šè¿‡æ·»åŠ æ›´å¤šçš„å±‚æ¥å¢å¼ºç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›. ä½†ä¸åŒçš„æ˜¯, å¢åŠ çš„æ¯ä¸€å±‚éƒ½éœ€è¦åœ¨æ—¶é—´æ­¥ä¸Šå±•å¼€, å°±åƒä¸Šå›¾ä¸€æ ·.\n![](notes/2022/2022.4/assets/Pasted%20image%2020220418224642.png)\n- å…·ä½“çš„æ¥è¯´, é™¤äº†è¾¹ç¼˜éƒ¨åˆ†å¤–, æ¯ä¸€ä¸ªéšçŠ¶æ€ $H^{(l)}_t$ åŒæ—¶æ¥å—ä¸Šä¸€å±‚åŒä¸€æ—¶é—´æ­¥çš„ $\\textcolor{red}{H^{(l-1)}_t}$ å’ŒåŒä¸€å±‚ä¸Šä¸€æ—¶é—´æ­¥çš„ $\\textcolor{red}{H^{(l)}_{t-1}}$ ä½œä¸ºè¾“å…¥, å¹¶ä¸”è¾“å‡ºåˆ°ä¸‹ä¸€å±‚åŒä¸€æ—¶é—´æ­¥çš„ $\\textcolor{royalblue}{H^{(l+1)}_t}$ å’ŒåŒä¸€å±‚ä¸‹ä¸€æ—¶é—´æ­¥çš„ $\\textcolor{royalblue}{H^{(l)}_{t+1}}$\n- ç”¨GRUæˆ–LSTMçš„éšçŠ¶æ€ä»£æ›¿ä¸Šå›¾ä¸­çš„éšçŠ¶æ€ï¼Œä¾¿å¾—åˆ°æ·±åº¦GRUæˆ–æ·±åº¦LSTMã€‚\n\n## å½¢å¼åŒ–å®šä¹‰\n- å‡è®¾åœ¨æ—¶é—´æ­¥ $t$ æœ‰ä¸€ä¸ªå°æ‰¹é‡çš„è¾“å…¥æ•°æ® $\\mathbf{X}_t \\in \\mathbb{R}^{n \\times d}$ï¼ˆæ ·æœ¬æ•°ï¼š$n$ï¼Œæ¯ä¸ªæ ·æœ¬ä¸­çš„è¾“å…¥æ•°ï¼š$d$ï¼‰ã€‚\n- åŒæ—¶ï¼Œå°† $l^\\mathrm{th}$ éšè—å±‚ï¼ˆ$l=1,\\ldots,L$ï¼‰çš„éšçŠ¶æ€è®¾ä¸º $\\mathbf{H}_t^{(l)}  \\in \\mathbb{R}^{n \\times h}$ï¼ˆéšè—å•å…ƒæ•°ï¼š$h$ï¼‰ï¼Œè¾“å‡ºå±‚å˜é‡è®¾ä¸º $\\mathbf{O}_t \\in \\mathbb{R}^{n \\times q}$ï¼ˆè¾“å‡ºæ•°ï¼š$q$ï¼‰ã€‚\n- è®¾ç½® $\\mathbf{H}_t^{(0)} = \\mathbf{X}_t$ï¼Œç¬¬ $l$ ä¸ªéšè—å±‚ä½¿ç”¨æ¿€æ´»å‡½æ•° $\\phi_l$ï¼Œåˆ™ï¼š\n\t$$\\mathbf{H}_t^{(l)} = \\phi_l(\\mathbf{H}_t^{(l-1)} \\mathbf{W}_{xh}^{(l)} + \\mathbf{H}_{t-1}^{(l)} \\mathbf{W}_{hh}^{(l)}  + \\mathbf{b}_h^{(l)})$$\n\t- å…¶ä¸­ï¼Œæƒé‡ $\\mathbf{W}_{xh}^{(l)} \\in \\mathbb{R}^{h \\times h}$ï¼Œ$\\mathbf{W}_{hh}^{(l)} \\in \\mathbb{R}^{h \\times h}$ å’Œåç½® $\\mathbf{b}_h^{(l)} \\in \\mathbb{R}^{1 \\times h}$ éƒ½æ˜¯ç¬¬ $l$ ä¸ªéšè—å±‚çš„å‚æ•°ã€‚\n\n- è¾“å‡ºå±‚çš„è®¡ç®—ä»…åŸºäºæœ€ç»ˆç¬¬ $l$ ä¸ªéšè—å±‚çš„éšçŠ¶æ€ï¼š\n$$\\mathbf{O}_t = \\mathbf{H}_t^{(L)} \\mathbf{W}_{hq} + \\mathbf{b}_q$$\n\n## å®ç°\nåœ¨æ¡†æ¶é‡Œé¢å¯ä»¥å¾ˆå®¹æ˜“çš„å®ç°å¤šå±‚RNN, æ¯”å¦‚å¤šå±‚LSTMåœ¨ `PyTorch` é‡Œé¢å¯ä»¥å®šä¹‰ä¸º: \n```python\nnn.LSTM(num_inputs, num_hiddens, num_layers)\n```\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-59-%E5%8F%8C%E5%90%91%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C":{"title":"D2L-59-åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ","content":"# Bidirectional Recurrent Neural Networks\n\n\u003cdiv align=\"right\"\u003e 2022-04-18\u003c/div\u003e\n\nTags: #RNN #DeepLearning #BidirectionalRNN\n\n\n![](notes/2022/2022.4/assets/birnn%202.svg)\n\n- åŒå‘ç¥ç»ç½‘ç»œå¢åŠ äº†åå‘æ‰«æçš„éšè—å±‚, ä½¿ç½‘ç»œæ‹¥æœ‰äº†\"å‰ç»èƒ½åŠ›\"\n- æ­£å‘å±‚å’Œåå‘å±‚çš„è¾“å…¥æ˜¯ç›¸åŒçš„, æ˜¯å¹¶è¡Œè¿›è¡Œçš„, æœ€åæ­£å‘å’Œåå‘çš„ç»“æœä¸€èµ·ç”Ÿæˆè¾“å‡º.\n- åœ¨D2Læ•™ç¨‹é‡Œé¢å°†æ­£å‘åå‘æ‰«æçš„è¿‡ç¨‹å’Œéšé©¬å°”ç§‘å¤«æ¨¡å‹åŠ¨æ€è§„åˆ’çš„æ­£å‘ä¸åå‘ä¼ é€’[^1]è¿›è¡Œäº†ç±»æ¯”: \n\u003e \tè¿™ç§è½¬å˜é›†ä¸­ä½“ç°äº†ç°ä»£æ·±åº¦ç½‘ç»œçš„è®¾è®¡åŸåˆ™ï¼š é¦–å…ˆä½¿ç”¨ç»å…¸ç»Ÿè®¡æ¨¡å‹çš„å‡½æ•°ä¾èµ–ç±»å‹ï¼Œç„¶åå°†å…¶å‚æ•°åŒ–ä¸ºé€šç”¨å½¢å¼ã€‚\n\n## å½¢å¼åŒ–å®šä¹‰\n- å¯¹äºä»»æ„æ—¶é—´æ­¥ $t$ï¼Œå¯¹äºä¸€ä¸ªæ‰¹é‡çš„è¾“å…¥ $\\mathbf{X}_t \\in \\mathbb{R}^{n \\times d}$ï¼ˆ$n$ ä¸ºæ ·æœ¬æ•°ï¼Œ$d$ ä¸ºæ¯ä¸ªç¤ºä¾‹ä¸­çš„è¾“å…¥æ•°ï¼‰ï¼Œå¹¶ä»¤éšè—å±‚æ¿€æ´»å‡½æ•°ä¸º $\\phi$ã€‚\n\t- åœ¨åŒå‘æ¶æ„ä¸­ï¼Œæˆ‘ä»¬è®¾è¯¥æ—¶é—´æ­¥çš„å‰å‘å’Œåå‘éšçŠ¶æ€åˆ†åˆ«ä¸º $\\overrightarrow{\\mathbf{H}}_t  \\in \\mathbb{R}^{n \\times h}$ å’Œ $\\overleftarrow{\\mathbf{H}}_t  \\in \\mathbb{R}^{n \\times h}$ï¼Œå…¶ä¸­ $h$ æ˜¯éšè—å•å…ƒçš„æ•°ç›®ã€‚\n\t- åˆ™Bidirectional RNNçš„æ›´æ–°è§„åˆ™å¯ä»¥å®šä¹‰å¦‚ä¸‹ï¼š\n\t$$\n\t\\begin{aligned}\n\t\\overrightarrow{\\mathbf{H}}_t \u0026= \\phi(\\mathbf{X}_t \\mathbf{W}_{xh}^{(f)} + \\overrightarrow{\\mathbf{H}}_{t-1} \\mathbf{W}_{hh}^{(f)}  + \\mathbf{b}_h^{(f)}),\\\\\n\t\\overleftarrow{\\mathbf{H}}_t \u0026= \\phi(\\mathbf{X}_t \\mathbf{W}_{xh}^{(b)} + \\overleftarrow{\\mathbf{H}}_{t+1} \\mathbf{W}_{hh}^{(b)}  + \\mathbf{b}_h^{(b)}),\n\t\\end{aligned}\n\t$$\n- å°†å‰å‘éšçŠ¶æ€ $\\overrightarrow{\\mathbf{H}}_t$ å’Œåå‘éšçŠ¶æ€ $\\overleftarrow{\\mathbf{H}}_t$ æ‹¼æ¥èµ·æ¥ï¼Œæˆ‘ä»¬å¾—åˆ°è¾“å‡ºå±‚çš„è¾“å…¥ $\\mathbf{H}_t \\in \\mathbb{R}^{n \\times 2h}$ã€‚\n\t- è¾“å‡º $\\mathbf{O}_t \\in \\mathbb{R}^{n \\times q}$ çš„è®¡ç®—å…¬å¼å¦‚ä¸‹:ï¼ˆ$q$ æ˜¯è¾“å‡ºå•å…ƒçš„æ•°ç›®ï¼‰\n\n$$\\mathbf{O}_t = \\mathbf{H}_t \\mathbf{W}_{hq} + \\mathbf{b}_q.$$\n\n- å€¼å¾—æ³¨æ„çš„æ˜¯, ä¸¤ä¸ªæ–¹å‘å…¶å®å¯ä»¥æ‹¥æœ‰ä¸åŒæ•°é‡çš„éšè—å•å…ƒ\n\n## åŒå‘æ¨¡å‹çš„å±€é™æ€§\n- å› ä¸ºåŒå‘æ¨¡å‹éœ€è¦åŒæ—¶ä½¿ç”¨æ¥è‡ªåºåˆ—ä¸¤ç«¯çš„ä¿¡æ¯æ¥ä¼°è®¡è¾“å‡º, æ‰€ä»¥å®ƒ**å®Œå…¨ä¸èƒ½ç”¨äºå•å‘çš„é¢„æµ‹**(å³ç»™ä¸€ä¸ªå¥å­å¼€å¤´, è®©æ¨¡å‹è¿›è¡Œç»­å†™)\n\t- [ä¸€ä¸ªå¤±è´¥çš„ä¾‹å­](https://zh-v2.d2l.ai/chapter_recurrent-modern/bi-rnn.html#id10)\n\t![](notes/2022/2022.4/assets/Pasted%20image%2020220419003512.png)\n\n- å¦ä¸€ä¸ªä¸¥é‡é—®é¢˜æ˜¯ï¼ŒåŒå‘å¾ªç¯ç¥ç»ç½‘ç»œçš„**è®¡ç®—é€Ÿåº¦éå¸¸æ…¢**ã€‚ \n\t- å…¶ä¸»è¦åŸå› æ˜¯ç½‘ç»œçš„å‰å‘ä¼ æ’­éœ€è¦åœ¨åŒå‘å±‚ä¸­è¿›è¡Œå‰å‘å’Œåå‘é€’å½’ï¼Œ å¹¶ä¸”ç½‘ç»œçš„åå‘ä¼ æ’­è¿˜ä¾èµ–äºå‰å‘ä¼ æ’­çš„ç»“æœã€‚ å› æ­¤ï¼Œæ¢¯åº¦æ±‚è§£å°†æœ‰ä¸€ä¸ªéå¸¸é•¿çš„é“¾ã€‚\n\n## åº”ç”¨\n- åŒå‘å±‚çš„ä½¿ç”¨åœ¨å®è·µä¸­éå¸¸å°‘ï¼Œå¹¶ä¸”ä»…ä»…åº”ç”¨äºéƒ¨åˆ†åœºåˆã€‚ \n\t- ä¾‹å¦‚ï¼Œfilling in missing words, annotating tokens (e.g., for named entity recognition), and encoding sequences wholesale as a step in a sequence processing pipeline (e.g., for machine translation)\n\n\n[^1]: [ä¹‹å‰çš„ç¬”è®° - åºåˆ—æ¨¡å‹-Sequence_Models](notes/2022/2022.3/D2L-48-åºåˆ—æ¨¡å‹-Sequence_Models.md#^f8bb86)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-60-Encoder-Decoder":{"title":"D2L-60-Encoder-Decoder","content":"# ç¼–ç å™¨-è§£ç å™¨æ¶æ„\n\n\u003cdiv align=\"right\"\u003e 2022-04-19\u003c/div\u003e\n\nTags: #EncoderDecoder #RNN #DeepLearning \n\n![](notes/2022/2022.4/assets/encoder-decoder.svg)\n\n- Encoder-Decoderå°†æ¨¡å‹åˆ†ä¸ºä¸¤éƒ¨åˆ†, ä½¿å¾—æˆ‘ä»¬å¯ä»¥å…ˆç”¨ç¼–ç å™¨å¤„ç†ä¸è§„åˆ™çš„è¾“å…¥, ç„¶åå†å°†è¾“å‡ºé€å…¥Decoderå¾—åˆ°æœ€ç»ˆç»“æœ.\n- Encoder-Decoderæ˜¯ä¸€ç§æŠ½è±¡çš„æ¨¡å‹æ¶æ„, å¯ä»¥æœ‰è®¸å¤šä¸åŒçš„å®ç°æ–¹å¼.\n\n- æœ‰çš„æ—¶å€™Decoderä¹Ÿéœ€è¦Input, æ‰€ä»¥ä¸Šå›¾ä¹Ÿå¯ä»¥è¡¨ç¤ºæˆä¸‹é¢çš„æ ·å­:\n\n![](notes/2022/2022.4/assets/encoder-decoder-cn.svg)\nIntuition:\n![](notes/2022/2022.4/assets/Encode-decoder-Intuition.svg)\n\n- Encoder-Decoderæ¨¡å‹é€‚ç”¨äºæœºå™¨ç¿»è¯‘ç­‰åºåˆ—è½¬æ¢é—®é¢˜ã€‚\n\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-61-Sequence-to-Sequence-Learning-Seq2Seq":{"title":"D2L-61-Sequence to Sequence Learning - Seq2Seq","content":"# Seq2Seq: åºåˆ—åˆ°åºåˆ—æ¨¡å‹\n\n\u003cdiv align=\"right\"\u003e 2022-04-19\u003c/div\u003e\n\nTags: #Seq2Seq #EncoderDecoder #DeepLearning #RNN \n\n- Seq2Seqä¹Ÿå°±æ˜¯Sequence to Sequence, é¡¾åæ€ä¹‰, å®ƒå®ç°çš„æ˜¯ä¸€ç§åºåˆ—åˆ°å¦ä¸€ç§åºåˆ—çš„è½¬æ¢(æ¯”å¦‚ä»è‹±è¯­åˆ°ä¸­æ–‡).\n- Seq2Seqç¬¦åˆ[Encoder-Decoder](notes/2022/2022.4/D2L-60-Encoder-Decoder.md)æ¶æ„\n\n![](notes/2022/2022.4/assets/seq2seq.svg)\n## æ€»è§ˆ\n- å¦‚ä¸Šå›¾æ‰€ç¤º, é¦–å…ˆEncoderè¾“å…¥é•¿åº¦å¯å˜çš„åºåˆ—ï¼Œ å¹¶å°†å…¶è½¬æ¢ä¸ºå›ºå®šå½¢çŠ¶çš„éšçŠ¶æ€ã€‚ç„¶åéšçŠ¶æ€è¾“å…¥Decoder, è§£ç å™¨æ ¹æ®éšçŠ¶æ€å’Œè¾“å…¥æ¥ç”Ÿæˆæœ€åçš„è¾“å‡º.\n![](notes/2022/2022.4/assets/seq2seq-details.svg)\n- æˆ‘ä»¬å¦‚ä½•å°†Encoderçš„ç»“æœè¾“å…¥åˆ°Decoderå‘¢? å…¶å®æœ‰ä¸¤ä¸ªæ–¹å¼:\n\t1. æˆ‘ä»¬å¯ä»¥åˆ©ç”¨Encoderæœ€åçš„éšçŠ¶æ€æ¥åˆå§‹åŒ–Decoderçš„éšçŠ¶æ€.\n\t\t- è¿™è¦æ±‚Encoderå’ŒDecoderçš„éšè—å±‚å¤§å°æ˜¯ä¸€æ ·çš„.\n\t\n\t2. æˆ‘ä»¬å¯ä»¥æŠŠEncoderæœ€åçš„éšçŠ¶æ€ä½œä¸ºDecoderè¾“å…¥çš„ä¸€éƒ¨åˆ†. \n\t\t- ä¹Ÿå°±æ˜¯è¯´, Decoderæ¯ä¸€æ¬¡çš„è¾“å…¥æ—¢åŒ…æ‹¬å‰ä¸€ä¸ªè¯, åˆåŒ…æ‹¬Encoderçš„éšçŠ¶æ€.\n\t\n\t- è¿™ä¸¤ç§æ–¹å¼å¯ä»¥åŒæ—¶ä½¿ç”¨.\n\n### Encoder\n#### ä¸Šä¸‹æ–‡å˜é‡: Encoderçš„è¾“å‡º\n- Encoderä¸ä»…å°†é•¿åº¦ä¸å®šçš„åºåˆ—è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„ä¸Šä¸‹æ–‡å˜é‡ $\\mathbf c$, ä¹Ÿå°†åºåˆ—æ‰€å«è¯­ä¹‰ç‰¹å¾ä¹Ÿæå–åˆ°äº† $\\mathbf c$ é‡Œé¢.\n\n- å½¢å¼åŒ–åœ°è¯´, \n\t- éšçŠ¶æ€åŒæ—¶å–å†³äºè¾“å…¥å’Œä¸Šä¸€ä¸ªéšçŠ¶æ€ \n\t$$\\mathbf{h}_t = f(\\mathbf{x}_t, \\mathbf{h}_{t-1}) $$\n\t- è€Œä¸Šä¸‹æ–‡å˜é‡åˆ™æ˜¯æ‰€æœ‰éšçŠ¶æ€çš„ç»¼åˆ:\n\t$$\\mathbf{c} =  q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T)$$\n\t- åœ¨ä¸Šé¢çš„å™è¿°ä¸­åšäº†ç®€åŒ–: ä¸Šä¸‹æ–‡å˜é‡å°±æ˜¯æœ€åä¸€ä¸ªéšçŠ¶æ€: $\\mathbf c= \\mathbf{h}_T$\n\n#### Encoderçš„æ¨¡å‹é€‰æ‹©\n- æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ™®é€šçš„RNNä½œä¸ºEncoder, å½“ç„¶ä¹Ÿå¯ä»¥ä½¿ç”¨GRU, LSTM... \n\t- ä½¿ç”¨LSTMçš„æ—¶å€™, Cell Stateä¹Ÿæ˜¯éšçŠ¶æ€çš„ä¸€éƒ¨åˆ†\n\n- æˆ‘ä»¬å¯ä»¥ä½¿ç”¨Bi-directionalçš„RNNæ¥ä½œä¸ºç¼–ç å™¨, å…¶å®åŒå‘RNNç»å¸¸è¢«ç”¨åœ¨Encoderé‡Œé¢.\n\n### Decoder\nè§£ç å™¨éœ€è¦æ ¹æ®ä¹‹å‰æ‰€æœ‰çš„é¢„æµ‹ $y_1, \\ldots, y_{t'-1}$ å’Œcontext variable $\\mathbf{c}$ æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå…ƒç´  $y_{t'}$, å³:\n$$P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c})$$\n- æ ¹æ®RNNçš„è®¡ç®—æ–¹å¼, Decoderé¦–å…ˆæ ¹æ® $y_{t^\\prime-1}, \\mathbf{c}, \\mathbf{s}_{t^\\prime-1}$ æ¥æ›´æ–°å½“å‰æ—¶é—´æ­¥çš„éšå˜é‡:\n$$\\mathbf{s}_{t^\\prime} = g(y_{t^\\prime-1}, \\mathbf{c}, \\mathbf{s}_{t^\\prime-1})$$\n- ç„¶åæ ¹æ®éšå˜é‡ç”¨è¾“å‡ºå±‚çš„MLPå’ŒSoftmaxæ¥ç”Ÿæˆå¯¹åº”çš„è¾“å‡º:\n\t$$\\mathbf{o_{t^\\prime}}=p(\\mathbf{s}_{t^\\prime})$$\n\t- ä¹Ÿå°±æ˜¯è®¡ç®—æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ $P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c})$\n\n![](notes/2022/2022.4/D2L-53-å¾ªç¯ç¥ç»ç½‘ç»œRNN.md#^ba5f9a)\n\n## Loss Function\n- å¯¹äºsoftmaxçš„è¾“å‡ºï¼Œ æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—[äº¤å‰ç†µæŸå¤±å‡½æ•°](notes/2022/2022.2/D2L-14-Cross%20Entropy%20as%20Loss.md)æ¥è¿›è¡Œä¼˜åŒ–ã€‚\n- ä½†æ˜¯ä¸ºäº†è¿›è¡Œæ‰¹é‡è®­ç»ƒ, æˆ‘ä»¬å¯¹åºåˆ—è¿›è¡Œäº†pad, åœ¨è®¡ç®—æŸå¤±çš„æ—¶å€™éœ€è¦å°†padæ’é™¤åœ¨å¤–.\n\n![](notes/2022/2022.4/assets/seq2seq.ipynb)\n\n## Train\n- åœ¨è®­ç»ƒçš„æ—¶å€™, `\u003cbos\u003e` + æ­£ç¡®åºåˆ—ä¼šè¢«è¾“å…¥åˆ°Decoderé‡Œé¢, è¿™è¢«ç§°ä¸º*Teacher Forcing*\n![](notes/2022/2022.4/assets/seq2seq.svg)\n## Predict\n- åœ¨é¢„æµ‹çš„æ—¶å€™, Decoderçš„è¾“å‡ºè¢«ç”¨ä½œä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥. \n\t- åœ¨è¾“å‡ºä¸º`\u003ceos\u003e`æˆ–è€…é•¿åº¦å¤§äºnum_stepsçš„æ—¶å€™åœæ­¢è¾“å‡º:\n![](notes/2022/2022.4/assets/seq2seq-predict.svg)\n## Evaluate\n- ä¸€ä¸ªåºåˆ—è¶Šé•¿, æˆåŠŸç¿»è¯‘å®ƒçš„éš¾åº¦å°±æ›´å¤§. ä¸ºäº†å¹³è¡¡ä¸åŒå¥å­é•¿åº¦çš„é¢„æµ‹éš¾åº¦, æˆ‘ä»¬ä½¿ç”¨BLEUæ¥ä½œä¸ºè¾“å‡ºæ•ˆæœçš„è¯„ä»·æ ‡å‡†. \n\t- ä¹‹å‰æˆ‘ä»¬ä½¿ç”¨çš„éƒ½æ˜¯[å›°æƒ‘åº¦ Perplexity](notes/2022/2022.4/D2L-53-å¾ªç¯ç¥ç»ç½‘ç»œRNN.md#RNNçš„è¯„ä¼°æŒ‡æ ‡%20å›°æƒ‘åº¦%20Perplexity)\n\n[D2L-62-BLEU (Bilingual Evaluation Understudy)](notes/2022/2022.4/D2L-62-BLEU%20(Bilingual%20Evaluation%20Understudy).md)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-62-BLEU-Bilingual-Evaluation-Understudy":{"title":"D2L-62-BLEU (Bilingual Evaluation Understudy)","content":"# BLEU (Bilingual Evaluation Understudy)\n\n\u003cdiv align=\"right\"\u003e 2022-04-20\u003c/div\u003e\n\nTags: #BLEU #DeepLearning \n\n- **BLEU** æ˜¯ä¸€ç§ç”¨äºè¯„ä»·è¾“å‡ºåºåˆ—è´¨é‡çš„è¯„ä»·æŒ‡æ ‡, å…¶ç‰¹ç‚¹åœ¨äºå®ƒè€ƒè™‘åˆ°äº†åºåˆ—é•¿åº¦å’Œé¢„æµ‹éš¾åº¦çš„å…³ç³».\n\n- **BLEU** é€šè¿‡ç»¼åˆ\"ä¸åŒ*n-gram*åœ¨ç»“æœä¸­çš„æˆåŠŸæ¬¡æ•°\"æ¥è¯„ä»·æœ€ç»ˆè´¨é‡çš„å¥½å.\n\n## å®šä¹‰\n$$ \\exp\\left(\\min\\left(0, 1 - \\frac{\\mathrm{len}_{\\text{label}}}{\\mathrm{len}_{\\text{pred}}}\\right)\\right) \\prod_{n=1}^k p_n^{1/2^n}$$\n\nå…¶ä¸­: \n- $\\mathrm{len}_{\\text{label}}$ è¡¨ç¤ºæ ‡ç­¾åºåˆ—ä¸­çš„è¯å…ƒæ•°\n- $\\mathrm{len}_{\\text{pred}}$ è¡¨ç¤ºé¢„æµ‹åºåˆ—ä¸­çš„è¯å…ƒæ•°\n- $k$ æ˜¯æœ€é•¿çš„ $n$ å…ƒè¯­æ³•çš„é•¿åº¦ã€‚\n\nå¦å¤–ï¼Œç”¨ $p_n$ è¡¨ç¤º $n$ å…ƒè¯­æ³•çš„ç²¾ç¡®åº¦ï¼Œå®ƒæ˜¯ä¸¤ä¸ªæ•°é‡çš„æ¯”å€¼ï¼š\n$$p_n=\\frac{\\operatorname{Num}^{(n)}_{match}}{\\operatorname{Num}^{(n)}_{total}}$$\n\n- åˆ†å­æ˜¯é¢„æµ‹åºåˆ—ä¸æ ‡ç­¾åºåˆ—ä¸­æˆåŠŸåŒ¹é…çš„ $n$ å…ƒè¯­æ³•ä¸ªæ•°ï¼Œ\n- åˆ†æ¯æ˜¯é¢„æµ‹åºåˆ—é‡Œé¢n-gramçš„æ€»ä¸ªæ•°ã€‚\n\nä¸¾ä¸ªä¾‹å­ï¼Œç»™å®šæ ‡ç­¾åºåˆ— $A$ã€$B$ã€$C$ã€$D$ã€$E$ã€$F$\nå’Œ é¢„æµ‹åºåˆ—                     $A$ã€$B$ã€$B$ã€$C$ã€$D$ï¼Œ\næˆ‘ä»¬æœ‰ $p_1 = 4/5$ã€$p_2 = 3/4$ã€$p_3 = 1/3$ å’Œ $p_4 = 0$ã€‚\n\n### è§£é‡Š\n#### ä¸Šé™: å®Œç¾æƒ…å†µ\nå½“ä¸¤ä¸ªåºåˆ—å®Œå…¨ç›¸åŒçš„æ—¶å€™, BLEU=1. \n\n#### ç³»æ•°: æƒ©ç½šçŸ­çš„é¢„æµ‹\n$$\\exp\\left(\\min\\left(0, 1 - \\frac{\\mathrm{len}_{\\text{label}}}{\\mathrm{len}_{\\text{pred}}}\\right)\\right)$$\n- è¿™ä¸ªç³»æ•°çš„ä½œç”¨æ˜¯: ä¸ºæ›´é•¿çš„$n$å…ƒè¯­æ³•çš„ç²¾ç¡®åº¦åˆ†é…æ›´å¤§çš„æƒé‡ã€‚\n- ä¾‹å¦‚ï¼Œå½“$k=2$æ—¶ï¼Œç»™å®šæ ‡ç­¾åºåˆ—$A$ã€$B$ã€$C$ã€$D$ã€$E$ã€$F$ å’Œé¢„æµ‹åºåˆ—$A$ã€$B$ï¼Œå°½ç®¡$p_1 = p_2 = 1$ï¼Œä½†æ˜¯æƒ©ç½šå› å­$\\exp(1-6/2) \\approx 0.14$ä¼šé™ä½BLEUã€‚\n\n#### åº•æ•°: ä¹Ÿåœ¨æƒ©ç½šçŸ­çš„é¢„æµ‹\n- å½“$p_n$å›ºå®šæ—¶(ä¹Ÿå°±æ˜¯å‡è®¾æ‰€æœ‰n-gramçš„é¢„æµ‹æˆåŠŸæ¯”ç‡éƒ½æ˜¯ä¸€æ ·çš„)ï¼Œ$p_n^{1/2^n}$ä¼šéšç€$n$çš„å¢é•¿è€Œå¢åŠ ï¼ˆåŸå§‹è®ºæ–‡ä½¿ç”¨$p_n^{1/n}$ï¼‰, æ‰€ä»¥nè¶Šå¤§å æ¯”è¶Šå¤§.\n![BLEU](notes/2022/2022.4/assets/img_2022-10-15.gif)\n[^1]\n\n## ä»£ç å®ç°\n```python\ndef bleu(pred_seq, label_seq, k):  #@save\n    \"\"\"è®¡ç®—BLEU\"\"\"\n    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n    len_pred, len_label = len(pred_tokens), len(label_tokens)\n    score = math.exp(min(0, 1 - len_label / len_pred))\n    for n in range(1, k + 1):\n        num_matches, label_subs = 0, collections.defaultdict(int)\n        for i in range(len_label - n + 1):\n            label_subs[' '.join(label_tokens[i: i + n])] += 1\n        for i in range(len_pred - n + 1):\n            if label_subs[' '.join(pred_tokens[i: i + n])] \u003e 0:\n                num_matches += 1\n                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n    return score\n```\n\n\n\n[^1]: [è®¡ç®—å™¨å¥—ä»¶ - GeoGebra](https://www.geogebra.org/calculator/x9gpkywp)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-63-Beam-Search":{"title":"D2L-63-Beam Search","content":"# æŸæœç´¢\n\n\u003cdiv  align=\"right\"\u003e  2022-04-20\u003c/div\u003e\n\nTags:  #BeamSearch  #DynamicProgramming\n\n- åœ¨[Seq2Seq](notes/2022/2022.4/D2L-61-Sequence%20to%20Sequence%20Learning%20-%20Seq2Seq.md)é‡Œé¢é¢„æµ‹çš„æ—¶å€™,  æˆ‘ä»¬ç›´æ¥å°±å°†ä¸Šä¸€æ­¥é¢„æµ‹æ¦‚ç‡æœ€å¤§çš„é€‰é¡¹è¾“å…¥åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥,  å…¶å®è¿™æ˜¯ä¸€ç§è´ªå¿ƒç­–ç•¥:  æœ€å¤§åŒ–å½“å‰æ—¶é—´æ­¥çš„é¢„æµ‹æ¦‚ç‡.  è€Œè´ªå¿ƒç®—æ³•å¸¸å¸¸ä¸èƒ½æ‰¾åˆ°å…¨å±€çš„æœ€ä¼˜è§£,  æˆ‘ä»¬èƒ½æ€æ ·æ”¹è¿›å‘¢?\n\n![](notes/2022/2022.4/assets/img_2022-10-15-6.png)\n\n## è´ªå¿ƒ Greedy Search\n\næˆ‘ä»¬å…ˆæ¥è¯„ä¼°ä¸€ä¸‹è´ªå¿ƒç®—æ³•çš„æ—¶é—´å¤æ‚åº¦, æˆ‘ä»¬éœ€è¦è®¡ç®— $T$ ä¸ªæ—¶é—´æ­¥çš„ $|\\mathcal{Y}|$ ä¸ªæ¦‚ç‡, æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º: $$\\mathcal{O}({T}\\cdot\\left|\\mathcal{Y}\\right|)$$\n\n## ç©·ä¸¾ç®—æ³•  Exhaustive  Search\n\nå¦‚æœæœç´¢ç©ºé—´ä¸å¤§,  æˆ‘ä»¬å¯ä»¥ç›´æ¥ç©·ä¸¾æ‰€æœ‰å¯èƒ½çš„åºåˆ—  $y_1,  \\cdots,  y_{t-1},  y_{t}$,  è¿™æ—¶çš„æ—¶é—´å¤æ‚åº¦ä¸º:$$\\mathcal{O}(\\left|\\mathcal{Y}\\right|^{T})$$\nå…¶ä¸­$|\\mathcal{Y}|$ è¡¨ç¤ºè¾“å‡ºè¯è¡¨çš„å¤§å°(åŒ…æ‹¬`\u003ceos\u003e`), ç”±äºè¯è¡¨æˆ–è€…æ—¶é—´æ­¥å¸¸å¸¸è¾ƒå¤§, æ‰€ä»¥ç©·ä¸¾åœ¨è®¡ç®—å¤æ‚åº¦ä¸Šæ˜¯ä¸å¯è¡Œçš„\n\n## Viterbi\n\næ±‚è§£æœ€ä¼˜åºåˆ—ä¹Ÿæ˜¯HMMæ¨¡å‹é‡Œé¢çš„ä¸€ä¸ªé—®é¢˜, è€Œæœ€å¸¸ç”¨çš„ç®—æ³•å°±æ˜¯[Viterbi Algorithm](notes/2022/2022.4/Viterbi%20Algorithm.md)äº†.\nåœ¨è¿™ä¸ªé—®é¢˜é‡Œé¢, Viterbiçš„å¤æ‚åº¦ä¸º:$$\\mathcal{O}({T}\\cdot\\left|\\mathcal{Y}\\right|^2)$$\næ¯”ç©·ä¸¾çš„æŒ‡æ•°å¤æ‚åº¦å¥½å¤šäº†, ä½†æ˜¯$|\\mathcal{Y}|^2$ä¾ç„¶æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„é¡¹, æˆ‘ä»¬å¸Œæœ›å¼€é”€æ›´å°ä¸€ç‚¹.\n\n## Beam Search\n\næŸæœç´¢å°±æ˜¯å¼€é”€ä»‹äºViterbiå’Œè´ªå¿ƒä¹‹é—´çš„é‚£ä¸ªç®—æ³•äº†: é€šè¿‡é€‰å®šä¸€ä¸ª _æŸå®½_ï¼ˆbeam sizeï¼‰$k$, æˆ‘ä»¬åœ¨æ¯ä¸€ä¸ªæ—¶é—´æ­¥åªé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ $k$ æ¡è·¯å¾„, è¿›ä¸€æ­¥å‡å°‘äº†è®¡ç®—å¼€é”€:\n$$\\mathcal{O}(k\\cdot{T}\\cdot\\left|\\mathcal{Y}\\right|)$$\nåœ¨æ—¶é—´æ­¥$1$ï¼Œæˆ‘ä»¬é€‰æ‹©å…·æœ‰æœ€é«˜æ¡ä»¶æ¦‚ç‡çš„$k$ä¸ªè¯å…ƒã€‚è¿™$k$ä¸ªè¯å…ƒå°†åˆ†åˆ«æ˜¯$k$ä¸ªå€™é€‰è¾“å‡ºåºåˆ—çš„ç¬¬ä¸€ä¸ªè¯å…ƒã€‚åœ¨éšåçš„æ¯ä¸ªæ—¶é—´æ­¥ï¼ŒåŸºäºä¸Šä¸€æ—¶é—´æ­¥çš„$k$ä¸ªå€™é€‰è¾“å‡ºåºåˆ—ï¼Œæˆ‘ä»¬å°†ç»§ç»­ä»$k\\left|\\mathcal{Y}\\right|$ä¸ªå¯èƒ½çš„é€‰æ‹©ä¸­æŒ‘å‡ºå…·æœ‰æœ€é«˜æ¡ä»¶æ¦‚ç‡çš„$k$ä¸ªå€™é€‰è¾“å‡ºåºåˆ—ã€‚\n![](notes/2022/2022.4/assets/beam-search.svg)\n\n### å¹³è¡¡åºåˆ—é•¿åº¦\n\n- æŸæœç´¢åœ¨æœ€åæ‰¾å‡ºçš„$k$ä¸ªåºåˆ—é•¿åº¦å¯èƒ½æ˜¯ä¸ç­‰çš„, è€Œé•¿åºåˆ—çš„æ¦‚ç‡æœ¬æ¥å°±è¾ƒä½. ä¸ºäº†å…¬å¹³çš„é€‰å‡ºæœ€ä¼˜åºåˆ—, æˆ‘ä»¬å¯¹åºåˆ—æ¦‚ç‡è¿›è¡Œäº†åŠ æƒ:\n$$ \\frac{1}{L^\\alpha} \\log P(y_1, \\ldots, y_{L}\\mid \\mathbf{c}) = \\frac{1}{L^\\alpha} \\sum_{t'=1}^L \\log P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c})$$\n- å…¶ä¸­$L$æ˜¯æœ€ç»ˆå€™é€‰åºåˆ—çš„é•¿åº¦ï¼Œ$\\alpha$é€šå¸¸è®¾ç½®ä¸º$0.75$ã€‚\n- è¿™ç§\"å¹³è¡¡åºåˆ—é•¿åº¦å¯¹ç»“æœå½±å“\"çš„æ€è·¯å’Œ[BLEU](notes/2022/2022.4/D2L-62-BLEU%20(Bilingual%20Evaluation%20Understudy).md)å¾ˆç›¸ä¼¼\n\n## æ€»ç»“\n\n- è´ªå¿ƒç®—æ³•æ˜¯è®°å¿†åŠ›ä¸º $1$ çš„å°å‚»ç“œ\n- è€ŒViterbiçš„è®°å¿†åŠ›ä¸ºæ¯ä¸€ä¸ªæ—¶é—´æ­¥çš„æ‰€æœ‰é€‰é¡¹å¤§å°(_vocab_size:_ $|\\mathcal{Y}|$ ),  æ‰€ä»¥èƒ½å¤Ÿæ‰¾åˆ°æœ€ä¼˜çš„åºåˆ—.\n- Beam Searchæ˜¯ä»‹äºä¸¤è€…ä¹‹é—´çš„,  ä¸ä¸€å®šèƒ½å¤Ÿæ‰¾åˆ°æœ€ä¼˜çš„æ–¹æ³•,  ä½†æ˜¯æ²¡æœ‰è´ªå¿ƒé‚£ä¹ˆå‚».\n- åé¢ä¸¤è€…éƒ½æ˜¯åŠ¨æ€è§„åˆ’ç®—æ³•.\n- å®é™…ä¸Šï¼Œè´ªå¿ƒæœç´¢å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§æŸå®½ä¸º $1$ çš„ç‰¹æ®Šçš„æŸæœç´¢, Viterbiæ˜¯æŸå®½ä¸º $|\\mathcal{Y}|$ çš„æŸæœç´¢ã€‚ é€šè¿‡çµæ´»åœ°é€‰æ‹©æŸå®½ï¼ŒæŸæœç´¢å¯ä»¥åœ¨æ­£ç¡®ç‡å’Œè®¡ç®—ä»£ä»·ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚\n\n---\nRef:\n[natural  language  -  What  is  the  difference  between  the  Viterbi  algorithm  and  beam  search?  -  Cross  Validated](https://stats.stackexchange.com/questions/536249/what-is-the-difference-between-the-viterbi-algorithm-and-beam-search)\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-64-Kernel-Regression":{"title":"D2L-64-Kernel Regression","content":"# Nadaraya-Watson Kernel Regression\n\n\u003cdiv align=\"right\"\u003e 2022-04-20\u003c/div\u003e\n\nTags: #KernelRegression #Nonparametric #Attention #MachineLearning \n\n## Intuition\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/t9-RDKyOU3o\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n## Definition\n$$f(x) = \\sum_{i=1}^n \\frac{K(x - x_i)}{\\sum_{j=1}^n K(x - x_j)} y_i$$\n- å…¶ä¸­æ˜¯$K$ æ˜¯ _æ ¸_ï¼ˆkernelï¼‰ï¼Œ ä¸Šé¢çš„ä¼°è®¡å™¨ï¼ˆEstimatorï¼‰ä¹Ÿè¢«ç§°ä¸º _Nadaraya-Watsonæ ¸å›å½’_ï¼ˆ*Nadaraya-Watson kernel regression*ï¼‰\n\n- åœ¨æ ¸ä¸ºé«˜æ–¯æ ¸ (Gaussian Kernel) çš„æ—¶å€™ï¼š\n\t$$K(u) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{u^2}{2})$$\n$$\\begin{split}\\begin{aligned} f(x) \u0026=\\sum_{i=1}^n \\frac{K(x - x_i)}{\\sum_{j=1}^n K(x - x_j)} y_i\\\\ \u0026= \\sum_{i=1}^n \\frac{\\exp\\left(-\\frac{1}{2}(x - x_i)^2\\right)}{\\sum_{j=1}^n \\exp\\left(-\\frac{1}{2}(x - x_j)^2\\right)} y_i \\\\\u0026= \\sum_{i=1}^n \\mathrm{softmax}\\left(-\\frac{1}{2}(x - x_i)^2\\right) y_i. \\end{aligned}\\end{split}$$\n ^33f5b4\n- å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒNadaraya-Watsonæ ¸å›å½’æ˜¯ä¸€ä¸ªéå‚æ•°æ¨¡å‹. å¯ä»¥çœ‹åˆ°ä¸Šå¼é‡Œé¢æ²¡æœ‰ä»»ä½•å‚æ•°, æ¨¡å‹çš„æ‹Ÿåˆç»“æœå®Œå…¨ç”±æ ·æœ¬ç‚¹å†³å®š.\n\n### Example of Nadarayaâ€“Watson Estimator in practice\n![](notes/2022/2022.4/assets/output_nadaraya-waston_736177_41_0.svg)[^2]\n![400](notes/2022/2022.4/assets/nw-1-1.png)[^1]\n\n## Kernel Regression and Attention \n[[notes/2022/2022.4/D2L-66-Kernel Regression and Attention]]\n\n\n\n\n[^1]: [6.2 Kernel regression estimation | Notes for Predictive Modeling](https://bookdown.org/egarpor/PM-UC3M/npreg-kre.html)\n[^2]: [10.2. æ³¨æ„åŠ›æ±‡èšï¼šNadaraya-Watson æ ¸å›å½’ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_attention-mechanisms/nadaraya-waston.html)\n\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-65-Attention-Cues-Attention-Mechanisms":{"title":"D2L-65-Attention Cues \u0026 Attention Mechanisms","content":"# æ³¨æ„åŠ›ä¿¡å· ä¸ æ³¨æ„åŠ›æœºåˆ¶\n\n\u003cdiv align=\"right\"\u003e 2022-04-20\u003c/div\u003e\n\nTags: #Attention #DeepLearning \n\n## Attention Cue\n- Attention Cueåˆ†ä¸ºä¸¤ç§: _nonvolitional cue_ å’Œ _volitional cue_.\n\n\u003e Your **volition** is the power you have to decide something for yourself. \n\n- æˆ‘åœ¨è¿™é‡Œç¿»è¯‘ä¸º\"è‡ªå‘çš„\"(_volitional_)å’Œ\"éè‡ªå‘çš„\"(_nonvolitional_)ä¿¡å·\n\n- Volitionalçš„ä¿¡å·æœ¬èº«å°±æ˜¯é†’ç›®çš„. (intrinsically salient and conspicuous)\n![300](notes/2022/2022.4/assets/eye-coffee.svg)\n- Nonvolitionalçš„ä¿¡å·æ˜¯ä½ ä¸»åŠ¨å»å…³æ³¨çš„. æ¯”å¦‚ä½ æƒ³è¦çœ‹ä¹¦, æ‰€ä»¥ä¼šå»å¯»æ‰¾ä¹¦æœ¬çš„ä¿¡å·.\n![300](notes/2022/2022.4/assets/eye-book.svg)\n\n## Attention Mechanism\n- å°½ç®¡ä¸Šé¢çš„æ³¨æ„åŠ›ä¿¡å·åˆ†ç±»æ˜¯ç²—æµ…çš„, ä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥æŒ‰ç…§è¿™ä¸ªæ€è·¯å»æ„é€ æ·±åº¦å­¦ä¹ é‡Œé¢çš„**æ³¨æ„åŠ›æœºåˆ¶**(Attention Mechanism).\n![](notes/2022/2022.4/assets/qkv.svg)\n### New Jargons\n- æˆ‘ä»¬å…ˆç»™ä¸¤ç§åŠ¨æœºä¸åŒçš„ä¿¡å·èµ·ä¸ªæ–°åå­—:\n\t- **Query**: Volitional Cue\n\t- **Key**: Nonvolitional Cue\n\n- å¹¶ä¸”æˆ‘ä»¬ç§° intermediate feature representations, ä¹Ÿå°±æ˜¯ Sensory Inputs ä¸º **Value**[^1]\n\n### Incorporate 2 Cues\n- å‰é¢æˆ‘ä»¬æåˆ°, Queryå’ŒKeyåˆ†åˆ«ä»£è¡¨äº†ä¸¤ç§ä¸åŒçš„Attention Cue. åœ¨Attention Mechanismé‡Œé¢, æˆ‘ä»¬å¯ä»¥å°†ä¸¤è€…é€šè¿‡Attention Poolingç»“åˆåˆ°ä¸€èµ·. ç„¶åä¸Valuesä¸€èµ·ç”Ÿæˆæœ€åçš„Output.\n![](notes/2022/2022.4/assets/qkv.svg)\n- One Query + Multiple Key-Value Pairs $\\rightarrow$ One Output\n\n- å…¶å®è¿˜æœ‰å…¶ä»–æ„é€ Attention Mechanismçš„æ–¹å¼.\n\n\n\n[^1]: å…¶å®æˆ‘æ„Ÿè§‰è¿™ä¸ªåå­—èµ·çš„ä¸æ˜¯å¾ˆå¥½, å¾ˆå¤šæ—¶å€™å¹¶æ²¡æœ‰valueé‡Œ\"ç»“æœ\"çš„æ„æ€","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-66-Kernel-Regression-and-Attention":{"title":"D2L-66-Kernel Regression and Attention","content":"# Kernel Regression And Attention\n\n\u003cdiv align=\"right\"\u003e 2022-04-20\u003c/div\u003e\n\nTags: #KernelRegression #Attention #DeepLearning \n\n- Nadaraya-Watson kernel regression is an example of machine learning with attention mechanisms.\n\n## æ›´ä¸€èˆ¬åŒ–çš„Attention Pooling\n- åœ¨Kernel Regressioné‡Œé¢, Estimatoræœ‰å¦‚ä¸‹å½¢å¼:\n$$f(x) = \\sum_{i=1}^n \\frac{K(x - x_i)}{\\sum_{j=1}^n K(x - x_j)} y_i$$\nå…¶ä¸­ $x$ å¯¹åº”query, è€Œ $(x_i, y_i)$ æ˜¯key-value pair.\n\n- å…¶ä¸­attention poolingçš„éƒ¨åˆ†å…¶å®åªåŒ…æ‹¬: $$\\frac{K(x - x_i)}{\\sum_{j=1}^n K(x - x_j)}$$\nå®ƒç»¼åˆqueryé‡Œé¢çš„volitional cueå’Œkeyé‡Œé¢çš„nonvolitional cue, å’Œvalue $y_i$ ä¸€èµ·ç”Ÿæˆæœ€åçš„ç»“æœ.\n![](notes/2022/2022.4/assets/qkv.svg)\n- Kernel Regressionåªæ˜¯æ³¨æ„åŠ›æœºåˆ¶ä¸€ä¸ªç®€å•çš„ç‰¹ä¾‹. æˆ‘ä»¬å¯ä»¥å°†Attention PoolingæŠ½è±¡æˆæ›´ä¸€èˆ¬çš„å½¢å¼: $$f(x) = \\sum_{i=1}^n \\alpha(x, x_i) y_i$$\nå…¶ä¸­ $\\alpha(x, x_i)$ ä»£è¡¨ _Attention Weight_ , è¡¨ç¤ºquery $x$ å’Œ key $x_i$ ä¸€èµ·ç”Ÿæˆçš„æ³¨æ„åŠ›æƒé‡, å¯¹åº”ç€value $y_i$.\n\n- åœ¨[Kernel Regression é‡Œé¢çš„é‡‡ç”¨é«˜æ–¯æ ¸çš„æ—¶å€™](notes/2022/2022.4/D2L-64-Kernel%20Regression.md#^33f5b4), æˆ‘ä»¬å¯ä»¥å¯è§†åŒ–æ‹Ÿåˆåçš„æ³¨æ„åŠ›æƒé‡$\\alpha(x, x_i)$å¦‚ä¸‹æ‰€ç¤º:\n![](notes/2022/2022.4/assets/output_nadaraya-watson_61a333_56_0.svg)\n- å…¶ä¸­testing inputsä»£è¡¨query $x$, training inputsä»£è¡¨keys $x_i$. \n- å¯ä»¥çœ‹åˆ°ä¸¤è€…ä¹‹å‰çš„æ³¨æ„åŠ›æƒé‡å’Œä¸¤è€…ä¹‹é—´çš„è·ç¦»å‘ˆæ­£ç›¸å…³, è·ç¦»è¶Šè¿‘, æƒé‡è¶Šå¤§.\n\n### æ€»ç»“\n- Kernel Regressioné‡Œé¢çš„Attention Poolingæ˜¯æ‰€æœ‰value $y_i$ (è®­ç»ƒè¾“å‡º)çš„åŠ æƒå¹³å‡. å…¶ä¸­æƒé‡å°±æ˜¯ $\\alpha(x, x_i)$ , å…¶å€¼å–å†³äºquery $x$ å’Œ key $x_i$\n\n## Parameterized Kernel Regression\n- Attention Poolingå¯ä»¥æ˜¯**nonparametric**çš„, ä¹Ÿå¯ä»¥æ˜¯**parametric**çš„, ä¸‹é¢ä¾¿æ˜¯ä¸€ä¸ªä¾‹å­:\n- æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ¨Kernel Regressioné‡Œé¢åŠ å…¥å¯å­¦ä¹ çš„å‚æ•°, æé«˜æ¨¡å‹çš„æ€§èƒ½. å½“ç„¶è¿™åŒæ—¶ä¹Ÿä¼šæ”¹å˜Attention weightçš„åˆ†å¸ƒ.\n- å‚æ•°åŒ–çš„Kernel Regressionå¯ä»¥è¡¨ç¤ºå¦‚ä¸‹(ä¾ç„¶é‡‡ç”¨é«˜æ–¯å‡½æ•°ä½œä¸ºæ ¸å‡½æ•°)\n$$\\begin{split}\\begin{aligned}f(x) \u0026= \\sum_{i=1}^n \\alpha(x, x_i) y_i \\\\\u0026= \\sum_{i=1}^n \\frac{\\exp\\left(-\\frac{1}{2}((x - x_i)w)^2\\right)}{\\sum_{j=1}^n \\exp\\left(-\\frac{1}{2}((x - x_j)w)^2\\right)} y_i \\\\\u0026= \\sum_{i=1}^n \\mathrm{softmax}\\left(-\\frac{1}{2}((x - x_i)w)^2\\right) y_i.\\end{aligned}\\end{split}$$\n- è®­ç»ƒçš„ç»“æœå¦‚ä¸‹:\n![](notes/2022/2022.4/assets/output_nadaraya-watson_61a333_128_0.svg)\n- å¯ä»¥çœ‹åˆ°, åŠ å…¥äº†weightçš„Attention Weightå˜å¾—æ›´é›†ä¸­äº†:\n\n![](notes/2022/2022.4/assets/output_nadaraya-watson_61a333_140_0.svg)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-67-Attention-Scoring-Function":{"title":"D2L-67-Attention Scoring Function","content":"# æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°\n\n\u003cdiv align=\"right\"\u003e 2022-04-21\u003c/div\u003e\n\nTags: #Attention #DeepLearning \n\n- æŠ½å–å‡ºAttention Poolingé‡Œé¢éƒ½æœ‰çš„Softmaxéƒ¨åˆ†, æˆ‘ä»¬å¯ä»¥å°†æ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç®€åŒ–ä¸ºAttention Scoring Functionçš„è®¾è®¡.\n\n![](notes/2022/2022.4/assets/attention-output%201.svg)\n\nå½¢å¼åŒ–çš„è¡¨è¾¾å¦‚ä¸‹: \n- query $\\mathbf{q} \\in \\mathbb{R}^q$,  \n- $m$ ä¸ªkey-value pairs $(\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)$, å…¶ä¸­ $\\mathbf{k}_i \\in \\mathbb{R}^k$ ä¸” $\\mathbf{v}_i \\in \\mathbb{R}^v$.\nåˆ™Attention Pooling $f$ å¯ä»¥è¡¨è¾¾ä¸ºvalueçš„å¦‚ä¸‹åŠ æƒå¹³å‡: \n$$f(\\mathbf{q}, (\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)) = \\sum_{i=1}^m \\alpha(\\mathbf{q}, \\mathbf{k}_i) \\mathbf{v}_i \\in \\mathbb{R}^v$$\n- è¿›ä¸€æ­¥å°†attention weighté‡Œé¢çš„softmaxæå–å‡ºæ¥:\n$$\\alpha(\\mathbf{q},Â \\mathbf{k}_i)Â =Â \\mathrm{softmax}(a(\\mathbf{q},Â \\mathbf{k}_i))Â =Â \\frac{\\exp(a(\\mathbf{q},Â \\mathbf{k}_i))}{\\sum_{j=1}^mÂ \\exp(a(\\mathbf{q},Â \\mathbf{k}_j))}Â \\inÂ \\mathbb{R}$$\nå…¶ä¸­ $a(\\mathbf{q},Â \\mathbf{k}_i)$ ä¾¿æ˜¯æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°çš„ä¸€èˆ¬å½¢å¼.\n\n- One Query + Multiple Keys $\\rightarrow$ Multiple Scores $\\rightarrow$ Multiple Weights + Corresponding Values $\\rightarrow$ One Output \n\n- æ›´ä¸€èˆ¬çš„æƒ…å†µä¼šåŒæ—¶å­˜åœ¨å¤šä¸ªQuery $q_1,\\cdots, q_i$, æˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸€ä¸ªkeyå’Œæ¯ä¸€ä¸ªqueryå¯¹åº”çš„æ³¨æ„åŠ›åˆ†æ•° $a(\\mathbf{q}_i,Â \\mathbf{k}_j)$. ä¹Ÿå°±æ˜¯è¯´, æ³¨æ„åŠ›åˆ†æ•°æ˜¯ä¸€ä¸ªäºŒç»´çš„çŸ©é˜µ, è€Œ**æ³¨æ„åŠ›Poolingçš„è¾“å‡ºçš„ä¸ªæ•°ç­‰äºQueryçš„ä¸ªæ•°, è¾“å‡ºçš„ç»´åº¦ç­‰äºValueçš„ç»´åº¦**\n\n## Masked SoftMax\n- å› ä¸ºbatchè®­ç»ƒçš„æ—¶å€™éœ€è¦å¯¹é•¿åº¦è¿›è¡ŒPad, æ‰€ä»¥ä¸ä»…éœ€è¦å¯¹Cost Functionè¿›è¡ŒMask, è¿˜éœ€è¦å¯¹Softmaxè¿›è¡ŒMask, åœ¨æ¦‚ç‡è®¡ç®—çš„æ—¶å€™æ’é™¤æ‰Padçš„ä½ç½®.\n- ç›¸æ¯”æ¯æ¬¡æ ¹æ®åºåˆ—é•¿åº¦æ§åˆ¶è®¡ç®—çš„å…ƒç´ ä¸ªæ•°, ä¸€ä¸ªæŠ€å·§æ˜¯ç›´æ¥å…ˆæŠŠpadçš„ä½ç½®æ›¿æ¢æˆä¸€ä¸ªå¾ˆå¤§çš„è´Ÿæ•°(e.g. -1e6), å†è®¡ç®—Softmax. è¿™æ ·åœ¨è®¡ç®—çš„æ—¶å€™æ— å…³çš„é¡¹å°±ä¼šå˜ä¸º0, ç®€åŒ–äº†è®¡ç®—çš„é€»è¾‘.\n- [ä»£ç ç¤ºä¾‹](https://d2l.ai/chapter_attention-mechanisms/attention-scoring-functions.html#masked-softmax-operation)\n\n## ä¸¤ç§æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°\n### Additive Attention\n[D2L-68-Additive Attention](notes/2022/2022.4/D2L-68-Additive%20Attention.md)\n\n### Scaled Dot-Product Attention\n[D2L-69-Scaled Dot-Product Attention](notes/2022/2022.4/D2L-69-Scaled%20Dot-Product%20Attention.md)\n\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-68-Additive-Attention":{"title":"D2L-68-Additive Attention","content":"# åŠ æ€§æ³¨æ„åŠ›\n\n\u003cdiv align=\"right\"\u003e 2022-04-21\u003c/div\u003e\n\nTags: #Attention #DeepLearning \n\n- ä¸€èˆ¬æ¥è¯´ï¼Œå½“Queryå’ŒKeyæ˜¯**ä¸åŒé•¿åº¦**çš„çŸ¢é‡æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Additive Attentionæ¥ä½œä¸ºScoring Functionã€‚\n- ç»™å®šæŸ¥è¯¢ $\\mathbf{q} \\in \\mathbb{R}^q$ å’Œé”® $\\mathbf{k} \\in \\mathbb{R}^k$ï¼Œ*åŠ æ€§æ³¨æ„åŠ›*ï¼ˆadditive attentionï¼‰çš„è¯„åˆ†å‡½æ•°(Scoring Function)ä¸º\n$$a(\\mathbf q, \\mathbf k) = \\mathbf w_v^\\top \\text{tanh}(\\mathbf W_q\\mathbf q + \\mathbf W_k \\mathbf k) \\in \\mathbb{R},$$\n- å‡½æ•°è¾“å‡ºçš„æ˜¯ä¸€ä¸ªæ ‡é‡. å…¶ä¸­å¯å­¦ä¹ çš„å‚æ•°æ˜¯ $\\mathbf W_q\\in\\mathbb R^{h\\times q}$ã€$\\mathbf W_k\\in\\mathbb R^{h\\times k}$ å’Œ $\\mathbf w_v\\in\\mathbb R^{h}$. å‰ä¸¤ä¸ªæƒé‡åˆ†åˆ«å°† Query å’Œ Key æ˜ å°„ä¸ºé•¿åº¦ä¸º $h$ çš„å‘é‡, ç„¶å $\\mathbf w_v$ å°†å‘é‡æ˜ å°„ä¸ºvalue å¯¹åº”çš„æ³¨æ„åŠ›æƒé‡.\n\n- ä¸‹å›¾å±•ç¤ºäº†Additive Attentionæ˜¯æ€æ ·ç­‰ä»·äºä¸€ä¸ªå•éšè—å±‚çš„MLPçš„. \n\t- (å›¾ä¸­ç®€åŒ–ä¸ºä¸€ä¸ª $k\\times1$ çš„keyå’Œä¸€ä¸ª $q\\times1$ çš„query)\n![Additive Attention](notes/2022/2022.4/assets/Additive%20Attention.svg)\n- æ³¨æ„ä¸Šé¢çš„MLPå’Œä¸‹å›¾çš„å¯¹åº”å…³ç³», ä¸€ä¸ªQueryéœ€è¦å’Œæ‰€æœ‰çš„Keysåˆ†åˆ«è®¡ç®—ä¸€æ¬¡Score. \n![](notes/2022/2022.4/assets/Pasted%20image%2020220427164928.png)\n\n\n## é€šç”¨å½¢å¼\n- åœ¨å®é™…åº”ç”¨ä¸­, Scoring functionéœ€è¦é¢å¯¹Batchå½¢å¼è¾“å…¥çš„Keys and Queries, å¹¶ä¸”æ¯ä¸€ä¸ªBatché‡Œé¢éƒ½æœ‰å¤šä¸ªKeys and Queries.\n```\nqueriesçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œnum_of_queriesï¼Œquery_length)\nkeyçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œnum_of_keyï¼value_pairï¼Œkey_length)\n```\n- åœ¨ä¸€ä¸ªBatché‡Œé¢, æˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸€ä¸ªKeyå’Œæ¯ä¸€ä¸ªQueryçš„æ³¨æ„åŠ›åˆ†æ•°, è¿™å¯ä»¥é€šè¿‡PyTorché‡Œé¢çš„Broadcastingæœºåˆ¶æ¥å·§å¦™åœ°å®ç°:\n```python\nclass AdditiveAttention(nn.Module):\n    \"\"\"åŠ æ€§æ³¨æ„åŠ›\"\"\"\n    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n        super(AdditiveAttention, self).__init__(**kwargs)\n        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, queries, keys, values, valid_lens):\n\t    # å…ˆå’Œæƒé‡ç›¸ä¹˜\n        queries, keys = self.W_q(queries), self.W_k(keys)\n        # åœ¨ç»´åº¦æ‰©å±•åï¼Œ\n        # queriesçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œ1ï¼Œnum_hidden)\n        # keyçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œ1ï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens)\n        # ä½¿ç”¨å¹¿æ’­æ–¹å¼è¿›è¡Œæ±‚å’Œ\n        # ç°åœ¨featureçš„å½¢çŠ¶ä¸º: \n        # (batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens)\n        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n        features = torch.tanh(features)\n        # w_v(features)çš„å½¢çŠ¶ä¸º:(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œ1)\n        # self.w_vä»…æœ‰ä¸€ä¸ªè¾“å‡ºï¼Œå› æ­¤ä»å½¢çŠ¶ä¸­ç§»é™¤æœ€åé‚£ä¸ªç»´åº¦ã€‚\n        scores = self.w_v(features).squeeze(-1)\n        # scoresçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œâ€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        # attention_weightsçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œâ€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°)\n        # valuesçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œå€¼çš„ç»´åº¦)\n        return torch.bmm(self.dropout(self.attention_weights), values)\n        # è¿”å›å€¼çš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œå€¼çš„ç»´åº¦)\n        \n```\n- å…¶ä¸­`masked_softmax`å¯¹äºæ¯ä¸€ä¸ªQueryå–å‰`valid_lens`ä¸ª \"key-value\" pair\n\nå¯è§†åŒ–Softmaxçš„ç»“æœ: attention_weightså¦‚ä¸‹:\n```python\nqueries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))\n# valuesçš„å°æ‰¹é‡ï¼Œä¸¤ä¸ªå€¼çŸ©é˜µæ˜¯ç›¸åŒçš„\nvalues = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(\n    2, 1, 1)\nvalid_lens = torch.tensor([2, 6])\n\nattention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8,\n                              dropout=0.1)\nattention.eval()\nattention(queries, keys, values, valid_lens)\n```\n![](notes/2022/2022.4/assets/Pasted%20image%2020220421153308.png)\n![](notes/2022/2022.4/assets/output_attention-scoring-functions_2a8fdc_78_0.svg)\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-69-Scaled-Dot-Product-Attention":{"title":"D2L-69-Scaled Dot-Product Attention","content":"# ç¼©æ”¾çš„ç‚¹ç§¯æ³¨æ„åŠ›\n\n\u003cdiv align=\"right\"\u003e 2022-04-21\u003c/div\u003e\n\nTags: #Attention #DeepLearning \n\n![](notes/2022/2022.4/assets/img_2022-10-15-7.png)[^1]\n\n- ç›¸æ¯”Additive Attention, ä½¿ç”¨ç‚¹ç§¯å¯ä»¥å¾—åˆ°è®¡ç®—æ•ˆç‡æ›´é«˜çš„Scoring Function. ä½†æ˜¯ç‚¹ç§¯æ“ä½œè¦æ±‚æŸ¥è¯¢å’Œé”®å…·æœ‰ç›¸åŒçš„é•¿åº¦ $d$ã€‚\n\n- æˆ‘ä»¬çŸ¥é“[å†…ç§¯å¯ä»¥è¡¡é‡ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦](notes/2021/2021.11/å†…ç§¯å’Œç›¸å…³æ€§çš„è”ç³»-Dot(Inner)_Product_\u0026_Correlation.md), æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¿™æ ·è§£è¯»ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›: \n\t- æ³¨æ„åŠ›æœºåˆ¶æ˜¯Valuesçš„ä¸€ä¸ªåŠ æƒå¹³å‡, è€Œç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ä¼šèµ‹äºˆå’Œ Query æ›´ç›¸ä¼¼çš„ Key-Value Pair æ›´é«˜çš„æƒé‡.\n\n- å‡è®¾Query $\\mathbf q$ å’ŒKey $\\mathbf k$ çš„æ‰€æœ‰å…ƒç´ éƒ½æ˜¯ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œå¹¶ä¸”å‡å€¼ä¸º $0$, æ–¹å·®ä¸º $1$. åˆ™å®ƒä»¬çš„ç‚¹ç§¯ $\\mathbf q^\\top\\mathbf k$ å†…å…ƒç´ çš„å‡å€¼ä¸º $0$ï¼Œæ–¹å·®ä¸º $d$ã€‚\n\t- ä¸ºç¡®ä¿ç»“æœçš„æ–¹å·®ä»ä¸º $1$ï¼Œæˆ‘ä»¬å°†ç‚¹ç§¯é™¤ä»¥ $\\sqrt{d}$ï¼Œå°±å¾—åˆ°äº†*ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›*ï¼ˆ*scaled dot-product attention*ï¼‰Scoring Functionï¼š\n$$a(\\mathbf q, \\mathbf k) = \\frac{\\mathbf{q}^\\top \\mathbf{k}}  {\\sqrt{d}}$$\n- ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›é‡Œé¢æ˜¯æ²¡æœ‰ä»»ä½•å‚æ•°çš„, è¿™æ˜¯å®ƒå’ŒåŠ æ€§æ³¨æ„åŠ›çš„ä¸€ä¸ªåŒºåˆ«.\n\n## é€šç”¨å½¢å¼\n- åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä»å°æ‰¹é‡çš„è§’åº¦æ¥è€ƒè™‘æé«˜æ•ˆç‡\n- ä¾‹å¦‚ä¸€ä¸ªBatchéœ€è¦åŸºäº $n$ ä¸ª Query å’Œ $m$ ä¸ª Key-value pair è®¡ç®—æ³¨æ„åŠ›ï¼Œå…¶ä¸­Queryå’ŒKeyçš„é•¿åº¦ä¸º $d$ï¼ŒValueçš„é•¿åº¦ä¸º $v$, æŸ¥è¯¢ $\\mathbf Q\\in\\mathbb R^{n\\times d}$ã€é”® $\\mathbf K\\in\\mathbb R^{m\\times d}$ , å€¼ $\\mathbf V\\in\\mathbb R^{m\\times v}$ . \n\t- åˆ™ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ä¸ºï¼š\n$$ \\mathrm{softmax}\\left(\\frac{\\mathbf Q \\mathbf K^\\top }{\\sqrt{d}}\\right) \\mathbf V \\in \\mathbb{R}^{n\\times v}.$$\n\n- **ä»£ç å®ç°:**\n```python\nclass DotProductAttention(nn.Module):\n    \"\"\"ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›\"\"\"\n    def __init__(self, dropout, **kwargs):\n        super(DotProductAttention, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n\n    # queriesçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œd)\n    # keysçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œd)\n    # valuesçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œå€¼çš„ç»´åº¦)\n    # valid_lensçš„å½¢çŠ¶:(batch_sizeï¼Œ)æˆ–è€…(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°)\n    def forward(self, queries, keys, values, valid_lens=None):\n        # è·å–queryçš„é•¿åº¦(keyçš„é•¿åº¦)\n        d = queries.shape[-1]\n        # è®¾ç½®transpose_b=Trueä¸ºäº†äº¤æ¢keysçš„æœ€åä¸¤ä¸ªç»´åº¦\n        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        return torch.bmm(self.dropout(self.attention_weights), values)\n```\n- åœ¨ä»£ç é‡Œé¢æˆ‘ä»¬è¿˜ä½¿ç”¨äº†[Dropout](notes/2022/2022.2/D2L-23-Dropout-ä¸¢å¼ƒæ³•.md)æ¥è¿›è¡Œæ­£åˆ™åŒ–\n\n\n[^1]: ä¸æ˜¯å›¾æº, ä½†æ˜¯æˆ‘æ˜¯åœ¨è¿™é‡Œçœ‹åˆ°çš„[Attentionæœºåˆ¶è¯¦è§£ï¼ˆäºŒï¼‰â€”â€”Self-Attentionä¸Transformer - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/47282410)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-70-Seq2Seq-with-Attention-Bahdanau-Attention":{"title":"D2L-70-Seq2Seq with Attention - Bahdanau Attention","content":"# å«æ³¨æ„åŠ›æœºåˆ¶çš„Seq2Seq\n\n\u003cdiv align=\"right\"\u003e 2022-04-22\u003c/div\u003e\n\nTags: #Seq2Seq #Attention #DeepLearning #RNN \n\n## Motivation\n- åœ¨[Seq2Seq](notes/2022/2022.4/D2L-61-Sequence%20to%20Sequence%20Learning%20-%20Seq2Seq.md)æ¨¡å‹é‡Œé¢, Encoderå‘Decoderä¼ é€’çš„ä»…ä»…æ˜¯æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€, ä¹Ÿå°±æ˜¯ä¸Šä¸‹æ–‡å˜é‡ $\\mathbf c= \\mathbf{h}_T$, æˆ‘ä»¬å‡è®¾é‡Œé¢å·²ç»åŒ…å«äº†è¾“å…¥åºåˆ—çš„æ‰€æœ‰ä¿¡æ¯:\n![](notes/2022/2022.4/assets/img_2022-10-15-8.png)\n- ä½†è¿™æ ·æ¯ä¸€æ­¥Decoderçš„è¾“å…¥éƒ½æ˜¯åŸåºåˆ—çš„ä¸€ä¸ª\"å…¨å±€, ç¬¼ç»Ÿçš„æ€»ç»“\", è¿™æ˜¯ä¸å¤ªåˆç†çš„: åœ¨ä¸‹å›¾ä¸­, åœ¨ç¿»è¯‘\"Knowledge\"çš„çš„æ—¶å€™, æ˜¾ç„¶\"åŠ›é‡\"è¿™ä¸ªè¯æ˜¯ä¸å¤ªé‡è¦çš„. \n\t![](notes/2022/2022.4/assets/img_2022-10-15-1.gif)[^1]\n\t- åœ¨åŸå§‹çš„Seq2Seqæ¨¡å‹é‡Œé¢, è¾“å…¥åºåˆ—é‡Œé¢çš„æ‰€æœ‰å…ƒç´ éƒ½æ˜¯åŒç­‰é‡è¦çš„, æˆ‘ä»¬å¯ä»¥å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æ¥è§£å†³è¿™ä¸€ç‚¹.\n\t- åœ¨Seq2Seqé‡Œé¢å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æœ‰ä¸åŒçš„æ–¹æ³•ï¼Œä¸‹é¢è¦ä»‹ç»çš„ç§°ä¸º**Bahdanauæ³¨æ„åŠ›**\n\t\t- [âœ‚ï¸ How to pronounce Bahdanau - YouTube](https://youtube.com/clip/UgkxQ5GU8jcvH5w14GCdZ3RypfWVN5Q1PeV6)\n\n## æ¨¡å‹æ„å»º\n- æˆ‘ä»¬å°†æ³¨æ„åŠ›æ¨¡å—æ•´åˆåˆ°Decoderé‡Œé¢å», è¿™æ ·åªéœ€è¦é‡å†™Decoderæ¨¡å—å°±å¥½å•¦.\n\t- å…¶å®æ–°å¢æ³¨æ„åŠ›æ¨¡å—ä¹Ÿç­‰ä»·äºé‡‡ç”¨æ–°çš„context variable $\\mathbf c$, è¿™ä¸ªæ–°çš„ä¸Šä¸‹æ–‡å˜é‡ä¼šéšç€æ—¶é—´æ­¥çš„å˜åŒ–è€Œå˜åŒ–.\n\n\t![](notes/2022/2022.4/assets/img_2022-10-15-9.png)\n\t\n**é€‰æ‹©æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°**\n- æˆ‘ä»¬é€‰æ‹©[Additive Attention](notes/2022/2022.4/D2L-68-Additive%20Attention.md), å› ä¸ºåŠ æ€§æ³¨æ„åŠ›é‡Œé¢æœ‰å¯ä»¥å­¦ä¹ çš„å‚æ•°, å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¢åŠ æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›.\n\n**DecoderéšçŠ¶æ€çš„åˆå§‹åŒ–**\n- å’Œä¹‹å‰ä¸€æ ·, æˆ‘ä»¬ä½¿ç”¨Encoderæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„`hidden_state`æ¥åˆå§‹åŒ–decoderçš„hidden state\n\n### æ³¨æ„åŠ›æ¨¡å—\n![](notes/2022/2022.4/assets/seq2seq-attention-details.svg)\nå‡è®¾è¾“å…¥åºåˆ—é•¿åº¦ä¸º $T$, åˆ™Decoderåœ¨æ—¶é—´æ­¥ $t^\\prime$ çš„ä¸Šä¸‹æ–‡å˜é‡ $\\mathbf{c}_{t'}$ ä¸º: (è¿™ä¹Ÿæ˜¯Attention Poolingåœ¨æ—¶é—´æ­¥ $t^\\prime$ çš„è¾“å‡º)\n$$\\mathbf{c}_{t'} = \\sum_{t=1}^T \\alpha(\\mathbf{s}_{t' - 1}, \\mathbf{h}_t) \\mathbf{h}_t$$\nå…¶ä¸­: \n- $\\alpha$ æ˜¯**Attention weight**\n- $\\mathbf{s}_{t' - 1}$ æ˜¯ä¸Šä¸€ä¸ªæ—¶é—´æ­¥Decoderçš„**hidden state**, å¯¹åº”Query\n- $\\mathbf{h}_t$ æ˜¯ **Encoder** `output` é‡Œé¢ç¬¬ $t$ ä¸ªæ—¶é—´æ­¥hidden stateçš„è¾“å‡º. æ—¢å¯¹åº”Key, åˆå¯¹åº” Value.\n- éœ€è¦æ³¨æ„çš„æ˜¯æ¯ä¸€ä¸ªæ—¶é—´æ­¥ $t^\\prime$ çš„ä¸Šä¸‹æ–‡å˜é‡ $\\mathbf{c}_{t'}$ æ˜¯Encoder**æ¯ä¸€ä¸ªæ—¶é—´æ­¥**çš„Attention**æ€»å’Œ**.\n\n**è¾“å…¥**\n- **Query:** $\\mathbf{s}_{t' - 1}$ \n\t- æ¥è‡ªDecoderå¾ªç¯å±‚çš„`output`\n- **Key \u0026 Value:** $\\mathbf{h}_t$\n\t- æ¥è‡ªEncoderçš„ `output`\n\n## æ¨¡å‹å®ç°\n![](notes/2022/2022.4/assets/bahdanau_attention.ipynb)\n\n\n\n[^1]: [Overview - seq2seq](https://google.github.io/seq2seq/)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-71-Multi-Head_Attention":{"title":"D2L-71-Multi-Head_Attention","content":"# å¤šå¤´æ³¨æ„åŠ›\n\n\u003cdiv align=\"right\"\u003e 2022-04-27\u003c/div\u003e\n\nTags: #Attention #Multi-headAttention #DeepLearning \n\n- å¤šå¤´æ³¨æ„åŠ›å°±æ˜¯å¯¹ Query, Key, Value è¿›è¡Œä¸€äº›çº¿æ€§å˜æ¢, å¹¶è¡Œåœ°è®¡ç®—å¤šä¸ªæ³¨æ„åŠ›, æœŸæœ›æ¨¡å‹èƒ½å­¦ä¹ åˆ°å¤šæ ·åŒ–çš„ä¾èµ–å…³ç³».\n\n![](notes/2022/2022.4/assets/multi-head-attention.svg)\n- Another way of seeing it:\n![350](notes/2022/2022.4/assets/Pasted%20image%2020220429225229.png)[^1]\n\n## æ¨¡å‹æ„å»º\nä¸‹é¢æˆ‘ä»¬ç»™å‡º Multi-Head Attention çš„å½¢è±¡åŒ–è¡¨ç¤º:\n### Part 1\n![](notes/2022/2022.4/assets/Pasted%20image%2020220427151440.png)\n- ç»™å®š Query $\\mathbf{q} \\in \\mathbb{R}^{d_q}$ã€Key $\\mathbf{k} \\in \\mathbb{R}^{d_k}$ å’Œ Value $\\mathbf{v} \\in \\mathbb{R}^{d_v}$ï¼Œåˆ™æ¯ä¸ªæ³¨æ„åŠ›å¤´ $\\mathbf{h}_i$ï¼ˆ$i = 1, \\ldots, h$ï¼‰çš„è®¡ç®—æ–¹æ³•ä¸ºï¼š\n\t$$\\mathbf{h}_i = f(\\mathbf W_i^{(q)}\\mathbf q, \\mathbf W_i^{(k)}\\mathbf k,\\mathbf W_i^{(v)}\\mathbf v) \\in \\mathbb R^{p_v}$$\n\t- å…¶ä¸­ï¼Œå¯å­¦ä¹ çš„å‚æ•°åŒ…æ‹¬\n\t\t- $\\mathbf W_i^{(q)}\\in\\mathbb R^{p_q\\times d_q}$ã€ $\\mathbf W_i^{(k)}\\in\\mathbb R^{p_k\\times d_k}$ å’Œ $\\mathbf W_i^{(v)}\\in\\mathbb R^{p_v\\times d_v}$ï¼Œ\n\t\t- ä»¥åŠä»£è¡¨æ³¨æ„åŠ›æ±‡èšçš„å‡½æ•° $f$ã€‚$f$ å¯ä»¥æ˜¯ [Attention Scoring Function](notes/2022/2022.4/D2L-67-Attention%20Scoring%20Function.md) ä¸­çš„åŠ æ€§æ³¨æ„åŠ›æˆ–ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ã€‚\n\n### Part 2\n![](notes/2022/2022.4/assets/Pasted%20image%2020220427151520.png)\n- ç„¶åæˆ‘ä»¬éœ€è¦æ±‡èš $h$ ä¸ªæ³¨æ„åŠ›å¤´çš„ç»“æœ. æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª FC æ¥è¿›è¡Œæ±‡èš (ä¹Ÿå°±æ˜¯å…ˆè¿›è¡Œ Concatenation, å†è¿›è¡Œä¸€ä¸ªçº¿æ€§å˜æ¢).\n\t$$\\mathbf W_o \\begin{bmatrix}\\mathbf h_1\\\\\\vdots\\\\\\mathbf h_h\\end{bmatrix} \\in \\mathbb{R}^{p_o}$$\n\t- å…¶ä¸­å¯å­¦ä¹ çš„å‚æ•°ä¸º $\\mathbf W_o\\in\\mathbb R^{p_o\\times h p_v}$ \n\n- åŸºäºè¿™ç§è®¾è®¡ï¼Œæ¯ä¸ªå¤´éƒ½å¯èƒ½ä¼šå…³æ³¨è¾“å…¥çš„ä¸åŒéƒ¨åˆ†ï¼Œå¯ä»¥è¡¨ç¤ºæ¯”ç®€å•åŠ æƒå¹³å‡å€¼æ›´å¤æ‚çš„å‡½æ•°ã€‚\n\n## æ¨¡å‹å®ç°\n- æ¨¡å‹å®ç°çš„å…³é”®åœ¨äº: **å¹¶è¡Œåœ°**è®¡ç®— $h$ ä¸ªå¤´çš„æ³¨æ„åŠ›.\n\n### Attention Pooling å‚æ•°è§„æ¨¡çš„é—®é¢˜\n- é¦–å…ˆ, å› ä¸ºå¤šå¤´æ³¨æ„åŠ›å¼•å…¥äº†å¤§é‡çš„å…¨è¿æ¥å±‚, è¿™ä¼šæå¤§åœ°å¢åŠ  Attention Pooling çš„å‚æ•°å¤§å°å’Œè®¡ç®—å¤æ‚åº¦. \n- ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜, æˆ‘ä»¬ä»¤ $p_q = p_k = p_v = p_o / h$, ä¹Ÿå°±æ˜¯è¯´, ç°åœ¨æ¯ä¸€ä¸ªå¤´é‡Œé¢çš„ Query, Key, Value éƒ½åªæœ‰åŸæ¥çš„ $1/h$ å¤§.\n- å› ä¸º Value å¤§å°å˜å‘³äº†åŸæ¥çš„ $1/h$, æ‰€ä»¥ Attention çš„è¾“å‡ºé•¿åº¦ä¹Ÿåªæœ‰åŸæ¥çš„ $1/h$. è€Œæ‹¼æ¥ä»¥åçš„ $\\begin{bmatrix}\\mathbf h_1\\\\\\vdots\\\\\\mathbf h_h\\end{bmatrix}$ é•¿åº¦å’ŒåŸæ¥ä¸€æ ·.\n- æœ€åçš„ $\\mathbf W_o$ è¾“å…¥è¾“å‡ºå¤§å°ä¸€æ ·.\n```python\nclass MultiHeadAttention(nn.Module):\n    \"\"\"å¤šå¤´æ³¨æ„åŠ›\"\"\"\n    def __init__(self, key_size, query_size, value_size, num_hiddens,\n                 num_heads, dropout, bias=False, **kwargs):\n        super(MultiHeadAttention, self).__init__(**kwargs)\n        self.num_heads = num_heads\n        self.attention = d2l.DotProductAttention(dropout)\n        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n\n######åˆå§‹åŒ–æ—¶############################\nnum_hiddens, num_heads = 100, 5\nattention = MultiHeadAttention(\n    key_size    =   num_hiddens,\n    query_size  =   num_hiddens,\n    value_size  =   num_hiddens,\n    num_hiddens =   num_hiddens,\n    num_heads   =   num_heads,\n    dropout     =   0.5 )\n```\n- æé—®: æ—¢ç„¶ Attention å‰çš„çº¿æ€§æ˜ å°„ç¼©å°äº† Query, Key å’Œ Value çš„é•¿åº¦, é‚£ä¸ºä»€ä¹ˆä¸Šé¢åˆå§‹åŒ–æ—¶ `key_size`, `query_size`, `value_size` è¿˜æ˜¯ç­‰äº `num_hiddens` å‘¢?\n\t- å…¶å® $W_q, W_k, W_v$ è¡¨ç¤ºçš„æ˜¯å°† $h$ ä¸ªå°å…¨è¿æ¥å±‚æ‹¼èµ·æ¥, å¾—åˆ°çš„ä¸€ä¸ª\"å¤§å·å…¨è¿æ¥å±‚\"çš„å‚æ•°.\n\t\t![Multihead Query](notes/2022/2022.4/assets/Multihead%20Query.svg)\n\n### å¹¶è¡ŒåŒ–æ€è·¯\n- ä¸ºäº†å®ç°å¹¶è¡Œè®¡ç®—, æˆ‘ä»¬å…ˆå°†çº¿æ€§æ˜ å°„ä¹‹åçš„ Query, Key, Value çš„æŒ‰ $Batches\\times heads$ çš„æ–¹å¼æ‹¼æ¥åœ¨ä¸€èµ·:\n![](notes/2022/2022.4/assets/Pasted%20image%2020220427202107.png)\n- ç„¶åå°†æ‹¼æ¥åçš„å¼ é‡ä¸€èµ·é€è¿› Attention, å¾—åˆ°æœªèåˆçš„æ³¨æ„åŠ›è¾“å‡º,\n\n- å†é‡æ–°å˜æ¢å½¢çŠ¶, å¾—åˆ° $\\begin{bmatrix}\\mathbf h_1\\\\\\vdots\\\\\\mathbf h_h\\end{bmatrix}$\n\n- æœ€åå†ç»è¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚ $\\mathbf W_o$, å¾—åˆ°èåˆåçš„æ³¨æ„åŠ›è¾“å‡º\n\n```python\ndef forward(self, queries, keys, values, valid_lens):\n        # queriesï¼Œkeysï¼Œvaluesçš„å½¢çŠ¶:\n        # (batch_sizeï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens)\n        # valid_lensã€€çš„å½¢çŠ¶:\n        # (batch_sizeï¼Œ)æˆ–(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°)\n        # ç»è¿‡å˜æ¢åï¼Œè¾“å‡ºçš„queriesï¼Œkeysï¼Œvaluesã€€çš„å½¢çŠ¶:\n        # (batch_size*num_headsï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œ\n        # num_hiddens/num_heads)\n        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n        values = transpose_qkv(self.W_v(values), self.num_heads)\n\n        if valid_lens is not None:\n            # åœ¨è½´0ï¼Œå°†ç¬¬ä¸€é¡¹ï¼ˆæ ‡é‡æˆ–è€…çŸ¢é‡ï¼‰å¤åˆ¶num_headsæ¬¡ï¼Œ\n            # ç„¶åå¦‚æ­¤å¤åˆ¶ç¬¬äºŒé¡¹ï¼Œç„¶åè¯¸å¦‚æ­¤ç±»ã€‚\n            valid_lens = torch.repeat_interleave(\n                valid_lens, repeats=self.num_heads, dim=0)\n\n        # outputçš„å½¢çŠ¶:(batch_size*num_headsï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œ\n        # num_hiddens/num_heads)\n        output = self.attention(queries, keys, values, valid_lens)\n\n        # output_concatçš„å½¢çŠ¶:(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œnum_hiddens)\n        output_concat = transpose_output(output, self.num_heads)\n        return self.W_o(output_concat)\n```\n\n### å¹¶è¡ŒåŒ–ç»†èŠ‚\n- è¯¦ç»†åœ°è¯´, å¼ é‡å½¢çŠ¶çš„å˜åŒ–å¦‚ä¸‹å›¾æ‰€ç¤º:\n![Tensor Shape in Multihead Attention](notes/2022/2022.4/assets/Tensor%20Shape%20in%20Multihead%20Attention.svg)\n\n\n![](notes/2022/2022.4/assets/multihead_attention.ipynb)\n\n[^1]: From Attention is All You Need","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-72-Self-Attention":{"title":"D2L-72-Self-Attention","content":"# è‡ªæ³¨æ„åŠ›\n\n\u003cdiv align=\"right\"\u003e 2022-04-26\u003c/div\u003e\n\nTags: #Self-Attention #Attention #DeepLearning \n\n- Attention æœºåˆ¶å¯ä»¥æŠ½è±¡ä¸º:[^1]\n$$\\begin{align}\n\\textit{Attention}(Q,K,V) = V\\cdot\\textit{softmax}\\space (\\textit{score}(Q, K))\n\\end{align}$$\nè‡ªæ³¨æ„åŠ›å°±æ˜¯ $Q = K = V$ , ä¹Ÿå°±æ˜¯åŒä¸€ä¸ªåºåˆ—åŒæ—¶ä½œä¸º Query, Key å’Œ Value.\n\n![450](notes/2022/2022.4/assets/img_2022-10-15-10.png)\n- å› ä¸º Query, Key, Value éƒ½æ˜¯åŒä¸€ä¸ªåºåˆ— $X$, æ‰€ä»¥**è‡ªæ³¨æ„åŠ›çš„è¾“å‡ºå°±æ˜¯è¾“å…¥ $X$ è‡ªèº«çš„ä¸€ä¸ªåŠ æƒå¹³å‡**, åªä¸è¿‡æ˜¯ä¸€ç§å…·å¤‡ Attention çš„, \"åŠ¨æ€çš„\"åŠ æƒå¹³å‡.\n\n![Self-Attention](notes/2022/2022.4/assets/Self-Attention.svg)\n\n## å®ç°\n- è‡ªæ³¨æ„åŠ›åªæ˜¯ä¸€ç§æ€æƒ³, ä»»ä½•ä¸€ç§ Attention Mechanism éƒ½å¯ä»¥é€šè¿‡æŠŠ $Q,K,V$ å˜æˆä¸€æ ·çš„æ¥å®ç°è‡ªæ³¨æ„åŠ›.\n\n- ä¸‹é¢æ˜¯ä¸€ä¸ªåˆ©ç”¨ Multihead Attention æ¥å®ç°è‡ªæ³¨æ„åŠ›çš„ä¾‹å­:[^2]\n```python\nnum_hiddens, num_heads = 100, 5\nattention = d2l.MultiHeadAttention(num_hiddens, \n\t\t\t\t\t\t\t\t   num_hiddens, \n\t\t\t\t\t\t\t\t   num_hiddens, \n\t\t\t\t\t\t\t\t   num_hiddens, \n\t\t\t\t\t\t\t\t   num_heads, 0.5)\nattention.eval()\n```\n\n## ä¼˜ç¼ºç‚¹\n- æˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯”è¾ƒ**CNN**, **RNN**, **è‡ªæ³¨æ„åŠ›**ä¸‰ç§ç»“æ„, æ¥åˆ†æè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ä¼˜ç¼ºç‚¹:\n![](notes/2022/2022.4/assets/cnn-rnn-self-attention.svg)\n\n- $k$ : å·ç§¯æ ¸å¤§å°\n- $n$ : åºåˆ—é•¿åº¦\n- $d$ : è¾“å…¥å’Œè¾“å‡ºçš„é€šé“æ•°é‡, éšçŠ¶æ€æ•°é‡, QKV çš„é•¿åº¦\n\n|            | CNN                  | RNN                 | è‡ªæ³¨æ„åŠ›            |\n| ---------- | -------------------- | ------------------- | ------------------- |\n| **è®¡ç®—å¤æ‚åº¦** | $\\mathcal{O}(knd^2)$ | $\\mathcal{O}(nd^2)$ | $\\mathcal{O}(n^2d)$ |\n| **å¹¶è¡Œåº¦**     | $\\mathcal{O}(n)$     | $\\mathcal{O}(1)$    | $\\mathcal{O}(n)$    |\n| **æœ€é•¿è·¯å¾„**   | $\\mathcal{O}(n/k)$   | $\\mathcal{O}(n)$    | $\\mathcal{O}(1)$    |\n- CNN é‡Œé¢**æœ€é•¿è·¯å¾„**çš„æ„æ€æ˜¯: å¦‚æœ $x_1$ éœ€è¦çœ‹åˆ° $x_5$, é‚£ä¹ˆéœ€è¦æœ‰ $n/k=5/3\\rightarrow 2$ ä¸ªå·ç§¯å±‚æ‰èƒ½çœ‹åˆ°.\n\n\n- **ä¼˜ç‚¹:** å¯ä»¥çœ‹åˆ°è‡ªæ³¨æ„åŠ›çš„å¹¶è¡Œåº¦å¥½, æœ€é•¿è·¯å¾„çŸ­(ä¿¡æ¯æµé€šå®¹æ˜“) é€‚åˆç”¨äºå¤„ç†é•¿åºåˆ—. \n- **ç¼ºç‚¹:** ä½†æ˜¯è‡ªæ³¨æ„åŠ›çš„è®¡ç®—å¤æ‚åº¦åœ¨åºåˆ—è¾ƒé•¿çš„æ—¶å€™ä¹Ÿå¢é•¿çš„å¾ˆå¿«\n\n- æ€»è€Œè¨€ä¹‹ï¼ŒCNN å’Œè‡ªæ³¨æ„åŠ›éƒ½æ‹¥æœ‰å¹¶è¡Œè®¡ç®—çš„ä¼˜åŠ¿ï¼Œ è€Œä¸”è‡ªæ³¨æ„åŠ›çš„æœ€å¤§è·¯å¾„é•¿åº¦æœ€çŸ­ã€‚ ä½†æ˜¯å› ä¸ºå…¶è®¡ç®—å¤æ‚åº¦æ˜¯å…³äºåºåˆ—é•¿åº¦çš„äºŒæ¬¡æ–¹ï¼Œæ‰€ä»¥åœ¨å¾ˆé•¿çš„åºåˆ—ä¸­è®¡ç®—ä¼šéå¸¸æ…¢ã€‚\n\n\n## ä½ç½®ç¼–ç \n- åœ¨å¤„ç†è¯å…ƒåºåˆ—æ—¶ï¼ŒRNNæ˜¯é€ä¸ªçš„é‡å¤åœ°å¤„ç†è¯å…ƒçš„ï¼Œ è€Œ**è‡ªæ³¨æ„åŠ›åˆ™å› ä¸ºå¹¶è¡Œè®¡ç®—è€Œæ”¾å¼ƒäº†é¡ºåºæ“ä½œ**ã€‚ \n[D2L-73-Positional_Encoding](notes/2022/2022.4/D2L-73-Positional_Encoding.md)\n\n\n[^1]:  å›çœ‹æˆ‘ä¹‹å‰çš„ç¬”è®°, æˆ‘å½“æ—¶è®°å½•çš„å¹¶æ²¡æœ‰è¿™ä¹ˆæ¸…æ™°. è¿™è¯´æ˜åœ¨ç¬¬ä¸€é\"å­¦æ‡‚\"ä»¥å, ç¬¬äºŒéçš„æ¢³ç†å¾€å¾€èƒ½è·å¾—æ–°çš„, æ›´å‡ç»ƒçš„ç†è§£. [What is Attention, Self Attention, Multi-Head Attention? | Aditya Agrawal](https://www.adityaagrawal.net/blog/deep_learning/attention)\n[^2]: [10.6. è‡ªæ³¨æ„åŠ›å’Œä½ç½®ç¼–ç  â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_attention-mechanisms/self-attention-and-positional-encoding.html#id7)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-73-Positional_Encoding":{"title":"D2L-73-Positional_Encoding","content":"# ä½ç½®ç¼–ç : å°†ä½ç½®ä¿¡æ¯åŠ å…¥æ•°æ®\n\n\u003cdiv align=\"right\"\u003e 2022-04-27\u003c/div\u003e\n\nTags: #PositionalEncoding #Self-Attention #DeepLearning \n\n\n- **ä¸ºäº†ä½¿ç”¨åºåˆ—çš„é¡ºåºä¿¡æ¯**ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨è¾“å…¥è¡¨ç¤ºä¸­æ·»åŠ  **ä½ç½®ç¼–ç **ï¼ˆ*positional encoding*ï¼‰æ¥æ³¨å…¥**ç»å¯¹çš„**æˆ–**ç›¸å¯¹çš„**ä½ç½®ä¿¡æ¯ã€‚\n\n- æˆ‘è§‰å¾—D2Lè®²çš„å¾ˆæ·±å…¥å¾ˆå¥½äº†: [10.6. Self-Attention and Positional Encoding](https://d2l.ai/chapter_attention-mechanisms/self-attention-and-positional-encoding.html#positional-encoding)\n\n**Highlights:**\n![Positional Encoding|300](notes/2022/2022.4/assets/Positional%20Encoding.svg)\n- In binary representations, a higher bit has a lower frequency than a lower bit. Similarly, as demonstrated in the heat map below, the positional encoding decreases frequencies along the encoding dimension by using trigonometric functions. Since the outputs are float numbers, such continuous representations are more space-efficient than binary representations.\n![](notes/2022/2022.4/assets/output_self-attention-and-positional-encoding_d76d5a_67_0.svg)\n\n\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-74-Transformer":{"title":"D2L-74-Transformer","content":"# Transformer\n\n\u003cdiv align=\"right\"\u003e 2022-04-27\u003c/div\u003e\n\nTags: #Transformer #Attention #DeepLearning \n\n![](notes/2022/2022.4/assets/transformer.svg)[^2]\n- Transformer æ˜¯ä¸€ä¸ªçº¯åŸºäº Attention çš„ [Encoder Decoder](notes/2022/2022.4/D2L-60-Encoder-Decoder.md) æ¶æ„æ¨¡å‹\n\n- **Hugging Face Explorable Transformer**: [exBERT](https://huggingface.co/exbert/?model=bert-base-uncased\u0026modelKind=bidirectional\u0026sentence=The%20girl%20ran%20to%20a%20local%20pub%20to%20escape%20the%20din%20of%20her%20city.\u0026layer=2\u0026heads=..0,1,2,3,4,5,6,7,8,9,10,11\u0026threshold=0.32\u0026tokenInd=11\u0026tokenSide=right\u0026maskInds=..\u0026hideClsSep=true)\n\n## Motivation\n- æˆ‘ä»¬åœ¨ [Self-Attention](notes/2022/2022.4/D2L-72-Self-Attention.md#ä¼˜ç¼ºç‚¹) ä¸­æ¯”è¾ƒäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œè‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè‡ªæ³¨æ„åŠ›åŒæ—¶å…·æœ‰**å¹¶è¡Œè®¡ç®—**å’Œ**æœ€çŸ­çš„æœ€å¤§è·¯å¾„é•¿åº¦**è¿™ä¸¤ä¸ªä¼˜åŠ¿ã€‚å› æ­¤ï¼Œ**ä½¿ç”¨è‡ªæ³¨æ„åŠ›æ¥è®¾è®¡æ·±åº¦æ¶æ„æ˜¯å¾ˆæœ‰å¸å¼•åŠ›çš„**.[^1]\n\n## æ•´ä½“æ¶æ„\n- å…¶å®æ•´ä¸ª Transformer çš„ç»“æ„æ˜¯å¾ˆæ¸…æ™°çš„ï¼šæ€»çš„æ¥è¯´ï¼ŒTransformer åˆ†ä¸º Encoder å’Œ Decoder ä¸¤ä¸ªéƒ¨åˆ†ï¼Œå¹¶ä¸”æ¯ä¸ªéƒ¨åˆ†éƒ½ç”± $n$ ä¸ªå—æ„æˆã€‚\n### Encoder Block\n![300](notes/2022/2022.4/assets/Pasted%20image%2020220429160435.png)\n- æ¯ä¸ª Encoder å—é‡Œé¢åŒ…å«ä¸€ä¸ªæ³¨æ„åŠ›å±‚å’Œä¸€ä¸ª FFN å±‚(å…¶å®å°±æ˜¯ä¸¤å±‚å…¨è¿æ¥)\n\t- Attention å±‚ä½¿ç”¨**å¤šå¤´è‡ªæ³¨æ„åŠ›**, ç”¨æ¥ä»æ•´ä¸ªè¾“å…¥åºåˆ—é‡Œé¢æç‚¼ä¿¡æ¯\n\t- FFNå±‚å¯¹æ¯ä¸€ä¸ªPositionè¿›è¡Œç›¸åŒçš„å˜æ¢\n\n- åœ¨æ¯ä¸€æ¬¡å˜æ¢ä»¥å, éƒ½è¿›è¡Œä¸€æ¬¡Layer Normå’Œæ®‹å·®è¿æ¥\n\n### Decoder Block\n![300](notes/2022/2022.4/assets/Pasted%20image%2020220429161346.png)\n- æ¯ä¸ª Decoder å—é‡Œé¢åŒ…å« 2 ä¸ªæ³¨æ„åŠ›å±‚å’Œ 1 ä¸ª FFN å±‚\n\t- ç¬¬ä¸€ä¸ªæ³¨æ„åŠ›å±‚ä¹Ÿä½¿ç”¨**å¤šå¤´è‡ªæ³¨æ„åŠ›**, ä½†æ˜¯ç”±äºé¢„æµ‹æ˜¯é€æ­¥å®Œæˆçš„, æ‰€ä»¥éœ€è¦Maskæ‰æœªçŸ¥çš„é¡¹\n\t- ç¬¬äºŒä¸ªæ³¨æ„åŠ›æ¥å— Encoder çš„è¾“å‡º, ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›, æ¥æ”¶ä¸Šä¸€å±‚çš„è¾“å‡ºä½œä¸º Query.\n\t- æœ€åä¸€å±‚ä½¿ç”¨ FFN å¯¹æ¯ä¸€ä¸ª Position è¿›è¡Œå•ç‹¬å˜æ¢.\n\n- å’Œ Encoder Block ä¸€æ · , æ¯ä¸€å±‚åé¢éƒ½è·Ÿç€ä¸€æ¬¡ Layer Norm å’Œ ä¸€æ¬¡æ®‹å·®è¿æ¥.\n\n- ä¸‹é¢æˆ‘ä»¬è¯¦ç»†çš„ä»‹ç»æ¯ä¸€ä¸ª Building Block:\n\n## Attention: 3 different kinds\n![499](notes/2022/2022.4/assets/Pasted%20image%2020220429162339.png)\n- åœ¨ Transformer é‡Œé¢, ä¸‰ä¸ªæ³¨æ„åŠ›å±‚æœ‰ç€ç»†å¾®çš„å·®åˆ«:\n\n- **Encoder é‡Œé¢çš„æ³¨æ„åŠ›å±‚: å¤šå¤´è‡ªæ³¨æ„åŠ›**\n\t- å¹¶è¡Œåœ°æå–è¾“å‡ºåºåˆ—é‡Œé¢çš„ä¿¡æ¯\n\n- **Decoder é‡Œé¢çš„æ³¨æ„åŠ›å±‚ A: Mask åçš„å¤šå¤´è‡ªæ³¨æ„åŠ›**\n\t- å› ä¸ºé¢„æµ‹æ˜¯ä¸€æ­¥ä¸€æ­¥åœ°è¿›è¡Œçš„, æˆ‘ä»¬ä¸èƒ½å‚è€ƒå½“å‰æ—¶é—´æ­¥ä»¥åçš„åºåˆ—. æ‰€ä»¥éœ€è¦è¿›è¡Œ Mask.\n\t- ä½†æ˜¯å®ƒä»ç„¶æ˜¯è‡ªæ³¨æ„åŠ›, åªä¸è¿‡æ¯ä¸€æ¬¡è‡ªæ³¨æ„åŠ›èƒ½ä½¿ç”¨çš„é•¿åº¦éƒ½åœ¨å¢åŠ .\n\n- **Decoder é‡Œé¢çš„æ³¨æ„åŠ›å±‚ B: å¸¸è§„çš„å¤šå¤´æ³¨æ„åŠ›**\n\t- è¿™ä¸€å±‚æ¥æ”¶ Encoder çš„è¾“å‡ºä½œä¸º Key-Value Pair, è€Œ Query æ˜¯ä¸Šä¸€å±‚çš„è¾“å‡º. æ‰€ä»¥å®ƒä¸å±äºè‡ªæ³¨æ„åŠ›äº†.\n\n- å¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„Attentionå±‚éƒ½ä½¿ç”¨äº†[å¤šå¤´æ³¨æ„åŠ›](notes/2022/2022.4/D2L-71-Multi-Head_Attention.md), å¹¶ä¸”æˆ‘ä»¬åœ¨èƒ½ä½¿ç”¨è‡ªæ³¨æ„åŠ›çš„åœ°æ–¹éƒ½ä½¿ç”¨äº†è‡ªæ³¨æ„åŠ›, ä¸æ„å»ºæ•´ä¸ªç½‘ç»œçš„Motivationç›¸ä¸€è‡´.\n\n## Position-wise Feed-Forward Networks\n- Position-wise FFN å°±æ˜¯ä¸€ä¸ªä¸¤å±‚çš„ MLP. \n- ä¹‹æ‰€ä»¥ç§°å®ƒä¸º\"Position-wise\" FFN, æ˜¯å› ä¸ºå®ƒåªå¯¹è¾“å…¥çš„æœ€åä¸€ä¸ªç»´åº¦è¿›è¡Œå˜æ¢(`num_hiddens`, æ¯ä¸€ä¸ªæ ·æœ¬çš„ç‰¹å¾ç»´åº¦). ä¹Ÿå°±æ˜¯è¯´å®ƒåªåœ¨æ¯ä¸€ä¸ªæ ·æœ¬å†…éƒ¨è¿›è¡Œç‰¹å¾è½¬æ¢, ä¸åŒä½ç½®çš„æ ·æœ¬ä¸ä¼šç›¸äº’å½±å“.\n![FFN|500](notes/2022/2022.4/assets/FFN.svg)\n```python\nclass PositionWiseFFN(nn.Module):\n    \"\"\"åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ\"\"\"\n    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n                 **kwargs):\n        super(PositionWiseFFN, self).__init__(**kwargs)\n        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n\n    def forward(self, X):\n        return self.dense2(self.relu(self.dense1(X)))\n```\n- åœ¨ Transformer é‡Œé¢, Position-wise FFN é€šå¸¸å…ˆå°†ç‰¹å¾ç»´æ”¾å¤§, ç„¶åå†è½¬æ¢å›å»:\n```python\n# D2Lé‡Œé¢çš„ä¾‹å­\nffn_num_input, ffn_num_hiddens = 32, 64\n```\nåŸè®ºæ–‡çš„è¯´æ˜\n![](notes/2022/2022.4/assets/Pasted%20image%2020220429170217.png)\n![FFN dimensions](notes/2022/2022.4/assets/FFN%20dimensions.svg)\n\n\n## Add \u0026 Norm\n- æˆ‘ä»¬ä¹‹æ‰€ä»¥å°†è¿™ä¸¤ä¸ªæ­¥éª¤æŠ½è±¡ä¸ºä¸€ä¸ªç»„ä»¶, æ˜¯å› ä¸ºå®ƒä»¬éƒ½æ˜¯æ„å»ºæœ‰æ•ˆçš„æ·±åº¦æ¶æ„çš„å…³é”®ã€‚\n### Residual Connection\n- æ®‹å·®è¿æ¥çš„æ€æƒ³æ¥è‡ªäº [ResNet](notes/2022/2022.3/D2L-45-ResNet.md#Motivation), å®ƒåœ¨ä¿è¯ç½‘ç»œçš„æ€§èƒ½çš„åŒæ—¶ä½¿è®­ç»ƒæ›´åŠ å®¹æ˜“äº†.\n- ä½†æ˜¯æ®‹å·®è¿æ¥éœ€è¦ä¸¤ä¸ªè¾“å…¥çš„å½¢çŠ¶ç›¸åŒ, è¿™å°±è¦æ±‚ Attention Layer, FFN éƒ½ä¸èƒ½æ”¹å˜å¼ é‡çš„å½¢çŠ¶.\n\n### Layer Norm\n- æˆ‘ä»¬ä¹‹å‰å­¦ä¹ è¿‡ [Batch_Normalization-æ‰¹é‡å½’ä¸€åŒ–](notes/2022/2022.3/D2L-44-Batch_Normalization-æ‰¹é‡å½’ä¸€åŒ–.md) å¯ä»¥ç”¨æ¥åŠ é€Ÿæ”¶æ•›, æˆ‘ä»¬è‡ªç„¶ä¹Ÿæƒ³æŠŠå®ƒç”¨åœ¨ Transformer é‡Œé¢.\n- ä½†æ˜¯ Transformer çš„è¾“å…¥æ˜¯**é•¿åº¦å˜åŒ–**çš„åºåˆ—: ä¸ä»…è®­ç»ƒç½‘ç»œçš„æ—¶å€™é•¿åº¦æ˜¯å˜åŒ–çš„, é¢„æµ‹çš„æ—¶å€™é•¿åº¦æ›´æ˜¯ä¸ç¡®å®šçš„, è¿™ä¼šç»™ Batch Normalization å¸¦æ¥ä¸€äº›é—®é¢˜:\n\t- Batch Normæ˜¯æŒ‰featureæ¥è¿›è¡Œå½’ä¸€åŒ–çš„, ä¹Ÿå°±æ˜¯è¯´, å®ƒä¼šå°†ä¸€ä¸ªBatché‡Œé¢çš„æ‰€æœ‰Sequenceçš„åŒä¸€ä¸ªFeatureæŠ½å‡ºæ¥è¿›è¡Œå½’ä¸€åŒ–.\n\t- ä½†å› ä¸ºåºåˆ—é•¿åº¦æ˜¯å˜åŒ–çš„, åˆ†é…ç»™æ¯ä¸€ä¸ªSequenceçš„\"ä»½é¢\", ä¼šå—å…¶ä»–Sequenceçš„å½±å“: è¦æ˜¯æœ‰ä¸€ä¸ªSequenceå¾ˆçŸ­, è€Œå…¶ä»–Sequenceéƒ½å¾ˆé•¿, é‚£ä¹ˆçŸ­çš„Sequenceæ‰€æœ‰Featureséƒ½ä¼šæ¯”è¾ƒå°, è¿™æ˜¯ä¸å¤ªåˆç†çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n\t![Layer Norn and Batch Norm](notes/2022/2022.4/assets/Layer%20Norn%20and%20Batch%20Norm.svg)\n- è€ŒLayer Normåªå¯¹ä¸€ä¸ª\"Layer\"é‡Œé¢çš„ä¸€ä¸ªæ ·æœ¬çš„è¿›è¡Œå½’ä¸€åŒ–, ä¸åŒé•¿åº¦çš„æ ·æœ¬ä¹‹é—´ä¸ä¼šç›¸äº’å½±å“.\n\n- è®²è§£è§è§†é¢‘ `25:38` [Transformerè®ºæ–‡é€æ®µç²¾è¯»](https://www.bilibili.com/video/BV1pu411o7BE?t=1538.0)\n\n- æ€»ä¹‹ï¼Œ å°½ç®¡Batch Normåœ¨è®¡ç®—æœºè§†è§‰ä¸­è¢«å¹¿æ³›åº”ç”¨ï¼Œä½†åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼ˆè¾“å…¥é€šå¸¸æ˜¯å˜é•¿åºåˆ—ï¼‰Batch Normé€šå¸¸ä¸å¦‚Layer Normçš„æ•ˆæœå¥½ã€‚[^3]\n\n### å®ç°\n- å€¼å¾—æ³¨æ„çš„æ˜¯, æˆ‘ä»¬è¿˜åœ¨æœ€åè¿›è¡Œäº†[Dropout](notes/2022/2022.2/D2L-23-Dropout-ä¸¢å¼ƒæ³•.md)\n```python\nclass AddNorm(nn.Module):\n    \"\"\"æ®‹å·®è¿æ¥åè¿›è¡Œå±‚è§„èŒƒåŒ–\"\"\"\n    def __init__(self, normalized_shape, dropout, **kwargs):\n        super(AddNorm, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n        self.ln = nn.LayerNorm(normalized_shape)\n\n    def forward(self, X, Y):\n        return self.ln(self.dropout(Y) + X)\n```\n\n## Input Preprocessing: Positional Encoding \u0026 Embedding\nå¯¹äºè¾“å…¥æˆ‘ä»¬éœ€è¦åšä¸¤ä»¶äº‹: \n- é¦–å…ˆéœ€è¦æŠŠåºåˆ—è½¬åŒ–ä¸ºå‘é‡: **Embedding**\n- ç„¶åå› ä¸º [è‡ªæ³¨æ„åŠ›å¿½ç•¥äº†åŸå§‹åºåˆ—çš„ä½ç½®ä¿¡æ¯](notes/2022/2022.4/D2L-72-Self-Attention.md#ä½ç½®ç¼–ç ), æˆ‘ä»¬éœ€è¦å†æŠŠä½ç½®ä¿¡æ¯åŠ å›å»: **Positional Encoding**\n\t- åœ¨Positional Encodingé‡Œé¢è¿˜åŠ å…¥äº†Dropout\n\n### å®ç°\n- å› ä¸ºåˆ©ç”¨ä¸‰è§’å‡½æ•°å®ç°çš„ä½ç½®ç¼–ç è¾“å‡ºèŒƒå›´åœ¨-1 å’Œ 1 ä¹‹é—´ï¼Œ ä¸ºäº†å¹³è¡¡ Positional Encoding å’Œ Embedding çš„æ•°é‡çº§ï¼Œ æˆ‘ä»¬éœ€è¦å…ˆå°† embedding çš„ç»“æ„ä¹˜ä¸Š $\\sqrt{d}$, å…¶ä¸­ $d$ æ˜¯ embedding çš„ç»´æ•°.\n```python\n# Since positional encoding values are between -1 and 1, the embedding\n# values are multiplied by the square root of the embedding dimension\n# to rescale before they are summed up\nX = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n```\n\n- æ³¨æ„ Positional Encoding \u0026 Embedding åœ¨ Encoder å’Œ Decoder é‡Œé¢éƒ½æ˜¯æœ‰çš„ã€‚\n\n## Putting it all together\n![](notes/2022/2022.4/assets/transformer.ipynb)\n\n- æœ‰äº†æ‰€æœ‰çš„ Building Blocks ä¹‹åï¼Œ æˆ‘ä»¬ä¾¿å¯ä»¥æ„å»ºèµ·æ•´ä¸ª Transformer æ¨¡å‹äº†ï¼š\n- ä¸‹é¢çš„è§†é¢‘å½¢è±¡è€Œç›´è§‚çš„å±•ç°äº† Transformer æ¨¡å‹çš„å·¥ä½œè¿‡ç¨‹ï¼š\n\t- è¾“å…¥åºåˆ—å…ˆè¿›å…¥ Encoderï¼Œå¹¶è¡Œåœ°è¿›è¡Œ $n$ æ¬¡å¤„ç†\n\t- ç„¶ååœ¨ Decoder ä¸­, æŒ‰ç…§æ—¶é—´æ­¥é¡ºåºä¾æ¬¡è¾“å‡ºæ¨¡å‹ç»“æœ\n\t\t- æ¯ä¸€ä¸ª Decoder å—çš„è¾“å…¥éƒ½åŒ…æ‹¬ Decoder å…ˆå‰çš„è¾“å‡ºå’Œ Encoder çš„è¾“å‡ºä¸¤éƒ¨åˆ†:![](notes/2022/2022.4/assets/The_transformer_encoder_decoder_stack.png)[^5]\n![](notes/2022/2022.4/assets/Attention%20Visualized.mp4) [^4]\n\nMore illustrations:[^5]\n![](notes/2022/2022.4/assets/transformer_resideual_layer_norm_3.png)\n![](notes/2022/2022.4/assets/transformer_decoding_2.gif)\n\n- ä¸‹é¢è¿™ä¸ªç¬”è®°æœ¬é‡Œé¢æœ‰ä¸€ä¸ªå¾ˆå¥½çš„å¤šå¤´æ³¨æ„åŠ›å¯è§†åŒ–:\n\t- [Tensor2Tensor Intro - Colaboratory](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)\n![](notes/2022/2022.4/assets/transformer_self-attention_visualization.png)\n![](notes/2022/2022.4/assets/Pasted%20image%2020220602115027.png)\n\n\n## Further Development\n- å°½ç®¡ Transformer æ¶æ„æ˜¯ä¸ºäº†â€œåºåˆ—åˆ°åºåˆ—â€çš„å­¦ä¹ è€Œæå‡ºçš„ï¼Œä½†åœ¨åç»­åŸºäº Transformer çš„æ¨¡å‹ä¸­(æ¯”å¦‚ BERT)ï¼ŒTransformer **Encoder** æˆ– Transformer **Decoder** é€šå¸¸è¢«**å•ç‹¬**ç”¨äºä¸åŒçš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­ã€‚\n\n\n\n\n[^1]: [10.7. Transformer â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_attention-mechanisms/transformer.html)\n[^2]: [10.7. Transformer â€” Dive into Deep Learning 0.17.5 documentation](https://d2l.ai/chapter_attention-mechanisms/transformer.html)\n[^3]: [10.7. Transformer â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_attention-mechanisms/transformer.html#id8)\n[^4]: [Google AI Blog: Transformer: A Novel Neural Network Architecture for Language Understanding](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)\n[^5]: [The Illustrated Transformer â€“ Jay Alammar â€“ Visualizing machine learning one concept at a time.](https://jalammar.github.io/illustrated-transformer/)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-75-BERT":{"title":"D2L-75-BERT","content":"# Bidirectional Encoder Representations from Transformers (BERT)\n\u003cdiv align=\"right\"\u003e 2022-04-30\u003c/div\u003e\n\nTags: #BERT #Transformer #DeepLearning \n\n![](notes/2022/2022.4/assets/img_2022-10-15-2.gif)\n\n## Motivation\n### æ„å»ºä¸€ä¸ªé€šç”¨çš„è¯­è¨€æ¨¡å‹\n- åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­, æˆ‘ä»¬èƒ½å¯¹ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„å¤§å‹ç½‘ç»œè¿›è¡Œå¾®è°ƒ(Fine-tune), ä»¥è¾ƒå°çš„è®¡ç®—æˆæœ¬å’Œç½‘ç»œæ”¹åŠ¨å°±èƒ½è·å¾—å¾ˆå¥½çš„æ¨¡å‹.\n- BERTå°±æ˜¯æœŸæœ›èƒ½å¤Ÿæ„å»ºä¸€ä¸ªè¶³å¤Ÿå¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹(Pretrained), æ¥é€‚é…å„ç§å„æ ·çš„ä»»åŠ¡.\n![450](notes/2022/2022.4/assets/img_2022-10-15-11.png)\n### ç»“åˆä¸¤ä¸ªç°æœ‰æ¶æ„çš„ä¼˜ç‚¹: ELMo \u0026 GPT\n### GPT: task-agnostic\n- å…¶å®åœ¨ BERT ä»¥å‰, OpenAI å·²ç»æå‡ºäº† GPT ï¼ˆGenerative Pre-Trainingï¼Œç”Ÿæˆå¼é¢„è®­ç»ƒï¼‰æ¨¡å‹, è¯•å›¾æä¾›ä¸€ç§æ—¢è€ƒè™‘ä¸Šä¸‹æ–‡è¯­æ„(context-sensitive), åˆèƒ½é€‚é…å¤šä»»åŠ¡(task-agnostic[^2])çš„æ¨¡å‹\n- ä½†æ˜¯ GPT æ˜¯åŸºäº Transformer Decoder çš„, è¿™å°±æ„å‘³ç€å®ƒå…·å¤‡è‡ªå›å½’æ¨¡å‹(Auto-regressive)çš„æ€§è´¨: åªèƒ½\"å‘å‰çœ‹\"(ä»å·¦åˆ°å³).\n\n- åœ¨ Fine-tune çš„æ—¶å€™, GPT ä¸å†»ç»“ä»»ä½•å‚æ•°, æ‰€æœ‰åŸæ¥çš„æ‰€æœ‰å‚æ•°ä¼šè·Ÿç€æ–°çš„è¾“å‡ºå±‚ä¸€èµ·è®­ç»ƒ\n### ELMo: Bi-directional\n - å°½ç®¡åŸºäº BiLSTM çš„ ELMo æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½çš„ç»¼åˆä¸¤ä¸ªæ–¹å‘çš„è¯­ä¹‰ä¿¡æ¯, ä½†æ˜¯ ELMo æ˜¯ task-specific çš„, æ— æ³•é€‚é…å¤šç§ä»»åŠ¡.\n\n- è¿™å°±æ„å‘³ç€æˆ‘ä»¬ Pretrained ELMo ä¹‹å, è¿˜éœ€è¦ä¸ºä¸åŒçš„ NLP ä»»åŠ¡è®¾è®¡ä¸åŒçš„åç»­æ¶æ„, è¿™æ˜¯å¾ˆç´¯çš„\n\n### BERT: Combining the Best of Both Worlds\n- BERT åŸºäº Transformer çš„ Bidirectional Encoder, æ—¢å¯ä»¥ç»¼åˆ Bidirectional çš„ä¸Šä¸‹æ–‡ä¿¡æ¯, åˆå¯ä»¥é€‚é…å¤šç§æ¨¡å‹(task-agnostic).\n![](notes/2022/2022.4/assets/elmo-gpt-bert.svg)\n- å¹¶ä¸” BERT åœ¨ Fine-tune çš„æ—¶å€™å’Œ GPT ç±»ä¼¼: æ‰€æœ‰åŸæ¥çš„æ‰€æœ‰å‚æ•°ä¼šè·Ÿç€æ–°çš„è¾“å‡ºå±‚ä¸€èµ·è®­ç»ƒ.\n\n![](notes/2022/2022.4/assets/BERT%20hang%20out.gif)\n\n## Model - Overview\n- ä½œä¸ºä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹, è®­ç»ƒ BERT åˆ†ä¸º Pre-train å’Œ Fine-tune ä¸¤éƒ¨åˆ†.\n\t- è€Œä¸”æˆ‘ä»¬éœ€è¦ä¸º Pretrain è®¾è®¡ä¸€ä¸ªé€šç”¨çš„è®­ç»ƒä»»åŠ¡, é€‚é…å¤šç§åº”ç”¨åœºæ™¯.\n\t![](notes/2022/2022.4/assets/Pasted%20image%2020220430172119.png)\n\n- BERT ç›¸å½“äºä¸€ä¸ªåªæœ‰ Encoder çš„ Transformer.\n\t- ä¸ºäº†é€‚é…è®¾è®¡çš„\"é€šç”¨ä»»åŠ¡\", æˆ‘ä»¬è¿˜éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œç›¸åº”çš„æ”¹è¿› ,åé¢è¯¦è¿°.\n\n- ä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹, BERTæä¾›äº†ä¸åŒè§„æ ¼çš„ä¸¤ä¸ªç‰ˆæœ¬.\n```\nBase: \n\t#blocks = 12, hidden size = 768, #heads = 12, #parameters = 110M\nLarge: \n\t#blocks = 24, hidden size = 1024, #heads = 16, #parameter = 340M\n```\n\n## é¢„è®­ç»ƒä»»åŠ¡\n![Pretrain Tasks](notes/2022/2022.4/D2L-76-BERT%20-%20Pretrain.md#Pretrain%20Tasks)\n\n## Model - Detail\n![](notes/2022/2022.4/assets/bert.ipynb)\n### Masked Language Model ä»»åŠ¡\n- æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå•éšå±‚çš„ MLP æ¥å°† Encoder çš„è¾“å‡ºè½¬åŒ–ä¸ºé¢„æµ‹çš„å•è¯æ ‡ç­¾(Vocab é‡Œé¢çš„åºå·)\n```python\nclass MaskLM(nn.Module):\n    \"\"\"BERTçš„æ©è”½è¯­è¨€æ¨¡å‹ä»»åŠ¡\"\"\"\n    def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs):\n        super(MaskLM, self).__init__(**kwargs)\n        self.mlp = nn.Sequential(\n\t     nn.Linear(num_inputs, num_hiddens),\n\t\t nn.ReLU(),\n\t\t nn.LayerNorm(num_hiddens),\n\t\t nn.Linear(num_hiddens, vocab_size))\n\n    def forward(self, X, pred_positions):\n        num_pred_positions = pred_positions.shape[1] # ä¸€å…±æœ‰å¤šå°‘ä¸ªä½ç½®éœ€è¦é¢„æµ‹\n        pred_positions = pred_positions.reshape(-1)  # å…¨éƒ¨æ’æˆä¸€åˆ—\n        batch_size = X.shape[0] \n        batch_idx = torch.arange(0, batch_size) # batchçš„åºå·\n        # å‡è®¾batch_size=4ï¼Œnum_pred_positions=2\n        # é‚£ä¹ˆbatch_idxæ˜¯np.arrayï¼ˆ[0,0,1,1,2,2,3,3]ï¼‰\n        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n        # å–å‡ºXé‡Œé¢éœ€è¦é¢„æµ‹çš„ä½ç½®\n        masked_X = X[batch_idx, pred_positions]\n        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n        # è¿›è¡Œé¢„æµ‹\n        mlm_Y_hat = self.mlp(masked_X)\n        return mlm_Y_hat\n```\n\n### Next Sentence Prediction ä»»åŠ¡\n- æˆ‘ä»¬ä¾ç„¶ä½¿ç”¨ä¸€ä¸ªå•éšå±‚çš„ MLP æ¥å¤„ç† NSP ä»»åŠ¡\n- ä½†æ˜¯å’Œ MLM ä»»åŠ¡ä¸åŒ, BERT åœ¨è¿™ä¸€æ­¥åªä½¿ç”¨äº†æ¯ä¸€ä¸ªåºåˆ—çš„ `\u003ccls\u003e` æ ‡ç­¾, è¿™ä¸ªæ ‡ç­¾åœ¨æ¯ä¸ªå¥å­çš„å¼€å¤´, å¯ä»¥ä½¿ç”¨ `encoded_X[:, 0, :]` æ¥æå–å‡ºæ¥\n![](notes/2022/2022.4/assets/bert-output-tensor%201.png)\n![](notes/2022/2022.4/assets/bert-output-tensor-selection.png)[^1]\n- `\u003ccls\u003e` æ ‡ç­¾è¡¨ç¤º Classification, æ˜¯ BERT ä¸­ä¸“é—¨ç”¨äºå¥å­åˆ†ç±»çš„ä¸€ä¸ªæ ‡ç­¾.\n\t- [What is purpose of the [CLS] token and why is its encoding output important? - Data Science Stack Exchange](https://datascience.stackexchange.com/questions/66207/what-is-purpose-of-the-cls-token-and-why-is-its-encoding-output-important )\n\t- [Why Bert transformer uses [CLS] token for classification instead of average over all tokens? - Data Science Stack Exchange](https://datascience.stackexchange.com/questions/77044/bert-transformer-why-bert-transformer-uses-cls-token-for-classification-inst?rq=1)\n\n```python\nclass NextSentencePred(nn.Module):\n    \"\"\"BERTçš„ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡\"\"\"\n\n    def __init__(self, num_inputs,  num_hiddens, **kwargs):\n        super(NextSentencePred, self).__init__(**kwargs)\n        print(\"num_inputs:\", num_inputs)\n\n        self.output = nn.Sequential(\n            nn.Linear(num_inputs, num_hiddens),\n            nn.Tanh(),\n            nn.Linear(num_hiddens, 2))\n\n    def forward(self, X):\n        # Xçš„å½¢çŠ¶ï¼š(batchsize,num_hiddens)\n        return self.output(X)\n```\n\n### å®Œæ•´çš„æ¨¡å‹\n```python\nclass BERTModel(nn.Module):\n    \"\"\"BERTæ¨¡å‹\"\"\"\n\n    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input, \n                 ffn_num_hiddens, num_heads, num_layers, dropout,\n                 max_len=1000,\n                 #  è¿™é‡Œè®¾ç½®é»˜è®¤å¤§å° 768 æœ‰ç‚¹è¯¯å¯¼, \n                 #  768æ˜¯BERT baseç‰ˆæœ¬çš„hidden_size\n                 #  å…¶å®è¿™é‡Œçš„ç»´åº¦è¦å’Œå‰é¢çš„hidden_sizeå¯¹åº”èµ·æ¥,\n                 key_size=768,\n                 query_size=768,\n                 value_size=768,\n                 mlm_in_features=768,\n                 nsp_in_features=768):\n        super(BERTModel, self).__init__()\n        self.encoder = BERTEncoder(vocab_size, \n\t        num_hiddens, norm_shape,  ffn_num_input, ffn_num_hiddens,\n\t        num_heads, num_layers, dropout, max_len=max_len,\n\t        key_size=key_size, query_size=query_size, \n\t        value_size=value_size)\n        # mlmçš„hidden_sizeæ˜¯768, ä½†æ˜¯å¯ä»¥å–ä¸ä¸€æ ·çš„\n        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)\n        self.nsp = NextSentencePred(nsp_in_features, num_hiddens)\n\n    def forward(self, tokens, segments, \n\t\t    valid_lens=None, pred_positions=None):\n        encoded_X = self.encoder(tokens, segments, valid_lens)\n        if pred_positions is not None:\n            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n        else:\n            mlm_Y_hat = None\n        # ç”¨äºä¸‹ä¸€å¥é¢„æµ‹çš„å¤šå±‚æ„ŸçŸ¥æœºåˆ†ç±»å™¨çš„éšè—å±‚ï¼Œ0æ˜¯â€œ\u003ccls\u003eâ€æ ‡è®°çš„ç´¢å¼•\n        nsp_Y_hat = self.nsp(encoded_X[:, 0, :])\n        return encoded_X, mlm_Y_hat, nsp_Y_hat\n```\n\n## Fine-tune\n[D2L-77-BERT - Fine-tune](notes/2022/2022.4/D2L-77-BERT%20-%20Fine-tune.md)\n\n![](notes/2022/2022.4/assets/BERT%20and%20ERNIE.gif)\n\n[^1]: [A Visual Guide to Using BERT for the First Time â€“ Jay Alammar â€“ Visualizing machine learning one concept at a time.](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)\n[^2]: Agonistic: someone who does not know, or believes that it is impossible to know, if a god exists ä¸å¯çŸ¥è®ºè€…ï¼ˆå¯¹ç¥å­˜åœ¨ä¸å¦ä¸èƒ½è‚¯å®šæˆ–è®¤ä¸ºä¸å¯çŸ¥ï¼‰,","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-76-BERT-Pretrain":{"title":"D2L-76-BERT - Pretrain","content":"# BERT: Pretrain\n\n\u003cdiv align=\"right\"\u003e 2022-04-30\u003c/div\u003e\n\nTags: #BERT #Pretrain #DeepLearning #Transformer \n\n\n## Pretrain Tasks\n### Task 1 - Masked Language Modeling\n#### Motivation\n- [è¯­è¨€æ¨¡å‹(Language Model)](notes/2022/2022.3/D2L-50-è¯­è¨€æ¨¡å‹-ä¼ ç»Ÿæ¨¡å‹çš„ä¸è¶³.md#è¯­è¨€æ¨¡å‹) åœ¨è¾“å‡ºæ—¶æ˜¯ä»å·¦åˆ°å³è¿›è¡Œçš„, ä½¿ç”¨å·¦ä¾§çš„ä¸Šä¸‹æ–‡æ¥é¢„æµ‹æœªçŸ¥è¯å…ƒã€‚\n\n- è€Œ BERT æ˜¯åŒå‘åœ°å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç çš„, æˆ‘ä»¬éœ€è¦ä¸ºæ¨¡å‹ä¿ç•™ä¸¤ä¸ªæ–¹å‘çš„ä¸Šä¸‹æ–‡. \n\t- æ‰€ä»¥æˆ‘ä»¬ç”¨ä¸€ç§ç±»ä¼¼\"å®Œå½¢å¡«ç©º\"çš„æ–¹å¼æ¥è®­ç»ƒæ¨¡å‹: éšæœº mask æ‰åºåˆ—é‡Œé¢çš„ä¸€äº›è¯å…ƒ, è®©æ¨¡å‹ä½¿ç”¨åŒå‘ä¸Šä¸‹æ–‡ä»¥ç±»ä¼¼è‡ªç›‘ç£çš„æ–¹å¼é¢„æµ‹æ©è”½è¯å…ƒ. \n\t- è¿™ç±»ä»»åŠ¡ç§°ä¸º**æ©è”½è¯­è¨€å»ºæ¨¡ (æ¨¡å‹)** : _masked language model_, MLM.\n\n#### ä»»åŠ¡ç»†èŠ‚\n\n**é¢„æµ‹å“ªäº›è¯?  é¢„æµ‹å¤šå°‘è¯?**\n- åœ¨ BERT çš„è®­ç»ƒä»»åŠ¡ä¸­, æˆ‘ä»¬ **éšæœº** é€‰æ‹© **15%** çš„è¯å…ƒè¿›è¡Œé¢„æµ‹\n\n**æ€ä¹ˆå¤„ç†è¾“å…¥?**\n- å¯¹äºéšæœºé€‰æ‹©çš„ 15%:\n\t- **80%** çš„æ¦‚ç‡: æ›¿æ¢ä¸º `\u003cmask\u003e` \n\t\t- ï¼ˆä¾‹å¦‚ï¼Œâ€œthis movie is **great**â€ å˜ä¸º â€œthis movie is `\u003cmask\u003e` \")\n\t- **10%** çš„æ¦‚ç‡: æ›¿æ¢ä¸º `éšæœºè¯å…ƒ`\n\t\t- ï¼ˆä¾‹å¦‚ï¼Œâ€œthis movie is **great**â€ å˜ä¸º â€œthis movie is **drink**â€ ï¼‰\n\t- **10%** çš„æ¦‚ç‡: `ä¸åšä»»ä½•æ”¹åŠ¨`\n\t\t- ï¼ˆä¾‹å¦‚ï¼Œâ€œthis movie is **great**â€ å˜ä¸º â€œthis movie is **great**â€ ï¼‰ã€‚\n\n**ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦åŠ å…¥éšæœºè¯å…ƒçš„ 10%å’Œä¸åšä»»ä½•æ”¹åŠ¨çš„ 10%?**\n- å› ä¸ºåœ¨ Finetuning çš„æ—¶å€™, è®­ç»ƒæ•°æ®éƒ½æ˜¯æ²¡æœ‰ `\u003cmask\u003e` çš„è¯­å¥, è¿™ä¼šå¯¼è‡´ Pretrain å’Œ Finetune çš„ mismatch.\n- æˆ‘ä»¬åŠ å…¥ **10%** å’Œ Finetune é‡Œé¢ä¸€æ ·çš„æ•°æ®\n- åŠ å…¥ **10%** éšæœºæ•°æ®ä½œä¸ºå™ªå£°, è®©æ¨¡å‹ä¸ä¼šè¿‡å¤šå…³æ³¨ `\u003cmask\u003e` ç¬¦å·.\n\n### Task 2 - Next Sentence Prediction\n#### Motivation\n- å°½ç®¡ Masked Language Modeling èƒ½å¤Ÿç¼–ç åŒå‘ä¸Šä¸‹æ–‡æ¥è¡¨ç¤ºå•ä¸ªè¯å…ƒï¼Œä½†å®ƒä¸èƒ½æ˜¾å¼åœ°å»ºæ¨¡æ–‡æœ¬å¯¹(text pairs)ä¹‹é—´çš„é€»è¾‘å…³ç³»ã€‚[^1]\n\t- ä¸ºäº†å¸®åŠ©BERTç†è§£ä¸¤ä¸ªæ–‡æœ¬åºåˆ—ä¹‹é—´çš„å…³ç³»ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªäºŒåˆ†ç±»ä»»åŠ¡:  **ä¸‹ä¸€å¥é¢„æµ‹** *(Next Sentence Prediction)* \n\n#### ä»»åŠ¡ç»†èŠ‚\n- åœ¨ç”Ÿæˆå¥å­å¯¹æ—¶: \n\t- **50%** çš„æ¦‚ç‡å®ƒä»¬çš„ç¡®æ˜¯è¿ç»­çš„, æ ‡ç­¾ä¸º\"True\"\n\t- **50%** çš„æ¦‚ç‡ç¬¬äºŒä¸ªå¥å­æ˜¯ä»è¯­æ–™åº“ä¸­éšæœºæŠ½å–çš„ï¼Œæ ‡ç­¾ä¸º\"False\"\n\n## Data Representation\nè¯¦è§[14.9. ç”¨äºé¢„è®­ç»ƒBERTçš„æ•°æ®é›† â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert-dataset.html)\n## Start Pretrain\nè¯¦ç»†çš„è¿‡ç¨‹å¯ä»¥å‚è§: [14.10. é¢„è®­ç»ƒBERT â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert-pretraining.html) , è¿™é‡Œè¯´æ˜å‡ ä¸ªéœ€è¦æ³¨æ„çš„ç‚¹:\n\n- BERT é¢„è®­ç»ƒçš„æœ€ç»ˆæŸå¤±æ˜¯é®è”½è¯­è¨€æ¨¡å‹æŸå¤±å’Œä¸‹ä¸€å¥é¢„æµ‹æŸå¤±çš„å’Œã€‚å½“ç„¶ä¹Ÿå¯ä»¥æ˜¯åŠ æƒäº†çš„å’Œ.\n- å› ä¸ºBERTæ¨¡å‹æ˜¯å¾ˆå¤§çš„, ç”¨æ¥è®­ç»ƒBERTçš„æ•°æ®é›†ä¹Ÿæ˜¯å¾ˆå¤§çš„, æ‰€ä»¥æˆ‘ä»¬é€šå¸¸æŒ‡å®šå…¥`num_steps`æŒ‡å®šäº†è®­ç»ƒçš„è¿­ä»£æ­¥æ•°ï¼ŒæŒ‡å®š`num_epoch`\n-  åœ¨é¢„è®­ç»ƒBERTä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥è¡¨ç¤ºå•ä¸ªæ–‡æœ¬ã€æ–‡æœ¬å¯¹æˆ–å…¶ä¸­çš„ä»»ä½•è¯å…ƒã€‚\n-  åœ¨å®éªŒä¸­ï¼ŒåŒä¸€ä¸ªè¯å…ƒåœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­å…·æœ‰ä¸åŒçš„BERTè¡¨ç¤ºã€‚è¿™æ”¯æŒBERTè¡¨ç¤ºæ˜¯**ä¸Šä¸‹æ–‡æ•æ„Ÿ**çš„ã€‚\n\n![](notes/2022/2022.4/assets/img_2022-10-15-3.gif)\n\n[^1]: [14.8. Bidirectional Encoder Representations from Transformers (BERT) â€” Dive into Deep Learning 0.17.5 documentation](https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html#next-sentence-prediction)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/D2L-77-BERT-Fine-tune":{"title":"D2L-77-BERT - Fine-tune","content":"# BERT: Fine-tune\n\n\u003cdiv align=\"right\"\u003e 2022-04-30\u003c/div\u003e\n\nTags: #BERT #Fine-tune #DeepLearning #Transformer \n\n\n![](notes/2022/2022.4/assets/img_2022-10-15-4.gif)\n\n- é¢„è®­ç»ƒå¥½ BERT ä»¥å, æˆ‘ä»¬åªéœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾ˆå°çš„æ”¹åŠ¨å³å¯é€‚é…å¾ˆå¤šä»»åŠ¡.\n- åœ¨ Finetuning çš„æ—¶å€™, æ–°å¢çš„è¾“å‡ºéƒ¨åˆ†æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒçš„, è€Œ BERT ä¸»ä½“éƒ¨åˆ†æ˜¯åœ¨ pre-train çš„åŸºç¡€ä¸Šè¿›è¡Œè®­ç»ƒçš„.\n\n## Single Text Classification\n![](notes/2022/2022.4/assets/bert-one-seq.svg)\n- æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ `\u003ccls\u003e` tagæ¥å¯¹ä¸€ä¸ªè¯­å¥åºåˆ—è¿›è¡Œåˆ†ç±», åªéœ€è¦æ·»åŠ ä¸€ä¸ªæ–°çš„å…¨è¿æ¥å±‚å°±å¥½äº†\n\n## Text Pair Classification or Regression\n![](notes/2022/2022.4/assets/bert-two-seqs.svg)\n- è¯­å¥å¯¹çš„åˆ†ç±»/å›å½’é—®é¢˜ä¾ç„¶åªéœ€è¦æ·»åŠ ä¸€ä¸ªå…¨è¿æ¥å±‚æ¥å¯¹ `\u003ccls\u003e` æ ‡ç­¾è¿›è¡Œåˆ†ç±». å®ƒå’Œä¸Šä¸€ä¸ªåº”ç”¨çš„å”¯ä¸€åŒºåˆ«å°±æ˜¯è¾“å…¥åºåˆ—çš„å½¢å¼ä¸åŒ.\n- æœ‰æ—¶æˆ‘ä»¬è¿˜ä¼šå¯¹æŸå¤±å‡½æ•°è¿›è¡Œæ›´æ”¹, æ¯”å¦‚å¯¹äºå›å½’ä»»åŠ¡, æˆ‘ä»¬å¯ä»¥æ”¹ç”¨[Mean_Squared_Error_å‡æ–¹è¯¯å·®](notes/2021/2021.8/Mean_Squared_Error_å‡æ–¹è¯¯å·®.md)\n\n## Text Tagging\n![](notes/2022/2022.4/assets/bert-tagging.svg)\n- æ–‡æœ¬æ ‡æ³¨åˆ™å°†Tokençš„è¾“å‡ºä½œä¸ºå…¨è¿æ¥çš„è¾“å…¥, å°½ç®¡æœ‰å¤šä¸ªToken, æˆ‘ä»¬ä»ä½¿ç”¨åŒä¸€ä¸ªå…¨è¿æ¥å±‚.\n\n## Question Answering\n![](notes/2022/2022.4/assets/bert-qa.svg)\n- é—®ç­”çš„è¾“å…¥ç”± Question å’Œ Passage ç»„æˆ\n- åœ¨é—®ç­”ä»»åŠ¡ä¸­, æ¨¡å‹éœ€è¦åœ¨ Passage é‡Œé¢æ‰¾åˆ°ç­”æ¡ˆçš„èµ·å§‹ä½ç½®. æˆ‘ä»¬çš„åšæ³•æ˜¯ç”¨ä¸¤ä¸ªå…¨è¿æ¥å±‚åˆ†åˆ«è¿›è¡Œ\"ç­”æ¡ˆèµ·å§‹ä½ç½®\"å’Œ\"ç­”æ¡ˆç»“æŸä½ç½®\"çš„é¢„æµ‹:  è¯„ä¼° Passage é‡Œé¢æ¯ä¸€ä¸ªè¯å…ƒä½œä¸ºèµ·å§‹/ç»“æŸä½ç½®çš„æ¦‚ç‡, é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ç‰‡æ®µä½œä¸ºè¾“å‡º.\n\n## å®ä¾‹\n[15.7. è‡ªç„¶è¯­è¨€æ¨æ–­ï¼šå¾®è°ƒBERT â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0-beta0 documentation](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-bert.html)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/Difference-between-Purple-and-Violet":{"title":"Difference between Purple and Violet","content":"# Difference between Purple and Violet\n\n\u003cdiv align=\"right\"\u003e 2022-04-23\u003c/div\u003e\n\nTags: #Purple #Violet #English #Color\n\n- Purpleæ˜¯å¤è‰²å…‰(Blue and Red 1:1)æ¿€å‘çš„é¢œè‰², è€ŒVioletæ˜¯å•è‰²å…‰æ¿€å‘çš„é¢œè‰² \n- å› è€Œçœ‹èµ·æ¥Purpleè¦Redä¸€ç‚¹, é¥±å’Œåº¦è¦é«˜ä¸€ç‚¹.\n \n![](notes/2022/2022.4/assets/img_2022-10-15-12.png)\n\n- **In depth reading**: [Difference between â€˜violetâ€™ and â€˜purpleâ€™](https://jakubmarian.com/difference-between-violet-and-purple/)\n\n\n\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/Get-ahead-of-oneself":{"title":"Get ahead of oneself","content":"## **get ahead of yourself**\n\nto do something too early, or before you are ready or prepared\n\n- That last game suggests that we have been getting ahead of ourselves in praising the team's progress.\n- She didn't want to get ahead of herself and risk losing what she had achieved so far.\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/Indexing-a-tensor-or-ndarray-with-None":{"title":"Indexing a tensor or ndarray with `None`","content":"#  `None` as index \n\n\u003cdiv align=\"right\"\u003e 2022-04-20\u003c/div\u003e\n\nTags: #Numpy #PyTorch \n\n## `None` in index is equivalent to `unsqueeze()`\nSimilar to NumPy you can insert a singleton dimension (_\"unsqueeze\"_ a dimension) by indexing this dimension with `None`. In turn `n[:, None]` will have the effect of inserting a new dimension on `dim=1`. This is equivalent to `n.unsqueeze(dim=1)`:\n\n```\n\u003e\u003e\u003e n = torch.rand(3, 100, 100)\n\n\u003e\u003e\u003e n[:, None].shape\n(3, 1, 100, 100)\n\n\u003e\u003e\u003e n.unsqueeze(1).shape\n(3, 1, 100, 100)\n```\n\n## Some other types of _`None` indexings_.\nIn the example above `:` is was used as a placeholder to designate the first dimension `dim=0`. If you want to insert a dimension on `dim=2`, you can add a second `:` as `n[:, :, None]`.\n\nYou can also _place_ `None` with respect to the last dimension instead. To do so you can use the [ellipsis](https://python-reference.readthedocs.io/en/latest/docs/brackets/ellipsis.html) syntax `...`:\n\n-   `n[..., None]` will insert a dimension last, _i.e._ `n.unsqueeze(dim=-1)`.\n    \n-   `n[..., None, :]` on the before last dimension, _i.e._ `n.unsqueeze(dim=-2)`.\n\n## `None` is slower than `unsqueeze()`\n`None` is a version with advanced indexing , which might be a bit slower because it has more checking to do to find out exactly what you want to do.\n\n---\nSources:\n- [syntax - Indexing a tensor with None in PyTorch - Stack Overflow](https://stackoverflow.com/a/69797906/15893958)\n- [What is the difference between [None, ...] and unsqueeze? - PyTorch Forums](https://discuss.pytorch.org/t/what-is-the-difference-between-none-and-unsqueeze/28451)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/Latex-White-Spaces":{"title":"Latex White Spaces","content":"# Latex é‡Œé¢çš„ç©ºæ ¼\n\n\u003cdiv align=\"right\"\u003e 2022-04-03\u003c/div\u003e\n\nTags: #Latex \n\n[There are a number of horizontal spacing macros for LaTeX](https://tex.stackexchange.com/a/74354/267634) :\n1.  `\\,` inserts a `.16667em` space in text mode, or `\\thinmuskip` (equivalent to `3mu`) in math mode; there's an equivalent `\\thinspace` macro;\n\n3.  `\\\u003e` (or `\\:`) inserts a `.2222em` space in text mode, or `\\medmuskip` (equivalent to `4.0mu plus 2.0mu minus 4.0mu`) in math mode; there's an equivalent `\\medspace`;\n4.  `\\negmedspace` is the _negative_ equivalent to `\\medspace`;\n5.  `\\;` inserts a `.2777em` space in text mode, or `\\thickmuskip` (equivalent to `5.0mu plus 5.0mu`) in math mode; there's an equivalent `\\thickspace`;\n\n7.  `\\enspace` inserts a space of `.5em` in text or math mode;\n8.  `\\quad` inserts a space of `1em` in text or math mode;\n9.  `\\qquad` inserts a space of `2em` in text or math mode;\n\n\n12.  `\\hspace{\u003clen\u003e}` ==inserts a space of length== `\u003clen\u003e` (may be negative) in math or text mode (a LaTeX `\\hskip`); ==å¾—å¸¦å•ä½==\n\n","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/RNN%E4%B8%ADoutput%E5%92%8Chidden_state%E7%9A%84%E5%8C%BA%E5%88%AB":{"title":"RNNä¸­outputå’Œhidden_stateçš„åŒºåˆ«","content":"# Difference between `output` and `hidden_state` in RNN\n\n\u003cdiv align=\"right\"\u003e 2022-04-22\u003c/div\u003e\n\nTags: #RNN \n\n- é¦–å…ˆè¦å°†RNNç†è§£ä¸ºä¸€ä¸ªäºŒç»´çš„ç½‘ç»œ, å®ƒä¸ä»…å¯èƒ½æœ‰å¤šä¸ªéšè—å±‚, è¿˜åœ¨æ—¶é—´ç»´åº¦ä¸Šæœ‰å¤šä¸ªæ—¶é—´æ­¥.\n\n![RNN in detail](notes/2022/2022.4/assets/RNN%20in%20detail.svg)\n\n- `output`æ˜¯ **æœ€åä¸€å±‚éšè—å±‚** åœ¨ *æ¯ä¸€ä¸ªæ—¶é—´æ­¥* çš„çŠ¶æ€\n- `hidden_state` æ˜¯ **æœ€åä¸€ä¸ªæ—¶é—´æ­¥** *æ‰€æœ‰éšè—å±‚* çš„çŠ¶æ€\n\n- `output` å¸¸å¸¸è¢«ç”¨ä½œEncoder-Decoderæ¶æ„é‡Œé¢Attentionçš„è¾“å…¥\n- `hidden_state` å¸¸å¸¸åœ¨Encoder-Decoderæ¶æ„é‡Œé¢è¢«ç”¨æ¥åˆå§‹åŒ–Decoderéšè—çŠ¶æ€\n\n## Bidirectional Case\n\u003e 1.  The `output` will give you the hidden layer outputs of the network for each time-step, _but only for the final layer_. This is useful in many applications, particularly encoder-decoders using attention. (These architectures build up a 'context' layer from all the hidden outputs, and it is extremely useful to have them sitting around as a self-contained unit.)\n\u003e     \n\u003e 2.  The `h_n` will give you the hidden layer outputs for the last time-step only, but for all the layers. Therefore, if and only if you have a single layer architecture, `h_n` is a strict subset of `output`. Otherwise, `output` and `h_n` intersect, but are not strict subsets of one another. (You will often want these, in an encoder-decoder model, from the encoder in order to jumpstart the decoder.)\n\u003e     \n\u003e 3.  **If you are using a bidirectional output** and you want to actually verify that part of `h_n` is contained in `output` (and vice-versa) you need to understand what PyTorch does behind the scenes in the organization of the inputs and outputs. Specifically, it concatenates a time-reversed input with the time-forward input and runs them together. This is literal. This means that the 'forward' output at time T is in the final position of the `output` tensor sitting right next to the 'reverse' output at time 0; if you're looking for the 'reverse' output at time T, it is in the first position.[^1]\n\n\n\n\n[^1]: [machine learning - Is hidden and output the same for a GRU unit in Pytorch? - Stack Overflow](https://stackoverflow.com/a/61195982/15893958)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/Variant-or-Variance":{"title":"Variant or Variance","content":"# Variant or Variance\n\n\u003cdiv align=\"right\"\u003e 2022-04-19\u003c/div\u003e\n\nTags: #English\n\nThey are pretty much the **same**.\n\n\u003e Very strictly speaking, variation is change, and a variant is one of the forms resulting from the change.\n\u003e \n\u003e The use of **variation** to mean **variant** is so common, though, that only a hardcore pedant would ever even recognize a difference in that context, much less say either one is incorrect.[^1]\n\n\n[^1]: [word choice - What is the difference between a variant and a variation? - English Language \u0026 Usage Stack Exchange](https://english.stackexchange.com/a/148805)","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.4/Viterbi-Algorithm":{"title":"Viterbi Algorithm","content":"# ç»´ç‰¹æ¯”ç®—æ³•\n\n\u003cdiv align=\"right\"\u003e 2022-04-19\u003c/div\u003e\n\nTags: #Viterbi\n\n**Viterbi ç®—æ³•**æ˜¯ä¸€ä¸ªç”¨äºæ±‚è§£æœ€ä½³è·¯å¾„çš„åŠ¨æ€è§„åˆ’ç®—æ³•ã€‚\n\n- Viterbi ç®—æ³•å¸¸å¸¸ç”¨äºHMMæ¨¡å‹é‡Œé¢ï¼Œç”¨äºå¯»æ‰¾æœ€æœ‰å¯èƒ½äº§ç”Ÿè§‚æµ‹äº‹ä»¶åºåˆ—çš„**ç»´ç‰¹æ¯”è·¯å¾„**â€”â€”éšå«çŠ¶æ€åºåˆ—\n\n- ä¸‹é¢è¿™ä¸ªå›ç­”è§£é‡Šçš„å¾ˆæ¸…æ¥šäº†ï¼š \n\tå¦‚ä½•é€šä¿—åœ°è®²è§£ Viterbi ç®—æ³•ï¼Ÿ https://www.zhihu.com/question/20136144/answer/763021768","lastmodified":"2023-11-19T19:19:34.362471215Z","tags":null},"/notes/2022/2022.5/%E4%BB%8E%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E5%88%B0%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83%E5%86%8D%E5%88%B0%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83-From-Binomial-Distribution-to-Poisson-Distribution-to-Exponential-Distribution":{"title":"ä»äºŒé¡¹åˆ†å¸ƒåˆ°æ³Šæ¾åˆ†å¸ƒå†åˆ°æŒ‡æ•°åˆ†å¸ƒ-From Binomial Distribution to Poisson Distribution to Exponential Distribution","content":"# From Binomial Distribution to Poisson Distribution to Exponential Distribution\n\n\u003cdiv align=\"right\"\u003e 2022-05-22\u003c/div\u003e\n\nTags: #Math/Probability #PoissonDistribution #BinomialDistribution #ExponentialDistribution\n\n- è¿™ä¸¤ä¸ªå›ç­”è®²çš„æŒºå¥½: \n\t- æ³Šæ¾åˆ†å¸ƒçš„ç°å®æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆç°å®ç”Ÿæ´»å¤šæ•°æœä»äºæ³Šæ¾åˆ†å¸ƒï¼Ÿ - é©¬åŒå­¦çš„å›ç­” - çŸ¥ä¹ https://www.zhihu.com/question/26441147/answer/429569625\n\t- æŒ‡æ•°åˆ†å¸ƒå…¬å¼çš„å«ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ - é©¬åŒå­¦çš„å›ç­” - çŸ¥ä¹ https://www.zhihu.com/question/24796044/answer/673838656\n\n### Binomial Distribution\n- å¯¹äºæ¦‚ç‡ä¸º $p$ çš„äº‹ä»¶, $n$ æ¬¡è¯•éªŒé‡Œé¢å‘ç”Ÿ $k$ æ¬¡çš„æ¦‚ç‡ä¸º:\n$$\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}$$\n### Poisson Distribution\n- åœ¨ $n\\rightarrow \\infty$ çš„æ—¶å€™, *Binominal Distribution* ç­‰ä»·äºæœŸæœ›ç›¸åŒçš„ *Poisson Distribution*: \n$$\\lim _{n \\rightarrow \\infty}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}$$\n- äºŒé¡¹åˆ†å¸ƒçš„æœŸæœ›ä¸º: $E(X)=np$, æ³Šæ¾åˆ†å¸ƒçš„æœŸæœ›ä¸º: $\\lambda$. å› ä¸ºæœŸæœ› $E(X)$ ç›¸åŒ: \n\t$$p=\\frac{\\lambda}{n}$$\n- å¸¦å…¥ä¸Šå¼, å¾—åˆ°:\n\t$$\\lim _{n \\rightarrow \\infty}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}=\\lim _{n \\rightarrow \\infty}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right)\\left(\\frac{\\lambda}{n}\\right)^{k}\\left(1-\\frac{\\lambda}{n}\\right)^{n-k}$$\n- æ±‚è§£è¿™ä¸ªæé™:\n$$\\begin{aligned}\n\\lim _{n \\rightarrow \\infty}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right)\\left(\\frac{\\lambda}{n}\\right)^{k}\\left(1-\\frac{\\lambda}{n}\\right)^{n-k} \u0026=\\lim _{n \\rightarrow \\infty} \\frac{n(n-1)(n-2) \\cdots(n-k+1)}{k !} \\frac{\\lambda^{k}}{n^{k}}\\left(1-\\frac{\\lambda}{n}\\right)^{n-k} \\\\\n\u0026=\\lim _{n \\rightarrow \\infty} \\frac{\\lambda^{k}}{k !} \\frac{n}{n} \\cdot \\frac{n-1}{n} \\cdots \\frac{n-k+1}{n}\\left(1-\\frac{\\lambda}{n}\\right)^{-k}\\left(1-\\frac{\\lambda}{n}\\right)^{n}\n\\end{aligned}$$\n\n- å…¶ä¸­:\n\t$$\\begin{gathered}\n\\lim _{n \\rightarrow \\infty} \\frac{n}{n} \\cdot \\frac{n-1}{n} \\cdots \\frac{n-k+1}{n}\\left(1-\\frac{\\lambda}{n}\\right)^{-k}=1 \\\\\n\\lim _{n \\rightarrow \\infty}\\left(1-\\frac{\\lambda}{n}\\right)^{n}=e^{-\\lambda}\n\\end{gathered}$$\n- æ‰€ä»¥\n\t$$\\lim _{n \\rightarrow \\infty}\\left(\\begin{array}{l}\n\tn \\\\\n\tk\n\t\\end{array}\\right)\\left(\\frac{\\lambda}{n}\\right)^{k}\\left(1-\\frac{\\lambda}{n}\\right)^{n-k}=\\frac{\\lambda^{k}\\space e^{-\\lambda}}{k !} $$\nä¹Ÿå°±æ˜¯ Poisson Distribution çš„æ¦‚ç‡å¯†åº¦å‡½æ•°\n\n- åœ¨ $n$ å¾ˆå¤§, ä¹Ÿå°±æ˜¯ $p$ å¾ˆå°çš„æ—¶å€™, ä¸¤è€…å¤§æ¦‚ç›¸ä¼¼:\n![](notes/2022/2022.5/assets/img_2022-10-15.jpg)\n\n### Exponential Distribution\n- The waiting times for *Poisson distribution* is an *exponential distribution* with parameter $\\lambda$.\n\t- æœä»æ³Šæ¾åˆ†å¸ƒçš„äº‹ä»¶ä¹‹é—´çš„æ—¶é—´å·®æœä»æŒ‡æ•°åˆ†å¸ƒ\n[Relationship between Poisson and exponential distribution - Cross Validated](https://stats.stackexchange.com/a/2094/354372)\n\nI will use the following notation to be as consistent as possible with the wiki (in case you want to go back and forth between my answer and the wiki definitions for the [poisson](http://en.wikipedia.org/wiki/Poisson_distribution) and [exponential](http://en.wikipedia.org/wiki/Exponential_distribution).)\n\n- $N_t$: the number of arrivals during time period $t$\n- $X_t$: the time it takes for one additional arrival to arrive assuming that someone arrived at time $t$\n\nBy definition, the following conditions are equivalent:\n$$(X_t\u003ex)â‰¡(N_t=N_t+x)$$\n- The event on the left captures the event that no one has arrived in the time interval $[t,t+x]$ which implies that our count of the number of arrivals at time $t+x$ is identical to the count at time $t$which is the event on the right.\n\n- By the complement rule, we also have:\n$$P(X_tâ‰¤x)=1âˆ’P(X_t\u003ex)$$\n- Using the equivalence of the two events that we described above, we can re-write the above as:\n$$P(X_tâ‰¤x)=1âˆ’P(N_{t+x}âˆ’N_t=0)$$\n- But,\n$$P(N_{t+x}âˆ’N_t=0)=P(N_x=0)$$\n- Using the poisson pmf the above where $Î»$ is the average number of arrivals per time unit and $x$ a quantity of time units, simplifies to:\n$$P(N_{t+x}âˆ’N_t=0)=\\frac{(Î»x)^0}{0!}e^{âˆ’Î»x}$$\n- i.e.\n$$P(N_{t+x}âˆ’N_t=0)=e^{âˆ’Î»x}$$\n- Substituting in our original eqn, we have:\n$$P(X_tâ‰¤x)=1âˆ’e^{âˆ’Î»x}$$\n- The above is the cdf of a exponential pdf.","lastmodified":"2023-11-19T19:19:34.486473237Z","tags":null},"/notes/2022/2022.5/%E7%A6%BB%E5%B2%B8%E4%BA%BA%E6%B0%91%E5%B8%81%E4%B8%8E%E5%9C%A8%E5%B2%B8%E4%BA%BA%E6%B0%91%E5%B8%81":{"title":"ç¦»å²¸äººæ°‘å¸ä¸åœ¨å²¸äººæ°‘å¸","content":"# æ±‡ç‡è®¡ç®—ä¸­ä¸¤ç§ä¸åŒçš„äººæ°‘å¸\n\n\u003cdiv align=\"right\"\u003e 2022-05-03\u003c/div\u003e\n\nTags: #ExchangeRate #CHY\n\nå…¶å®ç®€å•æ¥è¯´å°±æ˜¯ï¼Œåœ¨å²¸ä»·æ˜¯åœ¨**å›½å†…**æ¢æ±‡çš„æ±‡ç‡ï¼Œç¦»å²¸ä»·æ˜¯åœ¨**å›½å¤–**æ¢æ±‡çš„æ±‡ç‡ã€‚\n\n## ç¦»å²¸äººæ°‘å¸(CNH)\n- **ç¦»å²¸**â€”â€”åœ¨ä¸­å›½**å¢ƒå¤–**ç»è¥äººæ°‘å¸ä¸šåŠ¡(CHY offshore)ã€‚å¤®è¡Œå¼€æ”¾é¦™æ¸¯ä»¥åŠå…¶ä»–å›½å®¶è¿›è¡Œäººæ°‘å¸äº¤æ˜“çš„æ±‡ç‡å°±å«ç¦»å²¸äººæ°‘å¸ï¼Œè€Œ2010å¹´ä¸­å›½é¦™æ¸¯å®æ–½çš„äººæ°‘å¸ç¦»å²¸äº¤æ˜“(CNH)å·²ç»æ˜¯æ³›æŒ‡æµ·å¤–ç¦»å²¸äººæ°‘å¸äº¤æ˜“ã€‚\n\n- ç›®å‰ä¸»è¦çš„äººæ°‘å¸ç¦»å²¸å¸‚åœºåœ¨é¦™æ¸¯ï¼Œæ–°åŠ å¡ã€ä¼¦æ•¦ã€å°æ¹¾ä¹Ÿåœ¨ç§¯æå‘å±•äººæ°‘å¸ç¦»å²¸å¸‚åœºã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå›½å¤–å¸Œæœ›äººæ°‘å¸å¤§å¹…å‡å€¼ï¼Œè¿™æ ·æœ‰åˆ©äºæ‰“å¼€ä¸­å›½å¸‚åœºï¼Œä½†å›½å†…å¸Œæœ›å¢åŠ å‡ºå£ï¼Œæ‰€ä»¥ç¦»å²¸æ±‡ç‡é«˜äºåœ¨å²¸æ±‡ç‡ã€‚\n\n## åœ¨å²¸äººæ°‘å¸(CHY)\n- åœ¨å²¸â€”â€”åœ¨å›½å†…ç»è¥çš„äººæ°‘å¸ä¸šåŠ¡ã€‚å¤®è¡Œæˆæƒä¸­å›½å¤–æ±‡ä¸­å¿ƒäºæ¯ä¸ªå·¥ä½œæ—¥ä¸Šåˆå¯¹å¤–å…¬å¸ƒå½“æ—¥äººæ°‘å¸å…‘æ¢ç¾å…ƒã€æ¬§å…ƒã€æ—¥å…ƒã€æ¸¯å¸æ±‡ç‡çš„ä¸­é—´ä»·ä½œä¸ºå½“æ—¥é“¶è¡Œé—´å³æœŸå¤–æ±‡å¸‚åœºä»¥åŠé“¶è¡ŒæŸœå°äº¤æ˜“æ±‡ç‡çš„å‚è€ƒä»·æ ¼ï¼Œè¿™å°±å«åœ¨å²¸äººæ°‘å¸ã€‚\n\n## åŒºåˆ«\n- åœ¨å²¸äººæ°‘å¸å¸‚åœºå‘å±•çš„æ—¶é—´æ¯”è¾ƒé•¿ã€è§„æ¨¡æ¯”è¾ƒå¤§ã€å—åˆ°çš„ç®¡åˆ¶ä¹Ÿæ¯”è¾ƒå¤šï¼Œåœ¨å²¸æ±‡ç‡å—åˆ°å¤®å¦ˆæ”¿ç­–å½±å“æ¯”è¾ƒå¤§ã€‚è€Œç¦»å²¸åˆ™ç›¸åï¼Œä»–çš„æ±‡ç‡å˜åŒ–ä¸»è¦æ˜¯å—åˆ°å›½é™…å› ç´ å½±å“æ¯”è¾ƒå¤šï¼Œé€šå¸¸ç¦»å²¸äººæ°‘å¸å¸‚åœºæ›´èƒ½å……åˆ†åæ˜ å¸‚åœºå¯¹äººæ°‘å¸ä¾›éœ€ã€‚\n\n![](notes/2022/2022.5/assets/img_2022-10-15.png)\n\n[ç¦»å²¸äººæ°‘å¸ã€åœ¨å²¸äººæ°‘å¸å’Œäººæ°‘å¸ä¸­é—´ä»·çš„åŒºåˆ«ï¼Œä½ åˆ†å¾—æ¸…æ¥šå—ï¼Ÿ â€” æœèˆªç½‘](https://www.sofreight.com/news_57103.html)\n[CNY vs CNH - Differences Between Two Types of Renminbi - Wise, formerly TransferWise](https://wise.com/us/blog/cny-vs-cnh)","lastmodified":"2023-11-19T19:19:34.486473237Z","tags":null},"/notes/2022/2022.5/%E7%AB%AF%E5%88%B0%E7%AB%AF%E5%AD%A6%E4%B9%A0-End_to_End_Learning-E2E":{"title":"ç«¯åˆ°ç«¯å­¦ä¹ -End_to_End_Learning-E2E","content":"# ç«¯åˆ°ç«¯å­¦ä¹ \n\n\u003cdiv align=\"right\"\u003e 2022-05-05\u003c/div\u003e\n\nTags: #EndtoEndLearning #MachineLearning #DeepLearning \n\n- ç«¯åˆ°ç«¯çš„å­¦ä¹ å°±æ˜¯çœç•¥ä¸­é—´æ­¥éª¤ï¼Œç›´æ¥ä»è¾“å…¥å¾—åˆ°è¾“å‡ºç»“æœã€‚\n\n![End2End](notes/2022/2022.5/assets/End2End.svg)\n\n## Pro \u0026 Con\n### Pro\n- ä¸ç”¨äººä¸ºè®¾è®¡ä¸­é—´æ­¥éª¤, å‡å°‘äº†å·¥ä½œé‡, \n- å¹¶ä¸”é¿å…äººä¸ºæ·»åŠ çš„æ­¥éª¤ç»™æ¨¡å‹å¸¦æ¥ä¸å¥½çš„[å½’çº³åç½®](notes/2022/2022.2/å½’çº³åç½®-Inductive%20bias%20-%20learning%20bias.md).\n\n### Con\n- éœ€è¦è¶³å¤Ÿå¤šçš„æ•°æ®æ‰èƒ½è¾¾åˆ°è¾ƒå¥½çš„æ•ˆæœ\n- æœ‰æ—¶å€™äººä¸ºçš„æ­¥éª¤æ˜¯å¯ä»¥å¸®åŠ©æ¨¡å‹è¿›è¡Œå­¦ä¹ çš„\n\n- [What is end-to-end deep learning? (C3W2L09) - YouTube](https://www.youtube.com/watch?v=ImUoubi_t7s)\n- [Whether to Use End-To-End Deep Learning (C3W2L10) - YouTube](https://www.youtube.com/watch?v=l_-CUyEx_x4)\n\n\n","lastmodified":"2023-11-19T19:19:34.486473237Z","tags":null},"/notes/2022/2022.5/Cross_Entropy_Loss_Input_Format-%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%BE%93%E5%85%A5%E6%A0%BC%E5%BC%8F":{"title":"Cross_Entropy_Loss_Input_Format-äº¤å‰ç†µæŸå¤±å‡½æ•°è¾“å…¥æ ¼å¼","content":"## PyTorch\n\næ ‡ç­¾ä¸éœ€è¦å˜æˆç‹¬çƒ­ç¼–ç :\n\n![](notes/2022/2022.5/assets/img_2022-10-15-1.png)\n\n## Keras\n\nKearsæœ‰ä¸¤ç§å½¢å¼:\n\n- Categorical Cross Entropy [Doc](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class):\n\n\u003e Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a one_hot representation.\n\n```python\n\u003e\u003e\u003e y_true = [[0, 1, 0], [0, 0, 1]]\n\u003e\u003e\u003e y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n\u003e\u003e\u003e # Using 'auto'/'sum_over_batch_size' reduction type.  \n\u003e\u003e\u003e cce = tf.keras.losses.CategoricalCrossentropy()\n\u003e\u003e\u003e cce(y_true, y_pred).numpy()\n1.177\n```\n\n- Sparse Categorical Cross Entropy [Doc](https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class):\n\n\u003e Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided as integers.\n\n```python\n\u003e\u003e\u003e y_true = [1, 2]\n\u003e\u003e\u003e y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n\u003e\u003e\u003e # Using 'auto'/'sum_over_batch_size' reduction type.  \n\u003e\u003e\u003e scce = tf.keras.losses.SparseCategoricalCrossentropy()\n\u003e\u003e\u003e scce(y_true, y_pred).numpy()\n1.177\n```\n\n[python - What is the difference between sparse_categorical_crossentropy and categorical_crossentropy? - Stack Overflow](https://stackoverflow.com/a/68617676/15893958)\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.5/F1_Score":{"title":"F1_Score","content":"# F1 Score\n\n\u003cdiv align=\"right\"\u003e 2022-05-05\u003c/div\u003e\n\nTags: #F1Score \n\n\n- The traditional *F-measure* or *balanced F-score* (*F\u003csub\u003e1\u003c/sub\u003e score*) is the [Harmonic_Mean-è°ƒå’Œå¹³å‡æ•°](notes/2022/2022.5/Harmonic_Mean-è°ƒå’Œå¹³å‡æ•°.md) of [Precision Recall](notes/2022/2022.5/Precision%20Recall%20and%20Accuracy.md):\n\n$$F_{1}=\\frac{2}{\\text { recall }^{-1}+\\text { precision }^{-1}}=2 \\cdot \\frac{\\text { precision } \\cdot \\text { recall }}{\\text { precision }+\\text { recall }}=\\frac{\\text { tp }}{t p+\\frac{1}{2}(\\mathrm{fp}+\\mathrm{fn})}$$\n\n## ç›´è§‚è§£è¯» F1 score\n![ç›´è§‚ç†è§£](notes/2022/2022.5/Harmonic_Mean-è°ƒå’Œå¹³å‡æ•°.md#ç›´è§‚ç†è§£)","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.5/GeoGebra-Embed":{"title":"GeoGebra Embed","content":"```html\n\u003ciframe src=\"https://www.geogebra.org/calculator/jzuwutfr?embed\" width=\"800\" height=\"600\" allowfullscreen style=\"border: 1px solid #e4e4e4;border-radius: 4px;\" frameborder=\"0\"\u003e\u003c/iframe\u003e\n```\n\n- åªéœ€è¦åœ¨é“¾æ¥åæ·»åŠ  `?embed` å³å¯\n\n- ä¿®æ”¹é¡µé¢æ•ˆæœçš„è®¾ç½®åœ¨è¿™é‡Œ:\n![](notes/2022/2022.5/assets/img_2022-10-15-2.png)\n![](notes/2022/2022.5/assets/img_2022-10-15-3.png)\n![](notes/2022/2022.5/assets/img_2022-10-15-4.png)\n\n![](notes/2022/2022.5/assets/img_2022-10-15-5.png)\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.5/Harmonic_Mean-%E8%B0%83%E5%92%8C%E5%B9%B3%E5%9D%87%E6%95%B0":{"title":"Harmonic_Mean-è°ƒå’Œå¹³å‡æ•°","content":"# Harmonic Mean\n\n\u003cdiv align=\"right\"\u003e 2022-05-03\u003c/div\u003e\n\nTags: #HarmonicMean #Math \n\nç”¨ $H$ è¡¨ç¤ºä¸¤ä¸ªæ•°çš„è°ƒå’Œå¹³å‡æ•°, åˆ™:\n$$\\frac{1}{H}=\\frac{1}{2}\\left(\\frac{1}{x_{1}}+\\frac{1}{x_{2}}\\right)$$\næ˜¾å¼åœ°è¡¨ç¤ºä¸º:\n$$H=\\frac{2 x_{1} x_{2}}{x_{1}+x_{2}}$$\n\n## ç›´è§‚ç†è§£\nç”¨ç´«è‰²çº¿æ®µ $H$ è¡¨ç¤º $a, b$ çš„*Harmonic Mean*:\nå…¶ä¸­: \n- $$A=\\frac{a+b}{2}$$ä¸ºä¸¤æ•°çš„ç®—æ•°å¹³å‡æ•°(*Arithmetic Mean*)\n- $$G=\\sqrt{ab}$$ä¸ºä¸¤æ•°çš„å‡ ä½•å¹³å‡æ•°(*Geometric Mean*)\n\n\n![](notes/2022/2022.5/assets/MathematicalMeans.svg)\n\n- åœ¨ $a+b$ ä¿æŒä¸å˜çš„æƒ…å†µä¸‹å˜åŒ– $a,b$ ä¹‹å‰çš„æ¯”ä¾‹, å¯ä»¥çœ‹åˆ° $H$ åœ¨ $a=b$ çš„æ—¶å€™å–å¾—æœ€å¤§å€¼\n\n- å¯è§†åŒ–è¿™ç§å˜åŒ–å…³ç³»å¦‚ä¸‹:\n$$H=\\frac{2 x_{1} x_{2}}{x_{1}+x_{2}}$$\n\u003ciframe src=\"https://www.geogebra.org/calculator/jzuwutfr?embed\" width=\"800\" height=\"600\" allowfullscreen style=\"border: 1px solid #e4e4e4;border-radius: 4px;\" frameborder=\"0\"\u003e\u003c/iframe\u003e\n\n\n![](notes/2022/2022.5/assets/Harmonic_mean_3D_plot_from_0_to_100.png)\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.5/Jupyter_Notebook-%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86":{"title":"Jupyter_Notebook-ä½¿ç”¨ä»£ç†","content":"# å¦‚ä½•åœ¨Jupyter Notebooké‡Œé¢ä½¿ç”¨ä»£ç†\n\n\u003cdiv align=\"right\"\u003e 2022-05-18\u003c/div\u003e\n\nTags: #Jupyter #Python #Proxy\n\n## æ–¹æ¡ˆä¸€: ä½¿ç”¨ IPython å¯åŠ¨è„šæœ¬\n- æ ¹æ® [è¿™ä¸ªå›ç­”](https://stackoverflow.com/a/36884552/15893958) ä»¥åŠä¸‹é¢è¯„è®º, IPython å¯ä»¥åœ¨å¯åŠ¨ä¹‹å‰è¿è¡Œä¸€äº›ä»£ç . æˆ‘ä»¬å¯ä»¥å€ŸåŠ©è¿™ä¸ªåŠŸèƒ½æ¥ä¸º Jupyter Notebook è®¾ç½®ä»£ç†\n- Windows çš„å¯åŠ¨è„šæœ¬é»˜è®¤åœ¨ä»¥ä¸‹ç›®å½•:\n\t- `C:\\Users\\[ç”¨æˆ·å]\\.ipython\\profile_default\\startup`\n\n1. é˜…è¯»ç›®å½•é‡Œé¢çš„ Readme æŸ¥çœ‹ä½¿ç”¨æŒ‡å—\n2. åˆ›å»ºæ–°çš„ python æ–‡ä»¶, è¾“å…¥ä»¥ä¸‹å†…å®¹: \n\t```python\n\timport os\n\tos.environ['http_proxy'] = \"http://127.0.0.1:7890\"\n\tos.environ['https_proxy'] = \"http://127.0.0.1:7890\"\n\t```\n\t- æ³¨æ„éœ€è¦æ ¹æ®è‡ªå·±çš„é…ç½®ä¿®æ”¹ç›¸åº”çš„ä»£ç†åœ°å€.\n\t- æ·»åŠ åå¦‚å›¾æ‰€ç¤º: \n\t\t![](notes/2022/2022.5/assets/img_2022-10-15-6.png)\n3. ä»¥ååœ¨å¯åŠ¨ Jupyter Notebook æ—¶, ä¸Šé¢çš„è„šæœ¬éƒ½ä¼šè‡ªåŠ¨è¿è¡Œ, æ‰€æœ‰çš„ Jupyter Notebook éƒ½ä¼šæœ‰ä»£ç†åçš„ç½‘ç»œè¿æ¥.\n\n- **ä¼˜ç‚¹:** ä¸ç”¨ä¸ºæ¯ä¸€ä¸ªç¬”è®°æœ¬å•ç‹¬è®¾ç½®ä»£ç†, æ›´åŠ æ–¹ä¾¿\n- **ç¼ºç‚¹:** æ‰€æœ‰ç¬”è®°æœ¬éƒ½è¢«ä»£ç†äº†, è¿™ä¹Ÿæ„å‘³ç€å¦‚æœä¸å¼€ä»£ç†è½¯ä»¶, ç¬”è®°æœ¬çš„ç½‘ç»œè¿æ¥ä¼šå‡ºç°é—®é¢˜:\n\t- ![](notes/2022/2022.5/assets/img_2022-10-15-7.png)\n\t- **å¯¹ç­–:** è¿è¡Œä»¥ä¸‹ä»£ç å–æ¶ˆä»£ç† \n```python\nimport os\nos.environ['http_proxy'] = \"\"\nos.environ['https_proxy'] = \"\"\n```\n\n## æ–¹æ¡ˆäºŒ: ä¸ºæŸä¸ªç¬”è®°æœ¬å•ç‹¬è®¾ç½®ä»£ç†\nå¦‚æœåªæƒ³ä¸ºæŸä¸ªç¬”è®°æœ¬å•ç‹¬è®¾ç½®ä»£ç†, å¯ä»¥è¿è¡Œå¦‚ä¸‹å•å…ƒæ ¼:\n```python\nimport os\nos.environ['http_proxy'] = \"http://127.0.0.1:7890\"\nos.environ['https_proxy'] = \"http://127.0.0.1:7890\"\n```\n\n- è¿™ä¸ªæ–¹æ¡ˆå’Œæ–¹æ¡ˆä¸€æ˜¯äº’è¡¥çš„.\n\n## æ–¹æ¡ˆä¸‰: åœ¨ä½¿ç”¨äº†ä»£ç†çš„ç»ˆç«¯ä¸­å¯åŠ¨Jupyter Notebook\n- **ç¼ºç‚¹:** åªèƒ½åœ¨ç½‘é¡µç‰ˆæœ¬çš„Jupyter Notebookä¸­ä½¿ç”¨ä»£ç†, æ— æ³•åœ¨VScode å¯åŠ¨çš„ç¬”è®°æœ¬ä¸­ä½¿ç”¨ä»£ç†.\n\n\n\n\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.5/Precision-Recall-and-Accuracy":{"title":"Precision Recall and Accuracy","content":"# Precision, Recall \u0026 Accuracy\n\n\u003cdiv align=\"right\"\u003e 2022-05-05\u003c/div\u003e\n\nTags: #Precision #Recall\n\n- åœˆåœˆæ˜¯æ¨¡å‹çš„é¢„æµ‹: åœˆåœˆé‡Œé¢æ˜¯é¢„æµ‹çš„ Positive, åœˆåœˆå¤–é¢æ˜¯é¢„æµ‹çš„ Negative\n- æ–¹æ–¹æ˜¯çœŸå®çš„æƒ…å†µ: å·¦åŠè¾¹æ˜¯çœŸå®çš„ Positive(å®å¿ƒç‚¹ç‚¹), å³åŠè¾¹æ˜¯çœŸå®çš„ Negative(ç©ºå¿ƒç‚¹ç‚¹).\n![](notes/2022/2022.5/assets/Precisionrecall.svg) [^1]\n- Precision æ˜¯é¢„æµ‹çš„ Positive æœ‰å¤šå°‘æ˜¯å¯¹çš„: å³æŸ¥å‡†ç‡.\n- Recall æ˜¯æ‰€æœ‰ Positive é‡Œé¢ä½ æ‰¾å‡ºæ¥äº†å¤šå°‘: å³æŸ¥å…¨ç‡.\n- Accuracy åˆ™æ˜¯é¢„æµ‹çš„æ­£ä¾‹è´Ÿä¾‹ä¸€èµ·çš„å‡†ç¡®åº¦\n![](notes/2022/2022.5/assets/Acc%20Pre%20Rec%20F1.png)\n\n\n\n\n\n[^1]: Wikipedia [https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)\n","lastmodified":"2023-11-19T19:19:34.478473107Z","tags":null},"/notes/2022/2022.6/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86-%E5%91%A8%E6%9C%9F%E6%80%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E9%97%B4%E7%AD%89":{"title":"æ•°æ®é¢„å¤„ç†-å‘¨æœŸæ€§æ•°æ®(æ—¶é—´ç­‰)","content":"# å‘¨æœŸæ€§æ•°æ®çš„é¢„å¤„ç†\n\n\u003cdiv align=\"right\"\u003e 2022-06-14\u003c/div\u003e\n\nTags: #MachineLearning #DataPreprocessing #CyclicFeatureEncoding\n\nSource: [Three Approaches to Encoding Time Information as Features for ML Models | NVIDIA Technical Blog](https://developer.nvidia.com/blog/three-approaches-to-encoding-time-information-as-features-for-ml-models/)\n\n**ä¸‰ç§æ–¹æ³•:**\n- Dummy Variable ([One-hot_Encoding-ç‹¬çƒ­ç¼–ç ](notes/2022/2022.1/One-hot_Encoding-ç‹¬çƒ­ç¼–ç .md))\n- cyclical encoding with sine/cosine transformation\n- radial basis functions (å¾„å‘åŸºå‡½æ•°)\n\t![](notes/2022/2022.6/assets/img_2022-10-15.png)\n","lastmodified":"2023-11-19T19:19:34.486473237Z","tags":null},"/notes/2022/2022.6/Imbalanced-Data-%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%9D%87%E8%A1%A1":{"title":"Imbalanced Data - æ•°æ®ä¸å‡è¡¡","content":"# æ•°æ®ä¸å‡è¡¡\n\n\u003cdiv align=\"right\"\u003e 2022-06-07\u003c/div\u003e\n\nTags: #DataPreprocessing \n\n## [ä»€ä¹ˆæ˜¯æ•°æ®ä¸å‡è¡¡](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)\n- A classification data set with skewed class proportions is called **imbalanced**. Classes that make up a large proportion of the data set are called **majority classes**. Those that make up a smaller proportion are **minority classes**.\n\nWhat counts as imbalanced? The answer could range from mild to extreme, as the table below shows.\n\n| Degree of imbalance | Proportion of Minority Class |\n| ------ | ------ | \n| Mild |   20-40% of the data set| \n| Moderate |   1-20% of the data set| \n| Extreme |   \u003c1% of the data set| \n","lastmodified":"2023-11-19T19:19:34.486473237Z","tags":null},"/notes/2022/2022.6/JS%E6%95%A3%E5%BA%A6":{"title":"JSæ•£åº¦","content":"# Jensenâ€“Shannon divergence\n\n\u003cdiv align=\"right\"\u003e 2022-06-08\u003c/div\u003e\n\nTags: #JSDivergence \n\n- KL æ•£åº¦æ˜¯ä¸å¯¹ç§°çš„, è¿™ä½¿å¾—åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°ä¸€äº›é—®é¢˜ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨ KL æ•£åº¦åŸºç¡€ä¸Šå¼•å…¥ JS æ•£åº¦\n\n## å®šä¹‰\n- The Jensenâ€“Shannon divergence (JSD) $M_+^1( A ) Ã— M_+^1(A) â†’ [ 0 , âˆ )$ [^1]is a **symmetrized and smoothed version** of the [Kullbackâ€“Leibler divergence](notes/2022/2022.2/KL_Divergence-KLæ•£åº¦.md) $D ( P âˆ¥ Q )$ . \n- It is defined by \n$$\n\\operatorname{JSD}(P \\| Q)=\\frac{1}{2} D(P \\| M)+\\frac{1}{2} D(Q \\| M)\n$$\n\twhere $M=\\frac{1}{2}(P+Q)$.\n\n\n\n\n\n\n[^1]: çœ‹ä¸æ‡‚è¿™ä¸ªç¬¦å·: Consider the set $M_+^1( A )$ of probability distributions where $A$ is a set provided with some Ïƒ-algebra of measurable subsets. In particular we can take $A$  to be a finite or countable set with all subsets being measurable. [Jensenâ€“Shannon divergence - Wikipedia](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)","lastmodified":"2023-11-19T19:19:34.486473237Z","tags":null},"/notes/2022/2022.6/Un-is-not-always-negative-Ravel-Unravel":{"title":"Un- is not always negative - Ravel \u0026 Unravel","content":"# Ravel å’Œ Unravel æœ‰ç›¸åŒçš„æ„æ€\n\n\u003cdiv align=\"right\"\u003e 2022-06-13\u003c/div\u003e\n\nTags: #English \n\n[When 'Un-' Isn't Negative | Merriam-Webster](https://www.merriam-webster.com/words-at-play/when-un-isnt-negative)\n\n\u003e These are three instances in which a verb beginning with _un-_ means the same as, rather than the negative or opposite of, its stem.\n\u003e \n\u003e And while it might seem frustratingly illogical when you are used to regarding un- strictly as a negative prefix, this use of _un-_ isn't as irrational as it looks.\n\u003e \n\u003e In all three casesâ€”_unthaw_, _unloosen_, and _unravel_â€”the _un-_ form of the verb came into being only after its stem was already established in English.\n\u003e \n\u003e And in all three cases, notably, the verb stem already connotes some kind of undoing, an action of removing something from a state that had existed (frozenness, knottedness, intactness).\n\u003e \n\u003e Rather than negating each action, the placement of _un-_ in front of these verb stems seems to reinforce the undoing action of eachâ€”thereby _emphasizing_ the idea of negation rather than serving to negate the verb stem itself.\n\n\n\n## å¹¶ä¸”, ä¸ºä»€ä¹ˆ ravel æœ‰äº’ç›¸çŸ›ç›¾çš„æ„æ€?\nSource: [The verb \"ravel\" has two contradicting definitions. | WordReference Forums](https://forum.wordreference.com/threads/the-verb-ravel-has-two-contradicting-definitions.556645/)\n\n\u003e Don't blame the dictionaries. This is an odd word, which does have two contradictory meanings: to tangle, and to untangle.  \n\u003e   \n\u003e Online Etymology Dictionary:  \n\u003e ravel  \n\u003e 1582, \"to untangle, unwind,\" also \"to become tangled or confused\" (1585), from Du. ravelen \"to tangle, fray, unweave,\" from rafel \"frayed thread.\" **The seemingly contradictory senses of this word (ravel and unravel are both synonyms and antonyms) are reconciled by its roots in weaving and sewing: as threads become unwoven, they get tangled.**\n\n","lastmodified":"2023-11-19T19:19:34.486473237Z","tags":null},"/notes/2022/2022.7/%E4%BA%86%E8%A7%A3%E4%BF%A1%E7%94%A8%E5%8D%A1":{"title":"äº†è§£ä¿¡ç”¨å¡","content":"# äº†è§£ä¿¡ç”¨å¡\n\n\u003cdiv align=\"right\"\u003e 2022-07-11\u003c/div\u003e\n\nTags: #DailyLife #CreditCard\n\n## ä¿¡ç”¨å¡æ˜¯ä»€ä¹ˆ?\n- ä¿¡ç”¨å¡ï¼ˆè‹±è¯­ï¼šCredit Cardï¼‰ï¼Œæ˜¯ä¸€ç§éç°é‡‘äº¤æ˜“ä»˜æ¬¾çš„æ–¹å¼ï¼Œæ˜¯é“¶è¡Œä¸šæä¾›çš„**ä¿¡è´·æœåŠ¡**ã€‚\n- ä¸ä¸€èˆ¬çš„ä¿¡ç”¨å¡ä¸å€Ÿè®°å¡ã€ææ¬¾å¡ä¸åŒï¼Œä¿¡ç”¨å¡åœ¨æ¶ˆè´¹æ—¶ä¸ä¼šç›´æ¥æ‰£é™¤ç”¨æˆ·çš„èµ„é‡‘ï¼Œè€Œæ˜¯ç­‰åˆ°è´¦å•æ—¥æ—¶å†è¿›è¡Œè¿˜æ¬¾ã€‚\n\n## ä¿¡ç”¨å¡çš„å†å²\næ ¹æ®ç»´åŸºç™¾ç§‘ï¼Œæœ€æ—©çš„ä¿¡ç”¨æ”¯ä»˜å‡ºç°äº 19 ä¸–çºªæœ«çš„èµ„æœ¬ä¸»ä¹‰é‡é•‡è‹±å›½ï¼Œå¤§çº¦åœ¨åä¹ä¸–çºªå…«åå¹´ä»£ï¼Œé’ˆå¯¹æœ‰é’±äººè´­ä¹°æ˜‚è´µçš„å¥¢ä¾ˆå“å´æ²¡æœ‰éšèº«æºå¸¦é‚£ä¹ˆå¤šé’±ï¼Œè‹±å›½æœè£…ä¸šå‘å±•å‡ºæ‰€è°“çš„ä¿¡ç”¨åˆ¶åº¦ï¼Œåˆ©ç”¨è®°å½•å¡ï¼Œè´­ç‰©çš„æ—¶å€™å¯ä»¥åŠæ—©å¸¦æµè¡Œå•†å“å›å»ï¼Œæ—…æ¸¸ä¸šä¸å•†ä¸šéƒ¨é—¨ä¹Ÿéƒ½è·Ÿéšè¿™ä¸ªæ½®æµæŠ¢å å•†æœºã€‚\n\nä½†å½“æ—¶çš„å¡ç‰‡ä»…èƒ½è¿›è¡Œåœ¨ç‰¹å®šåœºæ‰€çš„çŸ­æœŸå•†ä¸šèµŠå€Ÿè¡Œä¸ºï¼Œæ¬¾é¡¹è¿˜æ˜¯è¦éšç”¨éšä»˜ï¼Œä¸èƒ½é•¿æœŸæ‹–æ¬ ï¼Œä¹Ÿæ²¡æœ‰æˆä¿¡é¢åº¦ï¼Œå®Œå…¨æ˜¯ä¾èµ–å¯Œè£•äººå£çš„èµ„æœ¬ä¿¡ç”¨è€Œè®¾è®¡ã€‚\n\n20 ä¸–çºª 50 å¹´ä»£ï¼Œç¬¬ä¸€å¼ é’ˆå¯¹å¤§ä¼—çš„ä¿¡ç”¨å¡å‡ºç°ï¼Œç¾å›½æ›¼å“ˆé¡¿ä¿¡è´·ä¸“å®¶éº¦å…‹çº³é©¬æ‹‰ï¼ˆFrank McNamaraï¼‰åœ¨é¥­åº—ç”¨é¤ï¼Œç”±äºæ²¡æœ‰å¸¦è¶³å¤Ÿçš„é’±ï¼Œåªèƒ½è®©å¤ªå¤ªé€é’±è¿‡æ¥ã€‚è¿™è®©ä»–è§‰å¾—å¾ˆç‹¼ç‹ˆï¼Œäºæ˜¯ç»„ç»‡äº†â€œé£Ÿå®¢ä¿±ä¹éƒ¨â€ï¼ˆè‹±è¯­ï¼šDiners Clubï¼Œå³ä¸ºå¤§æ¥å¡ï¼‰ï¼Œä»»ä½•äººè·å‡†æˆä¸ºä¼šå‘˜åï¼Œå¸¦ä¸€å¼ å°±é¤è®°è´¦å¡åˆ°æŒ‡å®š 27 é—´é¤å…å°±å¯ä»¥è®°è´¦æ¶ˆè´¹ï¼Œä¸å¿…ä»˜ç°é‡‘ï¼Œè¿™å°±æ˜¯æœ€æ—©çš„ä¿¡ç”¨å¡ã€‚\n\næ­¤åéšç­¾çº¦çš„åˆä½œå¯¹è±¡è¶Šæ¥è¶Šå¤šï¼Œå¯ä¾›ä¸´æ—¶é€æ”¯çš„æœåŠ¡èŒƒå›´ä¹Ÿè¶Šæ¥è¶Šå¤§ï¼Œäººä»¬ä¹Ÿä¹ æƒ¯äº†è¿™ç§ä¸å¿…æºå¸¦ç°é‡‘çš„æ–¹ä¾¿äº¤æ˜“å‹å¼ï¼Œä¿ƒè¿›äº†é“¶è¡Œä¿¡ç”¨å¡çš„åˆ°æ¥ï¼Œç¾å›½å¯Œå…°å…‹æ—å›½æ°‘é“¶è¡Œæ˜¯ç¬¬ä¸€å®¶å‘è¡Œä¿¡ç”¨å¡çš„é“¶è¡Œï¼Œä¹‹åå…¶ä»–ç¾å›½é“¶è¡Œä¹Ÿè·Ÿéšã€‚\n\nè¯¦ç»†çš„å†å²å¯ä»¥å‚è€ƒè¿™ç¯‡æ–‡ç« ï¼š[ä¿¡ç”¨å¡çš„å†å²èµ·æº - é˜®ä¸€å³°çš„ç½‘ç»œæ—¥å¿—](http://www.ruanyifeng.com/blog/2019/07/origin-of-credit-card.html)\n\n## ä¿¡ç”¨å¡ç”±è°å‘è¡Œ\nä¿¡ç”¨å¡ç”±**å›½é™…ä¿¡ç”¨å¡ç»„ç»‡**å‘è¡Œï¼Œå›½é™…ä¸Šå…­å¤§ä¿¡ç”¨å¡ç»„ç»‡åˆ†åˆ«æ˜¯ VISAã€MasterCardï¼ˆä¸‡äº‹è¾¾å¡ï¼‰ã€American Expressï¼ˆç¾å›½è¿é€šï¼‰ã€UnionPayï¼ˆé“¶è”ï¼‰ã€JCB å’Œ Diners Clubã€‚é™¤é“¶è”å’Œ JCB å¤–ï¼Œå…¶ä½™å››å¤§ä¿¡ç”¨å¡å‡èµ·æºäºç¾å›½ã€‚\n\n### ä¿¡ç”¨å¡ç»„ç»‡å’Œé“¶è¡Œçš„å…³ç³»æ˜¯ä»€ä¹ˆ\né“¶è¡Œå¡ç»„ç»‡æœ¬èº«å¹¶ä¸å‘å¡ï¼Œè€Œæ˜¯ç”±åŠ å…¥é“¶è¡Œå¡ç»„ç»‡çš„é‡‘èç±»æœºæ„ä¼šå‘˜ï¼ˆä¸»è¦æ˜¯é“¶è¡Œï¼‰æ¥å‘è¡Œå„ç§å¡ç‰‡ï¼Œå¹¶ä¸”ä¼šæç¤ºå…¶ä¼šå‘˜æœºæ„ä»¬å¼€å‘æ–°çš„æ”¯ä»˜äº§å“å’ŒæŠ€æœ¯ã€‚æŒå¡äººçš„ç›¸å…³å…³ç³»ä¹Ÿæœ‰å„é‡‘èæœºæ„è‡ªå·±è´Ÿè´£ç®¡ç†ã€‚[^1]\n\n\n\n\n\n\n\n[^1]: [Fetching Title#9j0f](https://zhuanlan.zhihu.com/p/32120593)","lastmodified":"2023-11-19T19:19:34.522473824Z","tags":null},"/notes/2022/2022.7/%E6%9C%89%E6%95%88%E5%9C%B0%E8%83%8C%E8%AF%B5GRE%E5%8D%95%E8%AF%8D":{"title":"æœ‰æ•ˆåœ°èƒŒè¯µGREå•è¯","content":"# æœ‰æ•ˆåœ°èƒŒè¯µ GRE å•è¯\n\n\u003cdiv align=\"right\"\u003e 2022-07-09\u003c/div\u003e\n\n#### Bathos\n- **Bathos** is a coined word(from Greek _bathys,_ â€œdeepâ€), which means unsuccessful, and therefore ludicrous, attempt to portray [pathos](https://www.merriam-webster.com/dictionary/pathos) in art, _i.e.,_ to evoke pity, sympathy, or sorrow. The term was first used in this sense by [Alexander Pope](https://www.britannica.com/biography/Alexander-Pope-English-author) in his [treatise](https://www.merriam-webster.com/dictionary/treatise) _Peri Bathous; or, The Art of Sinking in Poetry_ (1728).\n\n- **Pathos**: the power of a person, situation, piece of writing, or work of art to cause feelings of sadness, especially because people feel sympathy.ï¼ˆå¢ƒå†µã€æ–‡ç« ã€è‰ºæœ¯å“æˆ–äººçš„ï¼‰æ„ŸæŸ“åŠ›\n\n- Pathos is sincere compassion. Bathos is ridiculous and ludicrous.\n\n- Example of Bathos: [What Writers Should Learn From Wonder Woman - YouTube](https://www.youtube.com/watch?v=w-QhdzQo66o)\n\n#### miscreant\n- someone who has done something illegal or behave badly.\n- `mis-`,  ä¸; `cre-,cred-` believe, trust.\n\t- ä¸ç›¸ä¿¡åŸºç£çš„, non-Christian.\n\n#### filibuster\n- é€šè¿‡å‘è¡¨å†—é•¿çš„æ¼”è®²æ¥é˜»æ­¢å’Œæ‹–å»¶ä¸€ä¸ªæ³•å¾‹è¿›ç¨‹\n- `flibutor` åœ¨è·å…°è¯­é‡Œé¢çš„æ„æ€æ˜¯ `pirate`, ä¸€ä¸ª filibuster çš„äººå°±åƒ pirate ä¸€æ ·è®¨åŒ.\n\n#### robust\n- ä¸€ä¸ªåšå®šè€Œå¼ºçƒˆçš„è§‚ç‚¹ä¹Ÿå¯ä»¥æ˜¯ `robust` çš„\n- A British Foreign Office minister has made **a robust defence** of the agreement.\n- He has the keen eye and **robust approach** needed.\n\n#### feeble\nä¸€ä¸ªè¨€è®ºä¹Ÿå¯ä»¥æ˜¯ feeble çš„: ç«™ä¸ä½è„šçš„, unconvincing, poor, weak, å¹²å·´å·´çš„, \n- a feeble joke/excuse\n\n\n#### fledge\n- fledge: to acquire feathers\n- fledge + ling: fledgling æ­£åœ¨é•¿ç¾½æ¯›çš„ - åˆå‡ºèŒ…åºçš„, æ²¡æœ‰ç»éªŒçš„\n- fledge + ed: fledged ç¾½ç¿¼ä¸°æ»¡çš„\n\n#### credence\n- `noun`, ç›¸ä¿¡\n\t- add/give/lend **credence** to: è¯å®, ç›¸ä¿¡\n\n##### `creed-`, `cred` : to believe\n- credit: ä¿¡ç”¨\n- credulous: å®¹æ˜“è¢«éª—çš„\n- credential: è¯æ˜è‡ªå·±å¯ä»¥è¢«ç›¸ä¿¡çš„ä¸œè¥¿ -\u003e è¯ä¹¦, è¯ä»¶\n\n#### dolorous\n- `dole-` æ‚²ä¼¤, grieve, sorrow\n- dolo + rous -\u003e æ‚²ä¼¤çš„, sad\n- doleful -\u003e depressing, miserable\n\n#### override\n- over-ride\n- out-weight\n- over-come\n- super-sede\n- eclipse, æ—¥é£Ÿ, æœˆé£Ÿ -\u003e æ¯”å¦‚æ—¥é£Ÿçš„æ—¶å€™å¤§å®¶çš„æ³¨æ„åŠ›éƒ½åœ¨æœˆäº®ä¸Šé¢, å¼•ç”³ä¸º the second thing gets all the attention\n\n#### demoteâ˜¢â˜¢\n- å¯¹æ¯” pro-mote\n- downgrade, relegate, degrade\n\n#### rhetorical\n- rhetorical question: åé—®å¥\n- rhetoric: ä¿®è¾å­¦, é›„è¾©æœ¯-\u003eåè€Œä¸å®çš„ç…½åŠ¨æ€§è¯­è¨€\n\n#### cow\neasily herded =\u003e intimidate, daunt, frighten, scare, æå“\n\n\n#### culpable\n`culp-` =\u003e guilt, fault\næœ‰ç½ªçš„, blameworthy, wrong, guilty, to blame\n\n\n#### burgeonâ˜¢\nto bud, to sprout - å‘èŠ½, ç»“èŠ±è‹ =\u003e develop quickly, increase, flower, grow\n\n\n#### deign\ndescend + dignity =\u003e å±ˆå°Š\n\n#### condescend\ncon- ä¸€èµ· + descend ä¸‹é™ =\u003e ä¸€èµ·ä¸‹é™ =\u003e å±ˆå°Š\n\n\n#### impious\nim- + pious =\u003e ä¸+è™”è¯šçš„ =\u003e ä¸è™”è¯šçš„, å¯¹ç¥çµä¸æ•¬çš„\n\n#### tactile\ntact- tang- tag- =\u003e touch æ¯”å¦‚ tangible\ntact + ile =\u003e è§¦è§‰çš„, çˆ±åŠ¨æ‰‹åŠ¨è„šæ‘¸åˆ«äººçš„, æ‘¸èµ·æ¥èˆ’æœçš„\n\n#### prepossessingâ˜¢â˜¢\nattractive, impressive, interesting\npre- + possess + ing =\u003e é¢„å…ˆå é¢†çš„ (mentally) =\u003eç²¾ç¥ä¸Šé¢„å…ˆå é¢† =\u003e ç»™äººå¥½æ„Ÿçš„\n\n\n#### ingratiatingâ˜¢â˜¢\nin- ä½¿... + grat- é«˜å…´, æ„Ÿæ¿€ + ate åš, é€ æˆ + ing ... çš„\n=\u003e è®©äººæ„Ÿåˆ°é«˜å…´/æ„Ÿæ¿€çš„, =\u003e è¿åˆçš„, å¥‰æ‰¿çš„, \n- sycophantic\n- obsequious\n- servile\n\n#### sycophant\nsycophantï¼ˆé©¬å±ç²¾ï¼‰ï¼šæ›¿é¢†å¯¼ç”¨ä¸‹æµæ‰‹åŠ¿ä¾®è¾±å¯¹æ‰‹çš„äºº\nè‹±è¯­å•è¯sycophantï¼ˆè°„åªšè€…ï¼‰æ¥è‡ªå¸Œè…Šè¯­sykophantesï¼Œç”±sykonï¼ˆfigï¼Œæ— èŠ±æœï¼‰+phaineinï¼ˆto showï¼Œæ˜¾ç¤ºï¼‰ç»„æˆè€Œæˆï¼Œå­—é¢æ„æ€å°±æ˜¯fig-showerï¼ˆæ˜¾ç¤ºæ— èŠ±æœçš„äººï¼‰ã€‚åœ¨è¿™é‡Œï¼Œfigï¼ˆæ— èŠ±æœï¼‰éšå–»å¥³æ€§å¤–é˜´ï¼Œfig-showå°±æ˜¯ç”¨æ‰‹æ¯”åˆ’æˆå¥³æ€§å¤–é˜´çš„å½¢çŠ¶æ¥ä¾®è¾±å¯¹æ–¹ã€‚åœ¨å¤å¸Œè…Šï¼Œæ”¿æ²»å®¶ä»¬è¡¨é¢ä¸Šå¾ˆæ­£æ´¾ï¼ŒèƒŒåœ°é‡Œå´å”†ä½¿è‡ªå·±æ‰‹ä¸‹ç”¨è¿™ç§ä¸‹æµæ‰‹åŠ¿æ¥ä¾®è¾±è‡ªå·±çš„å¯¹æ‰‹ã€‚è€Œé‚£äº›å¬ä»å¤§äººç‰©çš„å©å’ï¼Œç”¨ä¸‹æµæ‰‹åŠ¿ä¾®è¾±å¯¹æ‰‹çš„æ‰‹ä¸‹åˆ™è¢«ç§°ä¸ºsycophantï¼ˆfig-showerï¼‰ã€‚ç°åœ¨ï¼Œè‹±è¯­sycophantç”¨æ¥æ¯”å–»é‚£ç§å‘é„™æ— è€»ã€å¥´é¢œå©¢è†çš„è°„åªšè€…ã€é©¬å±ç²¾ã€‚\nsycophantï¼š['sÉªkÉ™fÃ¦nt] n. è°„åªšè€…ï¼Œå¥‰æ‰¿è€…ï¼Œé©¬å±ç²¾ adj. è°„åªšçš„ï¼Œå¥‰æ‰¿çš„\nsycophanticï¼š[,sÉªkÉ™'fÃ¦ntÉªk] adj. è¯´å¥‰æ‰¿è¯çš„ï¼›é˜¿è°€çš„\nsycophancyï¼š['sÉªkÉ™fÃ¦nti] n. è°„åªšï¼›å¥‰æ‰¿ï¼›è¿½éšï¼›æ‹é©¬å±\n\n#### penitence\npenit- æ‡Šæ‚” + ence è¡¨çŠ¶æ€ =\u003e æ‡Šæ‚”çš„çŠ¶æ€, å¿æ‚”\n- repenitence: re-è¡¨ç¤ºå¼ºè°ƒ, å†, =\u003e æ‚”è¿‡, å¿æ‚”, regret, guilt, grief, sorrow.\n\n- penitent å¿æ‚”çš„, æ‚”è¿‡çš„\n- impenitent ä¸çŸ¥æ‚”æ”¹çš„\n\n\n#### sulk\n**sulk** ç”Ÿé—·æ°”, æ„ æ€’ -\u003e back-formation from **sulky**\n- sulky -\u003e quietly sullen\n- sullen -\u003e morose é—·é—·ä¸ä¹çš„, æ„ æ€’çš„\n\nsullen è¿˜èƒ½ç”¨æ¥å½¢å®¹å¤©æ°” =\u003e the sullen sky =\u003e dark and unpleasant\n=\u003e å°±åƒæ±‰è¯­é‡Œé¢\"é˜´æ²‰çš„\"æ—¢èƒ½ç”¨æ¥å½¢å®¹äººçš„æƒ…ç»ª, ä¹Ÿèƒ½ç”¨æ¥å½¢å®¹å¤©æ°”ä¸€æ ·.\n\n#### palatial\nlike a palace, magnificent\n\n#### incinerate\nin- ä½¿ â• ciner- ash ç° â• -ate åš,é€ æˆ =\u003e ä½¿å˜æˆç° =\u003e ç„šçƒ§, ç„šæ¯ / burn to death\n\n\n#### sporadic\nspor- spore, å­¢å­, ç§å­, å¼•ç”³ä¸º scattered åˆ†æ•£çš„, å†å¼•ç”³ä¸º \"æ—¶é—´ä¸Šåˆ†æ•£çš„\" =\u003e é—´æ–­çš„, ä¸è¿ç»­çš„, é›¶æ˜Ÿçš„ \n- intermittent\n- occasional\n- scattered\n\n#### incessant\nin- ä¸  â• cess- èµ°å¼€, åœæ­¢, æ’¤é€€, åœæ¯ â• -ant çš„ =\u003e ä¸åœæ¯çš„, è¿ç»­ä¸æ–­çš„, æ²¡å®Œæ²¡äº†çš„\n- all the time, constantly, continually, endlessly\n\n#### pensive\npen-ï¼šæ‚¬å‚ï¼Œç§°é‡ï¼Œä¹°ä¸œè¥¿ç§°é‡çš„æ—¶å€™éƒ½éœ€è¦æ€è€ƒ=\u003eæƒè¡¡, æ²‰æ€\npensiveï¼š ['pÉ›nsÉªv] adj. æ²‰æ€çš„ï¼Œå¿§éƒçš„ï¼›æ‚²ä¼¤çš„ï¼Œå“€æ„çš„\n\npansyï¼ˆä¸‰è‰²å ‡ï¼‰ï¼šçŠ¶å¦‚æ²‰æ€å°è„¸çš„èŠ±å‰\nå•è¯ pansy æ¥è‡ªæ‹‰ä¸è¯­åŠ¨è¯ pensareï¼ˆæ²‰æ€ï¼‰ï¼ŒåŠ¨è¯ pendereï¼ˆæƒè¡¡ã€ç§°é‡ï¼‰çš„åå¤å½¢å¼ï¼Œæœ¬æ„æ˜¯â€œæ²‰æ€çš„â€ï¼Œä¸å•è¯ pensiveï¼ˆæ²‰æ€çš„ï¼‰ã€pendentï¼ˆæ‚¬å‚çš„ï¼‰åŒæºã€‚æ¤ç‰©å­¦å®¶ç”¨ pansy ä¸€è¯æ¥è¡¨ç¤ºâ€œä¸‰è‰²å ‡â€è¿™ç§æ¤ç‰©ï¼Œå› ä¸ºå®ƒçš„èŠ±ç“£è¿‘ä¹åœ†å½¢ï¼ŒçŠ¶å¦‚ä¸€å¼ æ­£åœ¨æ²‰æ€çš„å°è„¸ï¼Œæ•…æ­¤å¾—äº†è¿™ä¹ˆä¸€ä¸ªå……æ»¡è¯—æ„çš„åç§°ã€‚\n![](notes/2022/2022.7/assets/1-1ZPGKA35a.jpg)\npendentï¼š['pÉ›ndÉ™nt] adj. æ‚¬è€Œæœªå†³çš„ï¼›ä¸‹å‚çš„ï¼›æœªå®šçš„ï¼›å‘å¤–ä¼¸å‡ºçš„\n\n#### heterodoxâ˜¢\nhetero-: the other, å¼‚çš„\n-dox: è§‚ç‚¹\n\n\n#### rostrum\nrostrum - è¯¥è¯ç³»æ‹‰ä¸è¯­å€Ÿç”¨è¯ï¼ŒåŸæŒ‡â€œé¸Ÿå˜´â€ã€‚å…¬å…ƒå‰ 338 å¹´å¤ç½—é©¬å¾æœäº†å®‰é½å¥¥ï¼ˆAnzioï¼Œæ—§å Antiumï¼‰ï¼Œå°†è¢«ä¿˜æˆ˜èˆ¹ä¸Šå–ä¸‹çš„å–™å½¢èˆ¹é¦–ä½œä¸ºæˆ˜åˆ©å“è¿å›ç½—é©¬ï¼Œå¹¶ç”¨å®ƒä»¬æ¥è£…é¥°å¤ç½—é©¬å¹¿åœºï¼ˆthe Roman Forumï¼‰çš„æ¼”è®²å°ã€‚è¿™äº›èˆ¹é¦–å› å½¢ä¼¼é¸Ÿå˜´ï¼Œæ•…ç½—é©¬äººç§°å–™å½¢èˆ¹é¦–ä¸º rostraï¼ˆrÅstrum çš„å¤æ•°å½¢å¼ï¼‰ï¼Œéšåå°†å¤ç½—é©¬å¹¿åœºçš„æ¼”è®²å°ä¹Ÿç§°ä½œ Rostraã€‚ä¸å°‘ç½—é©¬æ¼”è¯´å®¶æ›¾ç»ç™»ä¸Š Rostra å‘è¡¨æ¼”è¯´ï¼Œå¤ç½—é©¬æ”¿æ²»å®¶ã€æ¼”è¯´å®¶ã€å“²å­¦å®¶è¥¿å¡ç½—ï¼ˆCicero, 106-43 BCï¼‰å°±æ›¾åœ¨è¿™ä¸ª Rostra å‘è¡¨åå®‰ä¸œå°¼æ¼”è¯´ã€‚å‡¯æ’’ï¼ˆJulius Caesarï¼‰è¢«åˆºæ€åï¼Œè¥¿å¡ç½—é€ƒç¦»ç½—é©¬ï¼Œä¸ä¹…é­è¿½æ•å¹¶è¢«æ€å®³ï¼Œé¦–çº§å’ŒåŒæ‰‹è¢«ç ä¸‹é€å›ç½—é©¬æ‚¬äº Rostra ç¤ºä¼—ã€‚å—£åï¼Œrostra ä¸€è¯è¢«é€æ¸ç”¨ä»¥æ³›æŒ‡â€œæ¼”è®²å°â€ã€‚18 ä¸–çºª rÅstrum(rostra çš„å•æ•°å½¢å¼ï¼‰è¿›å…¥è‹±è¯­ä½œ rostrumï¼Œä¹Ÿç”¨ä»¥æ³›æŒ‡â€œæ¼”è®²å°â€æˆ–â€œè®²å›â€ã€‚\n\n\n#### macerateâ˜¢\nmacer- : soften, ä½¿å˜è½¯\nate : åš, é€ æˆ \nä½¿ä»€ä¹ˆä¸œè¥¿å˜è½¯, è®¸å¤šä¸œè¥¿åœ¨æ°´é‡Œæ³¡äº†ä¹‹åéƒ½ä¼šå˜è½¯, å¼•ç”³ä¸º**æµ¸æ³¡, è…Œåˆ¶**\n\n\n#### tenacity\n- quality of holding firmly: `ten-` hold + `acity` æœ‰...å€¾å‘ \ndetermination, åšæŒ, å›ºæ‰§, åšå®ˆ\n- tenacious\n\n#### recantâ˜¢â˜¢\n`re-` back\n`cant` Latin: *cantare* , to chant, to sing\n- back chant/sing =\u003e withdraw, take back, retract, disclaim\n\n\n#### satiate\n`satis` enough + ate =\u003e ä½¿è¶³å¤Ÿ, ä½¿æ»¡è¶³, =\u003e é¥±è¶³çš„, å……åˆ†æ»¡è¶³æ¬²æœ›, ä»¥è‡³äºæœ‰ä¸€ç‚¹åŒæ¶\n\nsatiating: é¥±è…¹æ„Ÿå¼ºçš„\n\n#### plethora\npleth- full + ora åè¯åç¼€ =\u003e noun. è¿‡å¤š, è¿‡å‰©, å¤šè¡€ç—‡\n\n\n#### ramshackle\næ‘‡æ‘‡æ¬²å çš„\n`ram-` æ ‘æ branch, + `shackle` æŸç¼š\n\nåƒæ ‘æä¸€æ ·ç»‘åœ¨ä¸€èµ·çš„, æ‘‡æ‘‡æ¬²å çš„\n\n#### impecuniousâ˜¢\n- im-,in-,il-,ir- è¡¨ç¤ºâ€œæ— ï¼Œæ²¡æœ‰ï¼ˆnot,oppositeï¼‰â€ï¼Œæ¥è‡ªæ‹‰ä¸è¯­ in-ã€‚\n- pecu- æ¥è‡ªæ‹‰ä¸è¯­ peculiumï¼Œè¡¨ç¤ºç§æœ‰è´¢äº§ï¼Œpecu- ç‰¹æŒ‡ç‰›ç¾¤æˆ–ç‰²ç•œï¼Œè¿™äº›éƒ½æ˜¯å½“æ—¶æœ€é‡è¦çš„è´¢äº§å½¢å¼ï¼Œæ‰€ä»¥ä¹Ÿå¼•ç”³ä¸ºè´¢äº§å’Œç‰¹æ®Šçš„ã€‚\n- -ous,-itious,-eous,-ious,-uous è¡¨å½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œâ€¦çš„â€ï¼Œç”¨äºåŒ–å­¦é¢†åŸŸè¡¨ç¤ºâ€œäºšé…¸çš„ï¼Œä½ä»·ï¼ˆé‡‘å±ï¼‰çš„â€\n\næ²¡æœ‰ç§äººè´¢äº§çš„, è´«ç©·çš„ \\\u003cFormal\u003e\n\n#### insular\ninsula: island\n- æ¯”å¦‚ peninsula: åŠå²› (`pen-` è¿‘ä¼¼, å·®ä¸å¤š)\n- insular, åƒå²›å±¿ä¸€æ ·çš„ =\u003e æ€æƒ³ç‹­éš˜çš„, ä¿å®ˆçš„, narrow-minded, prejudiced, provincial, closed\n\n- provincial =\u003e å¤–åœ°çš„, å¤–çœçš„ =\u003e ä¿å®ˆçš„, ç‹­éš˜çš„, å¯ä»¥çœ‹åˆ°å¤äººä¹Ÿè®¤ä¸ºåœ°åŸŸå†³å®šæ€æƒ³: åœ°åŸŸååƒ»åœ°æ–¹çš„äººçš„æ€æƒ³ä¹Ÿä¿å®ˆç‹­éš˜.\n\n#### haughty\nhaught: é«˜çš„, =\u003e è‡ªå·±ä»¥ä¸ºè‡ªå·±å¾ˆé«˜çš„ =\u003e å‚²æ…¢çš„\n\nhauteur =\u003e é«˜å‚², å‚²æ…¢\n\n#### verdant\n- `verd-` green + -ant =\u003e è‰æœ¨è‹ç¿ çš„ \n- green, lush, leafy, grassy\n\n#### dirge\ndirgeï¼ˆæŒ½æ­Œï¼‰ï¼šåŸºç£æ•™ä¸§ç¤¼ä¸Šçš„æŒ½æ­Œ\næ ¹æ®åŸºç£æ•™ç¤¼ä»ªï¼Œå½“åŸºç£æ•™å¾’å»ä¸–åï¼Œå°†åœ¨æ•™å ‚ä¸ºå…¶ä¸¾è¡Œä¸§ç¤¼ï¼ˆOffice of the Deadï¼‰ã€‚ä¸§ç¤¼é€šå¸¸åŒ…æ‹¬è‹¥å¹²æ¬¡ç¥·å‘Šï¼Œæ­»è€…çš„äº²æœ‹å¥½å‹åœ¨ç‰§å¸ˆçš„å¼•å¯¼ä¸‹ä¸€èµ·è¯µå¿µç¥·è¯æˆ–å”±åœ£æ­Œï¼ˆantiphonï¼‰ã€‚å…¶ä¸­ï¼Œæœ€æ—©çš„ä¸€æ¬¡ç¥·å‘Šç§°ä¸ºâ€œæ™¨ç¥·â€ï¼ˆMatinsæˆ–Office of Readingsï¼‰ã€‚æ™¨ç¥·ä¸€èˆ¬åœ¨æ‹‚æ™“æ—¶åˆ†è¿›è¡Œï¼Œæ‰€å”±çš„ç¬¬ä¸€é¦–åœ£æ­Œæ¥æºäºã€Šæ—§çº¦â€¢è¯—ç¯‡ã€‹ä¸­çš„ä¸€ç¯‡èµç¾è¯—ï¼Œç¬¬ä¸€å¥è¯å°±æ˜¯æ‹‰ä¸è¯­â€œDirige, Domine, Deus meus, in conspectu tuo viam meamâ€ï¼ˆä¸»å•Šï¼Œæˆ‘çš„ä¸Šå¸ï¼Œæ‚¨çš„ç›®å…‰å¼•å¯¼æˆ‘çš„é“è·¯ï¼‰ã€‚å…¶ä¸­çš„ç¬¬ä¸€ä¸ªå•è¯dirigeå°±æ˜¯â€œå¼•å¯¼â€çš„æ„æ€ï¼Œæ˜¯æ‹‰ä¸è¯­dirigereï¼ˆå¼•å¯¼ï¼‰çš„ç¥ˆä½¿å½¢æ€ï¼Œä¸è‹±è¯­å•è¯directï¼ˆå¼•å¯¼ï¼‰åŒæºã€‚å› æ­¤ï¼Œè¿™ä¸€ç¯‡èµç¾è¯—å°±è¢«ç§°ä¸ºdirigeï¼Œè¿›å…¥è‹±è¯­åæ‹¼å†™æ¼”å˜ä¸ºdirgeã€‚ç”±äºå®ƒæ˜¯ç”¨æ¥å“€æ‚¼æ­»è€…çš„ï¼Œæ‰€ä»¥dirgeé€šå¸¸è¢«è¯‘ä¸ºâ€œæŒ½æ­Œâ€ã€‚ç°åœ¨ï¼Œdirgeä¸€è¯å¯ä»¥ç”¨æ¥è¡¨ç¤ºå“€æ‚¼æ­»è€…çš„ä»»ä½•å“€æ­Œæˆ–æŒ½æ­Œã€‚\ndirgeï¼š[dÉœËdÊ’] n.æŒ½æ­Œï¼Œå“€æ‚¼æ­Œ\n\n\n#### Boisterous\n- çŒ›çƒˆçš„, å–§é—¹çš„, ç‹‚æš´çš„\n- Full of noisy enthusiasm and energy\n\nBoisterous è¯æºä¸è¯¦, ä½†æ˜¯å’Œ Beast å’Œ Boast å¾ˆåƒ\n\n\n#### cunning\n- cun =\u003e (g)noscere =\u003e to know, çŸ¥é“\n- ing =\u003e å½¢å®¹è¯åç¼€\ncunnning =\u003e learned, skillful, possessing knowledge, =\u003e ç‹¡çŒ¾çš„, æœºçµçš„, ç‹¡è¯ˆçš„\n\n#### jolt\n- to move sth suddenly and violently =\u003e çŒ›çš„ä¸€ä¸‹æ‘‡åŠ¨, éœ‡åŠ¨, å‰§çƒˆæ™ƒåŠ¨\n- =\u003e å¼•ç”³ä¸ºç²¾ç¥ä¸Šçš„\"éœ‡åŠ¨\" =\u003e ä½¿éœ‡æƒŠ, è®©æŸäººéœ‡æƒŠ, ä»¥è‡³äºæ”¹å˜äº† ta çš„æ€ç»´æ–¹å¼æˆ–è€…ä¿ƒä½¿ ta äº§ç”ŸæŸç§è¡ŒåŠ¨(to shock someone in order to change their behaviour or way of thinking)\n\n - The charity used photos of starving children in an attempt to jolt the public conscience (= make people feel guilty and take action). æ…ˆå–„æœºæ„ç”¨é¥¥é¥¿å„¿ç«¥çš„ç…§ç‰‡æ¥è§¦åŠ¨å…¬ä¼—çš„è‰¯çŸ¥ã€‚\n **jolt sb into/out of sth**\n- The news about Sam's illness jolted her into action.\n\n#### projectâ˜¢\nProject ä½œä¸ºåŠ¨è¯é™¤äº†\"æŠ•å½±\"è¿˜æœ‰:\n1. \"è®¡åˆ’, æœŸæœ›\"çš„æ„æ€:\n- This sector is projected to double in size over the next 12 months.\n- a projected deficit of $1.5 million\n\n2. å’Œä¸­æ–‡é‡Œé¢ä¸€æ ·, Project \"æŠ•å°„\"çš„å«ä¹‰è¿˜èƒ½å¼•ç”³åˆ°ç²¾ç¥å±‚é¢ =\u003e å°†(æƒ…æ„Ÿ, è§‚ç‚¹, æ„Ÿè§‰)æŠ•å½±, æŠ•å°„åˆ°å…¶ä»–äººèº«ä¸Š\n- I suspect he's projecting his fear onto you.\n\n3. å’Œä¸­æ–‡é‡Œé¢ä¸å¤ªä¸€æ ·çš„æ˜¯: è‹±è¯­é‡Œé¢ Project è¿™ä¸ª\"æŠ•å°„\"çš„æ„æ€è¿˜èƒ½å¼•ç”³ä¸º\"**å±•ç°**(æŸç§å“è´¨)\"çš„æ„æ€(If you project sb/sth in a particular way, you try to make people see them in that way. if you project a particular feeling or quality, you show it in your behaviour.)\n- Recently the president has sought to project a much tougher image.\n- Bradly projected a natural warmth and sincerity.\n\n\n4. æœ€å, Project ä½œä¸ºåŠ¨è¯, è¿˜æœ‰\"ä¼¸å‡º, çªå‡º(æŸä¸ªè¾¹ç¼˜, æŸä¸ªå¹³é¢)\"çš„æ„æ€, è¿™å¯èƒ½å’Œ\"æŠ•å½±\"çš„æ—¶å€™å…‰çº¿\"ä¼¸å‡º\"çš„è·¯å¾„æœ‰ç‚¹åƒ\n- ...the remains of a war-time defence which projected out from the shore.\n\n\n#### Compunction\nguilt, misgiving, remorse, scruples\n- have no **compunction** about doing sth\n\n- com- =\u003e ä¸€èµ·, è¡¨å¼ºè°ƒ\n- punct- =\u003e ç‚¹, å°– =\u003e åˆº, to prick\n- -ion =\u003e åè¯åç¼€\n\t- æµ‘èº«åƒé’ˆåˆºä¸€æ · =\u003e è‰¯å¿ƒçš„ä¸å®‰, å†…ç–š, è‡ªè´£, æ‚”æ¨\n\n#### sedulousâ˜¢â˜¢\n- careful and using a lot of effort/constant or persistent in use or attention\n- å‹¤å¥‹çš„, è°¨æ…è€Œåˆ»è‹¦çš„\n- sedulous =\u003e sedulo + ous \u0026\u0026 sedulo =\u003e sedolo =\u003e se + dolo\n- sedulo =\u003e sincerely, dilegently\n- sedolo =\u003e se- \"without\" + dolo \"deception, guile\"\n\t- å‹¤å¥‹åˆ»è‹¦çš„ =\u003e æ²¡æœ‰ + æ¬ºéª— =\u003e ä¸ä¼šå¯¹è‡ªå·±çš„å·¥ä½œè¯´è°\n\n##### sedentary\nä¹…åçš„\n\n#### rail\n- rail é™¤äº†\"é“è½¨\"çš„æ„æ€, è¿˜æœ‰\"æ‰¶æ‰‹, æŒ‚ä¸œè¥¿çš„æ¨ªæ†\"çš„æ„æ€\n\t- Will spectators please stay behind the rail?\n\t- The clothes rail in her wardrobe was crammed full of dresses.\n\t- The bathroom has a heated towel rail. æŒ‚æ¯›å·¾çš„é‚£ä¸ªæ†å­å°±å« rail\n\t- Hold on to the rail so you don't fall.\n\n- rail è¿˜æœ‰ä¸€ä¸ªè¯æºå®Œå…¨ä¸åŒçš„å«ä¹‰: to complain angrily\n\t- æ¥è‡ªæ³•è¯­\"raillier\" =\u003e to tease or joke\n\t- He railed against/at the injustice of the system.\n\n\n#### admonishâ˜¢â˜¢\n- ad- \n\tæ¥è‡ªæ‹‰ä¸ä»‹è¯ ad, è¡¨ç¤ºâ€œæœã€å‘ã€å»ï¼Œæˆ–å¼±åŒ–ä¸ºå¼ºè°ƒâ€ã€‚\n- mon- \n\t= warn, è¡¨ç¤ºâ€œè­¦å‘Šâ€ã€‚æºè‡ªæ‹‰ä¸è¯­ monere \"to remind, warn.\"\n- -ish \n\tè¡¨åŠ¨è¯ï¼Œâ€œé€ æˆâ€¦â€ã€‚\n\nå¢å¼º+è­¦å‘Š =\u003e too tell sb very seriously that they have done sth wrong.\n- reprimand, rebuke, caution, censure\n\n#### censor/censureâ˜¢\n- censor =\u003e å®¡æŸ¥\n- censure =\u003e è´£å¤‡, è°´è´£\n\n#### untoward\nun + toward =\u003e not having inclination =\u003e å’Œæ„¿æœ›ä¸ä¸€è‡´çš„ =\u003e äº‹ä¸æ„¿è¿çš„, æ„å¤–çš„(unexpected, not convenient, unpleasant)\n\n#### inter\nåŸ‹è‘¬ bury, lay to rest, entomb\n- in- + -ter (terra=\u003eearth) =\u003e (å°†é—ä½“)åŸ‹è¿›åœŸå£¤ä¸­ =\u003e åŸ‹è‘¬\n\n- disinter =\u003e å‘æ˜, æ˜¾éœ²\n- reinter =\u003e æ”¹è‘¬, é‡åŸ‹\n- interment =\u003e åŸ‹è‘¬(noun)\n\n#### salve\n- æ²¹è†, è½¯è†, è¯è†(ointment) =\u003e å¼•ç”³ä¸º\"å®½æ…°, æ…°è—‰\" \n- salve one's conscience =\u003e ä½¿æŸäººçš„è‰¯å¿ƒå¾—åˆ°å®½æ…°, å‡è½»æŸäººçš„å†…ç–šæ„Ÿ\n\t- He salves his conscience by giving money to charity.\n\n- selp- =\u003e fat, butter\n\n\n#### overt\n- overt =\u003e å…¬å¼€çš„, æ˜¾å¼åœ°, æ˜æ˜¾çš„, æ¯«ä¸æ©é¥°çš„\n- covert =\u003e éšè”½çš„, ç§˜å¯†çš„, éšè”½çš„, éšå¼çš„\n\n\n#### tractable\n- tract- =\u003e treat, handle =\u003e å¤„ç†\n- -able =\u003e èƒ½å¤Ÿ... çš„\nèƒ½å¤Ÿå¤„ç†çš„ =\u003e å®¹æ˜“å¤„ç†çš„, å®¹æ˜“æ§åˆ¶çš„, æ˜“é©¯æœçš„\n\nintractable =\u003e æ£˜æ‰‹çš„, éš¾ä»¥æ§åˆ¶çš„\n\n\n#### ripen\nripen æ˜¯åŠ¨è¯, ripe æ˜¯å½¢å®¹è¯\n- When fruits **ripen**, they become **ripe**.\n\n\n#### anachronism\n`ana-`  -\u003e é”™è¯¯çš„\n`chron-` -\u003e time\n`-ism` -\u003e æŠ½è±¡åè¯åç¼€\n- æ—¶ä»£é”™è¯¯ / è¿‡æ—¶çš„äº‹ç‰©\n\n- adj. anachronistic\n\n#### impassiveâ˜¢\n- im- \n\tè¡¨ç¤ºâ€œæ— ï¼Œæ²¡æœ‰ï¼ˆnot,oppositeï¼‰â€ï¼Œæºè‡ªæ‹‰ä¸è¯­ in- \"not.\"\n- pass- \n\t= suffer, è¡¨ç¤ºâ€œå¿å—â€ï¼Œå¼•ç”³ä¸ºâ€œæ„Ÿæƒ…â€ã€‚æºè‡ªæ‹‰ä¸è¯­ pati \"to suffer.\"\n- -ive \n\tè¡¨å½¢å®¹è¯ã€‚æºè‡ªæ‹‰ä¸è¯­ -ivus \"adjective suffix.\"\n\næ²¡æœ‰æ„Ÿæƒ…çš„ =\u003e ç¥æƒ…å†·æ¼ çš„, æœ¨ç„¶çš„ unemotional, unmoved, emotionless\n\n- impassivity\n- passible =\u003e susceptible to emotion or suffering, able to feel, å®¹æ˜“è¢«æ„ŸåŠ¨çš„, æ˜“åŠ¨æƒ…çš„\n- impassible =\u003e not susceptible to pain or injury, unmoved\n\n#### conflateâ˜¢â˜¢\nto combine two or more pieces of text or ideas into a single one.\n\n- `co-, com-, con-` =\u003e with, together\n- `flate` =\u003e blow\nto blow together.\n\n#### herald\n- herald è¡¨ç¤ºæ—§æ—¶çš„ä¼ ä»¤å®˜, åæ¥å¼•ç”³ä¸º\"é¢„å…†, å…ˆå…†\"çš„æ„æ€(forerunner, sign, signal, indication), \n\t- The president's speech heralds a new era in foreign policy.\n\n- ä¹Ÿå¯ä»¥ä½œä¸ºåŠ¨è¯, \"é¢„ç¤ºç€... çš„å¼€å§‹\"(indicate, promise, precede, pave the way)\n\t- Their discovery could herald a cure for some forms of impotence.\n\n#### demagogue\n- dem- \n\t= peopleï¼Œè¡¨ç¤ºâ€œäººæ°‘ï¼Œæ°‘ä¼—â€ã€‚æºè‡ªå¸Œè…Šè¯­ `demos` \"people, land.\"\n- agog- \n\t= lead, è¡¨ç¤ºâ€œå¼•å¯¼â€ã€‚æºè‡ªå¸Œè…Šè¯­ `agein` \"to drive, lead, weigh.\" \n- è¯ä¹‰è´¬ä¹‰åŒ–ï¼Œç”¨æ¥æŒ‡æš´æ°‘çš„é¢†å¯¼è€…ï¼Œè›Šæƒ‘æ°‘å¿ƒçš„æ”¿å®¢ã€‚\n\n`dem-, demo-` =\u003e people\n- democrat =\u003e demoãƒ»crat =\u003e æ°‘ä¸»å…šå…šå‘˜, æ°‘ä¸»ä¸»ä¹‰è€…\n- demos =\u003e demoãƒ»s =\u003e äººæ°‘, æ°‘ä¼—\n- demotic =\u003e demoãƒ»tic =\u003e äººæ°‘çš„, æ°‘ä¼—çš„\n- democracy =\u003e demoãƒ»cracy =\u003e æ°‘ä¸»ä¸»ä¹‰, æ°‘ä¸»æ”¿æ²»\n- demography =\u003e demoãƒ»graphy =\u003e äººå£ç»Ÿè®¡å­¦\n- epidemic =\u003e epiãƒ»demãƒ»ic =\u003e `epi-` \"åœ¨... å‘¨å›´\",   `-ic` å½¢å®¹è¯åç¼€ =\u003e åœ¨äººæ°‘å‘¨å›´çš„, =\u003e ä¼ æŸ“ç—…, ä¼ æŸ“ç—…çš„\n\n#### agogâ˜¢\nexcited and eager to see more.\nè¿™é‡Œçš„ agog å’Œä¸Šé¢çš„ demagogue é‡Œé¢çš„ agog æ˜¯åŒä¸€ä¸ªè¯æ ¹, è¿˜æœ‰ fun çš„æ„æ€. =\u003e å¼•ç”³ä¸º in a state of desire, imagination\n\n- We waited agog for the news.\n\n\n#### flag\n(verb) to put a mark on sth so it can be found easily among other similar things\n- Flag any file that might be useful later.\n\n#### retentive\nretent \"ä¿æŒ\"(retention) + ive =\u003e ä¿æŒçš„ å¼•ç”³ä¸º(mentally) =\u003e è®°å¿†åŠ›å¥½çš„\n- retentive feeling =\u003e æ‰§ç€çš„æ„Ÿæƒ…\n\n\n#### indolentâ˜¢\n- in- \"æ²¡æœ‰\"\n- dol- = dole, æ‚²ä¼¤, grieve\n- -ent ...çš„\n\næ²¡æœ‰æ‚²ä¼¤çš„, æ²¡æœ‰ç—›è‹¦çš„, å¼•ç”³ä¸º\"ä¸ç”¨å¿å—ç—›è‹¦çš„\" =\u003e æ‡’æƒ°çš„, æ‡’æ•£çš„, lazy, slack, slothful, \n\n- indolence =\u003e æ‡’æƒ°\n\n#### commensurate\nç›¸å¯¹åº”çš„, ç›¸ç§°çš„(corresponding in amount, degree or magnitude)\n- a salary that is commensurate with skills and experience.\n- equivalent, consistent, corresponding, comparable\n\ncom- \"ä¸€èµ·\" + mensur=measure \"æµ‹é‡\" +  ate \"...çš„\" =\u003e ä¸€èµ·æµ‹é‡çš„ =\u003e ç›¸ç§°çš„, ç›¸å½“çš„\n\n#### deplete\nuse up, reduce, drain, exhaust\nde- + -plete \n- de- =\u003e ç›¸å\n- plet, plen =\u003e full, fill \n\n#### replenish\nre- + plen + ish\n- re- é‡æ–°\n- plen, =\u003e fill, full\n- ish åŠ¨è¯åç¼€\nto make sth full or complete again\n\n#### fallible\nä¼šçŠ¯é”™çš„, å®¹æ˜“å‡ºé”™çš„\n- `fall-, fail-, fault-` =\u003e err, deceive é”™è¯¯, è°¬è¯¯, æ¬ºéª—\n- `-ible` èƒ½ .. çš„, å½¢å®¹è¯åç¼€\n\n- infallible =\u003e inãƒ»fallãƒ»ible =\u003e ä¸‡æ— ä¸€å¤±çš„\n- fallacy =\u003e fallãƒ»acy =\u003e è°¬è®º, è°¬è¯¯\n\n#### conservative\n- conservative æ˜¯\"ä¿å®ˆçš„\"çš„æ„æ€. åœ¨æ±‰è¯­é‡Œé¢, æœ‰\"ä¿å®ˆä¼°è®¡\"çš„è¯´æ³•, æ„æ€æ˜¯\"è°¨æ…çš„ä¼°è®¡\", æœ‰è¶£çš„æ˜¯è‹±è¯­é‡Œé¢ conservative ä¹Ÿå¯ä»¥è¿™æ ·ç”¨:\n- A conservative estimate of the bill\n\n#### axiomatic\naxiom =\u003e å…¬ç†, åœ¨æ•°å­¦é‡Œé¢, å…¬ç†æ˜¯ä¸éœ€è¦è¯æ˜çš„\naxiomatic =\u003e ä¸è¨€è‡ªæ˜çš„, æ˜¾è€Œæ˜“è§çš„ self-evident, given, understood, obviously true\n\n#### extravagant \n- è¯¥è¯å§‹ç”¨äº 14 ä¸–çºªï¼Œæºè‡ªæ‹‰ä¸è¯­ï¼Œç”±æ‹‰ä¸è¯­çš„ä¸¤ä¸ªè¯ extrÄ 'beyond, outside'ï¼ˆåœ¨å¤–ï¼‰ä¸ vagÄrÄ« 'wander'ï¼ˆæ¸¸è¡ï¼‰å¤åˆè€Œæˆï¼Œåˆèµ·æ¥å°±æ˜¯ wandering outsideï¼Œå³â€œæ¸¸è¡åœ¨å¤–â€çš„æ„æ€ã€‚åœ¨èç¿çš„è‘—åæ‚²å‰§ã€Šå“ˆå§†é›·ç‰¹ã€‹ï¼ˆHamlet, 1602ï¼‰ä¸­ï¼Œä¸¹éº¦ç‹å­å“ˆå§†é›·ç‰¹ç§°ä»–çˆ¶ç‹çš„äº¡é­‚ä¸º'the extravagant and erring spirit', extravagant å’Œ erring ä¸¤è¯æ­£æ˜¯ç”¨äºæ­¤ä¹‰ã€‚å—£åï¼Œextravagant çš„è¯ä¹‰é€æ¸å‘ç”Ÿå˜åŒ–ï¼Œç”±â€œæ¸¸è¡åœ¨å¤–â€ã€â€œç¦»å¼€æ­£é“çš„â€å¼•ç”³ä¸ºâ€œåç¦»åˆç†çš„é™åˆ¶èŒƒå›´â€ã€â€œè¶…è¿‡é™åº¦çš„â€ï¼Œæœ€åæ¼”å˜ä¸ºâ€œæŒ¥éœçš„â€ã€â€œå¥¢ä¾ˆçš„â€ï¼ˆspending much more than necessaryï¼‰è¿™ä¸€å¦‚ä»Šæœ€å¸¸ç”¨çš„è¯ä¹‰ã€‚æ­¤ä¹‰æ˜¯ç›´åˆ° 18 ä¸–çºªåˆæ‰ç¡®ç«‹ä¸‹æ¥çš„ã€‚\n\n- è‹±è¯­å¦æœ‰ä¸‰ä¸ªè¯vagabondï¼ˆæµæµªè€…ï¼‰ï¼Œvagrantï¼ˆæµæµªè€…ï¼‰ï¼Œvagaryï¼ˆæ€ªå¼‚å¤šå˜ï¼‰è·Ÿextravagantä¸€è¯æœ‰äº›äº²ç¼˜å…³ç³»ã€‚å®ƒä»¬éƒ½æºäºå‰é¢æåˆ°çš„æ‹‰ä¸è¯­vagÄrÄ« 'wander'ï¼ˆæ¸¸è¡ï¼‰ã€‚\n\nä¾‹:\n- It was extravagant of you to spend ï¿¥800 on a dress. èŠ± 800 å…ƒå»ä¹°ä¸€ä»¶è¡£æœï¼Œé‚£å¤ªå¥¢ä¾ˆäº†ã€‚\n- You are too extravagant with your father's money. ä½ èŠ±çˆ¶äº²çš„é’±å¤ªå¤§æ‰‹å¤§è„šäº†ã€‚\n- An extravagant person has extravagant tastes and habits. å¥¢ä¾ˆçš„äººæœ‰å¥¢ä¾ˆçš„å—œå¥½å’Œä¹ æƒ¯ã€‚\n- To be perfectly frank, I don't think I deserve such extravagant praise. å¦ç‡åœ°è¯´ï¼Œæˆ‘è®¤ä¸ºå¦‚æ­¤é«˜çš„æº¢ç¾ä¹‹è¯æˆ‘æ˜¯ä¸é…çš„ã€‚\n\n#### restitution\nå½’è¿˜, èµ”å¿, è¡¥å¿ compensate, satisfaction, amends, refund\n- re- é‡æ–°, å†\n- stitu- set up, place, å»ºç«‹, æ”¾\n- tion åè¯åç¼€\n\né‡æ–°å»ºç«‹, ä¿®å¤(æŸåçš„ä¸œè¥¿) =\u003e åé¢å¼•ç”³ä¸ºèµ”å¿, è¡¥å¿, å½’è¿˜è¢«ç›—æˆ–è€…ä¸¢å¤±çš„ä¸œè¥¿\n\n#### badinage\n\"light railery, playful banter,\" 1650s, from French badinage \"playfulness, jesting,\" from badiner (v.) \"to jest, joke,\" from badin \"silly, jesting\" (16c.)\n\n- banter, joking, teasing, mockery\n\n\n#### frosty\nä¸¥å¯’çš„, è¦†æ»¡å†°éœœçš„ =\u003e å¼•ç”³ä¸º(è¡Œä¸º)å†·æ·¡çš„, å†°å†·çš„\n- He gave me a frosty look\n- There was a certain frostiness in his smile.\n\næ¯”è¾ƒ: frigid\n\n#### Planet\nThe word planet derives ultimately from the Greek verb _planan_, â€œ*to wander*.â€ The planets were the heavenly bodies that appeared to wander across the sky, as opposed to the stars, which were (relatively) fixed.\n\n#### Jovial\n'Under the influence of planet Jupiter, pertaining to Jupiter'\n- (of a person) friendly and in good mood, (of a situation) enjoyable because if being friendly and pleasant.\n- cheerful, happy, jolly, animated\n\nJupiter, the largest planet, was named for the king of the Roman gods. _Jove_ is a form of Jupiter. A person born under the planet Jupiter, therefore, was believed to be **jovial**â€”**cheerful and friendly**. This may be perplexing if you think of Jove mostly as a thunder-god, as his Greek equivalent Zeus is often portrayed. But if Mars is ascendant in times of war, Jove is the god who rules when the the work of Mars is done, when peace and prosperity, feasting and gladness prevail.\n\n#### Saturnine\n- Of the seven planets that were visible to the ancients, Saturn was the coldest, the darkest, the most distant, and the slowest moving. Saturn was the oldest of the Roman gods, the father of Jupiter and several other of the major gods. A **_saturnine_** disposition, therefore, is **gloomy, sluggish, given to dark moods**.\n\n#### Mars\n- Mars, the red planet, was named for the Roman god of war. The word **_martial_** means â€œwarlikeâ€ or â€œrelated to the militaryâ€â€”as in martial law.\n\n#### Mercury\n- Mercury, the namesake of the planet, was the messenger god, always zooming around from one place to another, never keeping still. A **_mercurial_** personality is **impulsive, unpredictable, tending to change directions and change again at a momentâ€™s notice**. \n- If youâ€™ve ever seen the element mercury, the way it wiggles and zips around and splits into smaller beads and re-forms into larger beads, you have a good visual image of what mercurial means. (You will also know why the element mercuryâ€™s other name is quicksilver.)\n\n#### The Moon (Luna)\n- The moon was personified by the Roman goddess Luna. The adjective _**lunar_**, of course, refers to anything moon-related. The moon is both the closest and the most changeable of the heavenly bodies. Each nightâ€™s moon looks a little different from the previous nightâ€™s moon. It was believed that bodies beyond the moon were unchanging and unchangeable. But below the moon, everything changes. Thatâ€™s where the word _**sublunary_** comes from. Sublunary thingsâ€”that, is, everything beneath the moonâ€”is earthy, changeable, not perfect and immutable like the superlunary world.\n\n- The highly erratic Luna also made people insane. A _**lunatic_** is a person who has fallen under her influence. The word _**loony_** comes from the same place.\n\n![](notes/2022/2022.7/assets/Pasted%20image%2020220912014540.png)\n\n\n#### flounderâ˜¢â˜¢\n- have many problems and may soon fail completely\n\t- è¿™ä¸ªæ„æ€å’Œ founder çš„åŠ¨è¯æœ‰ç‚¹åƒ\n- sb is floundering =\u003e not making decisions and not knowing what to say or do.\n\t- I know that you're floundering around, trying to grasp at any straw.\n- flounder in mud/water =\u003e move in an uncontrolled way and trying not to sink.\n\n#### friable\nfri- =\u003e æ‘©æ“¦, friction\n-able =\u003e ... çš„\n- æ˜“æ‘©çš„, æ˜“ç¢çš„, crumbly\n\n#### accede (to)â˜¢\n- ac- ad- =\u003e to \n- cede =\u003e go away, withdraw, yield\naccede =\u003e come to or arrive at (a state, position, office etc.)\n=\u003e to agree to do what people have asked you to do. \n\t(to withdraw, yield and do what was asked åŒæ„, åº”å…)\n=\u003e to become king or queen, or to take a position or power. \n\t(to accept the position ç™»åŸº, å³ä½)\n\n- He graciously **acceded to** our request. \n\tä»–é€šæƒ…è¾¾ç†åœ°åŒæ„äº†æˆ‘ä»¬çš„è¯·æ±‚ã€‚\n- It is doubtful whether the government will ever **accede to** the nationalists' demands for independence. \n\tæ”¿åºœä¸å¤ªå¯èƒ½ä¼šåŒæ„æ°‘æ—ä¸»ä¹‰è€…çš„ç‹¬ç«‹è¦æ±‚ã€‚ \n\nå’Œconcedeç›¸æ¯”, è¿™ä¸ªæ²¡æœ‰\"ä¸æƒ…æ„¿\"çš„æ„æ€\n\n#### concedeâ˜¢\n- con- =\u003e with, together, åœ¨è¿™é‡Œè¡¨ç¤ºå¼ºè°ƒ\n- cede =\u003e go away, withdraw, yield\n\ngive away, yield, go away =\u003e å¼•ç”³ä¸º agree, consent(unwillingly)\n- Bess finally conceded that Nancy was right\n\nè¿˜å¯ä»¥ concede ç‰©å“ =\u003e give sb sth\n- The strike ended after the government concede some of their commands\n\nå¯ä»¥ concede æŸç§ rights or privileges\n- The French subsequently conceded full independence to Laos\n\nconcede è‡ªå·±çš„å¤±è´¥(defeat):\n- He happily concede the election =\u003e ä»–å¼€å¿ƒåœ°æ‰¿è®¤è‡ªå·±åœ¨é€‰ä¸¾ä¸­**å¤±è´¥**äº†\n- The company conceded defeat in its attempt to take control of its holiday industry rival.\n\n#### secede\n- se- =\u003e apart\n- cede =\u003e go away, withdraw, yield\nè„±ç¦», é€€å‡º(å›½å®¶æˆ–è€…æ”¿åºœ)\n- There is likely to be civil war if the region tries to secede from the south. \n\tå¦‚æœè¿™ä¸€åœ°åŒºæƒ³è„±ç¦»å—æ–¹è€Œç‹¬ç«‹ï¼Œå¾ˆå¯èƒ½ä¼šçˆ†å‘å†…æˆ˜ã€‚ \n\n#### intercedeâ˜¢\n- inter- =\u003e between, åœ¨ ... ä¹‹é—´\n- cede =\u003e go away, withdraw, yield\n\nto use your influence to persuade someone in authority to forgive another person, or save this person from punishment\nï¼ˆä¸ºæŸäººï¼‰æ±‚æƒ…ï¼Œè¯´æƒ…\n\n- Several religious leaders have interceded with the authorities on behalf of the condemned prisoner. \n\tä¸€äº›å®—æ•™é¢†è¢–æ›¿è¿™ä¸ªè¢«åˆ¤åˆ‘çš„çŠ¯äººå‘å½“å±€æ±‚æƒ…ã€‚\n\n#### connotationâ˜¢\ncon- =\u003e with, together ä¸€èµ·\nnotation =\u003e å«ä¹‰, mark, note\n=\u003e to mark along with =\u003e å†…æ¶µæ„ä¹‰, éšå«æ„ä¹‰, a feeling or idea that is suggested by a particular word although it need not to be a part of the word's meaning, or something suggested by an object or situation.\n\n- The word 'lady' has connotation of refinement and excessive femininity which some women find offensive.\n\n\n#### dilettante\nä¸€çŸ¥åŠè§£çš„ä¸šä½™çˆ±å¥½è€…\n- æ¥è‡ªæ„å¤§åˆ©è¯­deletto, æ„‰å¿«ï¼Œé«˜å…´ï¼Œè¯æºåŒdelight, delicious. åŸæŒ‡çˆ±å¥½è€…ï¼Œåè¯ä¹‰è´¬ä¹‰åŒ–ã€‚\n\n\n#### frail\nfrail \u003c=\u003e fragile \n- Frail is the Frenchified version of fragile.\n\n\n#### antediluvian\n- delugeï¼ˆæ´ªæ°´ï¼‰ï¼šåœ£ç»æ•…äº‹ä¸­ä¸Šå¸æ¯ç­äººç±»çš„å¤§æ´ªæ°´\n\t\n\tè‹±è¯­å•è¯ deluge åœ¨è¯å…¸ä¸­çš„è§£é‡Šæ˜¯â€œå¤§æ´ªæ°´ã€æš´é›¨â€ï¼Œäººä»¬å¾€å¾€ä¸çŸ¥é“å®ƒå’Œ floodï¼ˆæ´ªæ°´ï¼‰ä¹‹é—´çš„åŒºåˆ«ã€‚å…¶å®ï¼Œè¿™ä¸ªè¯æœ‰è‡ªå·±ç‹¬ç‰¹çš„èƒŒæ™¯ï¼Œå®ƒæ¥è‡ªåœ£ç»ï¼ŒæŒ‡çš„æ˜¯ä¸Šå¸æ¯ç­äººç±»ä¸–ç•Œçš„é‚£æ¬¡å¤§æ´ªæ°´ã€‚\n\t\n\tåœ¨ã€Šåœ£ç»â€¢åˆ›ä¸–çºªã€‹ä¸­è®°è½½ï¼Œä¸Šå¸é€ äººåï¼Œçœ‹åˆ°äººåœ¨ä¸–é—´èƒ¡ä½œéä¸ºï¼ŒçŠ¯ä¸‹å„ç§ç½ªæ¶ï¼Œä¾¿åæ‚”é€ äººäº†ï¼Œæƒ³æ¯ç­äººç±»ä¸–ç•Œï¼Œäºæ˜¯å‘ä¸‹å¤§æ´ªæ°´æ·¹æ²¡äº†æ•´ä¸ªä¸–ç•Œï¼Œäººç±»é­åˆ°æ¯ç­ï¼Œåªæœ‰æ•¬ç¥çš„è¯ºäºšä¸€å®¶å› ä¸ºäº‹å…ˆæŒ‰ç…§ä¸Šå¸çš„æ—¨æ„ä¿®å»ºäº†è¯ºäºšæ–¹èˆŸæ‰èº²è¿‡æ­¤éš¾ã€‚\n\t\n\tå•è¯ deluge åŸæœ¬ä¸“æŒ‡è¿™åœºå¤§æ´ªæ°´ï¼Œä½†äººä»¬é€šå¸¸ç”¨å®ƒæ¥æ¯”å–»å„ç§æ´ªæ°´ä¸€èˆ¬çš„äº‹ç‰©ã€‚åœ¨è¡¨ç¤ºå®é™…çš„æ´ªæ°´è¿™ä¸€è‡ªç„¶ç¾å®³æ—¶ï¼Œäººä»¬å¾€å¾€è¿˜æ˜¯ä½¿ç”¨ flood ä¸€è¯ã€‚\n\n- è‹±å›½ç‰©ç†å­¦å®¶æ‰˜é©¬æ–¯â€¢å¸ƒæœ—ï¼ˆThomas Browneï¼‰åœ¨ 17 ä¸–çºªåˆ›é€ äº† antediluvian ä¸€è¯ï¼Œå­—é¢æ„æ€ä¸ºâ€œå¤§æ´ªæ°´ä¹‹å‰çš„â€ï¼Œæ¯”å–»è¿œå¤çš„ã€‚\n\n- delugeï¼š['deljuËdÊ’] n. æ´ªæ°´ï¼Œæš´é›¨ï¼Œä¸Šå¸æ¯ç­äººç±»çš„å¤§æ´ªæ°´ vt. ä½¿æ³›æ»¥ï¼Œå‹å€’\n- antediluvianï¼š[,Ã¦ntÉªdÉª'luËvÉªÉ™n] adj. å¤§æ´ªæ°´å‰çš„ï¼›è¿œå¤çš„ï¼›é™ˆæ—§çš„ï¼›æ—§å¼çš„n. å¤§æ´ªæ°´ä»¥å‰çš„äººï¼›å¹´è¿ˆçš„äººï¼›ä¸åˆæ—¶å®œçš„äºº\n\n\n#### misanthrope\nmis- miso- =\u003e to hate\nanthrop anthropos =\u003e man human being\n- one who hates mankind, åŒæ¶äººç±»çš„äºº, åŒmisanthropist\n- cynic, sceptic, grouch, \n\n- misanthropic\n- misanthropize\n\n#### husky\nattractive rough and low voice\n- å¯ä»¥ç”¨æ¥å½¢å®¹ç”·æ€§å’Œå¥³æ€§\na tall, strong and attractive man\n- ç‰¹æŒ‡ç”·æ€§\n\n- å“ˆå£«å¥‡, çˆ±æ–¯åŸºæ‘©çŠ¬, åŒ—æçŠ¬\n\n#### carnal\ncarnal feelings and desires are sexual and physical, without any spiritual element.\n\n- carn- =\u003e flesh , , è¡¨ç¤ºâ€œè‚‰ï¼Œè‚‰æ¬²â€ï¼ŒåŸå§‹å«ä¹‰â€œåˆ‡ã€ç â€ä¸‹æ¥çš„ä¸€å—è‚‰ã€‚æºè‡ªæ‹‰ä¸è¯­ caro (è¯å¹² carn-) \"flesh.\"\n- -al  è¡¨å½¢å®¹è¯ï¼Œâ€œâ€¦çš„â€ï¼Œä¸€èˆ¬ç¼€äºåè¯åã€‚æºè‡ªæ‹‰ä¸è¯­ -alis\n\ncarnivalï¼ˆç‹‚æ¬¢èŠ‚ï¼‰ï¼šå¤§æ–‹æœŸå¼€å§‹å‰çš„â€œè°¢è‚‰èŠ‚â€\n- â€œç‹‚æ¬¢èŠ‚â€åœ¨è‹±è¯­ä¸­ä¸º carnivalï¼Œæ¥è‡ªæ‹‰ä¸æ–‡ carne valeï¼Œç­‰äºè‹±è¯­ä¸­çš„â€œflesh, farewell!â€ï¼ˆè‚‰ï¼Œå†è§ï¼ï¼‰ï¼Œæ‰€ä»¥ä¾å…¶æœ¬æ„åº”è¯‘ä¸ºâ€œè°¢è‚‰èŠ‚â€ã€‚æ ¹æ®åŸºç£æ•™çš„æ•™ä¹‰ï¼ŒåŸºç£å¤æ´»èŠ‚å‰ 40 å¤©æ˜¯ä¸€ä¸ªä¸ºæœŸ 40 å¤©çš„å¤§æ–‹æœŸï¼Œå³å››æ—¬æ–‹ï¼ˆlentï¼‰ã€‚æ–‹æœŸé‡Œï¼Œäººä»¬ç¦æ­¢å¨±ä¹ï¼Œç¦é£Ÿè‚‰é£Ÿï¼Œåçœã€å¿æ‚”ä»¥çºªå¿µå¤æ´»èŠ‚å‰ 3 å¤©é­éš¾çš„è€¶ç¨£ï¼Œç”Ÿæ´»è‚ƒç©†æ²‰é—·ã€‚å› æ­¤ï¼Œåœ¨å››æ—¬æ–‹å¼€å§‹å‰ä¸‰å¤©ï¼Œäººä»¬ä¾¿æŠ“ç´§æ—¶é—´å¼€å§‹çºµæƒ…åƒå–ç©ä¹ã€‚ä¸€äº›ä¸»å¼ å®—æ•™æ”¹é©çš„äººå¦‚æ–°æ•™å¾’ä¾¿å€Ÿæ­¤ä¸¾åŠå„ç§ç‹‚æ¬¢æ´»åŠ¨ï¼ŒæŒ‘æˆ˜å¤©ä¸»æ•™çš„æƒå¨ã€‚è·å…°ç”»å®¶ Pieter Bruegel çš„åç”»ã€Šç‹‚æ¬¢è€…ä¸æ–‹æˆ’è€…çš„æ–—äº‰ã€‹ï¼ˆFight Between Carnival and Lentï¼‰ä¾¿åæ˜ äº†ä¸¤æ•™æ´¾ä¹‹é—´çš„æ–—äº‰ã€‚\n- å› ä¸ºå†è¿‡ä¸‰å¤©å°±è¦è·Ÿè‚‰é£Ÿè¯´æ‹œæ‹œäº†ï¼Œè¿™ä¸‰å¤©æ•…æ­¤å¾—å carnivalï¼ˆè°¢è‚‰èŠ‚ï¼‰ã€‚ä¹…è€Œä¹…ä¹‹ï¼Œçºµæƒ…ç‹‚æ¬¢çš„ carnival å€’æˆäº†ä¸€ä¸ªç››å¤§èŠ‚æ—¥ï¼Œè€Œå››æ—¬æ–‹å´é€æ¸è¢«äººé—å¿˜ã€‚\n- carnivalçš„å‰åŠéƒ¨åˆ†æ˜¯è¯æ ¹carn-ï¼Œè¡¨ç¤ºâ€œè‚‰â€ã€‚è¯¥è¯æ ¹è¡ç”Ÿä¼—å¤šä¸â€œè‚‰â€æœ‰å…³çš„å•è¯ã€‚\ncarn-ï¼šè‚‰\ncarnalï¼š['kÉ‘Ën(É™)l] adj.è‚‰ä½“çš„ï¼Œæ€§æ¬²çš„\ncarnivalï¼š['kÉ‘ËnÉªv(É™)l] n.ç‹‚æ¬¢èŠ‚ï¼Œå˜‰å¹´åï¼Œé¥®å®´ç‹‚æ¬¢\ncarnivoreï¼š ['kÉ‘ËnÉªvÉ”Ë] n. é£Ÿè‚‰åŠ¨ç‰©ï¼Œé£Ÿè™«æ¤ç‰©\ncarnage: å¤§å± æ€, å¤§é‡ç­ç»\ncarnivorousï¼š[kÉ‘Ë'nÉªv(É™)rÉ™s] adj.é£Ÿè‚‰çš„ï¼Œè‚‰é£Ÿæ€§çš„\ncarcassï¼š ['kÉ‘rkÉ™s] n.ï¼ˆäººæˆ–åŠ¨ç‰©çš„ï¼‰å°¸ä½“ï¼Œæ®‹éª¸ï¼›ï¼ˆé™¤è„å»å¤´å¤‡é£Ÿç”¨çš„ï¼‰ç•œä½“\nreincarnateï¼š [,riËÉªn'kÉ‘ËneÉªt] vt.ä½¿è½¬ä¸–åŒ–èº«adj.è½¬ä¸–åŒ–èº«çš„ã€‚è®°ï¼šreå†æ¬¡+inè¿›å…¥+carnè‚‰ä½“+ateåŠ¨è¯åç¼€\n\n\n\n#### alacrity\nalacr- =\u003e swift\n-ity =\u003e åè¯åç¼€, è¡¨ç¤ºæŸç§ç‰¹è´¨\n\nliveliness, briskness, speed =\u003e å¼•ç”³ä¸º eagerness, ä¸ä»…åœ¨åŠ¨ä½œä¸Šè¿…é€Ÿ, åœ¨å¿ƒç†ä¸Šä¹Ÿå¾ˆæ„¿æ„, æ‰€ä»¥\"æ¬£ç„¶æ¥å—\"\n\n- alacrious adj.\n\n\n#### motileâ˜¢\nmotility n. =\u003e motile adj.\nç‰¹æŒ‡ plants, organisms and very small forms of life, å³è¿™äº›å¹³æ—¶çœ‹èµ·æ¥ä¸ä¼šåŠ¨çš„ä¸œè¥¿, =\u003e capable of moving by themselves.\n\n- mot- mob- mov- =\u003e move, æºè‡ªæ‹‰ä¸è¯­ movere \"move\", å…¶è¿‡å»åˆ†è¯ä¸º motus, å½¢å®¹è¯åˆ†è¯å½¢å¼ mobilis ã€‚\n- -ity è¡¨åè¯ï¼ŒæŒ‡å…·å¤‡æŸç§æ€§è´¨ã€‚\n\n\n#### conducive\nconduc(e) + ive\n\nproviding the right conditions for something good to happen or exist. æœ‰åˆ©çš„ï¼Œæœ‰åŠ©çš„ï¼Œæœ‰ç›Šçš„\n\n- Such a noisy environment was not ***conducive** to* a good night's sleep. åœ¨è¿™æ ·å˜ˆæ‚çš„ç¯å¢ƒä¸‹æ™šä¸Šéš¾ä»¥ç¡ä¸ªå¥½è§‰ã€‚\n- A quiet room is a more ***conducive*** atmosphere for studying. ç½®èº«ä¸€ä¸ªå®‰é™çš„æˆ¿é—´æ›´æœ‰åˆ©äºå­¦ä¹ ã€‚\n\n##### conduce\n- to help make a particular situation happen or help produce a particular result\n\tæœ‰åŠ©äºï¼Œå¯¼è‡´\n- the belief that technological progress conduces to human happiness ç°ä»£ç§‘æŠ€è¿›æ­¥å¯ä»¥ä¸ºäººç±»å¸¦æ¥å¹¸ç¦çš„æƒ³æ³•\n\n\"to lead, conduct\" (a sense now obsolete), from Latin conducere \"to lead or bring together, contribute, serve,\" from assimilated form of **com \"with, together\" (see con-)** + **ducere \"to lead\" (from PIE root *deuk- \"to lead\")**. Intransitive sense of \"aid in or contribute toward a result\" is from 1580s.\n\n#### vex\nannoy, bother, irritate, worry\n\nfrom Latin vexare 'to shake, jolt, toss violently' \n=figuratively=\u003e attack, harass, bother, trouble, annoy\n\n#### vitriolic\nfull of bitterness and hate, and so causes a lot of distress and pain.\nvitriol + ic ç›´æ¥ç†è§£å°±æ˜¯: åƒvitriolä¸€æ ·çš„, é‚£ä¹ˆvitriolæ˜¯ä»€ä¹ˆå‘¢?\n\nvitriol =\u003e n. ç¡«é…¸ç›, æ˜çŸ¾, vt. ç”¨ç¡«é…¸å¤„ç† =\u003e å¼•ç”³ä¸ºåƒç¡«é…¸ä¸€æ ·å°–é…¸åˆ»è–„çš„è¯\n- If you refer to what someone says or writes as vitriol, you disapprove of it because it is full of bitterness and hate, and so causes a lot of distress and pain. [disapproval]\n- The vitriol he hurled at members of the press knew no bounds. \n\nvitri- è¿™ä¸ªè¯æ ¹çš„å«ä¹‰æ˜¯ç»ç’ƒ æºè‡ªæ‹‰ä¸è¯­ vitrum, å¯æ˜¯ç¡«é…¸ç›å’Œç»ç’ƒæœ‰ä»€ä¹ˆå…³ç³»å‘¢? \n\næ˜çŸ¾æ˜¯åäºŒæ°´åˆç¡«é…¸é“é’¾, å®ƒçš„æ™¶ä½“æ˜¯è¿™ä¸ªæ ·å­çš„:\n![300](notes/2022/2022.7/assets/800px-Potassium_alum_octahedral_crystal.jpg)\nå’Œç»ç’ƒååˆ†ç›¸åƒ, å¹¶ä¸”æœ‰çš„ç¡«é…¸ç›åŠ çƒ­åä¼šåˆ†è§£ç”Ÿæˆç¡«é…¸, æ‰€ä»¥æœ‰äº†å’Œç¡«é…¸ç›¸å…³çš„å«ä¹‰.\n\n- vitreous =\u003e adj. ç»ç’ƒçš„, ç»ç’ƒçŠ¶çš„, ç»ç’ƒä¼¼çš„\n\t- vitreous china/enamel\n- vitrify =\u003e ç»ç’ƒåŒ–, ä½¿...æˆç»ç’ƒ\n\n\n#### lopsided\nlop + sided =\u003e lop : ç å», ç æ–­ =\u003e æœ‰ä¸€è¾¹è¢«ç å»äº†çš„ =\u003e ä¸å¹³è¡¡çš„, å‘ä¸€è¾¹å€¾æ–œçš„\ncrooked, one-sided, tilting, warped\n\n\n#### waddle\nto walk with short steps, swaying from side to side; to walk as a duck does.\næ˜¯ wade\"æ¶‰æ°´è€Œè¡Œ, è‰°éš¾åœ°è¡Œèµ°\"çš„åå¤åŠ¨è¯ =\u003e åƒé¸­å­é‚£æ ·èµ°å°±åƒæ˜¯åœ¨ä¸åœåœ°åœ¨æ°´é‡Œè¡Œèµ°ä¸€æ ·, æ‘‡æ‘‡æ‘†æ‘†åœ°.\n\n#### Waddle vs Wobble - What's the difference?\n- As **nouns** the difference between waddle and wobble is that waddle is a **swaying gait** while wobble is an **unsteady motion**.\n- As **verbs** the difference between waddle and wobble is that waddle is to **walk with short steps**, tilting the body from side to side while wobble is to **move with an uneven or rocking motion**, or unsteadily to and fro. \n\n#### inane\n*extremely* silly or with no real meaning or importance\n- He is always making inane remarks\n\nempty, void =\u003e è„‘è¢‹ç©ºç©º, ä¹Ÿå°±æ˜¯æ„šè ¢è‡³æ, æ²¡æœ‰æ„ä¹‰, æ— èŠ\n\n- inanity =\u003e n.\n\n#### convenienceâ˜¢\na public convenience =\u003e a public toilet\n\n\n#### cowardice\ncoward æ˜¯æ‡¦å¼±çš„äºº cowardice æ˜¯ cowardly behaviour\n\n\n#### quixotic\n- æ¥è‡ªè¥¿ç­ç‰™ä½œå®¶å¡ä¸‡ææ–¯çš„å°è¯´ Don Quixote--å ‚å‰è¯ƒ(hÄ“)å¾·. ä¹¦ä¸­ä¸»äººå…¬å ‚å‰è¯ƒå¾·ï¼Œä¼å›¾ç”¨ç†æƒ³åŒ–çš„éª‘å£«ç²¾ç¥æ”¹é€ ç¤¾ä¼šã€‚ä»–ç—›æ¨ä¸“åˆ¶æ®‹æš´ï¼Œä¸»æŒæ­£ä¹‰ï¼Œä½†è€½äºå¹»æƒ³ï¼Œè„±ç¦»å®é™…ï¼Œç»“æœåœ¨ç°å®é¢å‰åˆ°å¤„ç¢°å£ã€‚åæˆä¸ºå–„è‰¯ã€å‹‡æ•¢ä½†åˆç›²åŠ¨çš„äººç‰©çš„å…¸å‹ã€‚\n- æ‰€ä»¥ quixotic å°±æ˜¯ Quixote çš„å½¢å®¹è¯, \"åƒå ‚å‰è¯ƒå¾·ä¸€æ ·çš„\", ä¹Ÿå°±æ˜¯ç†æƒ³ä¸»ä¹‰çš„, ä¸åˆ‡å®é™…çš„, å¼‚æƒ³å¤©å¼€çš„, absurdly romantic, unrealistic, idealistic, absurd.\n\n\n#### naivety\nnaive çš„åè¯, gullibility, innocence, simplicity, inexperience\n\n\n#### peevishâ˜¢\nbad-tempered, irritable, cross, crabbed, childish\n=\u003e ä»è¿™ä¸ªå•è¯è¡ç”Ÿå‡ºäº†å•è¯\"peeve\" =\u003e ä»¤äººä¸å¿«çš„å°äº‹, æƒ¹æ¼(æŸäºº)\n\n##### pet peeve\n- The term _**pet peeve_** was introduced to a wide readership in the single-panel comic strip _The Little Pet Peeve_ in the [Chicago Tribune](https://en.wikipedia.org/wiki/Chicago_Tribune \"Chicago Tribune\") during the period 1916â€“1920.\n\n\n#### prescription\nåŒ»ç”Ÿå¼€çš„å¤„æ–¹ =\u003e å› ä¸ºåƒäº†å¤„æ–¹ä¸Šé¢çš„è¯ä¸€èˆ¬éƒ½ä¼šä½¿ç—…æƒ…å¥½è½¬, æ‰€ä»¥å¼•ç”³ä¸º\"è§£å†³é—®é¢˜çš„æ–¹æ³•, è¯€çª, è§£å†³æ–¹æ¡ˆ\" (e.g. a prescription for success)\n\n#### cower\né€€ç¼©, ç•ç¼©, bend your body or move backwards because of fear\ncringe, shrink, crouch\n\n#### desecrateâ˜¢\nde- =\u003e \"ç›¸å\"\nsecr = sacr =\u003e holy, ç¥åœ£çš„, sacred\n-ate =\u003e åŠ¨è¯åç¼€, åš, é€ æˆ...\n- ä½¿å…¶ä¸ç¥åœ£ç›¸å, ä½¿å…¶ä¸å†ç¥åœ£ =\u003e äºµæ¸ç¥çµ, æ±¡è¾±, ç·æ±¡, äºµæ¸, profane, dishonour, defile, violate\n\n- The mosque was desecrated by vandals.\n\ndesecration \u003c=\u003e sacrilege, debasement, blasphemy\n\n\n#### besmirchâ˜¢\n- be- \næ„æˆåŠ¨è¯ï¼Œè¡¨ç¤ºâ€œä½¿â€¦æˆä¸ºâ€ï¼Œæ¥æºäºç›æ ¼é²æ’’å…‹é€Šè¯­ã€‚\n- smirch \nvt. æ²¾æ±¡, å¼„è„ n. è„æ±¡, æ±¡ç‚¹\n=\u003e å¼•ç”³ä¸º ç·æ±¡, æŸåæŸäººçš„åèª‰\ntarnish, damage, stain\n\n\n#### meteoric\nmeteor + ic =\u003e åƒæµæ˜Ÿä¸€æ ·çš„, å’Œæµæ˜Ÿç›¸å…³çš„\nä½†æ˜¯, è™½ç„¶æµæ˜Ÿæ˜¯ä¸€é—ªè€Œè¿‡çš„, å‘ä¸‹å è½çš„, è¿™ä¸ªå•è¯**å¹¶ä¸æ˜¯**æ˜™èŠ±ä¸€ç°çš„æ„æ€.\n\nè¿™ä¸ªå•è¯ä¾§é‡äºæµæ˜Ÿ\"è¿…é€Ÿ, å¼•äººæ³¨ç›®\"çš„ç‰¹ç‚¹, ç”¨æ¥å½¢å®¹æŸä¸ªäº‹ç‰©å‘å±•ååˆ†è¿…çŒ›, å¹¶ä¸”å¸å¼•äº†å¾ˆå¤šæ³¨æ„åŠ›(\"çœ‹, æµæ˜Ÿ!\"ğŸŒ ğŸŒ ğŸŒ , å‡ºç°æµæ˜Ÿçš„æ—¶å€™å¤§å®¶çš„æ³¨æ„åŠ›éƒ½ä¼šé©¬ä¸Šè¢«å¸å¼•è¿‡å»)\n\n - The group had a meteoric rise to fame in the 70s. \n\t è¿™æ”¯ä¹é˜Ÿåœ¨ 20 ä¸–çºª 70 å¹´ä»£è¿…é€Ÿæˆåã€‚\n- Her political career has been meteoric. å¥¹çš„æ”¿æ²»ç”Ÿæ¶¯å¯è°“**æ‰¶æ‘‡ç›´ä¸Š**ã€‚ \n\n#### frigid\nfrig- friger- =\u003e = cold, è¡¨ç¤ºâ€œå†·â€ã€‚æºè‡ªæ‹‰ä¸è¯­ frigere \"to be code,\" frigidus \"cold.\" ä¾‹å¦‚ refrigerator, fridge(ç”µå†°ç®±)\n- ä¸¥å¯’çš„ï¼Œå¯’å†·çš„ï¼Œfreezing, cold, icy\n- å¼•ç”³åˆ°æƒ…æ„Ÿä¸Šé¢ =\u003e (of one's behaviour) very formal and unfriendly \n- å¼•ç”³åˆ°æ€§ä¸Šé¢ =\u003e æ€§å†·æ·¡çš„\n\n\n#### be on good, friendly, etc. terms (with sb)\nto have a good, friendly, etc. relationship with someone\nï¼ˆä¸æŸäººï¼‰å…³ç³»å¥½ï¼Œå…³ç³»å‹å¥½ï¼ˆç­‰ç­‰ï¼‰\n- My ex-wife and I are still on friendly terms. æˆ‘è·Ÿå‰å¦»ä»ç„¶å…³ç³»å‹å¥½ã€‚\n- Are you on good terms with your boss? ä½ è·Ÿè€æ¿å…³ç³»å¥½å—ï¼Ÿ\n\n\n#### mesmerize\nmesmerize - è¯¥è¯æºå‡ºå¥¥åœ°åˆ©åŒ»å¸ˆã€å½“ä»£å‚¬çœ æœ¯çš„å…ˆé©±Mesmer (Franz Anton Mesmer, 1734-1815)ã€‚ä»–è®¤å®šäººä½“å†…æœ‰ä¸€ç§æ½œåœ¨çš„â€œåŠ¨ç‰©ç£åŠ›â€ï¼ˆanimal magnetismï¼‰ï¼Œå¹¶ç”¨å®ƒæ¥æ²»ç—…ã€‚ç„¶è€Œï¼Œç»´ä¹Ÿçº³çš„åŒ»ç”ŸæŒ‡æ§ä»–ç©å¼„é­”æœ¯ã€‚1778å¹´ä»–è¢«è¿«ç¦»å¼€å¥¥åœ°åˆ©å»å·´é»å®šå±…ï¼Œåœ¨é‚£é‡Œç»§ç»­è¡ŒåŒ»ï¼Œå¹¶å†æ¬¡é­åˆ°åŒ»å­¦ç•Œçš„åå¯¹ã€‚1784å¹´è·¯æ˜“åå…­ä»»å‘½ä¸€ä¸ªç”±ç§‘å­¦å®¶å’ŒåŒ»ç”Ÿç»„æˆï¼Œå…¶ä¸­åŒ…æ‹¬B. å¯Œå…°å…‹æ—å’ŒA. æ‹‰ç“¦é”¡åœ¨å†…çš„ä¸“é—¨å§”å‘˜ä¼šå»è°ƒæŸ¥Mesmerçš„æ–¹æ³•ã€‚å§”å‘˜ä¼šçš„æŠ¥å‘Šå¯¹ä»–æŒå¦å®šæ€åº¦ï¼ŒæŠŠä»–ç§°ä¸ºéª—å­ï¼Œä½†æ‰¿è®¤ä»–çš„æ–¹æ³•æœ‰ç–—æ•ˆï¼Œå°†ä»–çš„â€œæ²»æ„ˆä¾‹â€å½’å› äºæ‚£è€…è‡ªå·±çš„æƒ³åƒã€‚ç»“æœï¼ŒMesmeråˆè¢«è¿«ç¦»å¼€å·´é»ï¼Œåœ¨ç‘å£«åº¦è¿‡äº†ä»–çš„ä½™ç”Ÿã€‚å…¶å®ï¼ŒMesmeræ‰€ç”¨çš„æ–¹æ³•å°±æ˜¯åäººæ‰€è°“çš„å‚¬çœ ï¼ˆæœ¯ï¼‰ã€‚åœ¨hypnotismå’Œhypnotizeå‡ºç°ä¹‹å‰ï¼Œäººä»¬æ®ä»–çš„å§“æ°åˆ›é€ äº†mesmerismåŠå…¶ç›¸åº”åŠ¨è¯å½¢å¼mesmerizeæ¥åˆ†åˆ«è¡¨ç¤ºâ€œå‚¬çœ ï¼ˆæœ¯ï¼‰â€å’Œâ€œå¯¹â€¦â€¦æ–½å‚¬çœ æœ¯â€ã€‚åœ¨å½“ä»£è‹±è¯­ä¸­åä¸¤è€…é™¤äº†ä½œä¸ºå‰ä¸¤è€…çš„åŒä¹‰è¯­ä½¿ç”¨ä¹‹å¤–ï¼Œæ›´å¸¸ç”¨äºå¼•ç”³ä¹‰ï¼Œåˆ†åˆ«è¡¨ç¤ºâ€œå·¨å¤§çš„é­…åŠ›â€å’Œâ€œä½¿å…¥è¿·â€æˆ–â€œæƒŠå¾—ç›®çªå£å‘†â€ã€‚\n\n- Hypnotizeæ˜¯Mesmerçš„ç¾å›½è¿½éšè€…coinå‡ºæ¥çš„ä¸€ä¸ªè¯, ä¸Mermerizeè¯ä¹‰åŸºæœ¬ç›¸åŒ\n\nä¾‹ \n- The magician mesmerized a volunteer from the audience. (NED) é­”æœ¯å¸ˆå¯¹è§‚ä¼—é‡Œçš„ä¸€ä½å¿—æ„¿è€…æ–½ä»¥å‚¬çœ æœ¯ã€‚\n- He was mesmerized by her charm and beauty. (LDC) ä»–è¢«å¥¹çš„é­…åŠ›å’Œç¾è²Œè¿·ä½ã€‚\n- She stood there mesmerized as he picked up the gun and turned it slowly towards her. (LLA) å½“ä»–æ‹¿èµ·æªï¼Œæ…¢æ…¢æŠŠæªå¯¹ç€å¥¹ï¼Œå¥¹ç«™åœ¨é‚£é‡ŒæƒŠå‘†äº†ã€‚\n\n- è¿™ä¸ªè§†é¢‘å°†Mermerçš„æ•…äº‹è®²çš„å¾ˆæ¸…æ¥š:\n\t[The phony health craze that inspired hypnotism - YouTube](https://youtu.be/KQyAnKjD6W4)\n\n- mesmerize -\u003e v. å‚¬çœ \n- mesmerism -\u003e n. å‚¬çœ æœ¯, å‚¬çœ çŠ¶æ€\n- mesmeric -\u003e adj. å‚¬çœ æœ¯çš„, ä»¤äººç€è¿·çš„, ä»¤äººé™¶é†‰çš„\n\t- ... music with a repetitive, slightly mesmeric quality\n\n#### aggravate\n- 1520s, \"make heavy, burden down,\" from Latin aggravatus, past participle of aggravare \"to render more troublesome,\" literally \"to make heavy or heavier, add to the weight of,\" \n- from ad \"to\" (see ad-) + gravare \"weigh down,\" from gravis \"heavy\" (from PIE root gwere- (1) \"heavy\"). The literal sense in English has become obsolete; meaning \"**to make a bad thing worse**\" is from 1590s; colloquial sense \"**exasperate, annoy**\" is from 1610s. The earlier English verb was aggrege \"make heavier or more burdensome; make more oppressive; increase, intensify\" (late 14c.), from Old French agreger.\n\n- æœ‰æ„æ€çš„æ˜¯, æ±‰è¯­é‡Œé¢çš„\"åŠ é‡\"ä¸€è¯å’Œ aggravate æœ¬ä¹‰å’Œå¼•ç”³ä¹‰éƒ½å¯¹åº”çš„ä¸Š: ä» make heavy =\u003e å¼•ç”³åˆ° ä½¿æœ¬æ¥å°±ç³Ÿç³•çš„æƒ…å†µæ¶åŒ–\n- åŒæ—¶\"ä½¿æƒ…å†µæ¶åŒ–\"ä¹Ÿè®©æˆ‘ä»¬æ„Ÿåˆ°\"æ¼æ€’, ä¸å¿«\", ä¹Ÿå°±æœ‰äº†\"annoy, exasperate\" çš„å«ä¹‰\n\n#### exodus\n- the movement of a lot of people from a place\n\tï¼ˆå¤§æ‰¹äººçš„ï¼‰é€€å‡ºï¼Œç¦»å¼€\n- There has been a mass exodus of workers from the villages to the towns. ä¸€ç›´æœ‰å¤§é‡å·¥äººæºæºä¸æ–­ä»å†œæ‘æ¶Œå…¥åŸå¸‚ã€‚\n\nè¿™ä¸ªå«ä¹‰æ˜¯ç”±ä¸‹é¢å¼•ç”³è€Œæ¥çš„:\n\n- the second book of the Bible telling of Moses and the journey of the Israelites out of Egypt\n\tã€Šå‡ºåŸƒåŠè®°ã€‹ï¼ˆåŸºç£æ•™ã€Šåœ£ç»â€§æ—§çº¦ã€‹ç¬¬äºŒå·ï¼Œè®°è½½æ‘©è¥¿ç‡é¢†ä»¥è‰²åˆ—äººç¦»å¼€åŸƒåŠä¹‹äº‹ï¼‰\n\t\n- ã€Šå‡ºåŸƒåŠè®°ã€‹æ˜¯åœ£ç»æ—§çº¦çš„ç¬¬äºŒä¹¦ï¼Œä¸»è¦æ˜¯è®²è¿°ä»¥è‰²åˆ—äººå¦‚ä½•åœ¨åŸƒåŠå¸å›½å—åˆ°é€¼å®³ï¼Œç„¶åç”±æ‘©è¥¿å¸¦é¢†ä»–ä»¬ç¦»å¼€åŸƒåŠçš„æ•…äº‹ã€‚å‡ºåŸƒåŠè®°ä¼ ç»Ÿä¸Šè®¤ä¸ºæ˜¯æ‘©è¥¿åœ¨æ—·é‡å®Œæˆçš„ç¬¬äºŒæœ¬ä¹¦ï¼Œå› æ­¤åœ¨ä¸€äº›åœ£ç»è¯‘æœ¬å¦‚å¾·æ–‡åœ£ç»ä¸­ï¼Œå®ƒä¹Ÿç®€ç§°ä½œæ‘©è¥¿äºŒä¹¦ï¼ˆ2. Moseï¼‰ã€‚ \n\n#### complacent\nfeeling so satisfied with your own abilities or situation that you feel you do not need to try any harder.  è‡ªæ»¡çš„ï¼Œè‡ªé¸£å¾—æ„çš„\n- a complacent smile/attitude è‡ªé¸£å¾—æ„çš„å¾®ç¬‘ï¼æ€åº¦\n- We can't afford to become complacent about any of our products. \n\tæˆ‘ä»¬ä¸èƒ½å¯¹è‡ªå·±çš„ä»»ä½•ä¸€æ¬¾äº§å“æ²¾æ²¾è‡ªå–œã€‚\n\n- å…¶ä»–è¡¨ç¤º\"æ»¡æ„çš„\"è¯è¿˜æœ‰ smug, self-satisfied, pleased, satisfied, gratified\n\t- smug å’Œ complacent ä¸€æ ·, å…·æœ‰è´¬ä¹‰(pejorative connotation), å¯¹è‡ªå·±çš„æˆå°±æ²¾æ²¾è‡ªå–œçš„æ„æ€, \n\t- satisfied, gratified æ²¡æœ‰è´¬ä¹‰\n\n- complacence\n- complacency\n\n#### don\n- If you don clothing, you put it on.\n- ä¾‹å¥: The crowd threw petrol bombs at the police, who responded by **donning** riot gear.\n\n\"to **put on** (articles of clothing),\" mid-14c. **contraction of do on** (compare doff). \"After 1650 retained in popular use only in north. dialect; as a literary archaism it has become very frequent in 19th c.\" \n\ndon (n.)\ntitle of respect, 1520s, **from Spanish or Portuguese Don, a title of respect prefixed to a man's Christian name**, from Latin dominus \"lord, master, owner\" (from domus \"house,\" from PIE root *dem- \"house, household\").\n![300](notes/2022/2022.7/assets/Pasted%20image%2020220717162321.png)\n\n\n#### spoofâ˜¢â˜¢\næ»‘ç¨½çš„æ¨¡ä»¿: spoof, parody, caricature\n\n#### be a glutton for punishmentâ˜¢\nåƒè‹¦è€åŠ³çš„äºº, ä»»åŠ³ä»»æ€¨çš„äºº\nHe's a real glutton for punishment, taking on all that extra work.\n\n\n#### glutton\nä½†ä¸åœ¨ç¥æ›²é‡Œæ ¹æ®æ¶è¡Œçš„ä¸¥é‡æ€§é¡ºåºåˆ—å‡ºäº†ä¸ƒå®—ç½ª(7 deadly sins):\n| ä¸­æ–‡ | æ‹‰ä¸æ–‡   | è‹±æ–‡     |\n| ---- | -------- | -------- |\n| å‚²æ…¢ | superbia | pride    |\n| å«‰å¦’ | invidia  | envy     |\n| æ„¤æ€’ | ira      | wrath    |\n| æ€ æƒ° | acedia   | sloth    |\n| è´ªå©ª | avaritia | greed    |\n| æš´é£Ÿ | gula     | gluttony |\n| è‰²æ¬² | luxuria  | lust     |\n\nå…¶ä¸­ gluttony æ˜¯ä¸ƒå®—ç½ªä¹‹ä¸€, è€Œ glutton å°±æ˜¯æš´é£Ÿçš„äºº: \n- a person who regularly eats and drinks more than is needed\n\tå¥½åƒè´ªæ¯çš„äººï¼›æš´é¥®æš´é£Ÿè€… \n\n- å…¶å®ä½†ä¸æ‰€è¯´çš„æš´é£Ÿå¹¶ä¸å•å•æŒ‡\"é¥®é£Ÿ\", ä½†ä¸çš„è§‚ç‚¹æ˜¯â€œè¿‡åˆ†è´ªå›¾é€¸ä¹â€ã€‚\n\n- ç›¸å¯¹äºä¸ƒå®—ç½ªï¼Œå¤©ä¸»æ•™ä¹Ÿåˆ—å‡ºäº†ä¸ƒç¾å¾·ã€‚ \n| ç½ªè¡Œ                               | ç¾å¾·               |\n| ---------------------------------- | ------------------ |\n| è‰²æ¬²ï¼ˆLustï¼‰                       | è´æ´ï¼ˆChastityï¼‰   |\n| æš´é£Ÿï¼ˆGluttonyï¼‰                   | èŠ‚åˆ¶ï¼ˆTemperanceï¼‰ |\n| è´ªå©ªï¼ˆGreedï¼‰                      | æ…·æ…¨ï¼ˆCharityï¼‰    |\n| æ‡’æƒ°ï¼ˆSlothï¼‰                      | å‹¤å‹‰ï¼ˆDiligenceï¼‰  |\n| æ„¤æ€’ï¼ˆWrathï¼‰                      | è€å¿ƒï¼ˆPatienceï¼‰   |\n| å«‰å¦’ï¼ˆEnvyï¼‰                       | å®½å®¹ï¼ˆKindnessï¼‰   |\n| å‚²æ…¢ï¼ˆPrideï¼‰                      | è°¦è™šï¼ˆHumilityï¼‰   |\n\n- gluttonous -\u003e adj.\n\nglut- =\u003e to devour, åä¸‹, åƒ\n-on =\u003e åè¯åç¼€ \n\n- glut =\u003e è¿‡å¤šä¾›åº”\n- deglutible =\u003e å¯åæœçš„\n\n\n#### terrorâ˜¢\nä½œä¸ºåè¯, è¿˜å¯ä»¥æŒ‡æ·˜æ°”çš„éš¾ç®¡æ•™çš„å°å­©, ç†Šå­©å­, unruly children\n- He was a terror. He had been a difficult child for as long as his parent can remember.\n\n#### atone\natone - atoneæ˜¯at oneäºŒè¯è¿å†™åˆæˆçš„ã€‚å®ƒæ˜¯å¦‚ä½•å½¢æˆçš„å‘¢ï¼Ÿæ—§æ—¶at oneå¸¸å¸¸å‡ºç°åœ¨to bring at one accordï¼ˆä½¿ä¸€è‡´ï¼‰å’Œto set at one assentï¼ˆä½¿ä¸€è‡´ï¼‰ç­‰ä¸€ç±»è¾ƒé•¿çš„è¯ç»„ä¸­ã€‚åœ¨ä½¿ç”¨ä¸­äººä»¬è§‰å¾—at oneäºŒè¯å°±è¶³ä»¥è¡¨è¾¾æ•´ä¸ªè¯ç»„çš„æ„æ€ï¼Œå› æ­¤at oneåé¢çš„åè¯å¾€å¾€è¢«çœç•¥æ‰ã€‚æ—©åœ¨13ä¸–çºªï¼Œç‰§å¸ˆåœ¨å¸ƒé“æ—¶å¸¸å¸¸æ³æ±‚æ•™å¾’to be at one with Godï¼ˆä¸ä¸Šå¸å’Œå¥½ï¼‰ã€‚ç”±äºæ­¤è¯­ç”¨å¾—å¦‚æ­¤é¢‘ç¹ï¼Œåˆ°äº†14ä¸–çºªat oneé€æ¸ç»“åˆä¸ºä¸€ä¸ªè¯ï¼Œå¹¶è¢«èµ‹äºˆâ€œï¼ˆä½¿ï¼‰å’Œè§£â€ã€â€œï¼ˆä½¿ï¼‰åè°ƒâ€ã€â€œä¸â€¦â€¦å®Œå…¨ä¸€è‡´â€ç­‰ä¹‰ã€‚å½“æ—¶oneè¯»å¦‚ownï¼Œæ‰€ä»¥atoneå‘æˆ/É™ËˆtÉ™ÊŠn/ã€‚è¿™å°±ä½¿å¾—åäººå¾€å¾€æ³¨æ„ä¸åˆ°atoneä¸­çš„-oneä¸æ•°è¯oneä¹‹é—´çš„å†å²è”ç³»äº†ã€‚ä¸€èˆ¬è¯´æ¥ï¼Œå’Œè§£ä¸åè°ƒå¾€å¾€æ˜¯åœ¨ä¸€æ–¹å‘å¦ä¸€æ–¹èµç½ªåå‡ºç°çš„ï¼Œè€Œåœ¨åŸºç£æ•™ä¸­ä¸ä¸Šå¸å’Œå¥½åˆ™æ„å‘³ç€é€šè¿‡ç¥ˆç¥·ã€è‹¦ä¿®å’Œè¡Œå–„ç­‰ä¸ºè‡ªå·±èµç½ªã€‚åˆ°äº†17ä¸–çºªæœ«æœŸatoneä½œä¸ºå®—æ•™æœ¯è¯­å¼€å§‹ç”±â€œå’Œè§£â€ã€â€œå’Œå¥½â€ã€â€œåè°ƒâ€ç­‰ä¹‰è½¬è€Œè¡¨ç¤ºâ€œèµç½ªâ€ã€â€œè¡¥å¿â€ã€â€œå¼¥è¡¥â€ç­‰ä¹‰ã€‚\n\natoneçš„åè¯å½¢å¼æ˜¯atonementã€‚æ˜”æ—¥ï¼Œat onementä¸€è¯­åœ¨åŸºç£æ•™ä¸­å¸¸è¢«ç”¨æ¥è¡¨ç¤ºä¸Šå¸ä¸äººçš„å’Œå¥½ï¼Œè‹±å›½ç¥å­¦å®¶å¨å…‹é‡Œå¤«ï¼ˆJohn Wycliffe, 1330?-1384ï¼‰åœ¨1382å¹´ç‰ˆæœ¬çš„ã€Šåœ£ç»ã€‹è‹±è¯‘æœ¬ä¸­å°±æ›¾ç”¨è¿‡onementä¸€è¯ã€‚å—£åï¼Œat onementäºŒè¯åˆè€Œä¸ºä¸€ï¼Œä½œatonementã€‚å› æ­¤ä¸€äº›è¾ä¹¦è®¤ä¸ºatoneç³»ç”±atonementé€†æ„è€Œç”Ÿï¼Œä¹Ÿä¸æ— é“ç†ã€‚\n\nä¾‹ \n- There was no way he could atone for the wrong he had done. ä»–æ— æ³•å¼¥è¡¥ä»–æ‰€çŠ¯çš„è¿‡é”™ã€‚\n- He gave large sums of money to charities in an effort to atone for his sins. (CAE) ä¸ºäº†èµç½ªï¼Œä»–æäº†ä¸€å¤§ç¬”é’±ç»™æ…ˆå–„äº‹ä¸šã€‚\n- His hard work atones for his lack of skill. ä»–çš„è‰°è‹¦åŠªåŠ›å¼¥è¡¥äº†æŠ€æœ¯ä¸Šçš„ä¸ç†Ÿç»ƒã€‚\n- They're still trying to make some sort of atonement and reparation. ä»–ä»¬ä»åœ¨å°½åŠ›ä½œå‡ºæŸç§è¡¥å¿ã€‚\n\n#### abreast\na - breast =\u003e å¹¶è‚©å‰è¡Œ, ä¸­å›½æ˜¯å¹¶è‚©, å¤–å›½æ˜¯å¹¶èƒ¸\n- å¼•ç”³ä¹‰ =\u003e è·Ÿä¸Š ... çš„æœ€æ–°è¿›å±• keep abreast of sth\n\t- I try to keep abreast if any developments.\n\n\n#### domicileâ˜¢\ndom- domin =\u003e house (e.g. domestic, domain, condominium)\n-ile =\u003e ç‰©ä½“\n\na place where a person lives == dwelling, home, residence, house\n\n\n#### esoteric\n- esoteric [,esÉ™'terÉªk] adj. ç§˜ä¼ çš„ï¼›é™äºåœˆå†…äººçš„ï¼›éš¾æ‡‚çš„ \n- exoteric [,eksÉ™(ÊŠ)'terÉªk] adj. å¼€æ”¾çš„ï¼›å¤–ç•Œçš„ï¼›é€šä¿—çš„ã€‚\n- ä¸¤ä¸ªå•è¯çš„æ‹¼å†™ç›¸å·®ä¸€ä¸ªå­—æ¯ï¼Œæ„æ€å´æˆªç„¶ç›¸åï¼Œä¸ºå•¥å“©ï¼Ÿå¸Œè…Šå‰ç¼€ exo-è¡¨ outer,outsideï¼Œå¦ä¸€ä¸ªå¸Œè…Šå‰ç¼€ eso-è¡¨ withinã€‚å…±åŒç‚¹æ˜¯ï¼š-ter-è¡¨æ¯”è¾ƒçº§ï¼Œåç¼€-ic è¡¨ having to do withã€‚\n\n\n\n#### excoriateâ˜¢â˜¢\nex- =\u003e å»é™¤, ä»...ç¦»å¼€\ncori- cort- =\u003e skin, from Latin \"corium\" =\u003e skin, hide, leather\n-ate =\u003e åš, é€ æˆ\nstrip off the skin of =\u003e å¼•ç”³ä¸ºä¸¥å‰çš„æŒ‡è´£, ç—›æ–¥\n- His latest novel received excoriating reviews. \n\tä»–çš„æœ€æ–°å°è¯´å—åˆ°äº†ä¸¥å‰çš„æ‰¹è¯„ã€‚\n- The president excoriated the Western press for their biased views. \n\tè¿™ä½æ€»ç»Ÿç—›æ–¥è¥¿æ–¹æ–°é—»ç•Œå……æ»¡åè§çš„è§‚ç‚¹ã€‚ \n\n\n#### indelible\nin- + del(ete) + ble =\u003e ä¸å¯ä»¥ delete çš„ =\u003e ä¸å¯ç£¨ç­çš„\n\npermanent, lasting, enduring, ingrained\n\n\n#### benightedâ˜¢â˜¢\novertaken by darkness =\u003e å¼•ç”³ä¸º overtaken by intellectual or moral darkness =\u003e without knowledge or morals \u003c=\u003e æ„šæ˜§çš„, æ— çŸ¥çš„, æœªå¼€åŒ–çš„ \n\n- Some of the early explorers thought of the locals people as benighted savages who could be exploited.\n\n#### halcyonâ˜¢\n![](notes/2022/2022.7/assets/White-throated_kingfisher.webp)\nhalcyonï¼ˆç¥ç¿ é¸Ÿï¼‰ï¼šæ®‰æƒ…è‡ªå°½çš„ç—´æƒ…å¤«å¦»\nå¸Œè…Šç¥è¯ä¸­ï¼Œé£ç¥æœ‰ä¸€ä¸ªå¥³å„¿å«è‰¾å°”èå¥¥å¦®ï¼ˆAlcyoneï¼‰ï¼Œå«ç»™äº†é»æ˜å¥³ç¥çš„å„¿å­ã€å›½ç‹è¥¿å…‹æ–¯ï¼ˆCeyx)ã€‚ä¸¤å£å­éå¸¸æ©çˆ±ï¼Œç«Ÿç„¶å¾—æ„åœ°è‡ªæ¯”å®™æ–¯å’Œèµ«æ‹‰ï¼Œç»“æœæƒ¹æ¼äº†å®™æ–¯å’Œèµ«æ‹‰ï¼Œå†³å®šè¦å¥½å¥½æƒ©ç½šè¿™ä¸¤ä¸ªä¸æ•¬ç¥çµçš„å‡¡äººã€‚äºæ˜¯ï¼Œæœ‰ä¸€å¤©ï¼Œè¥¿å…‹æ–¯åœ¨æµ·ä¸Šèˆªè¡Œçš„æ—¶å€™æººæ°´è€Œäº¡ï¼Œè‰¾å°”èå¥¥å¦®ä¼¤å¿ƒæ„ˆç»ï¼Œè·³å´–èº«äº¡ã€‚\nä¼—ç¥è¢«å¥¹çš„ç—´æƒ…æ„ŸåŠ¨ï¼Œå°±å°†è¥¿å…‹æ–¯ä¸è‰¾å°”èå¥¥å¦®åŒåŒå˜æˆç¥ç¿ é¸Ÿï¼ˆhalcyonï¼‰ï¼Œä»æ­¤æ°¸ä¸åˆ†ç¦»ã€‚ ä¼ è¯´ä¸­è¿™å¯¹æ©çˆ±çš„å¤«å¦»åœ¨æ³¢æµªä¸ŠæŠšè‚²ä»–ä»¬çš„å­©å­ï¼Œè€Œè‰¾å°”èå¥¥å¦®çš„çˆ¶äº²é£ç¥å› ä¸ºçœ·é¡¾å¥³å„¿ï¼Œ æ¯å¹´åäºŒæœˆä»½ï¼Œä»–å°±ä¼šå¹³æ¯æµ·æµªï¼Œä¾¿äºç¿ é¸Ÿåœ¨æµ·ä¸Šç­‘çªï¼Œç”Ÿè‚²åä»£ã€‚æ‰€ä»¥å•è¯ halcyon è¿˜æœ‰â€œé£æµªå¹³æ¯â€çš„å«ä¹‰ã€‚\nhalcyonï¼š ['hÃ¦lsÉªÉ™n; -Êƒ(É™)n] n.ç¥ç¿ é¸Ÿï¼Œç¿¡ç¿ é¸Ÿadj.å®é™çš„ï¼Œå¹³ç¨³çš„\nhalcyon daysï¼šå¤ªå¹³æ—¶æœŸ\n\n#### arable\nar- = to plow, è¡¨ç¤ºâ€œçŠåœ°â€ã€‚\n-able ä¸€èˆ¬ç¼€äºåŠ¨è¯åï¼Œæ„æˆå½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œå¯â€¦çš„ï¼Œèƒ½â€¦â€ã€‚\n\n#### profane\nadj. äºµæ¸çš„ï¼Œä¸–ä¿—çš„ vt. äºµæ¸ï¼Œç·æ±¡\n\n- profaneï¼ˆäºµæ¸çš„ï¼‰ï¼šä¸èƒ½è¿›å…¥ç¥åœ£åŒºåŸŸå†…çš„ä¿—äºº\n- è‹±è¯­å•è¯ profane åŸæœ¬æ˜¯ä¸€ä¸ªå®—æ•™æœ¯è¯­ã€‚åœ¨å¤ç½—é©¬äººçš„å®—æ•™ä»ªå¼ä¸­ï¼Œä¸€èˆ¬çš„â€œä¿—äººâ€ä¸å¾—è¿›å…¥å®—æ•™åœºæ‰€ä¸­çš„â€œç¥åœ£åŒºåŸŸâ€ï¼ˆfanumï¼‰ï¼Œå¦‚å¯ºåº™çš„å†…åº­ï¼Œåªæœ‰å—è¿‡â€œå¯è’™â€ï¼ˆinitiatedï¼‰çš„äººå³ç¥èŒäººå‘˜æ‰æœ‰èµ„æ ¼è¿›å…¥è¿™ç‰‡åŒºåŸŸæ‰§è¡Œå„ç§å®—æ•™ä»ªå¼ã€‚ä¸–ä¿—äººå£«å³ä½¿è¦å‘ç¥çµç¥­ç¥€ï¼Œä¹Ÿåªèƒ½å°†ç¥­ç¥€ç”¨çš„ç‰ºç‰²æ”¾åœ¨ fanum ä¹‹å‰çš„ç¥­å›ä¸Šã€‚å› æ­¤ï¼Œåœ¨æ‹‰ä¸è¯­ä¸­ï¼Œç”¨ profanus æ¥è¡¨ç¤ºâ€œä¸–ä¿—çš„â€ï¼Œæ˜¯ sacredï¼ˆç¥åœ£çš„ï¼‰çš„åä¹‰è¯ã€‚å®ƒç”± proï¼ˆin front ofï¼‰+fanum æ„æˆï¼Œå­—é¢æ„æ€å°±æ˜¯â€œåœ¨ fanum å‰é—¨å¤–çš„ï¼Œä¸å¾—è¿›å…¥ fanum çš„â€ã€‚\n- ç°åœ¨ï¼Œprofaneä¸€è¯çš„å®—æ•™è‰²å½©å·²ç»é€æ¸æ¶ˆå¤±ï¼Œå¹¶åœ¨â€œä¸–ä¿—çš„â€è¯ä¹‰ä¹‹ä¸Šè¡ç”Ÿå‡ºâ€œäºµæ¸çš„â€ä¹‹æ„ã€‚\n\n#### avow / disavow\n##### vow\nto make a determined decision or promise to do something\nå‘èª“ï¼Œç«‹èª“\n\n##### avow\n- a- è¡¨ç¤ºå¼ºè°ƒ\nto admit something or say something publicly\nå£°æ˜ï¼›å®£ç§°ï¼›æ‰¿è®¤\n- He **avowed** that he regretted what he had done. \n\tä»–æ‰¿è®¤å¯¹è‡ªå·±çš„æ‰€ä½œæ‰€ä¸ºæ„Ÿåˆ°åæ‚”ã€‚\n- It is a society in which homosexuality is rarely **avowed**. \n\tè¿™æ ·ä¸€ä¸ªç¤¾ä¼šä¸­ï¼Œå¾ˆå°‘æœ‰äººå…¬å¼€æ‰¿è®¤è‡ªå·±æ˜¯åŒæ€§æ‹ã€‚\n\n##### disavow\ndisãƒ»aãƒ»vow\n\nto say that you know nothing about something, or that you have no responsibility for or connection with something\nå£°ç§°å¯¹â€¦ä¸€æ— æ‰€çŸ¥ï¼›å¦è®¤å¯¹â€¦è´Ÿæœ‰ä»»ä½•è´£ä»»ï¼›å£°ç§°ä¸â€¦æ¯«æ— å…³è”\n\n- They were quick to **disavow** the rumour. \n\tä»–ä»¬è¿…é€Ÿå¦è®¤ä¸é‚£äº›è°£ä¼ æœ‰ä»»ä½•ç‰µè¿ã€‚\n\n\n#### deify\n- dei-  \n\t= god, divine, è¡¨ç¤ºâ€œç¥ã€ç¥çš„â€ã€‚æºè‡ªæ‹‰ä¸è¯­ deus \"god,\" divus \"divine, god.\"\n- -fy \n\tç¼€äºåè¯æˆ–å½¢å®¹è¯åï¼Œè¡¨ç¤º â€œâ€¦åŒ–â€, â€œä½œæˆâ€¦â€ç­‰æ„æ€çš„åŠ¨è¯\n\n- deity ç¥, ç¥æ€§\n- divine ç¥åœ£çš„\n\n\n#### concave\ncon- =\u003e è¡¨ç¤ºå¼ºè°ƒ\ncave =\u003e hole, æ´ç©´\næ´ç©´æ˜¯å‡¹ä¸‹å»çš„, =\u003e å‡¹çš„\n\nå‡¸çš„ =\u003e convex\n\n#### resuscitateâ˜¢â˜¢\nreãƒ»suscitate\n- 1530s, \"**revive, restore, revivify (a thing), restore (a person) to life**,\" from Latin resuscitatus, resuscitare \"rouse again, revive,\" from re- \"**again**\" + suscitare \"**to raise, revive**,\"\n\n- to bring someone or something back to life or wake someone or something\n\tä½¿è‹é†’ï¼›ä½¿æ¢å¤çŸ¥è§‰ï¼›ä½¿å¤æ´»\n- Her heart had stopped, but the doctors successfully resuscitated her. å¥¹çš„å¿ƒè·³éƒ½å·²ç»åœäº†ï¼Œä½†åŒ»ç”Ÿä»¬è¿˜æ˜¯æˆåŠŸåœ°æŠŠå¥¹ä»é¬¼é—¨å…³æ‹‰äº†å›æ¥ã€‚\n\n\n#### deadpan\ndead + pan è€Œ pan åœ¨ slang é‡Œé¢æ˜¯ face çš„æ„æ€\n- looking or seeming serious when you're telling a joke.\n\n- ...her natural capacity for irony and deadpan humour.\n\n\n#### platitude\nplat- =\u003e flat å¹³ (e.g. platform, plateau, platter)\n-itude =\u003e åè¯åç¼€, \"çŠ¶æ€, æ€§è´¨\"\nå¹³å‡¡æ— å¥‡çš„è¯ =\u003e å¼•ç”³ä¸º(è´¬ä¹‰çš„) é™ˆè¯æ»¥è°ƒ, è€ç”Ÿå¸¸è°ˆ\n\n- Why couldn't he say something original instead of spouting the same platitude?\n\nä¸è¦å’Œ plentitude ææ··\n\n#### goad\n![](notes/2022/2022.7/assets/Pasted%20image%2020220717195916.png)\nå¤æ—¶å€™ç”¨æ¥èµ¶ç‰›çš„å°–å°–çš„èµ¶ç‰›æ£’, åæ¥å¼•ç”³ä¸º: \n\næ‹›æƒ¹, åˆºæ¿€, æ¿€æ€’æŸäºº (ä¸ºäº†è®©ä»–ä»¬åšæŸäº‹) =\u003e èµ¶ç‰›æ£’è®©ç‰›å¾ˆçƒ¦èº\n- A group of children were goading (= laughing at or pushing) another child in the school playground. ä¸€ç¾¤å­©å­æ­£åœ¨å­¦æ ¡æ“åœºä¸Šå˜²å¼„æ¨æ¡å¦å¤–ä¸€ä¸ªå­©å­ã€‚ \n-  She seemed determined to goad him into a fight. å¥¹ä¼¼ä¹é“äº†å¿ƒè¦æ¿€æ€’ä»–æ¥æ‰“ä¸€æ¶ã€‚\n- He refused to be goaded by their insults. ä»–å¯¹ä»–ä»¬çš„ä¾®è¾±ä¸å±‘ä¸€é¡¾ã€‚\n\nåˆºæ¿€, é©±ä½¿  =\u003e èµ¶ç‰›æ£’å¯ä»¥åˆºæ¿€ç‰›å‘å‰èµ°\n- The runner was goaded on by his desire to keep up with the others. è¿™åè·‘è€…ä¸åœåœ°åŠªåŠ›ï¼Œä¸€å¿ƒè¦è·Ÿä¸Šå…¶ä»–äººã€‚\n\n\n#### evanesceâ˜¢â˜¢\n/ËŒev.É™Ëˆnes.É™ns/\ne- =\u003e \"ä»...ç¦»å¼€\"\nvan- =\u003e empty, ç©º, æºè‡ªæ‹‰ä¸è¯­ vanus \n-esce =\u003e \"åŠ¨ä½œçš„èµ·å§‹\"\n\n(of smoke, mist, etc.) è½¬ç¬å³é€, æ¶ˆæ•£, éšæ²¡\n\nevanescent =\u003e evanesce+ent =\u003e adj. çŸ­æš‚çš„, è½¬ç¬å³é€çš„, ç¬æ¯çš„\n\n##### -esce\nacãƒ»quiãƒ»esce   =\u003e   v. é»˜è®¸, é»˜ç„¶åŒæ„\nadolãƒ»esce        =\u003e   v. è¿›å…¥é’æ˜¥æœŸ\ncoãƒ»alãƒ»esce     =\u003e   v. è”åˆ\nfluorãƒ»esce        =\u003e   v. å‘è§å…‰\ninãƒ»candãƒ»esce =\u003e   v. ä½¿ç™½çƒ­åŒ–\nobãƒ»solãƒ»esce   =\u003e   v. ä½¿è¿‡æ—¶, ä½¿æ·˜æ±°\nopalãƒ»esce         =\u003e   v. å‘å‡ºä¹³ç™½è‰²çš„å…‰\nphosphorãƒ»esce =\u003e  v. å‘å‡ºç£·å…‰\nreãƒ»juvenãƒ»esce =\u003e  v. ä½¿é‡ç„•é’æ˜¥\n\n- ä¸Šé¢å¾ˆå¤šè¯å°†åç¼€ \"esce\" æ¢æˆå¤åˆåç¼€ \"escence\"(-esce + -ence) è¡¨ç¤º\"åŠ¨ä½œçš„èµ·å§‹\", å¯ä»¥å¾—åˆ°åè¯. æ¯”å¦‚ adolãƒ»escence\n\n\n#### importune â˜¢\nim- =\u003e æ²¡æœ‰\nport- =\u003e harbor æ¸¯å£\n\næ²¡æœ‰æ¸¯å£çš„, æ— æ³•å…¥æ¸¯çš„, =\u003e å¼•ç”³ä¸º\"éº»çƒ¦çš„\" =\u003e å¼ºæ±‚, çº ç¼ , pester, press, plague, hound\n\n\n#### court\ncourt ä½œä¸ºåŠ¨è¯è¿˜æœ‰\"å¥‰æ‰¿, è®¨å¥½, çŒ®æ®·å‹¤çš„æ„æ€\" \n- Adams is being courted by a number of football clubs. \n\tæœ‰å¥½å‡ å®¶è¶³çƒä¿±ä¹éƒ¨åœ¨å‘äºšå½“æ–¯çŒ®æ®·å‹¤ã€‚ \n\n=\u003e è¿›ä¸€æ­¥å¼•ç”³ä¸º\"æ±‚å–, è®¾æ³•å–å¾—\"çš„æ„æ€ \n - She courts publicity by inviting journalists to extravagant parties. å¥¹é‚€è¯·æ–°é—»è®°è€…å‚åŠ å¥¢åèšä¼šæ¥è°‹æ±‚æ›å…‰åº¦ã€‚\n\n=\u003e åŒæ—¶è¿˜æœ‰æ‹›è‡´, æ‹›æƒ¹éº»çƒ¦çš„æ„æ€\n- Drinking and driving is simply courting disaster. \n\té…’åé©¾è½¦çº¯ç²¹æ˜¯åœ¨æ‹›æƒ¹ç¥¸ç«¯ã€‚\n\n\n#### -sent\nsens-, sent- =\u003e feel, \"æ„Ÿè§‰\"\n\n##### dissent \ndis- =\u003e ç›¸å, differ\n=\u003ediffer in sentiments =\u003e ä¸åŒæ„, åå¯¹, å¼‚è®®\n\n##### assent\nas- =\u003e æœ, å‘, to, ä¸€æ ·\nfeel the same =\u003e èµæˆ, åŒæ„\n\n##### resent\nre- =\u003e ç›¸å, ç›¸å¯¹, ä¹Ÿè¡¨ç¤ºå¼ºè°ƒ\nhave a strong feeling against =\u003e æ†æ¨, æ„¤æ¨\n\n##### consent\ncon- =\u003e with, together \nfeel together =\u003e åŒæ„, ç­”åº”, è®¤å¯\n\n#### stippleâ˜¢\nç‚¹å½©ç”»æ³•, æ¯”å¦‚åŒ–å¦†æ—¶å€™ç”¨ç¾å¦†è›‹æŒ‰å‹çš„åŠ¨ä½œ, to apply paint with light dabs\n\n- ä¸è¦å’Œ dabble ææ··äº†\n\n#### discreditâ˜¢\ndis + credit =\u003e æŠ¹é»‘, ä½¿åèª‰å—æŸ, å¦è®¤, é©³æ–¥\ndisgrace, blame, shame, smear, dispute, \n\n#### pluck\n- æ‹”\npluck your eyebrows =\u003e ä¿®çœ‰\npluck the chicken =\u003e ç»™é¸¡æ‹”æ¯›\n- æ‘˜\npluck a lemon\n- æ‹¨(å¼¦)\npluck the strings of a guitar\n\nå¼•ç”³ä¸º =\u003e\n- to remove someone suddenly from a situation that is ordinary\n\tä½¿è„±é¢–è€Œå‡ºï¼›æå‡\n\tHe was plucked from obscurity to star in the film. ä»–è„±é¢–è€Œå‡ºæˆä¸ºè¿™éƒ¨ç”µå½±çš„ä¸»æ¼”ã€‚\n\n- to remove someone quickly from a dangerous or difficult situation   ä½¿.... è„±ç¦»é™©å¢ƒ \nThe last passengers were plucked from the ship just seconds before it sank. æœ€åä¸€æ‰¹æ¸¸å®¢åœ¨èˆ¹æ²‰æ²¡å‰å‡ ç§’é’Ÿè¢«æ•‘èµ·ã€‚\n=\u003e \n(noun.)\n- courage and a strong wish to succeed  èƒ†è¯†ï¼Œå‹‡æ°”\nShe showed a lot of pluck in standing up to her boss. \nå¥¹é¡¶æ’è€æ¿ï¼Œæ˜¾ç¤ºå‡ºäº†å¾ˆå¤§çš„å‹‡æ°”ã€‚\n\n#### abjureâ˜¢â˜¢\nab- =\u003e opposite, not, \njur- =\u003e swear, law, å‘èª“ï¼Œæ³•å¾‹\n- èƒŒç¦»è‡ªå·±çš„èª“è¨€ =\u003e å…¬å¼€æ”¾å¼ƒ\n\n#### adhere\nadhere æ˜¯é»é™„, é™„ç€çš„æ„æ€, å¯ä»¥å¼•ç”³ä¸º=\u003e \n- (é»é™„äºæŸç§ä¿¡å¿µ) =\u003e åšæŒæŸç§è§‚ç‚¹æˆ–è€…ä¿¡å¿µ\nIf you **adhere to an opinion or belief**, you support or hold it.\n- If you can't **adhere to** my values, then you have to find another place to live. \n\n- (é»é™„äºæŸç§è§„åˆ™) =\u003e éµå®ˆæŸä¸ªè§„åˆ™, å‡†åˆ™\nIf you **adhere to a rule or agreement**, you act in the way that it says you should.\n- All members of the association **adhere to** a strict code of practice.\n- It is only when safety procedures are not strictly **adhered to** that catastrophes occur. \n\n#### antagonize\n- ant- \nè¡¨ç¤ºâ€œåå¯¹ï¼Œç›¸åâ€ã€‚æºè‡ªå¸Œè…Šè¯­ anti \"against, opposite.\"\n- agon- \n= struggle, è¡¨ç¤ºâ€œæŒ£æ‰ï¼Œæ–—äº‰â€ã€‚æºè‡ªå¸Œè…Šè¯­ agein \"to drive, lead, weigh.\"\n- -ise \nåŠ¨è¯åç¼€ï¼Œä¸€èˆ¬ç¼€äºå½¢å®¹è¯åã€‚-ise æ˜¯è‹±å¼è‹±è¯­ï¼Œ-ize æ˜¯ç¾å¼è‹±è¯­ã€‚æºè‡ªå¸Œè…Šè¯­ -izein, verbal suffix.\n\ncompete against =\u003e å¼•ç”³ä¸º\"ä½¿æ•Œå¯¹, æ¿€æ€’\"\n\n#### anticâ˜¢â˜¢\nantic - è¿™ä¸ªè¯çš„ç‰¹æ®Šæ„ä¹‰äº§ç”Ÿäºæ„å¤§åˆ©ã€‚æ–‡è‰ºå¤å…´æ—¶ä»£ï¼Œæ„å¤§åˆ©äººåœ¨å¤ç½—é©¬é—è¿¹å‘æ˜å‡ºå¤§é‡å¥‡å½¢æ€ªçŠ¶çš„å‡é¢å…·å’Œé›•åƒã€‚åœ¨ç½—é©¬çš‡å¸æå›¾æ–¯ï¼ˆTitus, 39-81ï¼‰çš„è±ªåæµ´å…å¢™ä¸Šé›•åˆ»çš„äººç‰©ã€åŠ¨ç‰©ã€èŠ±è‰ç­‰æ›´ä»¥é£æ ¼å¥‡å¼‚ã€å½¢çŠ¶æ€ªè¯è€Œå¼•äººæ³¨ç›®ã€‚æ„å¤§åˆ©äººæŠŠè¿™äº›ç¨€å¥‡å¤æ€ªçš„é›•åˆ»å“ç§°ä½œanticoã€‚16ä¸–çºªè‹±è¯­å€Ÿç”¨äº†è¯¥è¯ï¼Œä½œanticã€‚æœ€åˆanticä¹ŸæŒ‡â€œå¥‡å½¢æ€ªçŠ¶çš„é›•å¡‘â€ï¼Œä»¥åå¼•ç”³ä¸ºâ€œä¸‘è§’â€ï¼Œä½†è¿™ä¸¤ä¸ªè¯ä¹‰ä»Šå·²ä¸ç”¨ã€‚ç°åœ¨anticå¸¸æŒ‡â€œæ»‘ç¨½åŠ¨ä½œâ€æˆ–â€œå¤æ€ªè¡Œä¸ºâ€ï¼Œä¸”å¤šä½œanticsã€‚åœ¨å½“å½¢å®¹è¯ç”¨æ—¶åˆ™æ˜¯â€œå¤æ€ªçš„â€ã€â€œæ»‘ç¨½çš„â€ä¹‹æ„ã€‚å®é™…ä¸Šanticoè¿™ä¸€æ„å¤§åˆ©è¯è¿˜å¯ä»¥è¿½æº¯åˆ°æ‹‰ä¸è¯­antÄ«quus 'ancient'ï¼ˆå¤è€çš„ï¼‰ï¼Œè‹±è¯­é‡Œæ„æŒ‡â€œå¤ç©â€ã€â€œå¤ç‰©â€çš„antiqueä¸€è¯ä¹Ÿæºå‡ºäºæ­¤ã€‚\n\nä¾‹ \n- The antics of the clowns amused the children.  å°ä¸‘ä»¬çš„æ»‘ç¨½åŠ¨ä½œæŠŠå­©å­ä»¬é€—å¾—å‘ç¬‘ã€‚\n- The audience were/was entertained by the antics of the magician. è§‚ä¼—è¢«é­”æœ¯å¸ˆçš„æ»‘ç¨½åŠ¨ä½œé€—ä¹äº†ã€‚\n\n##### attic\né˜æ¥¼\n\n#### auspiciousâ˜¢\n/É‘ËËˆspÉªÊƒ.É™s/\nauspice + -ous\n\nauspiceï¼ˆå‰å…†ï¼‰ï¼šå¤ç½—é©¬äººçš„é¸Ÿåœæ³•\nå¤ç½—é©¬çš„ä¼Šç‰¹é²åˆ©äºšäººæœ‰é€šè¿‡è§‚çœ‹é£é¸Ÿæ¥å åœå‡¶å‰çš„åšæ³•ã€‚å·«å¸ˆç”¨ä¸€ä¸ªé­”æ–ï¼ˆlituusï¼‰åœ¨å¤©ç©ºä¸­ç”»å‡ºä¸€ä¸ªåŒºåŸŸï¼Œè§‚å¯Ÿé¸Ÿåœ¨è¯¥åŒºåŸŸçš„é£è¡Œï¼Œé€šè¿‡é¸Ÿçš„é£è¡Œæ¥åˆ¤æ–­å‰å‡¶ã€‚è¿™ç§è§‚é¸Ÿå åœæ³•ç§°ä¸º auspiceï¼Œæºè‡ªæ‹‰ä¸è¯­ avisï¼ˆbirdï¼Œé¸Ÿï¼‰+specereï¼ˆlookï¼Œçœ‹ï¼‰ã€‚åæ¥ï¼Œauspice çš„å«ä¹‰æ¼”å˜ä¸ºå åœæ—¶å–å¾—çš„å‰å…†ï¼Œå¹¶é€æ¸è¡ç”Ÿå‡ºâ€œèµåŠ©ã€ä¸»åŠâ€çš„æ„æ€ï¼Œå› ä¸ºå‰å…†ä¸å°±æ˜¯è€å¤©çˆ·çš„æ”¯æŒå’ŒèµåŠ©å—ï¼Ÿæ‰§è¡Œè§‚é¸Ÿå åœçš„å·«å¸ˆå«åš augur æˆ– auspexï¼Œæ‰€ä»¥è§‚é¸Ÿå åœæ³•ä¹Ÿè¢«ç§°ä¸º auguryã€‚\n- auspiceï¼š['É”ËspÉªs] n. å‰å…†ï¼ŒèµåŠ©ï¼Œä¸»åŠ\n- auspiciousï¼š [É”'spÉªÊƒÉ™s] adj. å‰å…†çš„ï¼Œå‰åˆ©çš„ï¼›å¹¸è¿çš„\n\n- auguryï¼š['É”ËgjÊŠrÉª] n.å åœï¼Œé¢„è¨€ï¼Œé¢„å…†\n- augurï¼š['É”ËgÉ™] n. å åœå¸ˆï¼Œé¢„è¨€è€… v. é¢„è¨€ï¼Œå åœ\n- auspexï¼š ['É”Ëspeks] n. é¸Ÿåœè€…ï¼›å åœè€…\n\n\n#### belieâ˜¢\nbe- =\u003e ä½¿ ... æˆä¸º\nlie =\u003e æ©ç›–\nä½¿ ... è¢«æ©ç›– =\u003e disguise, misrepresent, conceal, distort\n\n- To belie means to contradict. If you are 93 but look like you are 53, then your young looks belie your age.\n\n\n#### atrociousâ˜¢\natroc- =\u003e cruel, æ®‹é…·\n\nç©·å‡¶ææ¶çš„, éª‡äººå¬é—»çš„, æ®‹æš´çš„\n=\u003e atrocity n. æš´è¡Œ\n\n\n#### clog\nåŸæ¥çš„æ„æ€æ˜¯ a lump of wood(ä¸€å¤§å—æœ¨å¤´) =\u003e å› ä¸ºæŠŠä¸€å¤§å—æœ¨å¤´ç»‘åœ¨ä¸Šé¢ä¸œè¥¿ä¸Šå°±ä¼šé˜»ç¢ ta çš„è¡ŒåŠ¨, æ‰€ä»¥åæ¥æœ‰äº† hinder, impede the movement of çš„æ„æ€, ä¹Ÿæœ‰é˜»å¡, å µå¡çš„æ„æ€\n- å› ä¸ºæœ‰'ä¸€å¤§å—æœ¨å¤´'çš„æ„æ€, æ‰€ä»¥clogä¹Ÿä»£è¡¨é‹åº•(sole)æ˜¯ç”¨ä¸€å—æœ¨å¤´åšæˆçš„é‹å­ =\u003e æœ¨å±, æœ¨åº•é‹\n\n#### culpable\nculp- =\u003e fault, è¿‡é”™, ç½ª\n- è‹±è¯­ä»æ‹‰ä¸æ–‡ç›´æ¥å€Ÿç”¨äº†ä¸å°‘è¯è¯­ï¼Œå¹¶ä¸”ä¿ç•™äº†åŸæ‹‰ä¸æ–‡æ‹¼å†™å½¢å¼ï¼Œmea culpa å³ä¸ºå…¶ä¸­ä¹‹ä¸€ï¼Œç›¸å½“äºè‹±è¯­ my faultï¼ˆæˆ‘çš„è¿‡å¤±ï¼‰ï¼Œæ˜¯ä¸ªè¾ƒæ­£å¼çš„ç”¨è¯­ã€‚å®ƒæºå‡ºç½—é©¬å¤©ä¸»æ•™ç¤¼æ‹œä»ªå¼çš„ç¥·æ–‡ï¼šâ€œmea culpa, mea culpa, mea maxima culpa.â€ï¼ˆè¿™æ˜¯æˆ‘çš„è¿‡å¤±ï¼Œæˆ‘çš„è¿‡å¤±ï¼Œæˆ‘çš„æå¤§è¿‡å¤±ã€‚ï¼‰æ•™å¾’ä»¥æ­¤å‘ä¸Šå¸è¡¨ç¤ºå¿æ‚”è®¤ç½ªã€‚å½¢å®¹è¯ culpable è¡¨é¢ä¸Šæ˜¯å€Ÿè‡ªå¤æ³•è¯­ coulpableï¼Œä½†å´æ˜¯æºäº culpa 'fault'ï¼ˆè¿‡å¤±ï¼‰ä¸€è¯ï¼Œå…¶å¤ä¹‰ä¸ºâ€œæœ‰ç½ªçš„â€ã€â€œçŠ¯äº†ç½ªçš„â€ï¼Œä½†ä»Šå¤©å¤šé‡Šä¹‰ä¸ºâ€œåº”å—è´£å¤‡çš„â€æˆ–â€œè¯¥å—æƒ©å¤„çš„â€ã€‚\n\nä¾‹ \n- They held him culpable for the offence. \n\tä»–ä»¬è®¤ä¸ºä»–æœ‰ç½ªï¼Œåº”å—æƒ©ç½šã€‚\n- The prime minister is highly culpable in this affair. \n\tè¿™ä»¶äº‹é¦–ç›¸éš¾è¾å…¶å’ã€‚\n\n##### culp-\n- exculpate =\u003e exãƒ»culpãƒ»ate =\u003e å¼€è„±, ä½¿æ— ç½ª\n- disculpate =\u003e disãƒ»culpãƒ»pate =\u003e å¼€è„±, ä½¿æ— ç½ª\n- inculpate =\u003e inãƒ»culpãƒ»ate =\u003e å½’ç½ªäº, åŠ ç½ªäº\n- inculpable =\u003e inãƒ»culpãƒ»able =\u003e æ— ç½ªçš„\n\n\n#### defray\n- æ¥è‡ªå¤æ³•è¯­ defrayer, æˆæœ¬ï¼Œæ”¯ä»˜ï¼Œæ¥è‡ª de-,å‘ä¸‹ï¼Œæ”¯å‡ºï¼Œ-frai,ç ´ç¢ï¼ŒèŠ±è´¹ï¼Œè¯æºåŒ break. åŸä¹‰ä¸ºç ´åå’Œå¹³çš„ç½šé‡‘ã€‚åè¯ä¹‰é€šç”¨åŒ–ã€‚\n\n\n\n#### delicacy\n- ç±»ä¼¼äº fragility, å½¢å®¹ç¾ä¸½ä¼˜é›…ç‰©å“çš„è„†å¼±ä¸ç²¾ç¾\n\t- the delicacy of a rose\n- å½¢å®¹ä¸€ä¸ªæƒ…å†µ, é—®é¢˜çš„\"å¾®å¦™\", éœ€è¦å¾ˆç»†è‡´åœ°å¤„ç†æ‰ä¸ä¼šå‡ºé”™çš„æƒ…å†µ\n\t- He sensed the delicacy of the situation\n\t- Both countries are behaving with rare delicacy.\n- çé¦, ä½³è‚´\n\t- Smoked salmon was considered an expensive delicacy.\n\n#### demolishâ˜¢\nto destroy (a large structure) completely \n- å¼•ç”³åˆ°è§‚ç‚¹, è®ºç‚¹ =\u003e æ¨ç¿»è®ºç‚¹, é¢ è¦†è§‚ç‚¹(å½¢å®¹å¾ˆå½»åº•)\n\t- Our intention was to demolish the rumours that surrounded him.\n- å¼•ç”³åˆ°æ¯”èµ›, å¯¹æ‰‹ =\u003e å®Œè´¥å¯¹æ‰‹, å½»åº•å‡»è´¥å¯¹æ‰‹\n\t- Millwall demolished Notts Country 6-0 on Saturday.\n- å¼•ç”³åˆ°é£Ÿç‰© =\u003e ç‹¼åè™å’½\n\t- Joe demolished an enormous plateful of chicken and fries.\n\n#### accrete\nac- =\u003e æ¥, å‘, å», ä¹Ÿè¡¨ç¤ºå¼ºè°ƒ\ncre- creas- =\u003e grow, make, å¢é•¿\n\n=\u003e accrete é€šå¸¸è¡¨ç¤ºè‡ªç„¶ç‰©è´¨çš„ç§¯èš, å †ç§¯, å¸ç§¯, ç´¯ç§¯, æ²‰ç§¯\n\n##### cre- creas- \n- increase\n- increment\n- crescendo =\u003e n. (å£°éŸ³, ä¹æ›²) æ¸å¼º, æœ€é«˜ç‚¹\n- procreate =\u003e v. ç”Ÿè‚², ç”Ÿæ®–, pro- è¡¨ç¤ºå¾ˆå¤š, å‘å‰(åœ¨è¿™é‡Œå¯ä»¥ç†è§£ä¸ºæ—¶é—´ä¸Šçš„å‘å‰)\n\n\n#### adulterate\nad- =\u003e æœ, å‘, å», æˆ–è€…ä¸ºå¼ºè°ƒ\nulter- alter- =\u003e æ”¹å˜, å…¶ä»–çš„, other, to change, from Latin \"alius\"\n-ate =\u003e åŠ¨è¯åç¼€, é€ æˆ, ä½¿...\n=\u003e to other, to change, =\u003e debase by mixing with foreign or inferior material, æºå‡, å…‘å‡è´§\n\n - There were complaints that the beer had been **adulterated with** water. æœ‰å¤šäººæŠ•è¯‰è¯´è¿™å•¤é…’é‡Œé¢å…‘äº†æ°´ã€‚ \n\n- adulterator\n- adulteration\n- adulterated\n\n=\u003e å¼•ç”³åˆ°æƒ…æ„Ÿå˜è´¨ =\u003e adultery n. é€šå¥¸, å©šå¤–æ€§è¡Œä¸º\n- adulterer å¥¸å¤«, é€šå¥¸è€…\n- adulteress å¥¸å¤«\n- adulterous adj. é€šå¥¸çš„, \n\n\n#### allureâ˜¢â˜¢\né¹°çŒï¼ˆfalconryï¼‰åœ¨è‹±å›½å’Œæ¬§æ´²å¤§é™†ä¸€åº¦æä¸ºç››è¡Œã€‚æ‰€è°“é¹°çŒä¹ƒæ˜¯æ”¾é¹°ç‹©çŒï¼Œå³ä½¿ç”¨é¹°ã€éš¼ç­‰æ¥ç‹©çŒçš„ä¸€ç§æ´»åŠ¨ã€‚è¿™ç§é¹°ï¼Œå³çŒé¹°ï¼ˆfalconï¼‰ï¼Œé¡»å…ˆç»è¿‡è€å¿ƒè€Œå¾—æ³•çš„é©¯åŒ–å’Œè®­ç»ƒï¼Œæ–¹èƒ½ç”¨äºé¹°çŒã€‚ç‹©çŒäººå¾€å¾€ç”¨ä¼´æœ‰è‚‰é£Ÿå¹¶ç³»ç€é•¿ç»³çš„ä¸€æŸé²œè‰³ç¾½æ¯›ä½œå¼•è¯±ç‰©å¬å›çŒé¹°ã€‚è¿™ç§å¼•è¯±ç‰©è‹±è¯­å°±ç§°lureã€‚lureçš„ç»ˆæè¯æºä¸ºæ—¥è€³æ›¼è¯­ä¹‹å¤æ³•è¯­è¯loirre 'bait'ï¼ˆè¯±é¥µï¼‰ã€‚åœ¨ç°ä»£è‹±è¯­ä¸­å®ƒé€šå¸¸ç”¨äºè´¬ä¹‰ï¼Œæ³›æŒ‡ä»»ä½•â€œå¼•è¯±ç‰©â€æˆ–â€œè¯±é¥µâ€ï¼Œå¹¶å¼•ç”³ä¸ºâ€œè¯±æƒ‘åŠ›â€æˆ–â€œå¸å¼•åŠ›â€ï¼Œä¹Ÿå¸¸ä½œåŠ¨è¯ç”¨ï¼Œè¡¨ç¤ºâ€œè¯±æƒ‘â€æˆ–â€œå¼•è¯±â€ã€‚ä½œä¸ºlureä¹‹åŒä¹‰è¯çš„allureäº§ç”ŸäºåŒä¸€èƒŒæ™¯ã€‚å®ƒæºè‡ªå¤æ³•è¯­alurerï¼Œç”±a 'to'åŠ lure 'falcon's lure'ï¼ˆç‹©çŒäººä¹‹è¯±é¥µï¼‰æ„æˆã€‚è™½ç„¶allureå’ŒlureåŸºæœ¬åŒä¹‰ï¼Œä¹Ÿè¡¨ç¤ºâ€œè¯±æƒ‘â€ã€â€œå¼•è¯±â€å’Œâ€œè¯±æƒ‘åŠ›â€ï¼Œä½†ä¸€èˆ¬ä¸å«è´¬ä¹‰ã€‚\n\nä¾‹ \n- Rewards **allure** men to brave danger. é‡èµä¹‹ä¸‹å¿…æœ‰å‹‡å¤«ã€‚\n- Even in her fifties she had lost none of her seductive **allure**. å¥¹è™½å¹´è¿‡åŠç™¾ï¼Œä½†é£éŸµçŠ¹å­˜ã€‚\n- Most newspaper journalists find it hard to resist the **allure** of working in television. å¤§å¤šæ•°æŠ¥çº¸è®°è€…å‘ç°å¾ˆéš¾æŠ—æ‹’åœ¨ç”µè§†å°å·¥ä½œçš„å¸å¼•åŠ›ã€‚\n- He was **lured** into the job by the offer of a high salary. ä»–å—é«˜è–ªè¯±æƒ‘æ‰æ¥å—äº†é‚£ä»½å·¥ä½œã€‚\n\n- alluring =\u003e attractive or exciting\n\t- She was wearing a most alluring dress at Sam's dinner party.\n- allurement\n\nä¸è¦å’Œ allude å¼„æ··äº†\n\n\n#### menaceâ˜¢\nå¨å“, ä»¥å–Šå«å¨èƒçš„æ–¹å¼é©±èµ¶ç‰²ç•œ\nå¤ä»£äººæ”¾ç‰§ã€é©±èµ¶ç‰²ç•œæ—¶æ¯”è¾ƒç²—æš´ç®€å•ï¼Œé€šå¸¸é€šè¿‡å–Šå«ã€å¨èƒæˆ–é­æ‰“çš„æ–¹å¼æ¥é©±èµ¶ç‰²ç•œï¼Œè¿™ç§æ–¹å¼åœ¨æ‹‰ä¸è¯­ä¸­å«åšminareï¼Œè¿›å…¥æ³•è¯­åæ‹¼å†™ä¸ºmenerã€‚è‹±è¯­å•è¯menaceï¼ˆå¨èƒï¼‰å°±æ¥æºäºæ­¤ï¼Œæœ¬æ„æŒ‡çš„æ˜¯é©±èµ¶ç‰²ç•œæ—¶äººæ‰€å‘å‡ºçš„å«å–Šå£°ã€å¨èƒå£°ï¼Œå…¼æœ‰â€œå¨èƒâ€å’Œâ€œé©±ç­–â€çš„å«ä¹‰ã€‚åæ¥â€œé©±ç­–â€çš„å«ä¹‰é€æ¸æ¶ˆå¤±ï¼Œä»…ä»…è¡¨ç¤ºâ€œå¨èƒã€æå“â€ï¼Œå˜æˆäº†threatençš„åŒä¹‰è¯ã€‚\nmenaceï¼š['menÉ™s] n.v.å¨èƒï¼Œæå“\nminaciousï¼š [mÉª'neÊƒÉ™s] adj. å¨å“çš„\nminatoryï¼š['mÉªnÉ™,tÉ™ri] adj. æå“çš„ï¼Œå¨èƒçš„\n\n#### amenableâ˜¢â˜¢\nè¿˜æœ‰ä¸€ä¸ªå•è¯ä¹Ÿæ¥æºäºæ­¤ï¼Œé‚£å°±æ˜¯amenableï¼Œç”±aï¼ˆ=toï¼Œé¢å¯¹ï¼‰+menerï¼ˆé©±èµ¶ã€é¢†å¯¼ï¼‰+ableï¼ˆèƒ½å¤Ÿï¼‰ï¼Œå­—é¢æ„æ€å°±æ˜¯â€œèƒ½å¤Ÿé¢å¯¹é¢†å¯¼â€ï¼Œå¼•ç”³ä¸ºâ€œé¡ºä»çš„ã€æ˜“äºç®¡æ•™ã€æ˜“äºå±ˆæœã€å®¹æ˜“è¢«è¯´æœçš„â€ï¼Œè¿˜å¯ä»¥è¡¨ç¤ºâ€œè´Ÿæœ‰è´£ä»»çš„ã€ç»å¾—èµ·æ£€éªŒçš„â€ã€‚è¦æ³¨æ„è¿™ä¸ªè¯ä¸amendï¼ˆæ”¹å–„ï¼‰å¹¶æ²¡æœ‰å…³ç³»ã€‚\namenableï¼š[É™'miËnÉ™b(É™)l] adj.é¡ºä»çš„ï¼Œè‚¯æ¥å—çš„ï¼›è´Ÿæœ‰è´£ä»»çš„ï¼›ç»å¾—èµ·æ£€éªŒçš„\npromenadeï¼š[,prÉ‘mÉ™'ned] v. æ•£æ­¥ï¼Œæ¼«æ­¥ï¼›éª‘é©¬ n. æ•£æ­¥ï¼›èˆä¼šï¼›éª‘é©¬ adj. æ•£æ­¥çš„\n\n\n#### ancillary\nancilla + ary\nancilla =\u003e Latin \"handmaid\" å¥³ä½£çš„, ä¹Ÿå°±æ˜¯å‹¤æ‚äººå‘˜çš„æ„æ€, å¼•ç”³ä¸º\"é™„å±çš„, é™„åŠ çš„, è¾…åŠ©çš„\"\n\n#### apparition\napparitionï¼ˆå¹½çµï¼‰ï¼šè€¶ç¨£åŸºç£ä»¥å©´å„¿å½¢æ€è¯ç”Ÿ\nè‹±è¯­å•è¯ apparition æ¥è‡ªæ‹‰ä¸è¯­ apparitionemï¼Œæ˜¯åŠ¨è¯ apparereï¼ˆappearï¼Œæ˜¾ç°ï¼‰çš„è¿‡å»åˆ†è¯åŠ¨åè¯å½¢å¼ï¼Œæœ¬æ„å°±æ˜¯â€œæ˜¾ç°â€ã€‚è¿™ä¸ªè¯æœ€åˆç”¨äºå®—æ•™åœºåˆï¼Œè¡¨ç¤ºâ€œåŸºç£æ˜¾ç°â€ï¼Œå³è€¶ç¨£åŸºç£ä»¥å©´å„¿çš„å½¢æ€è¯ç”Ÿã€‚æ®ã€Šåœ£ç»â€¢æ–°çº¦ã€‹è®°è½½ï¼Œè€¶ç¨£è¯ç”Ÿæ—¶ï¼Œä¸œæ–¹ä¸‰åšå£«åœ¨è§‚æ˜Ÿæ—¶å‘ç°å¼‚è±¡ï¼Œä¾¿ä¸€è·¯å‘è¥¿å‰æ¥æ‹œè§â€œçŠ¹å¤ªäººçš„ç‹â€ï¼Œæœ€åè§åˆ°äº†åˆšå‡ºä¸–çš„è€¶ç¨£ï¼Œå‘ä»–çŒ®ä¸Šäº†ä¸‰ä»¶å®ç‰©ä¸ºç¤¼ã€‚ä¸ºäº†çºªå¿µè€¶ç¨£åŸºç£çš„æ˜¾ç°ï¼ŒåŸºç£æ•™å¾’å°†è€¶ç¨£è¯ç”Ÿä¹‹æ—¥å®šä¸ºâ€œä¸»æ˜¾èŠ‚â€ï¼ˆEpiphanyï¼‰ã€‚å•è¯ epiphany çš„æœ¬æ„å’Œ apparition ä¸€æ ·ï¼Œéƒ½è¡¨ç¤ºâ€œåŸºç£æ˜¾ç°â€ï¼Œä½†å¸¸å¸¸ç”¨æ¥è¡¨ç¤ºâ€œä¸»æ˜¾èŠ‚â€ã€‚è€Œ apparition ä¸€è¯çš„å®—æ•™è‰²å½©é€æ¸æ¶ˆé€€ï¼Œå¸¸å¸¸ç”¨æ¥è¡¨ç¤ºå¹½çµé¬¼æ€ªçš„æ˜¾ç°ã€‚\n- apparitionï¼š[,Ã¦pÉ™'rÉªÊƒÉ™n] n. å¹½çµï¼Œå¹»å½±ï¼Œç¦»å¥‡å‡ºç°çš„ä¸œè¥¿\n- epiphanyï¼š[Éª'pÉªfÉ™ni] n. ä¸»æ˜¾èŠ‚ï¼Œæ˜¾ç°\n\nappearance å’Œ apparition çš„è¯æ ¹ç›¸åŒ, ä¹Ÿéƒ½è¡¨ç¤º\"å‡ºç°\", ä½†æ˜¯ apparition è¡¨ç¤ºä»¤äººæƒŠè®¶çš„, unexpected çš„æ˜¾ç°, æ‰€ä»¥é€šå¸¸ç”¨æ¥æŒ‡é¬¼çµçš„æ˜¾ç°, è€Œ appearance åˆ™ç”¨æ¥æŒ‡ä¸€èˆ¬çš„å‡ºç°äº†\n\n#### attest\nat- =\u003e to\ntest =\u003e è¯æ˜ \nto test, to bear witness to =\u003e prove, affirm, confirm, testify\n\n##### test-\n- è‹±è¯­è¯æ ¹ testi-è¡¨ç¤ºâ€œä½œè¯â€ï¼Œå¦‚ testifyï¼ˆä½œè¯ã€è¯æ˜ï¼‰ã€testamentï¼ˆåœ£çº¦ï¼‰ã€testimonyï¼ˆè¯è¨€ã€è¯æ®ï¼‰ã€‚è¿™ä¸ªè¯æ ¹æ¥è‡ªæ‹‰ä¸è¯­ testisï¼ˆç¾ä¸¸ï¼‰ï¼Œä¸å•è¯ testicleï¼ˆç¾ä¸¸ï¼‰åŒæºã€‚ç¾ä¸¸å’Œä½œè¯æœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿæœ‰ç§è¯´æ³•è®¤ä¸ºï¼Œç¾ä¸¸æ˜¯ç”·æ€§ç‰¹å¾çš„è¯æ˜ï¼Œæ‰€ä»¥åŸæœ¬è¡¨ç¤ºç¾ä¸¸çš„ testis ä¾¿è¡ç”Ÿå‡ºâ€œè¯æ˜â€ä¹‹æ„ã€‚è¿˜æœ‰äººè®¤ä¸ºï¼Œå¤ä»£ç½—é©¬äººåœ¨æ³•åº­ä¸Šä½œè¯æ—¶ï¼Œä¼šç”¨æ‰‹æ§ç€ç¾ä¸¸ä»¥è¡¨ç¤ºè‡ªå·±æ‰€è¯´çš„åƒçœŸä¸‡ç¡®ã€ç»æ— è™šè¨€ã€‚\n- ä½†æ˜¯ï¼Œä¸å°‘è¯æºå­¦å®¶è®¤ä¸ºè¿™ä¸€ç†ç”±ç¼ºä¹æ ¹æ®ï¼Œå±äºä¼ è¯´ã€‚ä¸ç®¡æ€æ ·ï¼Œè¯æ ¹ testi-ä¸ testicleï¼ˆç¾ä¸¸ï¼‰åŒæºï¼Œè¿™ä¸ªæ•…äº‹æœ‰åŠ©äºæˆ‘ä»¬è®°å¿†è¿™äº›å•è¯ã€‚\ntestifyï¼š['testÉªfaÉª] v. ä½œè¯ï¼Œè¯æ˜ï¼Œè¯å®\ntestimonyï¼š['testÉªmÉ™nÉª] n. è¯è¯ï¼Œè¯è¨€ï¼Œè¯æ®\ntestamentï¼š['tÉ›stÉ™mÉ™nt] n. åœ£çº¦ï¼Œç¡®å®çš„è¯æ˜\ntesticleï¼š['testÉªk(É™)l] n. ç¾ä¸¸\ntesticularï¼š[tÉ›s'tÉªkjÊŠlÉš] adj. [è§£å‰–] ç¾ä¸¸çš„ï¼›ç¾ä¸¸çŠ¶çš„\n\n\n#### awry\na-  =\u003e è¡¨ç¤ºåŠ å¼º\nwry =\u003e wring, è¡¨ç¤º\"æ‹§, æ‰­\", \n\"æ‰­\"æ›²çš„, crooked, æ­ªçš„, =\u003e å¼•ç”³ä¸º \"å‘å±•æ–¹å‘ç¦»å¼€é¢„æœŸè·¯çº¿çš„, å‡ºé”™äº†çš„\"\n\n\n#### bonhomie\nbon =\u003e æ³•è¯­, å¥½çš„\nhom =\u003e hum , è¡¨ç¤º \"äºº\", human\n\nå¥½äºº =\u003e å’Œè”¼çš„, æ€§æƒ…æ¸©å’Œçš„\n\n\n#### bootless\nboot =\u003e æ•ˆç”¨, å¯ä»¥è¿™æ ·è®°å¿†: boot æœ‰å¯åŠ¨è®¡ç®—æœº, çŒ›è¸¢ä¸€è„šçš„æ„æ€, è€Œ bootless å°±æ˜¯\"æ²¡æœ‰ç”¨çš„, æ— æ•ˆçš„, å¾’åŠ³çš„\" çš„æ„æ€\n\n#### bound\né™¤äº†\"è¾¹ç•Œ, ç•Œé™\"çš„æ„æ€, å…¶å® bound è¿˜æœ‰ä»¥ä¸‹å«ä¹‰\n\n**be bound to** happen =\u003e very likely to happen\n- You're bound to forget other people's names occasionally\n- These two young musicians **are bound for** international success.\n**I'll be bound** =\u003e æˆ‘æ•¢è‚¯å®š, æˆ‘æ‰“åŒ…ç¥¨\n\nbound è¿˜æ˜¯ bind çš„è¿‡å»å¼, æ‰€ä»¥å°±æœ‰äº†\"æ†, æ “, ç»‘\"çš„æ„æ€, å¼•ç”³ä¸º \"æŸç¼š, æœ‰ä¹‰åŠ¡, å—çº¦æŸ\"çš„æ„æ€, ä¹Ÿå¼•ç”³ä¸ºäº†\"ç´§å¯†ç›¸å…³\"çš„æ„æ€\n- We found the girl **bound** and gagged.\n- She feels (duty)-**bound** to tell him everything.\n- The company **is bound by** a special agreement to involve the union in important decisions.\n- We **are** as tightly **bound to** the people we dislike as to the people we love.\n- Economic growth **is** still **bound to** the issues of poverty, social justice and conservation. \n\n-bound =\u003e ... è£…å¸§çš„ä¹¦\na leather-bound book\n\nç”¨äºäº¤é€šå·¥å…·, è¿˜æœ‰ destinated for çš„æ„æ€: going to å»â€¦çš„ï¼›å‡†å¤‡å‰å¾€â€¦çš„ï¼›å¼€å¾€â€¦çš„\n- She was on a plane **bound for** Moscow when she got sick. å¥¹åœ¨å‰å¾€è«æ–¯ç§‘çš„é£æœºä¸Šçªç„¶ç”Ÿç—…äº†ã€‚\n\n#### vogueâ˜¢\na fashion or general liking\n**in vogue**\n- The short hemline(çŸ­çš„è£™å­ä¸‹æ‘† =\u003e çŸ­è£™) is very much **in vogue** this spring.\n\n\n#### debunk\n##### bunk\nbunk æœ‰ä¸Šä¸‹é“º, ç«è½¦å§é“ºçš„\"é“º\"çš„æ„æ€, è¯¥è¯å¯èƒ½ç³»ç”± bunkerï¼ˆç®±ï¼‰é€†æ„è€Œæˆ.\nè€Œ bunk å¦ä¸€ä¸ªå«ä¹‰\"nonsense\"åˆ™æœ‰ä¸ªæ•…äº‹:\n- è‹±è¯­å•è¯ bunk æºè‡ªç¾å›½åŒ—å¡ç½—æ¥çº³å· Buncombe å¿çš„åç§°ã€‚1820 å¹´ 2 æœˆ 25 æ—¥ï¼Œåœ¨ç¾å›½ç¬¬ 16 å±Šå›½ä¼šä¸Šï¼Œå—åŒ—åŒæ–¹è®®å‘˜å°±å¥´éš¶åˆ¶é—®é¢˜è¿›è¡Œäº†æ¿€çƒˆè®¨è®ºã€‚åœ¨ä¼šè®®ä¸­ï¼ŒåŒ—å¡ç½—æ¥çº³å· Buncombe å¿è®®å‘˜è´¹åŠ›å…‹æ–¯â€¢æ²ƒå…‹å‘è¡¨äº†å†—é•¿çš„è®²è¯ï¼Œå¹¶ä¸”ä¸è®¨è®ºçš„é—®é¢˜æ¯«ä¸ç›¸å…³ã€‚è®¸å¤šä¸ä¼šè€…çº·çº·é€€åœºã€‚ä½†æ²ƒå…‹ä¸è‚¯ç¼©çŸ­è‡ªå·±çš„è®²è¯ã€‚ä»–è§£é‡Šè¯´ï¼Œä»–è¿™ç•ªé•¿ç¯‡æ¼”è®²ä¸æ˜¯è¯´ç»™å¤§ä¼šå¬çš„ï¼Œè€Œæ˜¯è¯´ç»™ä»–çš„å®¶ä¹¡ Buncombe å¬çš„ï¼ˆtalking to Buncombeï¼‰ï¼Œä¸ºçš„æ˜¯ä½¿è‡ªå·±çš„è®²è¯å†…å®¹èƒ½å¤Ÿå‘è¡¨åœ¨ Buncombe å½“åœ°æŠ¥çº¸ä¸Šï¼Œä»¥è¯æ˜è‡ªå·±çš„å‹¤å‹‰å·¥ä½œã€‚\n- å› æ­¤ï¼Œtalking to Buncombe å°±æˆäº†â€œtalking nonsense, ä½œç©ºæ´å†—é•¿çš„æ¼”è®²â€çš„ä»£åè¯ï¼Œåæ¥è¯¥çŸ­è¯­è¢«ç¼©å†™ä¸º bunkumï¼Œåˆ°äº† 20 ä¸–çºªåˆè¿›ä¸€æ­¥ç¼©å‡ä¸º bunkï¼Œè¡¨ç¤ºâ€œåºŸè¯â€ã€â€œç©ºè¯â€ã€‚\n- 1916 å¹´ç¾å›½æ±½è½¦åˆ¶é€ å•†ç¦ç‰¹è¯´äº†ä¸€å¥åè¨€ï¼šâ€œHistory is more or less bunk.â€ï¼ˆå†å²å¤šå°‘æœ‰ç‚¹éª—äººï¼‰ï¼Œä½¿ bunk ä¸€è¯å¾—ä»¥å¹¿ä¸ºæµä¼ ã€‚çº¦åœ¨ 1920 å¹´æœ‰ä¸€ä½åå« William E. Woodward çš„äººé’ˆå¯¹ç¦ç‰¹å†™äº†ã€Šéª—äººçš„é¬¼è¯ã€‹ï¼ˆBunkï¼‰ä¸€ä¹¦ã€‚ä»–åœ¨ä¹¦ä¸­æ® bunk æœæ’°äº† debunk ä¸€è¯ï¼Œç”¨ä»¥è¡¨ç¤ºâ€œæ­ç©¿â€æˆ–â€œæš´éœ²â€ã€‚ä»Šå¤© bunk åœ¨ç¾å›½å‡ ä¹æˆäº†ä¸€ä¸ªå®¶å–»æˆ·æ™“çš„å¸¸ç”¨è¯ã€‚\n\nä¾‹ \n- Most doctors think his theories are sheer bunk.\n- I've heard enough of your bunk. \n\n\n#### calumniate\næ¯è°¤ï¼›æ¶æ„ä¸­ä¼¤ï¼›æ±¡è”‘\n- He has tried to calumniate and destroy everyone whose opinions differ from his. ä»–ä¼šå»æ¶æ„ä¸­ä¼¤å’Œæ‘§æ¯æ‰€æœ‰ä¸ä»–æ„è§ä¸åŒçš„äººã€‚\n\n- cal- \n= to deceive, è¡¨ç¤ºâ€œæ¬ºéª—ï¼ŒæŒ‘åˆºâ€ã€‚æºè‡ªæ‹‰ä¸è¯­ calvi \"to deceive, trick,\" cavilla \"a jeering.\"\n\n- cavil (å¹æ¯›æ±‚ç–µ, æŒ‘å‰”)çš„è¯æ ¹ä¹Ÿæ¥è‡ªè¿™é‡Œ\n\n##### calumny\n/ËˆkÃ¦l.É™m.ni/\n- æ®æœ‰å…³è®°è½½ï¼Œå¤ç½—é©¬äººå¯¹è¯¬é™·è€…æ–½è¡Œä¸€ç§æƒ©æˆ’æ€§åšæ³•ï¼Œå³åœ¨ä»–çš„å‰é¢æ‰“ä¸Š K å­—å°è®°ï¼ŒK è¡¨ç¤º kalumniaï¼Œæ„æ€æ˜¯â€œè¯½è°¤â€ã€‚ä»¥å kalumnia æ¼”å˜ä¸º calumniaã€‚è‹±è¯­çš„ calumny æºè‡ªè¯¥æ‹‰ä¸è¯ï¼Œæ‰€ä»¥æœ‰â€œè¯½è°¤â€ã€â€œè¯¬é™·ä¹‹è¯â€ç­‰ä¹‰ã€‚å…¶æ´¾ç”Ÿè¯ calumniator åˆ™æŒ‡â€œè¯½è°¤è€…â€ã€‚\n- åœ¨ä¸­ä¸–çºªï¼Œä¸€ä¸ªäººå€˜è‹¥é­åˆ°è¯½è°¤ï¼Œå¾ˆå¯èƒ½ä¼šå‘è¯½è°¤è€…æå‡ºæŒ‘æˆ˜ï¼Œè¦æ±‚å†³æ–—ã€‚æ„ä¸ºâ€œæŒ‘æˆ˜â€çš„challengeä¸€è¯ï¼Œè‹¥ç©¶å…¶æ ¹æºï¼Œä¹Ÿå¯ä¸€ç›´è¿½æº¯åˆ°è¿™ä¸ªè¡¨ç¤ºâ€œè¯½è°¤â€çš„æ‹‰ä¸è¯ã€‚è¿™ä¸¤è€…è¢«è”ç³»åœ¨ä¸€èµ·æ˜¯å› ä¸ºå®ƒä»¬ä¹‹é—´å­˜åœ¨ä¸€ç§å› æœå…³ç³»çš„ç¼˜æ•…ã€‚\n\nä¾‹ \n- Calumnies are answered best with silence.\n- He was subjected to the most vicious calumny, but he never complained and never sued.\n\n\n#### cadge\n\"to beg\" (1812), \"to get by begging\" (1848), of uncertain origin, perhaps a back-formation from cadger \"*itinerant dealer with a pack-horse*\" (mid-15c.)\n- åƒè¿™ç§å°è´©éƒ½æ˜¯å¾ˆç¼ äººçš„, æ‰€ä»¥æœ‰äº†\"ä¹è®¨, ç´¢å–\"çš„æ„æ€\n\n#### discharge\ncharge æœ€åŸå§‹çš„æ„æ€æ˜¯\"to load\", dis-charge å°±æ˜¯\"unload, å¸è´§\"çš„æ„æ€\n\n- å¸é™¤åˆ‘ç½š, è„±ç¦»ç–¾ç—… =\u003e å…è®¸ä».. ç¦»å¼€, å‡ºé™¢, é‡Šæ”¾\n- å¸é™¤èŒè´£, ä¹‰åŠ¡ =\u003e å±¥è¡ŒèŒè´£, ä¹‰åŠ¡\n- \"å¸è´§\"å¼•ç”³ä¸º\"æ’æ”¾, æ’å‡º(åºŸæ°”, åºŸç‰©ç­‰)\"\n- \"æ’å‡º\"ä¸€ä¹‰åˆå¼•ç”³åˆ°äº†æ­¦å™¨ä¸Šé¢, æ„æ€æ˜¯\"å¼€ç«, å¼€æª\"(å‘å‡ºå­å¼¹)\n- charge æœ‰\"æ”¶è´¹\"çš„æ„æ€, discharge ä¹Ÿå°±æœ‰äº†\"è¿˜æ¸…å€ºåŠ¡\"çš„æ„æ€\n\n\n\n#### disseminateâ˜¢\ndis- =\u003e åˆ†å¼€, æ•£å¼€\nsemin =\u003e seed, ç§å­\n-ate =\u003eåŠ¨è¯åç¼€\nä½¿ç§å­åˆ†æ•£å¼€æ¥ =\u003e å¼•ç”³ä¸ºæ•£å¸ƒ, ä¼ æ’­(ä¿¡æ¯, æ€æƒ³)\n- They disseminated anti-French propaganda\n\n##### semin-\n- semen ç²¾æ¶²\n- seminal ç²¾æ¶²çš„ =\u003e å¼•ç”³ä¸º å…·æœ‰æ·±è¿œå½±å“åŠ›çš„, influential, ground-breaking, \n- inseminate =\u003e ä½¿å—ç²¾, ä½¿å—å­•\n- seminar =\u003e ä¹Ÿè®¸æ˜¯\"åŸ¹å…»ç§å­äººæ‰\"çš„ç ”è®¨ä¼šçš„æ„æ€?\n\n#### exacerbate\nex- =\u003e å‘å¤–, å‘ä¸Š, here probably thoroughly\nacerb =\u003e acid- acri- acu- å°–, é…¸, é”åˆ©, sour, sharp\n-ate =\u003e åŠ¨è¯åç¼€\n\nè¿›ä¸€æ­¥(å®Œå…¨åœ°)å‰²å…¥, è¿›ä¸€æ­¥(ç”¨é…¸)è…èš€ =\u003e ä½¿åŸæœ¬å°±ååœ°æƒ…å†µæ¶åŒ–, åŠ å‰§\n\n- This attack will **exacerbate** the already tense relations between the two communities.\n\n#### explicate\nå¯ä»¥å’Œ complicate ä¸€èµ·è®°å¿†:\nplic- =\u003e æºè‡ªæ‹‰ä¸è¯­\"plicare\" to bend, to fold\nex- =\u003e å‘å¤–, \n-ate =\u003e åŠ¨è¯åç¼€, ä½¿....\n- ex-æ˜¯å‘å¤–, explicate å°±æ˜¯\"å±•å¼€\", ä¹Ÿå°±æ˜¯ **(å±•å¼€æ¥)è¯¦ç»†è§£é‡Š, åˆ†æ**\n- è€Œ com-æ˜¯\"ä¸€èµ·\", å°†ä¸åŒçš„ä¸œè¥¿ä¸€èµ·å¼¯æ›²æŠ˜å , ä¹Ÿå°±æ˜¯å°†å…¶å˜å¾—å¾ˆå¤æ‚\n\n**implicate**\n- è¿˜æœ‰ä¸ª implicate, im- =\u003e åœ¨å†…, ä¹Ÿå°±æ˜¯å°†... åŒ…åœ¨é‡Œé¢, ä¸æ”¾åœ¨è¡¨é¢ä¸Š =\u003e æš—ç¤º, ç‰µæ¶‰, ç‰µè¿\n\n#### extricateâ˜¢â˜¢\nè¿™ä¸ªä¹Ÿå¯ä»¥å’Œ\"intricate\"ä¸€èµ·è®°å¿†\n- ex- =\u003e å‘å¤–, ä» ... ç¦»å¼€\n- tric-, trig-  =\u003e hindrance, petty obstacles éšœç¢\n- -ate\nç›´æ¥çš„ç†è§£å°±æ˜¯\"å°†..ä»éšœç¢, å›°éš¾é‡Œé¢ç§»å‡ºæ¥\" =\u003e **è§£æ•‘, ä½¿æ‘†è„±**\n\n**intricate** å°±æ˜¯\"è¿›å…¥éšœç¢, å›°å¢ƒ\" =\u003e å¼•ç”³ä¸º adj. é”™ç»¼å¤æ‚çš„, ç²¾å¯†å¤æ‚çš„\nè¿™é‡Œ-ateå˜æˆäº†å½¢å®¹è¯åç¼€, è¡¨ç¤º \"...çš„\", æ¯”å¦‚\"accurate, intimate\"\n\n\n#### expurgateâ˜¢\nex- å‘å¤–, ä»... ç¦»å¼€ \npurge =\u003e è‚ƒæ¸…, æ¸…é™¤\n-ate =\u003e åŠ¨è¯åç¼€\nto purge =\u003e å¼•ç”³åˆ°æ–‡å­—ä¸Šé¢å°±æ˜¯ åˆ èŠ‚, åˆ é™¤(ä¸æ­£å½“çš„æ–‡å­—)\n\n\n\n#### fad\nfiddle-faddle çš„ç¼©å†™ \nfiddle-faddle æ˜¯\"çæ, èƒ¡é—¹\"çš„æ„æ€(è¿‡æ—¶äº†)\nåæ¥å¼•ç”³ä¸ºäº†\"çŸ­æš‚çš„é£æ½®, ä¸€æ—¶çš„ç‹‚çƒ­\"\n- craze, fashion\n\n\n#### fastidiousâ˜¢â˜¢\n- meticulous å’Œ fastidious éƒ½æ˜¯**æ²¡æœ‰**è´¬ä¹‰çš„, è¡¨ç¤ºä¸¥è°¨, ä¸€ä¸ä¸è‹Ÿçš„\n- è€Œ particular æœ‰\"not easily satisfied\"çš„æ„æ€, (æŒ‘å‰”)\n- fussy åˆ™æ˜¯ä¸€ä¸ªè´¬ä¹‰è¯, è¿‡åˆ†æŒ‘å‰”çš„, éš¾ç¼ çš„\n\n\n#### fecklessâ˜¢â˜¢\n\"effect+less\"çš„ç®€å†™, ç›´è¯‘è¿‡æ¥å°±æ˜¯\"æ²¡æœ‰æ•ˆç”¨çš„\", å¤šç”¨äºå½¢å®¹äºº, è¡¨ç¤º\"æ— èƒ½çš„, è½¯å¼±è€Œä¸è´Ÿè´£ä»»çš„\"(æ‰€ä»¥ä¸èƒ½äº§ç”Ÿä»»ä½•æ­£å‘çš„ effect)\n- ç±»ä¼¼äº bootless\n\n#### futileâ˜¢\nfrugal =\u003e èŠ‚ä¿­çš„\nfutile =\u003e å¾’åŠ³çš„\n\nfus- fund- =\u003e pour æµ, æ³„\n-ile =\u003e ... çš„ \npouring out easily =\u003e å¼•ç”³ä¸ºå¾’åŠ³çš„, æ— ç”¨çš„\n\n##### fus-\n- confuse =\u003e ä¸€èµ·æµåŠ¨, =\u003e æ··åœ¨äº†ä¸€èµ·, æ··ä¹±çš„ =\u003e å¼•ç”³åˆ°å¿ƒç†ä¸Š, è¿·æƒ‘çš„, ç³Šæ¶‚çš„\n- fuse =\u003e ç†”åŒ–, ç†”è\n- diffuse =\u003e dif- \"apart, in every direction\" å‘å››å‘¨æµ =\u003e æ‰©æ•£, å¼¥æ•£, åˆ†æ•£, æ•£å°„\n- infuse =\u003e å‘å†…æµåŠ¨, =\u003e å……æ»¡, çŒè¾“, æµ¸æ¶¦, æ³¡(èŒ¶) =\u003e ä½¿æŸäººå……æ»¡æŸç§æ„Ÿæƒ…, å°†æŸç§ç‰¹æ€§æ³¨å…¥æŸç‰©\n- suffuse =\u003e suf-: \"under\" =\u003e to pour under, overspread, å¼¥æ¼«äº, å……æ»¡\n\n\n#### indigenous\n**å½“åœ°çš„ï¼ŒåœŸç”ŸåœŸé•¿çš„**\n- endo- è¡¨ç¤ºâ€œå†…éƒ¨â€ã€‚\n- gen-,gener-,genit-,-genesis = birth, produce, è¡¨ç¤ºâ€œå‡ºç”Ÿï¼Œäº§ç”Ÿâ€ï¼ŒåŒ»å­¦ä¸Šå¼•ç”³ä¸ºâ€œç”Ÿæ®–æˆ–åŸºå› â€ã€‚\n- -ous,-itious,-eous,-ious,-uous è¡¨å½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œâ€¦çš„â€\n\n#### indigentâ˜¢\n- endo- è¡¨ç¤ºâ€œå†…éƒ¨â€ã€‚\n- ig- =\u003e lack\n- -ent =\u003e ...çš„\nååˆ†è´«ç©·çš„\n\n#### knotty\nå¤šç»“çš„ =\u003e å¼•ç”³ä¸ºæ£˜æ‰‹çš„, å¤æ‚çš„\na knotty problem\n\n\n#### jocular\njoke çš„å½¢å®¹è¯å½¢å¼\n\n\n#### labyrinthine\næˆ‘ä»¬ä»Šå¤©ç”¨ä»¥æ³›æŒ‡â€œè¿·å®«â€çš„ labyrinth ä¸€è¯åŸæŒ‡ç¥è¯ä¼ è¯´ä¸­çš„å¸Œè…Šå»ºç­‘å¸ˆå’Œé›•åˆ»å®¶ä»£è¾¾ç½—æ–¯ï¼ˆDaedalusï¼‰ä¸ºå…‹é‡Œç‰¹å›½ç‹å¼¥è¯ºæ–¯ï¼ˆMinosï¼‰åœ¨é¦–éƒ½å…‹è¯ºç´¢æ–¯ï¼ˆKnossosï¼‰ç‹å®«ä¸‹é¢æ‰€ä¿®å»ºçš„å…‹é‡Œç‰¹è¿·å®«ï¼ˆthe Cretan labyrinthï¼‰ã€‚\nä¼ è¯´ï¼Œå…‹é‡Œç‰¹å²›çš„å›½ç‹ç±³è¯ºæ–¯ï¼ˆMinosï¼‰æ˜¯å®™æ–¯å’Œæ¬§ç½—å·´å…¬ä¸»çš„å„¿å­ã€‚åœ¨ä»–ä¸å…„å¼Ÿäº‰å¤ºç‹ä½æ—¶ï¼Œæ›¾è¯·æ±‚æµ·ç¥æ³¢å¡å†¬é™ä¸‹ç¥è¿¹æ¥æ”¯æŒä»–ã€‚æ³¢å¡å†¬ç­”åº”äº†ä»–ï¼Œä»æµ·ä¸­å‡å‡ºä¸€å¤´ä¿Šç¾çš„ç™½è‰²å…¬ç‰›ï¼Œå¹¶è¦æ±‚äº‹åæŠŠå…¬ç‰›çŒ®ç¥­ç»™ä»–ã€‚æ²¡æƒ³åˆ°ç±³è¯ºæ–¯å½“ä¸Šå›½ç‹åï¼Œèˆä¸å¾—å®°æ€è¿™å¤´ä¿Šç¾çš„ç™½ç‰›ï¼Œå°±ç”¨å¦ä¸€å¤´ç‰›ä»£æ›¿çŒ®ç¥­ç»™äº†æ³¢å¡å†¬ã€‚æ³¢å¡å†¬ç‰¹åˆ«ç”Ÿæ°”ï¼Œæƒ³ä¸¥æƒ©è¿™ä¸ªæ¬ºéª—ç¥çµçš„å›½ç‹ï¼Œå°±æ–½å±•æ³•åŠ›ï¼Œä½¿ç‹åçˆ±ä¸Šäº†è¿™å¤´ç™½ç‰›ã€‚ç‹ååæ¥ç”Ÿä¸‹äº†ä¸€ä¸ªç‰›å¤´äººèº«çš„æ€ªç‰©ç±³è¯ºé™¶æ´›æ–¯ã€‚ä¸ºäº†é®ç¾ï¼Œç±³è¯ºæ–¯è¯·å½“æ—¶è‘—åçš„å·¥åŒ ä»£è¾¾ç½—æ–¯ï¼ˆDaedalusï¼‰å»ºé€ äº†ä¸€åº§åå« labyrinth çš„è¿·å®«ï¼ŒæŠŠå¼¥è¯ºé™¶æ´›æ–¯ï¼ˆMinotaurï¼‰å…³åœ¨é‡Œé¢ã€‚\nåæ¥å¼¥è¯ºæ–¯çš„å„¿å­è¢«é›…å…¸äººæ‰€æ€ï¼Œå¼¥è¯ºæ–¯ä¸ºäº†æŠ¥ä»‡ï¼Œå¼ºè¿«é›…å…¸äººæ¯å¹´ï¼ˆä¸€è¯´æ¯ä¹å¹´ï¼‰é€ç«¥ç”·ç«¥å¥³å„ä¸ƒåç»™æ€ªç‰©åé£Ÿã€‚åˆ°ç¬¬ä¸‰æ¬¡çŒ®ç‰²çš„æ—¶å€™ï¼Œå¸Œè…Šè‹±é›„é›…å…¸ç‹å­æä¿®æ–¯ï¼ˆTheseusï¼‰è‡ªå‘Šå¥‹å‹‡å‰å¾€å…‹é‡Œç‰¹è¿·å®«é™¤å¦–ã€‚è¿·å®«æ›²å¾„ç¹å¤šï¼Œé—¨æˆ·é€šé“å¤æ‚éš¾è¾¨ï¼Œä¸€è¿›å»ä¸æ˜“æ‰¾åˆ°å‡ºè·¯ã€‚æä¿®æ–¯æ€æ­»æ€ªç‰©åï¼Œåœ¨å¼¥è¯ºæ–¯çš„å¥³å„¿é˜¿é‡Œé˜¿å¾·æ¶…ï¼ˆAriadneï¼‰çš„å¸®åŠ©ä¸‹ï¼Œé å¥¹æ‰€ç»™çš„çº¿å›¢å¼•è·¯ï¼Œæ‰å¾—ä»¥é€ƒç¦»è¿·å®«ã€‚\n\nlabyrinthä¸€è¯æ˜¯14ä¸–çºªè¿›å…¥è‹±è¯­çš„ã€‚å®ƒæºè‡ªå¸Œè…Šè¯­labÃ½rinthos/labÃºrinthosï¼Œè‹¥å†è¿›ä¸€æ­¥è¿½æœ¬æº¯æºï¼Œåˆ™å¯è¿½æº¯è‡³å¸Œè…Šè¯æ ¹lÃ¡brus/lÃ¡brys 'double-bladed axe'ï¼ˆåŒåˆƒæ–§ï¼‰ã€‚æŒ‰å­—é¢ä¹‰ï¼Œlabyrinthä¾¿æ˜¯â€œthe house of the axeâ€çš„æ„æ€ã€‚è‹±å›½è€ƒå¤å­¦å®¶ä¼Šæ–‡æ€ï¼ˆArthur John Evans, 1851-1941ï¼‰äº1900-1908å¹´é—´å‘æ˜äº†å…‹é‡Œç‰¹å²›ä¸Šçš„å…‹è¯ºç´¢æ–¯å¤åŸï¼Œå‡ºåœŸå¤ä»£ç‹å®«é—å€ä¸€å¤„ï¼Œå åœ°5.5è‹±äº©ï¼Œå…¶è§„æ¨¡å®å¤§å£®è§‚ï¼Œç‹å®«å¢™ä¸Šä¾¿å¯è§åˆ°è¿™ç§æ–§å¤´å›¾å½¢ã€‚å…³äºå…‹é‡Œç‰¹è¿·å®«çš„ä¼ è¯´ï¼Œåæ˜ äº†å…¬å…ƒå‰2000å¹´å…‹é‡Œç‰¹å›½çš„ç¹è£ã€‚\n\nä¾‹ \n- We could not find our way out of the labyrinth of dark and narrow streets. æˆ‘ä»¬æ²¡èƒ½ä»è¿·å®«èˆ¬åˆé»‘åˆçª„çš„è¡—é“ä¸­æ‰¾åˆ°å‡ºè·¯ã€‚\n- Finally through a labyrinth of corridors she found his office. (CID) ç©¿è¿‡è¿·å®«èˆ¬çš„èµ°å»Šï¼Œå¥¹ç»ˆäºæ‰¾åˆ°äº†ä»–çš„åŠå…¬å®¤ã€‚\n\nlabyrinthï¼š['lÃ¦b(É™)rÉªnÎ¸] n.è¿·å®«\nlabyrinthineï¼š[,lÃ¦bÉ™'rÉªnÎ¸aÉªn]adj. è¿·å®«çš„ï¼Œé”™ç»¼å¤æ‚çš„\n\n##### clue\nclueï¼ˆçº¿ç´¢ï¼‰ï¼šå¼•å¯¼å¿’ä¿®æ–¯èµ°å‡ºè¿·å®«çš„çº¿å›¢\nå…‹é‡Œç‰¹å›½ç‹ç±³è¯ºæ–¯çš„å„¿å­è¢«é›…å…¸äººæ€å®³ã€‚ç±³è¯ºæ–¯æ›¿å„¿å­æŠ¥ä»‡ï¼Œæ‰“è´¥äº†é›…å…¸äººï¼Œå¼ºè¿«ä»–ä»¬æ¯å¹´ç»™å…¬ç‰›æ€ªç±³è¯ºé™¶æ´›æ–¯è¿›è´¡ä¸ƒå¯¹ç«¥ç”·ç«¥å¥³ã€‚é›…å…¸å›½ç‹åŸƒå‹¾æ–¯ï¼ˆAegeusï¼‰çš„å„¿å­ã€è‹±é›„å¿’ä¿®æ–¯ï¼ˆTheseusï¼‰ä¸ºäº†æ›¿æ°‘é™¤å®³ï¼Œè‡ªæ„¿ä½œä¸ºè´¡å“å‰å¾€å…‹é‡Œç‰¹å²›ã€‚å…‹é‡Œç‰¹å›½ç‹çš„å¥³å„¿é˜¿é‡Œé˜¿å¾·æ¶…ï¼ˆAriadneï¼‰çˆ±ä¸Šäº†å¿’ä¿®æ–¯ï¼Œé€ç»™ä»–ä¸€æŠŠåˆ©å‰‘å’Œä¸€ä¸ªçº¿å›¢ã€‚å¿’ä¿®æ–¯è¿›å…¥è¿·å®«ï¼Œæ‰‹æŒåˆ©å‰‘æ€æ­»äº†å…¬ç‰›æ€ªï¼Œç„¶åé¡ºç€çº¿å›¢åŸè·¯è¿”å›ï¼Œé¡ºåˆ©é€ƒç¦»è¿·å®«ã€‚\nè‹±è¯­å•è¯ clue çš„æ¥æºå°±ä¸è¿™ä¸ªæ•…äº‹æœ‰å…³ã€‚clue åœ¨å¤è‹±è¯­ä¸­æ‹¼ä½œ clewï¼ŒåŸæ„æ˜¯â€œçº¿å›¢â€ã€‚å› ä¸ºå¿’ä¿®æ–¯æ˜¯å‡­å€Ÿçº¿å›¢é€ƒå‡ºè¿·å®«çš„ï¼Œæ‰€ä»¥çº¿å›¢æˆäº†ä»–ç ´è§£è¿·å®«çš„çº¿ç´¢ã€‚ç”±æ­¤ï¼Œå•è¯ clue å°±ä»â€œçº¿å›¢â€å¼•ç”³å‡ºâ€œçº¿ç´¢â€çš„å«ä¹‰ã€‚\n- clueï¼š[kluË] n. çº¿ç´¢ï¼Œæƒ…èŠ‚\n- cluelessï¼š ['klulÉ™s] adj. æ— çº¿ç´¢çš„ï¼›æ„šè ¢çš„\n\n#### lachrymose\nlachrym- =\u003e tear, æ³ª\n- lachrymal adj, çœ¼æ³ªçš„, n. æ³ªè…º\n- lachrymose çˆ±å“­çš„, æ‚²ä¼¤çš„, ä¼¤æ„Ÿçš„\n\nåç¼€ -ose è¡¨ç¤º\"... å¤šçš„\". æ¯”å¦‚\"morose, grandiose, verbose\"\n\n\n#### laconicâ˜¢\nlaconic - å¸Œè…Šä¼¯ç½—å¥”å°¼æ’’åŠå²›ï¼ˆPeloponnesusï¼‰ä¸œå—éƒ¨æœ‰ä¸ªç•œç‰§å±±åŒºå«åš Laconiaï¼ŒåŸä¸ºå¤å¸Œè…Šè‘—åå¥´éš¶åˆ¶åŸé‚¦æ–¯å·´è¾¾ï¼ˆSpartaï¼‰çš„æ‰€åœ¨åœ°ã€‚å¤æ—¶å€™è¯¥åœ°åŒºçš„äººï¼ˆå³ Laconiansï¼‰æ›¾ä»¥è¯´è¯ç®€æ´ã€æªè¾ç²¾ç»ƒè‘—ç§°äºä¸–ã€‚ä»–ä»¬æ¯æ¯ä»¥æœ€å°‘çš„è¯­è¯è¡¨è¾¾è‡ªå·±çš„æ„æ€ã€‚æœ‰ä¸€æ¬¡é©¬å…¶é¡¿å›½ç‹è…“åŠ›äºŒä¸–ï¼ˆPhilip of Macedonï¼‰é€ä¿¡ç»™æ–¯å·´è¾¾è¡Œæ”¿å®˜ï¼Œå¨èƒè¯´ï¼Œâ€œå¦‚æœæˆ‘ä»¬è¿›å…¥ Laconiaï¼Œæˆ‘ä»¬éæŠŠä½ ä»¬çš„åŸå¸‚å¤·ä¸ºå¹³åœ°ä¸å¯ï¼â€ï¼ˆIf we enter Laconia, we will raze it to the ground.ï¼‰å¾—åˆ°çš„å›å¤ç«Ÿç„¶æ˜¯ç®€çŸ­è€Œåˆå«è“„çš„â€œå¦‚æœâ€äºŒå­—ï¼ˆIfï¼‰ã€‚\n\n\n#### lout â˜¢\na young man who behaves in a very rude, offensive, and sometimes violent way.\nä¸è‰¯å°‘å¹´\n\nloutish =\u003e ç²—ä¿—çš„, æ— ç†çš„, ç²—æš´çš„\n\n\n#### madcap â˜¢\nmad + cap\ncapåœ¨è¿™é‡Œç”¨æ¥æ¯”å–»å¤´ =\u003e \"ç–¯å¤´\" =\u003e æ„šè ¢çš„, è’å”çš„, \n\n\n#### mendaciousâ˜¢\nnot telling the truth\n- mend- =\u003e fault, physical defect (æ¯”å¦‚ amend)\n- -acious =\u003e å½¢å®¹è¯åç¼€, å…·æœ‰ ... ç‰¹å¾çš„ (æ¯”å¦‚ capacious, instantaneous, tenacious)\n\n\n#### mishap â˜¢\nmis + hap\nhap =\u003e luck, chance\n- ä¸å¹¸, æ¨¡ä»¿ mischance é€ å‡ºæ¥çš„ä¸€ä¸ªè¯, mischance ä¹Ÿæ˜¯\"ä¸å¹¸\"çš„æ„æ€\n\n#### mottle\n![300](notes/2022/2022.7/assets/illamasqua-mottle-swatch-macro.webp)\n\n#### murky\n![300](notes/2022/2022.7/assets/360_F_327352560_Z6yMt0anWYWTVOnulbml9ZqVLlTlah0z.jpg)\n- dark and dirty and difficult to see through\nå¼•ç”³ä¸ºæƒ…å†µå¤æ‚è€Œä¸æ˜æœ—çš„\næœ‰è¶£çš„æ˜¯, get into the murky water of ... å°±æ˜¯ä¸­æ–‡é‡Œé¢çš„\"è¶Ÿæµ‘æ°´\"çš„æ„æ€\n- I don't want to get into the murky water of family arguments.\n\n#### nascent\nLatin nasci \"to be born\" =\u003e `nasc-`, `nat-`, `nai-` \n- nascent =\u003e nascãƒ»ent =\u003e å‡ºç”Ÿçš„ =\u003e  æ–°ç”Ÿçš„, èŒèŠ½çš„, developing, beginning, dawning, evolving\n- natãƒ»ive\n- naiãƒ»ve\n- natãƒ»al\n- inãƒ»natãƒ»e\n- reãƒ»naissãƒ»ance\n\n#### nexus\n`nect- nex-` =\u003e to bind, tie, connect, è¿ç»“, æºè‡ªæ‹‰ä¸è¯­\"nectere, è¿‡å»åˆ†è¯, **nexus**\"\n\n- connect =\u003e conãƒ»nect\n- nexus =\u003e nexãƒ»us\n- annex =\u003e anãƒ»nex =\u003e åå¹¶, å…¼å¹¶, å¼ºå  basically means \"to connect with\" \n\n#### notch\nV å½¢çš„æ§½ =\u003e å¼•ç”³ä¸ºåˆ»åº¦, ç­‰çº§\n- Average earnings in the economy moved up another **notch** in August\n\n- iPhoneæ‰‹æœºä¸Šé¢çš„åˆ˜æµ·ä¹Ÿå« notch\n![300](notes/2022/2022.7/assets/iphone-x-notch.jpg)\n\n#### onerous\noner- =\u003e load, burden, æ¥è‡ªå¸Œè…Šè¯­onus\n-ous =\u003e ... çš„\n**burdensome, troublesome**, difficult to do or needing a lot of effort\n\n- exonerate =\u003e exãƒ»onerãƒ»ate =\u003e å…é™¤è´Ÿæ‹… =\u003e è¯æ˜... æ— ç½ª, å…é™¤ç½ªè´£, å…é™¤è´£ä»»\n\n#### opineâ˜¢\n**opt-**  =\u003e to choose, from Latin \"opinari\"\n\n- to choose, to have an opinion =\u003e express an opinion, å‘è¡¨æ„è§\n\n- opinion\n- option\n- opt (for, to do..)\n- adopt \n\n\n#### opportuneâ˜¢\nop- =\u003e against, æœ, å¯¹, å‘\nport =\u003e harbor, æµ·æ¸¯, æ¸¯å£\n=\u003e é¢å‘æ¸¯å£çš„ =\u003e (æ—¶é—´)æ–¹ä¾¿çš„, åˆé€‚çš„, æ°å½“çš„, é€‚å®œçš„\n- Would it be opportune to discuss the contract now?\n\n- inopportune\n- opportunity\nè¿˜æœ‰ä¸€ä¸ªå…³äº\"æµ·æ¸¯ port-\"çš„å•è¯æ˜¯ importune \n![importune](#importune)\n\n\n#### ossify\nfrom Latin \"ossis\" =\u003e bone\néª¨åŒ– =\u003e å¼•ç”³ä¸º åƒµåŒ–, ä½¿(æ€ç»´, è¡Œä¸º)å›ºå®šä¸å˜ \n- å˜å¾—å¾ˆç¡¬, åƒéª¨å¤´ä¸€æ ·ç¡¬, æ‰€ä»¥éš¾ä»¥æ”¹å˜, åƒµåŒ–é‡Œé¢çš„\"åƒµ\"ä¹Ÿæ˜¯\"ç¡¬\"çš„æ„æ€\n\n#### paragon\nparagonï¼ˆæ¨¡èŒƒï¼‰ï¼šç”¨æ¥æ£€éªŒé‡‘å­çº¯åº¦çš„è¯•é‡‘çŸ³\nå¤ä»£è¥¿æ–¹äººä¸ºäº†æ£€éªŒé‡‘å­çš„çº¯åº¦ï¼Œå¸¸å¸¸ä½¿ç”¨ä¸€ç§ç”¨çº¹ç†ç»†å¯†çš„æ·±è‰²ç‰çŸ³åšæˆçš„è¯•é‡‘çŸ³ï¼ˆ**touchstone**ï¼‰ã€‚å°†è¦æ£€éªŒçš„é‡‘å­åœ¨è¯•é‡‘çŸ³ä¸Šæ‘©æ“¦ï¼Œå°±å¯ä»¥æ ¹æ®åˆ’ç—•é¢œè‰²æ¥åˆ¤æ–­é‡‘å­çš„çº¯åº¦ã€‚è¿™ç§è¯•é‡‘çŸ³åœ¨æ„å¤§åˆ©è¯­ä¸­è¢«ç§°ä¸ºparagoneï¼Œå®ƒæ¥è‡ªå¸Œè…Šè¯­parakonanï¼Œç”±paraï¼ˆå¹¶åˆ—ã€å¯¹æŠ—ï¼‰+ akoneï¼ˆç£¨çŸ³ï¼‰æ„æˆã€‚è‹±è¯­å•è¯paragonå°±æ¥æºäºæ­¤ï¼Œæœ¬æ„å°±æ˜¯è¿™ç§è¯•é‡‘çŸ³ã€‚å› ä¸ºè¯•é‡‘çŸ³æ˜¯è¡¡é‡ä»·å€¼çš„æ ‡å‡†ï¼Œå› æ­¤è¡ç”Ÿå‡ºâ€œå®Œç¾ä¹‹ç‰©ã€æ¨¡èŒƒâ€ä¹‹æ„ã€‚\nparagonï¼š ['pÃ¦rÉ™g(É™)n] n. å®Œç¾ä¹‹ç‰©ï¼Œæ¨¡èŒƒï¼Œè¯•é‡‘çŸ³ adj. å®Œç¾çš„\n\n![](notes/2022/2022.7/assets/Touchstone.webp)\n\n#### paramount\npara æ„ä¸º\"è¶…è¿‡\", mount è¡¨ç¤º\"å±±é¡¶\", æ¯”å±±é¡¶è¿˜é«˜çš„ =\u003e è‡³é«˜æ— ä¸Šçš„\n\n\n#### paunch\nå¤§è‚šå­, å•¤é…’è‚š, a fat stomach\npaunchy =\u003e æœ‰ paunch çš„\n\n#### perambulateâ˜¢\nper- å‘å‰\nambulate ç§»åŠ¨, æ­¥è¡Œ, èµ°åŠ¨\n=\u003e to walk around for pleasure\n\n\n#### perfervid\nper- å®Œå…¨\nfervid, çƒ­æƒ…çš„, çƒ­å¿±çš„, \n=\u003e very hot, very ardent, enthusiastic, zealous\næ„Ÿè§‰ perfervid è¦æ¯” fervid æ›´å¼ºçƒˆä¸€ç‚¹\n\n##### ferv-\næ¥è‡ªæ‹‰ä¸è¯­, boil, æ²¸, çƒ­, å¸¸å¸¸å¼•ç”³ä¸ºæƒ…æ„Ÿçš„å¼ºçƒˆ, æ¯”å¦‚æ±‰è¯­é‡Œé¢çš„çƒ­æƒ…, çƒ­å¿±, çƒ­çˆ±.\n- æœ‰è¶£çš„æ˜¯, [æ±‰è¯­é‡Œé¢çš„â€œçƒ­çˆ±â€ä¸€è¯æ¥è‡ªè‹±æ–‡çš„ ardently love](https://zh.wikipedia.org/wiki/%E6%8B%89%E4%B8%81%E8%AF%AD)ï¼Œè€Œè¯¥è‹±æ–‡è¯æºè‡ªæ‹‰ä¸è¯­çš„ ardenter amareã€‚è¿™ç§è¯´æ³•åœ¨å¤ä»£æ±‰è¯­ä¸­æ˜¯æ‰¾ä¸åˆ°çš„ã€‚ \n\n- fervent\n- fervid\n- fervor, fervour\n- fervency\n\n#### perspicaciousâ˜¢\næ•é”çš„, æœ‰æ´å¯ŸåŠ›çš„\nå¦‚æœä»å•è¯ç›´æ¥æ¥ç†è§£å°±æ˜¯ \"æœ‰èƒ½çœ‹ç©¿ä¸œè¥¿çš„èƒ½åŠ›çš„\"\n- per- =\u003e å®Œå…¨, è´¯ç©¿, forth, å‘å‰\n- spic- =\u003e to look, see, æ¥ç€æ‹‰ä¸è¯­ specere\n- -acious =\u003e å…·æœ‰... ç‰¹å¾çš„\n\nè¿˜æœ‰ä¸€ä¸ªè¯å¾ˆåƒ: **perspicuous** =\u003e æ¸…æ™°æ˜äº†çš„, æ˜“æ‡‚çš„ â˜¢\n- per- =\u003e å®Œå…¨, è´¯ç©¿, forth, å‘å‰\n- spic- =\u003e to look, see, æ¥ç€æ‹‰ä¸è¯­ specere\n- -uous =\u003e ... çš„\nä»å•è¯ç›´æ¥ç†è§£å°±æ˜¯ \"èƒ½å¤Ÿè¢«ç›´æ¥çœ‹ç©¿çš„\"\n\n- **perspic**acious çš„åè¯æ˜¯ **perspic**acity\n- **perspic**uous çš„åè¯æ˜¯ **perspic**uity\n\n#### pithyâ˜¢\npith =\u003e é«“, æœ¨é«“, éª¨é«“ å¼•ç”³ä¸º \"æ„ä¹‰, ç²¾å\"\npithy å°±æ˜¯\"å‡ç»ƒçš„, ç²¾è¾Ÿçš„\"\n\næœ‰æ„æ€çš„æ˜¯å¥å­å¤–é¢é‚£å±‚ç™½è‰²çš„ä¸œè¥¿ä¸œè¥¿ä¹Ÿå« pith\n- a pithy orange\n\n#### philistine\nphilistineï¼ˆåº¸ä¿—ä¹‹è¾ˆï¼‰ï¼šä»¥è‰²åˆ—çš„æ­»æ•Œè…“åŠ›æ–¯äºº\n- è…“åŠ›æ–¯äººï¼ˆphilistineï¼‰å±…ä½åœ¨ä¸­ä¸œè¿¦å—å—éƒ¨æµ·å²¸çš„å¤æ°‘æ—ï¼Œå…¶é¢†åœŸåœ¨åæ¥çš„æ–‡çŒ®ä¸­è¢«ç§°ä¸ºâ€œè…“åŠ›æ–¯åœ°â€ï¼ˆPalaestinaï¼Œå·´å‹’æ–¯å¦ï¼‰ã€‚è…“åŠ›æ–¯äººæ˜¯ä»¥è‰²åˆ—äººçš„åŠ²æ•Œï¼Œåœ¨åœ£ç»æ—§çº¦ä¸­è¯¦ç»†è®°è½½äº†ä»¥è‰²åˆ—äººå’Œè…“åŠ›æ–¯äººçš„æˆ˜äº‰å’Œæ©æ€¨ã€‚åœ¨ä»¥è‰²åˆ—äººçœ¼ä¸­ï¼Œè…“åŠ›æ–¯äººæ˜¯æ²¡æœ‰ä¿¡ä»°çš„é‡è›®äººï¼Œæ˜¯æ–‡æ˜çš„ç ´åè€…ã€‚\n- 1689 å¹´ï¼Œåœ¨å¾·å›½ä¸€ä¸ªå«åšè€¶æ‹¿ï¼ˆJenaï¼‰çš„åŸå¸‚ä¸­ï¼Œå½“åœ°çš„å¤§å­¦ç”Ÿå’Œå¸‚æ°‘ä¹‹é—´çˆ†å‘äº†ä¸€åœºæ¿€çƒˆçš„å†²çªï¼Œæœ‰æ•°äººåœ¨å†²çªä¸­ä¸§ç”Ÿã€‚äº‹åï¼Œè€¶æ‹¿å¤§å­¦çš„ç‰§å¸ˆåœ¨ä¸€æ¬¡å¸ƒé“ä¸­ï¼Œé’ˆå¯¹è¿™åœºå¤§å­¦ç”Ÿå’Œå¸‚æ°‘ä¹‹é—´çš„å†²çªå‘è¡¨äº†å°–é”çš„è¯„è®ºï¼ŒæŠŠä¸å­¦ç”Ÿä½œå¯¹çš„å¸‚æ°‘æ¯”ä½œåœ£ç»ä¸­ä¸ä»¥è‰²åˆ—äººä½œå¯¹çš„è…“åŠ›æ–¯äººã€‚ä»æ­¤ä»¥åï¼Œäººä»¬ç”¨â€œè…“åŠ›æ–¯äººâ€ï¼ˆphilistineï¼‰æ¥å½¢å®¹é‚£äº›æ²¡æœ‰æ¥å—è¿‡å¤§å­¦æ•™è‚²ï¼Œç¼ºä¹æ–‡åŒ–ä¿®å…»å¹¶é„™è§†æ–‡åŒ–çš„äººã€‚ä»è¿™ä¸ªè¯è¿˜äº§ç”Ÿäº†â€œåº¸ä¿—ä¸»ä¹‰â€ï¼ˆPhilistinismï¼‰ä¸€è¯ï¼Œå­—é¢æ„æ€å°±æ˜¯â€œè…“åŠ›æ–¯äººçš„æ–¹å¼ã€ä¹ æƒ¯ã€ä¸ªæ€§å’Œæ€ç»´æ–¹å¼â€ï¼ŒæŒ‡çš„æ˜¯ä½ä¼°ã€é„™è§†è‰ºæœ¯ã€å®¡ç¾ã€ç²¾ç¥å’Œæ™ºåŠ›çš„æ€åº¦ï¼Œä¹Ÿç§°ä¸ºâ€œåæ™ºä¸»ä¹‰â€ã€‚\n- philistineï¼š ['fÉªlÉªstin] adj. ä¿—æ°”çš„ï¼›æ— æ•™å…»çš„ï¼›è…“åŠ›æ–¯äººçš„ n. ä¿—æ°”çš„äººï¼›ä»‡æ•Œï¼›é—¨å¤–æ±‰\n- Philistinismï¼š['fÉªlÉ™stÉªnzÉ™m] n.åº¸ä¿—ä¸»ä¹‰ï¼Œå®åˆ©ä¸»ä¹‰ï¼Œå¸‚ä¾©ä¸»ä¹‰\n\n\n#### affectation\nbehaviour or speech that is not sincere\nçŸ«æ‰é€ ä½œï¼Œåšä½œï¼Œè£…æ¨¡ä½œæ ·ï¼›å‡è£…\n- She has so many little affectations. \n\tå¥¹èº«ä¸Šæœ‰å¥½å¤šçŸ«æ‰é€ ä½œçš„å°æ¯›ç—…ã€‚ \n\n- å•è¯ **affect** ä¹Ÿæœ‰å¯¹åº”çš„æ„æ€\n\nto pretend to feel or think something, å‡è£…\n- To all his problems she affected indifference. \n\tå¯¹ä»–æ‰€æœ‰çš„é—®é¢˜ï¼Œå¥¹éƒ½è£…ä½œæ¼ ä¸å…³å¿ƒçš„æ ·å­ã€‚\n\nto start to wear or do something in order to make people admire or respect you, ï¼ˆä¸ºå¼•äººæ³¨æ„æˆ–è‡ªæŠ¬èº«ä»·è€Œï¼‰åˆ»æ„ç©¿æˆ´ï¼Œæ•…ä½œ\n- At university he affected an upper-class accent. \n\tåœ¨å¤§å­¦é‡Œä»–æ‹¿è…”æè°ƒå‡è£…ä¸Šæµç¤¾ä¼šå£éŸ³ã€‚\n- He's recently affected a hat and cane. \n\tè¿‘æ¥ï¼Œä»–å¤´ä¸Šæˆ´äº†é¡¶å¸½å­ï¼Œæ‰‹ä¸Šæ‹¿äº†æ ¹æ‹æ–ï¼Œè£…è…”ä½œåŠ¿èµ·æ¥ã€‚\n\n\n\n#### decry\nde- =\u003e å‘ä¸‹, ä»... ç¦»å¼€, ç›¸å, ä½¿ç›¸å\ncry =\u003e å‘¼å–Š\nåç€å‘¼å–Š =\u003e è°´è´£, æŠ¨å‡», condemn, blame, abuse, blast\n\n#### deracinate\nde- =\u003e å½»åº•ç¦»å¼€, å®Œå…¨ç¦»å¼€\nrad-, radic- =\u003e root\n-ate =\u003e åŠ¨è¯åç¼€, ä½¿..., é€ æˆ..\n=\u003e è¿æ ¹æ‹”é™¤, æ ¹é™¤, to pluck up by the roots\n\n##### rad-, radic-\n- radish =\u003e radãƒ»ish =\u003e èåœ\n- radical =\u003e radãƒ»ical =\u003e \"åƒæ ¹ä¸€æ ·çš„\" =\u003e æ ¹æœ¬çš„, åŸºæœ¬çš„ =\u003e è¦æ ¹æœ¬æ”¹å˜éœ€è¦å¾ˆå½»åº•, æ¿€è¿›çš„æ”¹å˜ =\u003e æ¿€è¿›çš„, æ¿€è¿›åˆ†å­  \n- radix =\u003e radixå°±æ˜¯Latinçš„root =\u003e \"æ•°å­—çš„æ ¹\" =\u003e åŸºæ•°\n- eradicate =\u003e eãƒ»radicãƒ»ate =\u003e è¿æ ¹æ‹”èµ·, æ ¹é™¤\n- irradicable =\u003e irãƒ»radicãƒ»able =\u003e ä¸èƒ½æ ¹é™¤çš„\n\n\n#### [æ ¹é™¤, å½»åº•æ¶ˆç­](https://www.writingtips.cc/exterminate-vs-extirpate-vs-eradicate-vs-uproot-vs-deracinate-vs-wipe/)\n**Exterminate** implies utter extinction; it therefore usually implies a killing off.\n\n/Ëˆek.stÉš.peÉªt/\n**Extirpate**Â implies extinction of a group, kind, or growth, but it may carry less an implication of killing off, asÂ _exterminate_Â carries, than one of the destruction or removal of the things essential to survival and reproduction; thus, wolves might beÂ _exterminated_Â by hunting in a particular area, but large carnivores in general areÂ _extirpated_Â by changed conditions in thickly settled regions; a heresy is oftenÂ _extirpated,_Â rather thanÂ _exterminated,_Â by the removal of the leaders from a position of influence; a vice cannot easily beÂ _extirpated_ so long as the conditions which promote it remain in existence.\n\n**Eradicate** stresses the driving out or elimination of something that has taken root or has established itself.\n\n**Uproot**Â differs fromÂ _eradicate_ chiefly in being more definitely figurative and in suggesting forcible and violent methods similar to those of a tempest that tears trees out by their roots.\n\n**Deracinate**Â basically is very close toÂ _uproot_, but in much recent use it denotes specifically to separate (as oneself or one's work) from a natural or traditional racial, social, or intellectual group.\n\n**Wipe**Â (in this sense used withÂ _out_ ) often implies extermination, but it equally often suggests a canceling or obliterating (as by payment, retaliation, or exhaustion of supply).\n\n\n#### discursiveâ˜¢\ndiscursive æœ‰ä¸¤ä¸ªæ„æ€, \"ä¸œæ‹‰è¥¿æ‰¯çš„\"å’Œ\"è®ºè¯çš„\", åˆ†åˆ«å¯ä»¥è¿™æ ·ç†è§£:\n- ä¸œæ‹‰è¥¿æ‰¯çš„\ndis- =\u003e åˆ†å¼€, æ•£å¼€, apart\ncurs =\u003e run, \n-ive =\u003e ... çš„\nåˆ°å¤„è·‘çš„, å‘å››å‘¨è·‘çš„ =\u003e å¼•ç”³ä¸ºè®ºè¯ä¸ç€è¾¹é™…, ä¸œæ‹‰è¥¿æ‰¯\n\n- è®ºè¯çš„, æ¨ç†çš„\n##### discourse\ndis- =\u003e apart\ncourse =\u003e to run\n=\u003e to run about, to run to and fro =\u003e ç±»æ¯”äº¤è°ˆæ—¶å€™ä¸¤ä¸ªäººä¸€æ¥ä¸€å›çš„è¯´è¯\n- discursive å°±æ˜¯ discourse çš„å½¢å®¹è¯, ä¹Ÿå°±æ˜¯\"äº¤è°ˆçš„\", ä¹Ÿè®¸æ˜¯å¤äººè®ºè¯ä¼šé‡‡ç”¨\"å¯¹è¯å¼è®ºè¯\", å°±å¼•ç”³ä¸ºäº†\"è®ºè¯çš„, æ¨ç†çš„\"\n\n##### currere : æµ\ncurrency æ˜¯ current çš„æ´¾ç”Ÿè¯ã€‚æŒ‰å­—é¢ä¹‰ï¼Œcurrent çš„æ„æ€æ˜¯ runningï¼Œè€Œ currency çš„æ„æ€åˆ™æ˜¯ running moneyã€‚å®ƒä»¬æºè‡ªæ‹‰ä¸è¯­åŠ¨è¯ currere 'to run'ï¼ˆæµï¼‰ã€‚è¯¥è¯åŸæŒ‡æ¶²ä½“çš„æµåŠ¨ï¼Œåœ¨ä¸­ä¸–çºªæ‹‰ä¸è¯­ä¸­è½¬æŒ‡ä»ä¸€åœ°æµé€šåˆ°å¦ä¸€åœ°çš„é’±ï¼Œè¿›å…¥å¤æ³•è¯­åå˜ä¸º corirã€‚å…¶å˜åŒ–è¯å½¢ä¹‹ä¸€çš„ currant è¿›å…¥ä¸­å¤è‹±è¯­ï¼Œæœ€åæ¼”å˜ä¸º currentã€‚current åœ¨ç°ä»£è‹±è¯­ç”¨äºâ€œç°æ—¶çš„â€ã€â€œç°è¡Œçš„â€ã€â€œæ°´æµâ€ã€â€œç”µæµâ€ç­‰ä¹‰ï¼Œä½†æ—©åœ¨ 15 ä¸–çºªæ—¶ current ä¹Ÿæœ‰ä¸é‡‘é’±æµé€šç›¸å…³çš„æ„æ€ã€‚æ­¤ä¹‰åæ¥è½¬åˆ°äº† currencyã€‚åœ¨ 17 ä¸–çºªæœ«ï¼Œå½“ currency å¼€å§‹åœ¨è‹±å›½ä½¿ç”¨æ—¶ï¼Œå®ƒä»…æŒ‡ç¡¬å¸ï¼Œå› ä¸ºå½“æ—¶è¿˜æ²¡æœ‰çº¸å¸ã€‚é€šè´§ä¹‹æ‰€ä»¥ç§° currencyï¼Œå› ä¸ºå®ƒæ˜¯ running moneyï¼ˆæµé€šè´§å¸ï¼‰ï¼Œä¹Ÿæ˜¯ the current medium of exchangeï¼ˆæµé€šçš„äº¤æ¢åª’ä»‹ï¼‰ã€‚currency ç”¨äºæ­¤ä¹‰çš„æœ€æ—©æ–‡å­—è®°å½•è§äºç¾å›½æ”¿æ²»å®¶å’Œç§‘å­¦å®¶å¯Œå…°å…‹æ—ï¼ˆBenjamin Franklin, 1706-1790ï¼‰1729 å¹´çš„è‘—ä½œä¸­ã€‚é™¤æŒ‡â€œè´§å¸â€å’Œâ€œé€šè´§â€ä¹‹å¤–ï¼Œcurrency ä¹Ÿå¯è¡¨ç¤ºâ€œæµé€šâ€æˆ–â€œä¼ æ’­â€ã€‚\n\nè‹±è¯­ä¸­æºäºæ‹‰ä¸è¯­åŠ¨è¯ currere çš„è¯è¿˜æœ‰ä¸å°‘ï¼Œè¯¸å¦‚:\n- concurï¼ˆåŸä¹‰ï¼šâ€œæµåˆ°ä¸€èµ·, ä¸€èµ·æµåŠ¨â€ï¼Œä»Šä¹‰ï¼šâ€œåŒæ—¶å‘ç”Ÿâ€æˆ–â€œåŒæ„â€ï¼‰ï¼Œ\n- occurï¼ˆåŸä¹‰ï¼šâ€œæµå‘â€ï¼Œä»Šä¹‰ï¼šâ€œå‘ç”Ÿâ€ï¼‰ï¼Œ\n- recurï¼ˆåŸä¹‰ï¼šâ€œå†æµâ€ï¼Œä»Šä¹‰ï¼šâ€œå¤å‘â€ï¼‰ï¼Œ\n- courseï¼ˆæ°´æµç­‰çš„èµ°å‘ï¼›è¿›ç¨‹ï¼›è¯¾ç¨‹ï¼‰ï¼Œ\n- discourseï¼ˆè¯è¯­ï¼›äº¤è°ˆï¼‰ï¼Œ\n- courierï¼ˆä¿¡ä½¿ï¼‰\nç­‰ç­‰ã€‚\n\nä¾‹ \n- Do you change foreign currency? ä½ ä»¬å…‘æ¢å¤–å¸å—ï¼Ÿ\n- The Euro will eventually replace European national currencies. æ¬§å…ƒå°†æœ€ç»ˆå–ä»£æ¬§æ´²å„å›½è´§å¸ã€‚\n- The word has obtained/attained general currency.\n\tè¯¥è¯å·²ç»å¾—åˆ°æ™®éä½¿ç”¨äº†ã€‚\n\n#### dissembleâ˜¢\næ”¹å†™è‡ªdissimulate \ndis- =\u003e ä¸, apart\nsimul- =\u003e alike, same\n-ate\nä½¿è‡ªå·±å’Œ(çœŸå®çš„æ ·å­)ä¸ä¸€æ ·, =\u003e æ©é¥°, æ©ç›–(çœŸå®åŠ¨æœº, æƒ…æ„Ÿ, çœŸç›¸ç­‰)\n- Henry was not slow to dissemble when it served his purposes\n\n#### effronteryâ˜¢\nåšé¢œæ— è€»ï¼›æ”¾è‚†\nef- =\u003e ex-çš„å˜å½¢, å‘å¤–, å‘ä¸Š\nfront =\u003e forehead, å‰é¢\n-ery =\u003e **åè¯**åç¼€, è¡¨ç¤ºæŸç§æƒ…å†µ\n- ä¸æ˜¯å¾ˆå¥½ç†è§£, ä¸‹é¢æœ‰ä¸¤ä¸ªæ–¹æ³•å¸®åŠ©è®°å¿†:\n\n- For every discussion he comes to the front and argue. How rude!\n- Think: I'm the king, but he stepped ***in front of me***. How dare he be so bold!\n\n- He was silent all through the meal and then had the effrontery to complain that I looked bored!\n\n#### germaneâ˜¢\ngerm- =\u003e ç§å­, seed \ngermane =\u003e having the same parents, from the same seeds, =\u003e åŒç±»çš„ä¸œè¥¿æƒ³å¿…å…³ç³»å¯†åˆ‡ =\u003e å…³ç³»å¯†åˆ‡çš„, ç´§å¯†ç›¸å…³çš„(é€šå¸¸ç”¨äº ideas and information)\n- Her remarks could not have been more germane to the discussion.\n\n#### inveighâ˜¢\nin- =\u003e in, è¿›å…¥\nveigh =\u003e to carry, è¿è¾“\n=\u003e ç›´è¯‘å°±æ˜¯\"è¿è¿›æ¥\", \"æŠ¨å‡», ç—›æ–¥\"çš„æ„æ€æ˜¯ç”± invective ä¸€è¯å¸¦æ¥çš„, \"æŠŠ(åè¯)è¿è¿›æ¥\" =\u003e çŒ›çƒˆæŠ¨å‡», ç—›éª‚\n\ninvective =\u003e noun. criticism that is very forceful, unkind, and often rude\n\n\n#### jettison\nto throw overboard, åŸæŒ‡åœ¨èˆ¹åªé‡é™©çš„æ—¶å€™, å°†èˆ¹ä¸Šçš„è´§ç‰©ä¸¢å¼ƒåˆ°æµ·ä¸­å‡è½»é‡é‡, \"ç´§æ€¥æ—¶åˆ»ä¸¢å¼ƒèˆ¹, é£æœºä¸Šé¢çš„è´§ç‰©æ¥å‡è½»é‡é‡\" =\u003e å¼•ç”³ä¸º\"å°†... ä¸¢å¼ƒ, æ”¾å¼ƒ(æŸä¸ªè®¡åˆ’æˆ–æƒ³æ³•)\", \n\n#### lamentable\nlamentæ˜¯å“€æ‚¼, æ‚²å¹çš„æ„æ€, lamentableç›´æ¥ç†è§£å°±æ˜¯\"è®©äººæ„Ÿåˆ°æ‚²ä¼¤çš„, è®©äººå“€æ‚¼çš„\", ç°åœ¨é€šå¸¸æŒ‡ä¸€ä¸ªæƒ…å†µå¤ªç³Ÿç³•äº†, ç³Ÿç³•åˆ°è®©äººæœ‰ç‚¹ç”Ÿæ°”, åº”è¯¥æ”¶åˆ°è°´è´£çš„ç³Ÿç³•, \"å¯æ‚²çš„\",  regrettable, distressing, tragic, \n\n\n#### mangyâ˜¢\nmange æ˜¯å®¶ç•œçš„ä¸€ç§çš®è‚¤ä¼ æŸ“ç—…, ç—‡çŠ¶åŒ…æ‹¬ç˜™ç—’, è„±æ¯›, çš®è‚¤ç²—ç³™, æ°´æ³¡\n\"ç–¥ç™£\", mangyå°±æ˜¯\"å¾—äº†mangeçš„\"\n\nåˆå› ä¸ºé•¿äº†è¿™ç§ç™£çš„åŠ¨ç‰©å°±å˜å¾—å¾ˆä¸‘, å¾ˆè„ =\u003e å¼•ç”³ä¸º dirty, old, shabby çš„ä¸œè¥¿\n\nä¸è¦å’Œmingyææ··äº†, mingyæ˜¯å°æ°”çš„, åå•¬çš„çš„æ„æ€, ä¹Ÿç”¨äºå½¢å®¹æ•°é‡å°‘å¾—å¯æ€œçš„\n\n\n#### nip\n- å»ä¸€ä¼šå„¿(æŸä¸ªåœ°æ–¹) e.g. nip to the shop\n- è½»å’¬, è½»æ\n\n- ä¸€ç‚¹ç‚¹(çƒˆæ€§é…’) =\u003e å¤§æ¦‚æ˜¯å› ä¸ºé‚£ç§çŒ›çš„ä¸€ä¸‹ç«è¾£è¾£çš„æ„Ÿè§‰å’Œ nip çš„åŠ¨ä½œå¾ˆåƒ\n\n##### a nip (in the air)\nç”¨æ¥å½¢å®¹å¯’å†·, å¤§æ¦‚æ˜¯å› ä¸ºå†·é£åœ¨è„¸ä¸Šçš„åˆºç—›æ„Ÿä¹Ÿå’Œnipçš„åŠ¨ä½œå¾ˆåƒå­\næ±‰è¯­æ˜¯\"åˆºéª¨\", è‹±è¯­æ˜¯\"å’¬è„¸\"ğŸ¤£\n- You can tell the winter's on its way - there a real nip in the air in the morning\n\n##### to nip something in the bud\næŠŠ....æ‰¼æ€åœ¨èŒèŠ½çŠ¶æ€ =\u003e è¿™ä¸ªçŸ­è¯­å’Œæ±‰è¯­é‡Œé¢çš„ç»“æ„å‡ ä¹ä¸€æ · \"æŠŠ...çš„èŠ½/èŠ±è‹ææ‰\"\n\n\n#### perniciousâ˜¢\nper- =\u003e completely å®Œå…¨çš„, e.g. perfect, permanent\nnic- =\u003e hurt, poison, ä¼¤å®³, æ¯”å¦‚ innocent, innocuous\n-ious =\u003e ... çš„, å½¢å®¹è¯åç¼€\n=\u003e \"å®Œå…¨ä¼¤å®³çš„\" =\u003e æå…¶æ¶åŠ£çš„, æå…¶æœ‰å®³çš„, very harmful, wicked\n\n##### noc-, nox- â˜¢\n- innocent =\u003e inãƒ»nocãƒ»ent =\u003e æ²¡æœ‰ç½ªçš„ =\u003e æ— ç½ªçš„, æ— è¾œçš„, å¤©çœŸçš„\n- innocuous =\u003e inãƒ»nocãƒ»uous =\u003e æ— æ¯’çš„ =\u003e æ— å®³çš„\n- nocuous =\u003e æœ‰å®³çš„\n- obnoxious =\u003e obè¡¨ç¤ºå¼ºè°ƒ =\u003e æœ‰å®³çš„ =\u003e ä»¤äººè®¨åŒçš„, å¯æ†çš„\n- noxious =\u003e æœ‰æ¯’çš„\n\n#### phenomenal\néå‡¡çš„, æ°å‡ºçš„, remarkable\nå…¶å® phenomenon é™¤äº†\"ç°è±¡\"è¿™ä¸ªå«ä¹‰ä»¥å¤–, è¿˜æœ‰\"ä¸åŒå¯»å¸¸çš„äº‹ç‰©\"çš„å«ä¹‰, è¿™ä¸¤ä¸ªä¹‹é—´çš„è”ç³»å¯èƒ½æ˜¯ phenomenon æ‰€æè¿°çš„ç°è±¡æœ¬æ¥å°±æ˜¯ unusual å’Œ interesting çš„\n\n\n#### magpieâ˜¢\nå–œé¹Š\n![](notes/2022/2022.7/assets/index.jpg)\n##### pied\nå› ä¸ºå–œé¹Šçš„ç¾½æ¯›é¢œè‰²æ˜¯é»‘ç™½ç›¸é—´çš„, æ‰€ä»¥piedå°±æœ‰äº†\"æ‚è‰²çš„, (é»‘ç™½)æ··è‰²çš„\"çš„æ„æ€\n\n##### piebald\nbald å¤æ—¶ä¹Ÿæœ‰\"æ–‘é©³çš„\"å«ä¹‰, ä¸¤è€…ç›¸ç»“åˆ, ä»ç„¶è¡¨ç¤º\"æœ‰é»‘ç™½èŠ±æ–‘çš„\"çš„å«ä¹‰\n\n#### plummet\nplumb- æ¥ç€ Latin é‡Œé¢çš„ plumbum, è¡¨ç¤º lead, é“…å…ƒç´ \næˆ‘ä»¬çŸ¥é“é“…çš„å¯†åº¦å¾ˆå¤§, plummet å°±æ˜¯\"åƒé“…å—ä¸€æ ·ä¸‹å \" =\u003e to fall very quickly and suddenly, ä¹Ÿç”¨äºæè¿°ä»·æ ¼, æ•°é‡ç­‰æ¦‚å¿µçš„\"æš´è·Œ\"\n\n##### aplomb\n- aplombï¼ˆæ²‰ç€ï¼‰ï¼šåƒé“…å‚é‚£æ ·å¤„äºå‚ç›´çŠ¶æ€\nå¤äººå¾ˆæ—©å°±å‘ç°é“…çš„æ¯”é‡è¾ƒå¤§ï¼Œç‰¹åˆ«é€‚åˆç”¨æ¥ç¡®å®šå‚ç›´çº¿ï¼Œä¸å®¹æ˜“å› ä¸ºé£ã€æ°´æµç­‰åç¦»å‚ç›´æ–¹å‘ï¼Œæ‰€ä»¥åœ¨å»ºç­‘ã€æµ‹æ·±ç­‰é¢†åŸŸå¹¿æ³›ä½¿ç”¨é“…å‚ã€‚è‹±è¯­ä¸­è¡¨ç¤ºâ€œé“…â€çš„å•è¯plumbæ¥è‡ªæ‹‰ä¸è¯­plumbumã€‚å®ƒæ—¢èƒ½è¡¨ç¤ºâ€œé“…â€è¿™ç§ç‰©è´¨ï¼Œè¿˜å¯ä»¥è¡¨ç¤ºâ€œå‚ç›´çš„â€ã€â€œä½¿å‚ç›´â€ç­‰å«ä¹‰ã€‚è‹±è¯­å•è¯aplombç”±aï¼ˆatï¼Œå¤„äºâ€¦â€¦çŠ¶æ€ï¼‰å’Œplombï¼ˆplumbï¼Œå‚ç›´çš„ï¼‰ç»„æˆï¼Œå­—é¢æ„æ€å°±æ˜¯â€œåƒé“…å‚é‚£æ ·å¤„äºå‚ç›´çŠ¶æ€â€ã€‚ç”±äºé“…å‚ä¸æ˜“å—é£æˆ–æ°´æµå½±å“è€Œå·¦å³ä¹±åŠ¨ï¼Œæ‰€ä»¥aplombå¼•ç”³å‡ºâ€œæ²‰ç€ã€æ³°ç„¶è‡ªè‹¥â€çš„å«ä¹‰ã€‚\naplombï¼š[É™'plÉ’m] n. å‚ç›´ï¼Œæ²‰ç€ï¼Œæ³°ç„¶è‡ªè‹¥\nplumbï¼š[plÊŒm] n. é“…å‚ï¼Œå‚ç›´ adj. å‚ç›´çš„ vt. ä½¿å‚ç›´ï¼Œæ¢ç´¢ï¼Œæ¢æµ‹\n\n##### plumber\n- plumberï¼ˆæ°´ç®¡å·¥ï¼‰ï¼šå¤ç½—é©¬äººç”¨é“…åˆ¶ä½œæ°´ç®¡\nåœ¨è‹±è¯­ä¸­ï¼Œè¡¨ç¤ºâ€œæ°´ç®¡å·¥â€çš„å•è¯æ˜¯plumberï¼Œç”±plumbï¼ˆé“…ï¼‰+erï¼ˆäººï¼‰ç»„æˆï¼Œå­—é¢æ„æ€å°±æ˜¯â€œé“…åˆ¶å“å·¥äººâ€ã€‚æ°´ç®¡ä¸é“…åˆ¶å“æœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼ŸåŸæ¥ï¼Œè¿™æ˜¯å› ä¸ºåœ¨å¤ç½—é©¬æ—¶æœŸï¼Œäººä»¬å¹¿æ³›ç”¨é“…æ¥åˆ¶ä½œæ°´ç®¡ã€‚\nå¤ç½—é©¬äººçš„å†¶é‡‘æŠ€æœ¯å·²ç»ç›¸å½“å‘è¾¾ã€‚åœ¨å†¶ç‚¼ç™½é“¶çš„è¿‡ç¨‹ä¸­ï¼Œä»–ä»¬å¾—åˆ°äº†å‰¯äº§å“é“…ã€‚å¤ç½—é©¬äººå‘ç°é‡‘å±é“…å…·æœ‰å¾ˆå¥½çš„ç‰¹æ€§ï¼Œç”¨é“…åˆ¶æˆçš„æ—¥å¸¸å™¨çš¿èƒ½ä¿æŒæŒä¹…å…‰äº®ï¼Œä¸ä¼šåƒé“œå™¨é‚£æ ·äº§ç”Ÿç»¿ç»£ï¼›åœ¨è‘¡è„é…’ä¸­åŠ å…¥é“…ç²‰ä¸ä»…èƒ½å»é™¤è‘¡è„çš„é…¸å‘³ï¼Œè¿˜èƒ½ä½¿é…’å‘³æ›´åŠ é†‡åšï¼›ç”¨é“…ç²‰åšæˆçš„åŒ–å¦†å“èƒ½å¤Ÿè®©å¦‡å¥³çš„çš®è‚¤æ›´ç™½ã€‚å› æ­¤ï¼Œå¤ç½—é©¬äººçš„è´µæ—å¹¿æ³›ä½¿ç”¨é“…åˆ¶å“ï¼Œä¾‹å¦‚ï¼Œä»–ä»¬æŠŠé“…æ¡å¤¹åœ¨æœ¨æ£ä¸­ç”¨äºä¹¦å†™ï¼Œè¿™å°±æ˜¯â€œé“…ç¬”â€ä¸€è¯çš„ç”±æ¥ã€‚ä»–ä»¬è¿˜ä½¿ç”¨é“…åšæˆæ°´ç®¡ï¼Œæ„å»ºäº†å››é€šå…«è¾¾çš„åœ°ä¸‹ç®¡é“ã€‚è¿™äº›ç®¡é“ä¸­å«æœ‰çš„é‡‘å±é“…é€æ­¥æº¶è§£ä¹‹æ°´ä¸­ï¼Œè¢«å–è¿›ç½—é©¬äººçš„èº«ä½“å†…ï¼Œç”šè‡³æ˜¯å­•å¦‡çš„ä½“å†…ã€‚å°±è¿™æ ·ï¼Œä¸€ä»£åˆä¸€ä»£çš„ç½—é©¬äººéƒ½å—åˆ°äº†ä¸¥é‡çš„é“…ä¸­æ¯’ã€‚å¾ˆå¤šç§‘å­¦å®¶è®¤ä¸ºï¼Œé“…ä¸­æ¯’æ˜¯å¤ç½—é©¬å¸å›½ç ´è½çš„é‡è¦åŸå› ä¹‹ä¸€ã€‚\nåœ¨æ‹‰ä¸è¯­ä¸­ï¼Œplumbumè¡¨ç¤ºâ€œé“…â€ï¼Œç”±æ­¤è¡ç”Ÿå‡ºè‹±è¯­å•è¯plumbï¼ˆé“…ï¼‰ã€‚ç”±äºå¤ç½—é©¬çš„ä¸Šä¸‹æ°´ç®¡é“éƒ½æ˜¯ç”¨é“…åˆ¶æˆçš„ï¼Œå› æ­¤å®‰è£…ã€ç»´ä¿®è¿™äº›ç®¡é“çš„å·¥äººåœ¨è‹±è¯­ä¸­å°±è¢«ç§°ä¸ºplumberï¼ˆé“…åˆ¶å“å·¥äººï¼‰äº†ã€‚\nplumbï¼š[plÊŒm] n. é“…ï¼Œé“…å‚ï¼Œå‚ç›´ adj. å‚ç›´çš„ vt. ä½¿å‚ç›´ï¼Œï¼ˆç”¨é“…å‚ï¼‰æ¢æµ‹\nplumberï¼š['plÊŒmÉ™] n.æ°´ç®¡å·¥\nplumbingï¼š['plÊŒmÉªÅ‹]n. é“…å·¥ä¸šï¼Œæ°´ç®¡å·¥ä¸šï¼Œæ°´ç®¡å·¥ä½œ\n\n\n#### ambrosial\nambrosial æ˜¯ ambrosia çš„å½¢å®¹è¯\n##### ambrosia\nåœ¨å¸Œè…Šç¥è¯ä¸­ï¼Œä¼—ç¥é£Ÿç”¨çš„é£Ÿç‰©å«åš ambrosiaï¼Œç¥ä»™ä»¬é£Ÿç”¨åå¯ä»¥æ°¸è‘†ç¾è²Œå¹¶é•¿ç”Ÿä¸è€ã€‚è¯¥è¯ç”± aï¼ˆä¸ï¼‰+mbrotosï¼ˆ=mortosï¼Œæ­»äº¡ï¼‰+åè¯åç¼€-iaï¼Œå­—é¢æ„æ€å°±æ˜¯â€œé•¿ç”Ÿä¸æ­»â€ã€‚è‹±è¯­å•è¯ ambrosia å°±æ¥æºäºæ­¤ã€‚\n- ambrosiaï¼š[Ã¦m'brÉ™ÊŠzÉªÉ™] n. ç¥çš„é£Ÿç‰©ï¼Œç‰¹åˆ«ç¾å‘³çš„é£Ÿç‰©\n- ambrosialï¼š[Ã¦m'brÉ™ÊŠzjÉ™l] adj. ç‰¹åˆ«ç¾å‘³çš„ï¼Œå¯å£çš„ï¼ŒèŠ¬é¦™çš„\n- ambrosianï¼š[Ã¦m'brÉ™uzjÉ™l,-zjÉ™n] adj. ç‰¹åˆ«ç¾å‘³çš„ï¼Œå¯å£çš„ï¼ŒèŠ¬é¦™çš„ï¼›ç¥çš„ï¼Œæ•¬ç¥çš„ï¼Œé€‚ç”¨äºç¥çš„\n\n##### mort- â˜¢\n= death\n- mor-ï¼ˆæ­»äº¡ï¼‰ï¼šæ­»ç¥å¢¨å°”æ–¯\nåœ¨ç½—é©¬ç¥è¯ä¸­ï¼Œæ­»ç¥å«åšå¢¨å°“æ–¯ï¼ˆMorsï¼‰ï¼Œå¯¹åº”äºå¸Œè…Šç¥è¯ä¸­çš„æ¡‘çº³æ‰˜æ–¯ã€‚åœ¨è¥¿æ–¹æ–‡åŒ–ä¸­ï¼Œå¢¨å°“æ–¯å¸¸è¢«æç»˜ä¸ºèº«ç€é»‘è‰²é•¿è¢ï¼Œæ‰‹æŒé•¿æŸ„é•°åˆ€çš„é˜´æ£®è€äººã€‚å¢¨å°“æ–¯çš„åå­— Mors åœ¨æ‹‰ä¸è¯­ä¸­å°±æ˜¯â€œæ­»äº¡â€çš„æ„æ€ï¼Œè‹±è¯­ä¸­è¡¨ç¤ºâ€œæ­»äº¡â€çš„è¯æ ¹ mor-/mort-å°±æ¥æºäºæ­¤ã€‚\n- Mors is often connected to Mars, the Roman god of war; å› ä¸ºç«æ˜Ÿåœ¨è‚‰çœ¼çœ‹æ¥æ˜¯çº¢è‰²çš„, æ‰€ä»¥å¤äººå°†ç«æ˜Ÿçœ‹ä½œ\"ç¾æ˜Ÿ\"\n\n- mortalï¼š['mÉ”Ët(É™)l] adj. å‡¡äººçš„ï¼Œè‡´æ­»çš„ï¼Œæ€»æœ‰ä¸€æ­»çš„ n. äººç±»ï¼Œå‡¡äºº\n- mortalityï¼š[mÉ”Ë'tÃ¦lÉªtÉª] n. æ­»äº¡æ•°ï¼Œæ­»äº¡ç‡ï¼Œå¿…æ­»æ€§\n- immortalï¼š[Éª'mÉ”Ët(É™)l] adj. ä¸æœ½çš„ï¼Œé•¿ç”Ÿä¸æ­»çš„ï¼Œç¥ä»™çš„ n. ç¥ä»™ï¼Œä¸æœ½äººç‰©\n- immortalityï¼š [,ÉªmÉ”r'tÃ¦lÉ™ti] n. ä¸æœ½ï¼›ä¸æœ½çš„å£°åï¼›ä¸ç­\n- moribundï¼š['mÉ’rÉªbÊŒnd] adj. å‚æ­»çš„ï¼Œåœæ»ä¸å‰çš„ n. å‚æ­»çš„äºº\n- morticianï¼š[mÉ”Ë'tÉªÊƒ(É™)n] n. æ®¡è‘¬ä¸šè€…ï¼Œä¸§äº‹æ‰¿åŠäºº\n- mortuaryï¼š['mÉ”ËtjÊŠÉ™rÉª; -tÊƒÊŠ-] n. å¤ªå¹³é—´ adj. æ­»çš„ï¼Œæ‚²å“€çš„\n- mortifyï¼š ['mÉ”rtÉªfaÉª] vt. æŠ‘åˆ¶ï¼›è‹¦ä¿®ï¼›ä½¿â€¦æ„Ÿå±ˆè¾± vi. ç¦æ¬²ï¼›è‹¦è¡Œï¼›çº¦æŸ\n\n###### mortgage\nmortgageï¼ˆæŠµæŠ¼è´·æ¬¾ï¼‰ï¼šä»¥çˆ¶äº²é—äº§ä¸ºæ‹…ä¿çš„è´·æ¬¾\nåœ¨å¤ä»£è¥¿æ–¹ï¼Œå®¶åº­ä¸­çš„é•¿å­åœ¨æ³•å¾‹ä¸Šæ‹¥æœ‰ç»§æ‰¿çˆ¶äº²é—äº§çš„æƒåˆ©ã€‚å¦‚æœé•¿å­éœ€è¦ä¸€å¤§ç¬”é’±ï¼Œè€Œåˆæ— æ³•ä»å…¶çˆ¶äº²é‚£é‡Œè·å¾—ï¼Œä»–å¾€å¾€ä¼šæ‰¾å…¶ä»–äººå€Ÿæ¬¾ã€‚è€Œå…¶ä»–äººä¹‹æ‰€ä»¥æ„¿æ„å€Ÿé’±ç»™ä»–ï¼Œçœ‹ä¸­çš„æ˜¯ä»–çš„é•¿å­ç»§æ‰¿æƒï¼Œç›¸ä¿¡ä»–å°†æ¥ç»§æ‰¿é—äº§åå¯ä»¥å¿è¿˜å€ºåŠ¡ã€‚å€Ÿé’±çš„æ—¶å€™ï¼Œå€Ÿæ¬¾äººä¼šç«‹ä¸‹èª“è¨€ï¼Œç­‰ä»–çˆ¶äº²å»ä¸–ï¼Œä»–ç»§æ‰¿é—äº§åå°±ä¼šå¿è¿˜å€ºåŠ¡åŠå…¶åˆ©æ¯ã€‚è¿™å°±æ˜¯è‹±è¯­å•è¯ mortgage çš„æ¥æºã€‚mortgage ç”± mort å’Œ gage ç»„æˆï¼Œmort è¡¨ç¤ºâ€œæ­»äº¡â€ï¼Œgage è¡¨ç¤ºâ€œèª“è¨€ã€ä¿è¯â€ï¼Œæ‰€ä»¥ mortgage ä¸€è¯çš„å­—é¢å«ä¹‰å°±æ˜¯â€œæ­»äº¡ä¿è¯â€ï¼Œå³ä»¥å…¶çˆ¶äº²çš„æ­»äº¡ï¼ˆç­‰äºé—äº§ï¼‰ä¸ºä¿è¯çš„è´·æ¬¾ã€‚\n- mortgageï¼š ['mÉ”ËgÉªdÊ’] vt.n. æŠµæŠ¼è´·æ¬¾\n\n\n\n#### apprehendâ˜¢\nap- =\u003e to, æœ, å‘, å», æˆ–è€…å¼±åŒ–ä¸ºå¼ºè°ƒ\nprehend- =\u003e to grasp, catch, seize æŠ“ä½\n=\u003e å¼•ç”³åˆ°\"ç²¾ç¥ä¸Š\"å°±æ˜¯ understand fully çš„æ„æ€. \n=\u003e åœ¨ç ´æ¡ˆçš„æ—¶å€™, è­¦å¯Ÿéœ€è¦æ ¹æ®çº¿ç´¢\"apprehend\"æ•´ä¸ªæ¡ˆä»¶, ç„¶åé€®æ•å«Œç–‘äºº, æ‰€ä»¥ apprehend ä¹Ÿæœ‰\"é€®æ•, æ‹˜æ•\"çš„æ„æ€, arrest, catch\n- è€Œ **apprehensive** ç›´æ¥çœ‹å°±æ˜¯ capable of perceiving çš„æ„æ€, åæ¥æ¸æ¸æ¼”å˜ä¸ºäº†\"å¤šè™‘çš„, æƒ´æƒ´ä¸å®‰çš„, too concerned, anxious\"çš„æ„æ€\n\n##### -prehend-â˜¢\nto grasp, catch, seize æŠ“ä½\nåœ¨å½¢å®¹è¯é‡Œé¢æœ€åçš„ d ä¸€èˆ¬ä¼šå˜æˆ s\n- reprehend =\u003e reãƒ»prenend =\u003e ä¸æŠ“ =\u003e æ¨å¼€, å¼•ç”³åˆ°è¨€è¯­ä¸Šå°±æ˜¯\"è°´è´£, ééš¾\"çš„æ„æ€\n- reprehensible =\u003e reãƒ»prehensãƒ»ible =\u003e åº”è¯¥è¢« reprehend çš„, åº”å—è°´è´£çš„\n- comprehend =\u003e comãƒ»prehend =\u003e è¿™é‡Œ com æ„æ€ä¸º\"ä¸€èµ·\", æˆ–è€…è¡¨ç¤ºå¼ºè°ƒ\"completely\", =\u003e å®Œå…¨åœ°ç†è§£, å……åˆ†ç†è§£, é¢†æ‚Ÿ\n- comprehension =\u003e ç†è§£, ç†è§£åŠ›\n- comprehensive =\u003e \"å……åˆ†ç†è§£çš„\" =\u003eå¼•ç”³ä¸º\"å…¨é¢çš„, è¯¦å°½çš„, åŒ…ç½—ä¸‡è±¡çš„\"\n\n##### apprehend? comprehend? What's the difference?\nThe main difference is one of style. *Apprehend* is almost never used in modern spoken English with the meaning â€˜understandâ€™. Itâ€™s old-fashioned, formal and literary in style. In modern (British) English *apprehend* means â€˜arrestâ€™: \n- the police *apprehended* the suspect. \n\n*Comprehend* is more common, but it is used less often than â€˜understandâ€™ in conversation. It is often used where the verb is negative: \n- People do not *comprehend* the complexity of the issue; \n- There are some things that the human mind cannot *comprehend*.\n\n#### astound\nastound æ˜¯ä» astone æ¥çš„, aãƒ»stone ç›´æ¥ç†è§£å°±æ˜¯\"å˜å¾—åƒçŸ³å¤´ä¸€æ ·\", äººåœ¨éå¸¸éœ‡æƒŠçš„æ—¶å€™ä¼š freezed, å‘†ä½, å°±åƒçŸ³å¤´ä¸€æ ·. astound å°±æ˜¯\"ä½¿å…¶å‘†ä½\" =\u003e \"ä½¿éœ‡æƒŠ, ä½¿æƒŠéª‡\"çš„æ„æ€äº† \n\nastounding å°±æ˜¯\"ååˆ†ä»¤äººæƒŠè®¶çš„, ä»¤äººæƒŠéª‡çš„\"çš„æ„æ€, æœ‰ shocked çš„å«ä¹‰åœ¨é‡Œé¢, æ¯” surprised è¦å¼ºçƒˆ.\n\n\n#### broachâ˜¢\næèµ·(æŸä¸ªæ•æ„Ÿçš„æˆ–è€…å›°éš¾çš„è¯é¢˜)\nåŸæ¥çš„æ„æ€æ˜¯\"to pierce\", ç±»ä¼¼äºæ±‰è¯­é‡Œé¢çš„\"æŒ‘æ˜äº†è¯´\", ä½†æ˜¯å«ä¹‰ç¨æœ‰ä¸åŒ, \n##### brokerï¼ˆç»çºªäººï¼‰ï¼šæ‰“å¼€é…’æ¡¶å–é…’çš„äºº\nåœ¨å¤ä»£æ¬§æ´²çš„é…’å§æˆ–å…¶ä»–é›¶å”®é…’æ°´çš„åœ°æ–¹ï¼Œå–é…’çš„å°è´©ä¼šæ‰¹å‘é‡‡è´­ä¸€æ¡¶ä¸€æ¡¶çš„å•¤é…’æˆ–å…¶ä»–é…’ç±»ï¼Œç„¶åæ‰“å¼€é…’æ¡¶ï¼Œè£…ä¸Šé¾™å¤´ï¼Œç„¶åä¸€æ¯ä¸€æ¯åœ°å–ç»™å–é…’çš„äººã€‚æ‰“å¼€é…’æ¡¶çš„å·¥å…·åœ¨æ³•è¯­ä¸­å« brocheï¼Œåæ¥æ¼”å˜ä¸ºè‹±è¯­å•è¯ broachï¼ˆé’»å¤´ã€å‡¿å­ï¼‰ã€‚è€Œè¡¨ç¤ºâ€œæ‰“å¼€é…’æ¡¶â€çš„æ³•è¯­åŠ¨è¯ brochier äº§ç”Ÿäº†åè¯ brocheorï¼Œåæ¥æ¼”å˜æˆè‹±è¯­ä¸­çš„ brokerï¼Œå­—é¢æ„æ€å°±æ˜¯â€œæ‰“å¼€é…’æ¡¶çš„äººâ€ï¼ŒåŸæœ¬ç”¨æ¥è¡¨ç¤ºé›¶å”®é…’æ°´çš„å°è´©ï¼Œåæ¥æ³›æŒ‡å„ç§ç»é”€å•†ï¼Œåœ¨é‡‘èè¡Œä¸šä¸­ï¼Œåˆ™ç”¨æ¥è¡¨ç¤ºç»çºªäººã€æ®å®¢ã€‚è™½ç„¶ä¸­æ–‡å«æ³•ä¸åŒï¼Œä½†å…¶å®éƒ½æ˜¯ç»é”€å•†ã€ä¸­é—´äººçš„æ„æ€ã€‚ç»çºªäººå…¶å®å°±æ˜¯æŠŠè‚¡ç¥¨ã€è¯åˆ¸ç­‰é‡‘èäº§å“è´©å–ç»™ä¸ªä½“æŠ•èµ„è€…çš„ä¸­é—´äººã€‚\n- brokerï¼š ['brÉ™ÊŠkÉ™] n. ç»çºªäººï¼Œä¸­é—´äººï¼Œæ®å®¢ v. ä»¥ä¸­é—´äººèº«ä»½æ¥è°ˆåˆ¤ã€å®‰æ’\n- brokerageï¼š['brokÉ™rÉªdÊ’] n. ä½£é‡‘ï¼›å›æ‰£ï¼›ä¸­é—´äººä¸šåŠ¡\n- broachï¼š [brÉ™ÊŠtÊƒ] n. é’»å¤´ï¼Œå‡¿å­ï¼Œèƒ¸é’ˆ vt. æå‡ºï¼Œç»™â€¦â€¦é’»å­”ã€å¼€å£ï¼Œå¼€å§‹è®¨è®º\n\n\n#### damper\ndamper æ˜¯åè¯, **put a damper on sth** çš„æ„æ€æ˜¯\"ç»™... æµ‡å†·æ°´, æµ‡ç­... çš„å…´è‡´çš„æ„æ€\", to stop an occasion from being enjoyable\n\n- damp æ˜¯\"æ½®æ¹¿çš„, é˜´å†·çš„\"çš„æ„æ€, ä¹Ÿæœ‰\"ä½¿æ½®æ¹¿çš„æ„æ€\"\n- ä¸€å¼€å§‹ damp æ˜¯ç”¨æ¥å½¢å®¹ç…¤çŸ¿é‡Œé¢çš„æ¯’æ°”çš„, åæ¥å˜æˆäº†å½¢å®¹ç…¤çŸ¿é‡Œé¢é˜´å†·æ½®æ¹¿çš„çŠ¶æ€, \n- damper ä»ä¸Šé¢è¿™ä¸ªå«ä¹‰å¼•ç”³æ¥äº†\"to suffocate\"çš„æ„æ€, damper å°±æ˜¯ç”¨æ¥æ§åˆ¶ç«ç„°å¤§å°çš„ æŒ¡æ¿\n- åæ¥ç”¨åœ¨ä¹å™¨ä¸Šé¢, å°±æ˜¯ç”¨æ¥æ§åˆ¶å£°éŸ³å¤§å°, ä½¿ç´å¼¦åœæ­¢éœ‡åŠ¨çš„\"é˜»å°¼å™¨, å‡æŒ¯å™¨\",\n- **put a damper on** å°±ç±»ä¼¼äºè¸©ä¸‹é’¢ç´çš„ damper, è®©å£°éŸ³ä¸€ä¸‹å‡å¼±, \n\n\n#### ephemeral\n- ep- \nè¡¨ç¤ºâ€œåœ¨â€¦ä¸Šï¼Œåœ¨â€¦å‘¨å›´ï¼Œåœ¨â€¦åé¢â€ã€‚æºè‡ªå¸Œè…Šè¯­ epi \"on, over, at.\"\n- hemer- \n= day, è¡¨ç¤ºâ€œä¸€å¤©â€ã€‚æºè‡ªå¸Œè…Šè¯­ hemera \"day.\"\n- -al \nè¡¨å½¢å®¹è¯ï¼Œâ€œâ€¦çš„â€ï¼Œä¸€èˆ¬ç¼€äºåè¯åã€‚æºè‡ªæ‹‰ä¸è¯­ -alis, adjective suffix.\n\nephemeronï¼ˆèœ‰è£ï¼‰ï¼šåªæœ‰ä¸€å¤©å¯¿å‘½çš„å°è™«\nèœ‰è£ï¼ˆephemeronï¼‰æ˜¯æœ€åŸå§‹çš„æœ‰ç¿…æ˜†è™«ï¼Œå…¶å¹¼è™«ç”Ÿæ´»åœ¨æ·¡æ°´æ¹–æˆ–æºªæµä¸­ã€‚ç»è¿‡ä¸€å¹´å·¦å³çš„æˆé•¿æœŸåï¼Œå¹¼è™«æˆ–æµ®å‡åˆ°æ°´é¢ï¼Œæˆ–çˆ¬åˆ°æ°´è¾¹çŸ³å—æˆ–æ¤ç‰©èŒä¸Šï¼Œæ—¥è½åç¾½åŒ–ä¸ºäºšæˆè™«ã€‚äºšæˆè™«ä¸æˆè™«ç›¸ä¼¼ï¼Œå‡ºæ°´ååœç•™åœ¨æ°´åŸŸé™„è¿‘çš„æ¤ç‰©ä¸Šï¼Œä¸€èˆ¬ç»24å°æ—¶å·¦å³èœ•çš®ä¸ºæˆè™«ã€‚èœ‰è£æˆè™«ä¸è¿›é£Ÿï¼Œå¯¿å‘½çŸ­ï¼Œåªè´Ÿè´£ç¹è¡åä»£çš„ä»»åŠ¡ï¼Œä¸€èˆ¬åªæ´»å‡ å°æ—¶è‡³æ•°å¤©ï¼Œæ‰€ä»¥æœ‰â€œæœç”Ÿæš®æ­»â€çš„è¯´æ³•ã€‚èœ‰è£çš„è‹±æ–‡åç§°ephemeronä¹Ÿåæ˜ äº†å®ƒçš„è¿™ä¸€ç‰¹æ€§ã€‚ephemeronæ¥è‡ªå¸Œè…Šè¯­ephemerosï¼Œç”±epi-ï¼ˆonï¼‰+hemeraï¼ˆdayï¼‰æ„æˆï¼Œå­—é¢æ„æ€å°±æ˜¯â€œå»¶ç»­ä¸€å¤©çš„â€ã€‚\nephemeronï¼š[Éª'fÉ›mÉ™,rÉ‘n] n. èœ‰è£ï¼›ç”Ÿå‘½æçŸ­æš‚çš„ä¸œè¥¿\nephemeralï¼š[É™'fÉ›mÉ™rÉ™l] adj. çŸ­æš‚çš„ï¼›æœç”Ÿæš®æ­»çš„ n. åªç”Ÿå­˜ä¸€å¤©çš„äº‹ç‰©\n\n#### exhilarate\nex- =\u003e out, out of, thoroughly\nhilar- =\u003e glad, å¼€å¿ƒ, æ¯”å¦‚ hilarious\n-ate\nå°†å¼€å¿ƒå¸¦å‡ºæ¥ =\u003e ä½¿å¼€å¿ƒ, ä½¿å…´å¥‹, ä½¿æ¿€åŠ¨, elate\n\n\n#### exorbitant\n(ä»·æ ¼, è¦æ±‚ç­‰)ç¦»è°±çš„, è¿‡åˆ†çš„\n\nç›´æ¥ç¿»è¯‘è¿™ä¸ªå•è¯ç›¸å½“äº\"ç¦»è½¨çš„\", \n\n#### frowzyâ˜¢\nnot attractive, new, or fashionable\né‚‹é¢çš„ï¼Œä¸æ•´æ´çš„\n- She was wearing a frowzy dress in a dour shade of purple.\n\nå’Œ frown é•¿å¾—å¾ˆåƒ, å¯ä»¥è¿™æ ·è®°å¿†, ä¸€ä¸ªä¸œè¥¿å¦‚æ­¤çš„\"frowzy\", ä»¥è‡³äºä¸€è§åˆ°, ä¸€é—»åˆ°å°±è¦çš±çœ‰å¤´\"frown\"\n\n#### irascibleâ˜¢\nire æ˜¯ anger, rage, fury çš„æ„æ€\nirascible å°±æ˜¯ made angry easily çš„æ„æ€\n\n#### maudlin\nmaudlinï¼ˆå¤šæ„å–„æ„Ÿçš„ï¼‰ï¼šåœ£ç»ä¸­çˆ±æ‰çœ¼æ³ªçš„å¥³äººæŠ¹å¤§æ‹‰\nè‹±è¯­å•è¯maudlinæ¥è‡ªã€Šåœ£ç»ã€‹é‡Œçš„ä¸€ä¸ªå¥³æ€§äººç‰©ï¼šæŠ¹å¤§æ‹‰çš„ç›åˆ©äºšã€‚å¾ˆä¹…ä»¥æ¥è¿™ä¸ªå¥³äººä¸€ç›´ä»¥ä¸€ä¸ªè¢«è€¶ç¨£æ‹¯æ•‘çš„å¦“å¥³å½¢è±¡å‡ºç°åœ¨åŸºç£æ•™çš„ä¼ è¯´é‡Œï¼šå¥¹ç”¨å¿æ‚”çš„çœ¼æ³ªä¸ºè€¶ç¨£æ´—è„šï¼Œç”¨å¯†è½¯çš„é»‘å‘æŠŠå®ƒä»¬æ“¦å¹²ï¼›åœ¨è€¶ç¨£è¢«é’‰ä¸Šåå­—æ¶è¡Œåˆ‘çš„æ—¥æ—¥å¤œå¤œé‡Œå“€å“­ç¥ˆç¥·ã€å–‚ä»–å–æ°´ï¼›è€¶ç¨£æ­»åå¥¹è¿›å…¥åœå°¸çš„å¢“ç©´é¢„å¤‡äº²è‡ªç”¨æ²¹è„‚ä¸ºå…¶å‡€èº«ï¼Œå´æ„å¤–å‘ç°è€¶ç¨£æ­»è€Œå¤æ´»ã€‚ç”±äºæŠ¹å¤§æ‹‰å¸¸å¸¸ä»¥æµæ³ªçš„å½¢è±¡å‡ºç°ï¼Œæ‰€ä»¥å¥¹çš„åå­—æˆä¸ºäº†å¤šæ„å–„æ„Ÿè€…çš„ä»£åè¯ã€‚\nmaudlin: ['mÉ”ËdlÉªn] adj. å¤šæ„å–„æ„Ÿçš„ï¼Œæ˜“ä¼¤æ„Ÿçš„ï¼Œæ˜“æµæ³ªçš„ n. ä¼¤æ„Ÿ\n\n#### medley\nåŸä¹‰æ˜¯\"å¾’æ‰‹æ··æˆ˜, hand-to-hand combat\", å¾’æ‰‹å¤§å®¶éƒ½æ˜¯å¾ˆæ··ä¹±çš„\nmedley çš„è¯æ ¹å’Œ meddle æ˜¯ä¸€æ ·çš„, mesler =\u003e to mix, mingle, meddle, åæ¥ä¹ŸæŒ‡ä¸€ç§ç”±è®¸å¤šä¸åŒé¢œè‰²çš„ç¾Šæ¯›æ··ç»‡çš„èŠ±å¸ƒ, æœ€åå¼•ç”³ä¸ºäº†ç°åœ¨çš„æ„æ€: \"æ··åˆç‰©, æ··æ‚ç‰©, (éŸ³ä¹)ä¸²çƒ§, å¤§æ‚çƒ©\"\n\n\n#### mirthâ˜¢\næ¥è‡ª merry, æ¬¢ä¹, æ¬¢ç¬‘\n- mirthful, æ„‰å¿«çš„, é«˜å…´çš„, ä»¤äººæ¬¢ä¹çš„\n- mirthless. æ²‰é—·çš„, ä¸å¿«çš„, å¿§éƒçš„\n\n##### mir- \nwonder, look, è¡¨ç¤ºæƒŠå¥‡\n- admire\n- miracle\n- miraculous\n- mirage =\u003e æµ·å¸‚èœƒæ¥¼, å¹»æƒ³, å¦„æƒ³\n\n\n#### pariah\nå°åº¦ç§å§“ï¼ˆcasteï¼‰å¤šè€Œå¤æ‚ï¼Œå¤§è‡´å¯åˆ†å››å¤§ç­‰çº§ï¼Œæœ€é«˜ç­‰çº§å«å©†ç½—é—¨ï¼ˆåƒ§ä¾£ï¼‰ï¼Œæœ€ä½ç­‰çº§å«é¦–é™€ç½—ï¼ˆæ‰‹è‰ºäººå’ŒåŠ³åŠ¨è€…ï¼‰ã€‚å°åº¦å—éƒ¨æœ€å¤§çš„ç§å§“åœ¨æ³°ç±³å°”è¯­ï¼ˆTamilï¼‰ä¸­å«paraiyarï¼Œæ„ä¸ºdrummersï¼ˆé¼“æ‰‹ï¼‰ï¼Œå› ä¸ºæ­¤ä¸€ç§å§“çš„äººå¸¸å¸¸å……å½“èŠ‚åº†ç¤¼ä»ªçš„é¼“æ‰‹ï¼Œæ•…åã€‚è‹±å›½æ®–æ°‘è€…å®¶ä¸­çš„ä»†ä½£ä¹Ÿå¤šåŠæ˜¯æ­¤ä¸€ç§å§“çš„äººã€‚è‹±è¯­pariahä¸€è¯å³ç”±æ­¤è€Œæ¥ã€‚è™½ç„¶pariahå¹¶éæœ€ä½è´±çš„ç§å§“ï¼Œä½†åœ¨æœ€é«˜è´µçš„å©†ç½—é—¨çœ¼ä¸­ï¼Œå´è¢«çœ‹æˆç§å§“ä¹‹å¤–çš„â€œä¸å¯æ¥è§¦è€…â€ï¼ˆuntouchableï¼‰ï¼Œå³æœ€å—æ­§è§†å’Œå‹è¿«çš„â€œè´±æ°‘â€ã€‚å› æ­¤ï¼Œpariahåœ¨17ä¸–çºªåˆè¿›å…¥è‹±è¯­æ—¶ï¼Œå³è¢«èµ‹äºˆâ€œè´±æ°‘â€ä¸€ä¹‰ï¼Œåˆ°äº†19ä¸–çºªåˆè¿›è€Œå¼•ç”³ä¸ºâ€œé­ç¤¾ä¼šé—å¼ƒçš„äººâ€æˆ–â€œè¢«ç—›æ¨æˆ–æ’æ–¥çš„äººâ€ã€‚\n\n\n#### patrician\nå¤ç½—é©¬å»ºåŸä¹‹åˆï¼Œåˆ›å»ºè€…ç½—æ…•è·¯æ–¯å¬é›†å„æ°æ—ä¸­å¾·é«˜æœ›é‡çš„é¦–è„‘äººç‰©ï¼Œç”±ä»–ä»¬ç»„æˆå…ƒè€é™¢ï¼Œæ‹…ä»»å„ç§å…¬èŒï¼ŒååŠ©ä»–æ²»ç†ç½—é©¬ã€‚è¿™äº›äººè¢«ç§°ä¸º patresï¼Œæ˜¯ paterï¼ˆfatherï¼Œå®¶é•¿ã€å®¶çˆ¶ï¼‰çš„å¤æ•°å½¢å¼ã€‚è‹±è¯­è¯æ ¹ pater-/patri-ï¼ˆçˆ¶ï¼‰å°±æ¥æºäºæ­¤ã€‚\nå¤ç½—é©¬å»ºç«‹åå¾ˆé•¿ä¸€æ®µæ—¶æœŸå†…ï¼Œæ‰€æœ‰å…¬èŒéƒ½åªèƒ½ç”± patres çš„åä»£æ¥æ‹…ä»»ï¼Œå› æ­¤å½¢æˆäº†ä¸€ä¸ªä¸“é—¨çš„ç»Ÿæ²»é˜¶çº§ï¼Œè¢«ç§°ä¸º patriciusã€‚è¯¥è¯ç»ç”±æ³•è¯­è¿›å…¥è‹±è¯­åæ¼”å˜ä¸º patricianï¼ˆè´µæ—ï¼‰ã€‚ç½—é©¬å…¬æ°‘ä¸­ï¼Œpatrician ä»¥å¤–çš„äººè¢«ç§°ä¸º plebeianï¼ˆå¹³æ°‘ï¼‰ã€‚æœ€åˆï¼Œè´µæ—å’Œå¹³æ°‘ä¹‹é—´ä¸å¾—é€šå©šï¼Œå¹³æ°‘ä¸èƒ½æ‹…ä»»ä»»ä½•å…¬èŒã€‚ç»è¿‡å¹³æ°‘é˜¶çº§çš„é•¿æœŸæŠ—äº‰åï¼Œæœ€åæ‰è¿«ä½¿è´µæ—ä»¬åºŸé™¤äº†è¿™äº›ä¸å¹³ç­‰åˆ¶åº¦ã€‚\nä¸ nobleman ä¸åŒï¼Œpatrician æ˜¯ç”±è¡€ç»Ÿå†³å®šçš„ï¼Œå…·æœ‰å°é—­æ€§å’Œä¸–è¢­æ€§ã€‚patrician çš„åä»£æ°¸è¿œæ˜¯ patricianï¼Œè€Œ plebeian çš„åä»£æ°¸è¿œä¸èƒ½æˆä¸º patricianï¼Œä½†å¦‚æœèƒ½å–å¾—æ‰§æ”¿å®˜è¿™æ ·çš„é«˜ä½åï¼Œå°±å˜æˆäº† noblemanï¼Œä»–çš„åä»£ä¹Ÿèƒ½ä¸–è¢­ä¸º noblemanã€‚æ‰€ä»¥ patrician ç®—æ˜¯è€ç‰Œè´µæ—ï¼Œè€Œ nobleman ç®—æ˜¯æ–°å…´è´µæ—ã€‚\n- pater-/patri-ï¼šçˆ¶\n- patricianï¼š[pÉ™'trÉªÊƒ(É™)n] n. è´µæ—ï¼Œå¤ç½—é©¬æ°æ—è´µæ— adj. è´µæ—çš„ï¼Œæ˜¾è´µçš„\n- Patrickï¼š['pÃ¦trÉªk] n. å¸•ç‰¹é‡Œå…‹ï¼ˆç”·å­åï¼‰ï¼Œæ„ä¸ºâ€œé«˜è´µçš„â€\n- Patriciaï¼š[pÉ™'triÊƒÉ™] n. å¸•ç‰¹ä¸½å¤ï¼ˆå¥³å­åï¼‰ï¼Œæ„ä¸ºâ€œé«˜è´µçš„â€\n- paternalï¼š[pÉ™'tÉnl] adj. çˆ¶äº²çš„ï¼›å¾—è‡ªçˆ¶äº²çš„ï¼›çˆ¶äº²èˆ¬çš„\n- paternityï¼š[pÉ™'tÉnÉ™ti] n. çˆ¶æƒï¼›çˆ¶ç³»ï¼›çˆ¶ç³»åè£”\n- patrimonyï¼š ['pÃ¦trÉªmoni] n. é—äº§ï¼›ç¥–ä¼ çš„è´¢ç‰©ï¼›ç»§æ‰¿ç‰©ï¼›æ•™ä¼šçš„è´¢äº§\n- patriarchï¼š['petrÉªÉ‘rk] n. å®¶é•¿ï¼›æ—é•¿ï¼›å…ƒè€ï¼›åˆ›å§‹äºº\n\n#### pertinacious\nper- + tenacious(tinacious)\n- per- ä½œä¸ºå‰ç¼€è¡¨ç¤ºå®Œå…¨, è‡ªå§‹è‡³ç»ˆ, è€Œ tenacious æœ¬æ¥å°±æœ‰\"åšæŒçš„, é¡½å›ºçš„\"çš„æ„æ€, åˆåœ¨ä¸€èµ·è¡¨ç¤º\"åšå†³çš„, åšå®šä¸ç§»çš„, é¡½å¼ºçš„\"\n\n#### precipitateâ˜¢\n- precipitate æœ‰ä¸‰ä¸ªè¯æ€§:\n\t- åè¯: (åŒ–å­¦é‡Œé¢çš„)æ²‰æ·€ç‰©\n\t- å½¢å®¹è¯: ä»“ä¿ƒçš„, è´¸ç„¶çš„, è½»ç‡çš„\n\t- åŠ¨è¯: ä¿ƒæˆ(...çš„å‘ç”Ÿ), åŠ é€Ÿ...çš„å‘ç”Ÿ\n\n- pre-åœ¨å‰ + cipit-å¤´ + -ate ä½¿ â†’ ä½¿å¤´åœ¨å‰ï¼Œä¸€å¤´æ ½ä¸‹ï¼Œåç”¨äºæ°”è±¡æœ¯è¯­ï¼Œé™æ°´ï¼Œé™é›ªï¼Œå¼•ç”³ç‰©ç†æœ¯è¯­æ²‰æ·€ï¼Œæ²‰ç§¯ï¼Œç§¯ç°ã€‚\n- è‹±è¯­ä¸­æœ‰ä¸ºæ•°ä¸å°‘çš„è¯ï¼Œå…¶ç»ˆæè¯æºå¯ä»¥ä¸€ç›´è¿½æº¯åˆ°æ‹‰ä¸è¯­ caputï¼ˆå¤´ï¼‰ï¼Œcapital å³ä¸ºå…¶ä¸­ä¹‹ä¸€ã€‚å®ƒæ¥è‡ª caput çš„æ´¾ç”Ÿè¯ capitÄlis 'of the head'ï¼Œå› æ­¤æœ€åˆä¹Ÿè¡¨ç¤ºâ€œå¤´çš„â€ã€‚è‹±å›½è¯—äººå¼¥å°”é¡¿ï¼ˆJohn Milton, 1608-1674ï¼‰åœ¨é•¿è¯—ã€Šå¤±ä¹å›­ã€‹ä¸­å†™äº†(Serpent's) capital bruiseï¼ˆå¤´éƒ¨çš„ä¼¤ç—•ï¼‰è¿™æ ·çš„å­—å¥ï¼Œå…¶ä¸­ capital ä¸€è¯å³å«æ­¤ä¹‰ã€‚capital çš„å‡ ä¸ªå¸¸ç”¨è¯ä¹‰å‡ä¸â€œå¤´â€æœ‰è”ç³»ã€‚æ—§æ—¶ä¸€ä¸ªäººçŠ¯äº† capital crimeï¼ˆæ­»ç½ªï¼‰è¢«åˆ¤ä»¥ capital sentenceï¼ˆæ­»åˆ‘ï¼‰æˆ–è¢«å¤„ä»¥ capital punishmentï¼ˆæåˆ‘ï¼‰ï¼Œä¸æ˜¯è¢«ç å¤´å°±æ˜¯è¢«ç»æ­»ã€‚capital letterï¼ˆå¤§å†™å­—æ¯ï¼‰ä¸€èˆ¬å¤šä½äºå¥é¦–å’Œè¯é¦–ã€‚capital è¿˜ç”¨ä»¥æŒ‡â€œé¦–éƒ½â€ã€â€œé¦–åºœâ€ï¼Œè¯¥ç”¨æ³•å‡ºè‡ªå¼¥å°”é¡¿ç¬”ä¸‹ï¼Œå§‹è§äºã€Šå¤±ä¹å›­ã€‹ã€‚capital ç”¨ä»¥æŒ‡â€œèµ„æœ¬â€åˆ™å§‹äºç”¨ç‰›çš„å¤´æ•°è®¡ç®—è´¢å¯Œçš„æ—¶ä»£ï¼Œä½†è¿™ä¸€ç”¨æ³•ç›´è‡³ 18 ä¸–çºªæ‰é€šç”¨èµ·æ¥ã€‚\n- é™¤äº†capitalï¼Œæºè‡ªæ‹‰ä¸è¯­caputçš„è‹±è¯­å¸¸ç”¨è¯è¿˜æœ‰capeï¼ˆæµ·è§’ï¼‰ï¼Œcaptainï¼ˆé˜Ÿé•¿ï¼Œèˆ¹é•¿ï¼‰ï¼Œdecapitateï¼ˆæ–©é¦–ï¼‰ï¼Œchapterï¼ˆç« ï¼Œå›ï¼‰ï¼Œprecipiceï¼ˆæ‚¬å´–ï¼‰ï¼Œprecipitateï¼ˆçªç„¶ä¸‹é™ï¼›ä¿ƒæˆï¼›æ²‰æ·€ï¼‰ç­‰ã€‚\n\n\n#### prescienceâ˜¢\nforeknowledge, knowledge of events before they take place.\n\n##### science\nstate or fact of knowing, from Latin *scientia* \"knowledge, expertness\"\n\n##### scientist\nå¾ˆå¤šäººè®¤ä¸ºï¼Œè‹±è¯­å•è¯ scienceï¼ˆç§‘å­¦ï¼‰å’Œ scientistï¼ˆç§‘å­¦å®¶ï¼‰çš„è¯ç”Ÿæ—¶é—´åº”è¯¥ç›¸å·®ä¸è¿œï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆæ™®éçš„è¯¯è§£ã€‚äº‹å®ä¸Šï¼Œscienceï¼ˆç§‘å­¦ï¼‰ä¸€è¯å‡ºç°äº 14 ä¸–çºªä¸­æœŸï¼Œè€Œ scientistï¼ˆç§‘å­¦å®¶ï¼‰ä¸€è¯ç›´åˆ° 19 ä¸–çºª 30 å¹´ä»£æ‰è¯ç”Ÿï¼ŒäºŒè€…ç›¸å·®æ¥è¿‘ 5 ä¸ªä¸–çºªã€‚é‚£ä¹ˆï¼Œåœ¨ scientist ä¸€è¯å‡ºç°ä¹‹å‰ï¼Œç ”ç©¶ science çš„äººå«åšä»€ä¹ˆå‘¢ï¼Ÿâ€œè‡ªç„¶å“²å­¦å®¶â€ï¼Œè¿™æ˜¯ scientist ä¸€è¯è¯ç”Ÿä¹‹å‰ç§‘å­¦å®¶ä»¬æœ€å¸¸ä½¿ç”¨çš„ç§°è°“ï¼Œå› ä¸ºä»–ä»¬è®¤ä¸ºè‡ªå·±ç ”ç©¶çš„æ˜¯â€œè‡ªç„¶å“²å­¦â€ï¼Œå¦‚ 1687 å¹´ï¼Œå¤§ç§‘å­¦å®¶ç‰›é¡¿å‡ºç‰ˆçš„ç§‘å­¦å·¨è‘—å°±å«åšã€Šè‡ªç„¶å“²å­¦çš„æ•°å­¦åŸç†ã€‹ï¼Œè€Œä¸æ˜¯ã€Šè‡ªç„¶ç§‘å­¦çš„æ•°å­¦åŸç†ã€‹ã€‚\nç„¶è€Œï¼Œåˆ°äº† 19 ä¸–çºªï¼Œè¶Šæ¥è¶Šå¤šçš„äººå¯¹â€œè‡ªç„¶å“²å­¦å®¶â€è¿™ä¸€ç§°è°“æ„Ÿåˆ°ä¸æ»¡äº†ã€‚åœ¨ 1833 å¹´å¬å¼€çš„è‹±å›½ç§‘å­¦ä¿ƒè¿›åä¼šçš„ä¸€æ¬¡å¤§ä¼šä¸Šï¼Œè‘—åè¯—äººæŸ¯å‹’å¾‹æ²»ç«™èµ·æ¥å¯¹å‚ä¼šè€…è¯´ï¼šâ€œä½ ä»¬å¿…é¡»åœæ­¢è‡ªç§°ä¸ºâ€˜è‡ªç„¶å“²å­¦å®¶â€™ã€‚â€åœ¨ä»–çœ‹æ¥ï¼ŒçœŸæ­£çš„å“²å­¦å®¶åº”è¯¥åƒä»–é‚£æ ·ï¼Œååœ¨æ‰¶æ‰‹æ¤…ä¸Šå¯¹ç€æ˜Ÿç©ºè¿›è¡Œæ²‰æ€ï¼Œè€Œä¸æ˜¯åƒåä¼šçš„å¤§å¤šæ•°æˆå‘˜é‚£æ ·å¿™äºåšå„ç§ç¨€å¥‡å¤æ€ªçš„å®éªŒã€‚é¢å¯¹æŸ¯å‹’å¾‹æ²»çš„è´¨ç–‘ï¼Œä¸€ä½åå« William Whewell çš„â€œè‡ªç„¶å“²å­¦å®¶â€å‘è¨€ï¼Œæå‡ºå¦‚æœè®¤ä¸ºâ€œå“²å­¦å®¶â€ä¸€è¯è¿‡äºå®½æ³›ã€è¿‡äºå´‡é«˜ï¼Œé‚£ä¹ˆï¼Œå¯ä»¥ä»¿ç…§â€œartistâ€ï¼ˆè‰ºæœ¯å®¶ï¼‰ç”Ÿé€ ä¸€ä¸ªè¯ï¼šâ€œScientistâ€ï¼Œç”¨ä½œå¯¹ç§‘å­¦å®¶çš„ç§°è°“ã€‚ä¸€å¹´åï¼Œåœ¨ä¸€ç¯‡åŒ¿åä¹¦è¯„ä¸­ï¼ŒWhewell å†æ¬¡æåˆ°è¿™ä¸ªå»ºè®®ã€‚ä»æ­¤ä»¥åï¼Œscientist ä¸€è¯é€æ¸å¾—åˆ°æ™®åŠï¼Œæˆä¸ºäº†ç§‘å­¦å®¶çš„ç§°è°“ï¼Œå“²å­¦å®¶å’Œç§‘å­¦å®¶ä¹Ÿæœ€ç»ˆå®ç°äº†åˆ†å®¶ã€‚\n- scienceï¼š['saÉªÉ™ns] n. ç§‘å­¦ï¼Œå­¦ç§‘\n- scientistï¼š['saÉªÉ™ntÉªst] n. ç§‘å­¦å®¶\n\n#### recalcitrantâ˜¢\n\"**refusing to submit, not submissive or compliant**,\" 1823, from French rÃ©calcitrant, literally \"**kicking back**\" (17c.-18c.), from Late Latin recalcitrantem (nominative recalcitrans), present participle of recalcitrare \"**to kick back**\" (of horses), also \"be inaccessible,\" in Late Latin \"to be petulant or disobedient;\" from re- \"back\" (see re-) + Latin calcitrare \"to kick,\" from calx (genitive calcis) \"heel\" (see calcaneus). Used from 1797 as a French word in English.\n\n#### renegeâ˜¢\nre- è¿™é‡Œè¡¨ç¤ºå¼ºè°ƒ\nneg =\u003e to refuse, æ¯”å¦‚ negate\n=\u003e å¦è®¤è‡ªå·±åšè¿‡çš„æ‰¿è¯º =\u003e è¿èƒŒè¯ºè¨€, è¿çº¦, break your word, default, go back\n\n- renegade =\u003e å˜èŠ‚è€…\n\n#### resplendentâ˜¢\nre- è¿™é‡Œè¡¨ç¤ºå¼ºè°ƒ\nsplendent =\u003e to shine, be splendid\n=\u003e è¾‰ç…Œçš„, ç¿çƒ‚çš„, åä¸½çš„, brilliant, radiant, splendid. glorious\n\nåœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥å‘ç°\"å…‰æ˜\"å’Œ\"ç«ç„°\"åœ¨æ±‰è¯­å’Œè‹±è¯­é‡Œé¢éƒ½æœ‰ç€ååˆ†ç§¯æçš„å«ä¹‰.\n\n#### retaliateâ˜¢\næ¥è‡ªæ‹‰ä¸è¯­ retaliare, å¿è¿˜ï¼Œè¿”è¿˜ï¼Œæ¥è‡ª re-, å‘åï¼Œå¾€å›ï¼Œtalis, åŒæ ·ï¼ŒåŒç±»ï¼Œè¯æºåŒ this, that. å³åŸæ ·è¿”è¿˜çš„ï¼Œåç”¨äºæŒ‡æŠ¥ä»‡ï¼Œä»¥çœ¼è¿˜çœ¼ï¼Œä»¥ç‰™è¿˜ç‰™\n\n####  rub-\nrub-ï¼šçº¢è‰²ï¼Œçº¢è‰²çš„\nå¤ä»£ç½—é©¬äººå‘ç°ä¸€ç§é¢œè‰²å‘çº¢çš„æ©¡æœ¨è´¨åœ°ç‰¹åˆ«åšç¡¬ï¼Œå› æ­¤å¹¿æ³›ä½¿ç”¨è¿™ç§æ©¡æœ¨ä½œä¸ºå»ºç­‘ææ–™ã€‚è¿™ç§æ©¡æœ¨åœ¨æ‹‰ä¸è¯­ä¸­ç§°ä¸º rubusï¼Œæ¥è‡ª ruberï¼ˆredï¼Œçº¢è‰²ï¼‰ã€‚rubus çš„å½¢å®¹è¯æ˜¯ robustusï¼Œæœ¬æ„æ˜¯â€œrubus åšçš„â€ã€‚ç”±äº rubus ç‰¹åˆ«åšç¡¬ï¼Œå› æ­¤ robustus ä¹Ÿå°±è¡ç”Ÿå‡ºâ€œåšç¡¬ã€å¼ºå£®ï¼Œåƒæ©¡æ ‘ä¸€æ ·â€çš„æ„æ€ã€‚è‹±è¯­å•è¯ robust å°±æ¥æºäº robustusã€‚è‹±è¯­ä¸­è¡¨ç¤ºâ€œçº¢è‰²â€çš„è¯æ ¹ rub-åŒæ ·æ¥è‡ªæ‹‰ä¸è¯­ ruberï¼ˆçº¢è‰²ï¼‰ã€‚\n- redï¼š [rÉ›d] n. çº¢è‰²ï¼Œçº¢é¢œæ–™ï¼›èµ¤å­— adj. çº¢è‰²çš„\n- robustï¼š [rÉ™(ÊŠ)'bÊŒst] adj. å¼ºå¥çš„ï¼Œå¼ºå£®çš„ï¼Œç²—é‡çš„ï¼Œç²—é²çš„\n- rubyï¼š['rubi] n. çº¢å®çŸ³ï¼›çº¢å®çŸ³è‰² adj. çº¢å®çŸ³è‰²çš„ vt. ä½¿å¸¦çº¢å®çŸ³è‰²\n- rubicundï¼š['ruËbÉªk(É™)nd] adj. çº¢æ¶¦çš„ï¼›é€çº¢çš„\n- rubricï¼š ['rubrÉªk] n. çº¢å­—æ ‡é¢˜ï¼›çº¢è‰²å°åˆ·ï¼›é¢˜ç›® adj. å°ä¸ºçº¢å­—çš„\n\n#### sectary â‰  secretary\nsecretary æ˜¯ç§˜ä¹¦çš„æ„æ€\nsectary çš„è¯æ ¹æ˜¯ sect-, æ˜¯å®—æ´¾æˆå‘˜çš„æ„æ€.\nsectarian =\u003e adj. å®—æ´¾æˆå‘˜\nsectarianism =\u003e n. å®—æ´¾ä¸»ä¹‰\n\n#### soliloquy\nsoli- =\u003e alone\nloqu- =\u003e speak (e.g. loquacious)\nto speak alone =\u003e ç‹¬ç™½\n\n#### stodgyâ˜¢\nStodgy food =\u003e heavy and unhealthy, èƒ€è‚šå­çš„, è®©äººæ˜“é¥±çš„, é«˜æ·€ç²‰çš„\n=\u003e å¼•ç”³åˆ°äººçš„æ€§æ ¼ä¸Šé¢ =\u003e boring,  serious, and formal, å¤æ¿çš„, æ¯ç‡¥ä¹å‘³çš„.\n\n#### superimpose\n![300](notes/2022/2022.7/assets/1000x1000bb.jpg)\n\n#### surreptitiousâ˜¢\n- sur- \n= sub-ï¼Œç”¨åœ¨åŒè¾…éŸ³è¯æ ¹å‰è¡¨ç¤ºâ€œåœ¨â€¦ä¸‹é¢â€ã€‚æºè‡ªæ‹‰ä¸è¯­ sub \"under.\"\n- rept- \n= creep, è¡¨ç¤ºâ€œçˆ¬â€ã€‚æºè‡ªæ‹‰ä¸è¯­ repere \"to creep.\", æ¯”å¦‚ reptile\n- -itious \nè¡¨å½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œâ€¦çš„â€\n=\u003e to creep under, =\u003e é¬¼é¬¼ç¥Ÿç¥Ÿçš„, å·å·æ‘¸æ‘¸çš„, secret, clandestine, furtive, sneaking\n\n#### derelict\nde- =\u003e \"entirely\"\nre- =\u003e è¡¨å¼ºè°ƒ\nlict =\u003e to leave, ç•™ä¸‹, é—å¼ƒ\n=\u003e å‰é¢ä¸¤ä¸ªå‰ç¼€ç›¸å½“äºéƒ½æ˜¯è¡¨å¼ºè°ƒ =\u003e (adj. å»ºç­‘)å¹´ä¹…å¤±ä¿®çš„, ç ´è´¥çš„, åºŸå¼ƒçš„, (noun. )æ— å®¶å¯å½’çš„äºº\n\n- a derelict site\n\n##### dereliction\né™¤äº†\"å»ºç­‘ç‰©çš„åºŸå¼ƒ\"(noun.)è¿™ä¸€ä¸ªæ„æ€, dereliction å¼•ç”³ä¹‹åè¿˜æœ‰\"ç©å¿½èŒå®ˆ, æ¸èŒçš„æ„æ€\"\n- What you did was a grave dereliction of duty.\n\n#### temporizeâ˜¢\n- tempor =\u003e time, age, season, æ—¶é—´, e.g. temporal\n- -ize =\u003e åŠ¨è¯åç¼€\nto pass one's time, wait one's time =\u003e (ä¸ºäº†å–å¾—æœ‰åˆ©æ¡ä»¶è€Œ)æ‹–å»¶æ—¶é—´\n\n\n#### indictâ˜¢â˜¢\nèµ·è¯‰, æŒ‡æ§, æ§å‘Š =\u003e å’Œå®šç½ªä¸ä¸€æ ·, åªæ˜¯èµ·è¯‰\ncharge, accuse, prosecute, \nå¹¶ä¸”æ³¨æ„è¯»éŸ³:  /ÉªnËˆdaÉªt/ \n- He was indicted on drug charges at Snaresbrook Crown Court. \n\tåœ¨æ–¯å¥ˆå°”æ–¯å¸ƒé²å…‹åˆ‘äº‹æ³•åº­ä»–è¢«èµ·è¯‰çŠ¯æœ‰ä¸æ¯’å“æœ‰å…³çš„ç½ªè¡Œã€‚\n- US Five people were indicted for making and selling counterfeit currency. 5äººå› åˆ¶å”®å‡é’è¢«èµ·è¯‰ã€‚\n\n#### impunity\n- im- æ— , æ²¡æœ‰\n- pun- æƒ©ç½š, ç½ªè´£ (ä¾‹å¦‚punish)\n- -ity åè¯åç¼€\næ²¡æœ‰ç½ªè´£, å…é™¤ç½ªè´£(æ³¨æ„è¿™æ˜¯ä¸€ä¸ªåè¯)\n- Criminal gang are terrorizing the city with apparent impunity.\n\n\n#### panacea\nå¸Œè…Šç¥è¯ä¸­ï¼Œå¸•é‚£åˆ»äºšï¼ˆPanakeiaï¼‰æ˜¯åŒ»è¯ç¥åŸƒæ–¯åº“æ‹‰åº‡ä¹Œæ–¯çš„å¥³å„¿ï¼Œå…‰æ˜ç¥é˜¿æ³¢ç½—çš„å­™å¥³ã€‚åŸƒæ–¯åº“æ‹‰åº‡ä¹Œæ–¯å…±æœ‰5ä¸ªå¥³å„¿ï¼Œåˆ†åˆ«ä»£è¡¨äº†é˜¿æ³¢ç½—çš„ä¸€ç§åŒ»è¯èƒ½åŠ›ï¼Œå…¶ä¸­ä»¥å¸•é‚£åˆ»äºšå’Œè®¸ç™¸å„äºšæœ€ä¸ºæœ‰åã€‚å¸•é‚£åˆ»äºšä»£è¡¨äº†æ²»ç–—ï¼Œè€Œè®¸ç™¸å„äºšä»£è¡¨äº†æ¸…æ´å«ç”Ÿä¸å¥åº·ã€‚å¤ä»£åŒ»ç”Ÿåœ¨å¼€å§‹æ­£å¼ä»ä¸šå‰ï¼Œè¦å®£è¯»è‘—åçš„å¸Œæ³¢å…‹æ‹‰åº•èª“è¯ï¼Œå®£èª“å¯¹è±¡é™¤äº†é˜¿æ³¢ç½—ä¸åŸƒæ–¯åº“æ‹‰åº‡ä¹Œæ–¯å¤–ï¼Œè¿˜åŒ…æ‹¬è®¸ç™¸å„äºšå’Œå¸•é‚£åˆ»äºšå§å¦¹ä¿©ã€‚\nå¸•é‚£åˆ»äºšçš„åå­—Panakeiaåœ¨å¸Œè…Šè¯­ä¸­æ˜¯â€œæ²»ç–—ä¸€åˆ‡â€çš„æ„æ€ï¼Œç”±panï¼ˆå…¨éƒ¨ï¼‰å’Œakos ï¼ˆæ²»æ„ˆï¼‰æ„æˆï¼Œç›¸å½“äºè‹±è¯­ä¸­çš„all+cureã€‚å¥¹çš„åå­—ç»ç”±æ‹‰ä¸è¯­è¿›å…¥è‹±è¯­åï¼Œæ¼”å˜ä¸ºè‹±è¯­å•è¯panaceaï¼Œç”¨æ¥è¡¨ç¤ºâ€œåŒ…æ²»ç™¾ç—…çš„çµä¸¹å¦™è¯â€ã€‚\npanaceaï¼š[,pÃ¦nÉ™'siÉ™] n.åŒ…æ²»ç™¾ç—…çš„çµä¸¹å¦™è¯\n\n#### capriceâ˜¢â˜¢\næˆ‘ä»¬åœ¨ç”¨ caprice ä¸€è¯æ—¶ï¼Œä¸€èˆ¬æ˜¯ä¸ä¼šç«‹åˆ»è”æƒ³åˆ°åˆºçŒ¬å’Œå±±ç¾Šçš„ã€‚å¯æ˜¯ï¼Œå®ƒä»¬åœ¨ caprice çš„è¯ä¹‰å‘å±•ä¸­å´èµ·äº†ä¸€å®šä½œç”¨ã€‚caprice ç›´æ¥å€Ÿè‡ªæ³•è¯­ capriceï¼Œä½†å´æºäºæ„å¤§åˆ©è¯­ capriccioã€‚è¯¥æ„å¤§åˆ©è¯ç”± capo 'head'ï¼ˆå¤´ï¼‰å’Œ riccio 'hedgehog'ï¼ˆåˆºçŒ¬ï¼‰ä¸¤éƒ¨åˆ†ç»„æˆï¼Œå­—é¢ä¹‰æ˜¯â€œåˆºçŒ¬å¤´â€ï¼Œå«æœ‰ head with hair standing on endï¼ˆæ¯›éª¨æ‚šç„¶ï¼‰æˆ– frightï¼ˆæƒŠå“ï¼‰ç­‰ä¹‰ï¼Œå› ä¸ºäººåœ¨å—æƒŠå“æ—¶æ¯›å‘å°±ä¼šç«–èµ·ï¼Œæ­£åƒåˆºçŒ¬çš„ç¡¬åˆºä¸€æ ·ã€‚ä»¥å capriccio å› å‰åŠéƒ¨ capr å½¢ä¼¼æ„å¤§åˆ©è¯ capraï¼ˆå±±ç¾Šï¼‰è€Œä¸å±±ç¾Šçš„ç‰¹æ€§ç›¸è”ç³»ã€‚å±±ç¾Šæœ‰ä¸ªå¥‡ç‰¹çš„ä¹ æ€§ï¼Œåœ¨å®‰è¯¦åœ°ä½å¤´åƒè‰çš„æ—¶å€™ï¼Œå¾€å¾€ä¼šçªç„¶è·ƒèµ·æˆ–è·³å‘ä¸€æ—ï¼Œç„¶ååˆè‹¥æ— å…¶äº‹åœ°æ¢å¤åŸçŠ¶è€Œç»§ç»­ä½å¤´åƒè‰ï¼Œcapriccio å› è€Œè¢«èµ‹äºˆäº†è‹±è¯­ caprice è‡³ä»Šè¿˜åœ¨ä½¿ç”¨çš„â€œåå¤æ— å¸¸â€ã€â€œå¤šå˜â€ã€â€œä»»æ€§â€ç­‰ä¹‰ã€‚åŸæ„å¤§åˆ©è¯ capriccio ä¹Ÿè¢«è‹±è¯­ç›´æ¥å¸æ”¶ï¼Œç”¨ä½œéŸ³ä¹æœ¯è¯­ï¼ŒæŒ‡â€œéšæƒ³æ›²â€ã€‚\n\nä¾‹ \n- Her decision was pure caprice. \n\tå¥¹çš„å†³å®šçº¯ç²¹æ˜¯ä¸€æ—¶å¿ƒè¡€æ¥æ½®ã€‚\n- Mary's actions are unpredictable. She is known for her caprice. ç›ä¸½çš„è¡ŒåŠ¨æ˜¯éš¾ä»¥é¢„æµ‹çš„ã€‚å¥¹çš„åå¤æ— å¸¸æ˜¯å‡ºäº†åçš„ã€‚\n- He burst into a rage, out of caprice. \n\tä»–è«åå…¶å¦™åœ°å‹ƒç„¶å¤§æ€’èµ·æ¥ã€‚\n\n- whim, impulse, \n\n#### browbeat\nå­—é¢æ„ä¹‰æ˜¯\"ç”¨çœ‰æ¯›æ‰“\", å¯ä»¥æƒ³åˆ°æŒ‡çš„æ˜¯å¯¹æŸäººå¹èƒ¡å­çªçœ¼(æƒ³è¦å¨å“, å“å”¬)çš„æ„æ€, åæ¥å°±ç”¨æ¥æŒ‡\"å¨å“, å“å”¬\"æŸäºº\n\nDon't be browbeaten into working more hours than you want!\n\n#### draconian\nå…¬å…ƒå‰621å¹´ï¼Œå¸Œè…ŠåŸé‚¦é›…å…¸çš„ç»Ÿæ²»è€…å¾·æ‹‰å¤ï¼ˆDracoï¼‰è¿«äºå¹³æ°‘çš„å‹åŠ›ï¼Œå°†ä»¥å¾€çš„ä¹ æƒ¯æ³•åŠ ä»¥ç¼–çº‚ï¼Œé¢å¸ƒäº†å¤å¸Œè…Šçš„ç¬¬ä¸€éƒ¨æˆæ–‡æ³•ã€‚è¯¥æ³•ä»¥ä¸¥é…·è€Œé—»åã€‚å¯¹äºåˆ‘äº‹çŠ¯ç½ªï¼Œä¸€å¾‹å¤„ä»¥æ­»åˆ‘ã€‚å°±è¿ç›—çªƒæ°´æœè¿™æ ·çš„è½»ç½ªä¹Ÿæ˜¯æ­»åˆ‘ã€‚å¾·æ‹‰å¤è§£é‡Šè¯´è½»ç½ªæœ¬æ¥å°±è¯¥å¤„æ­»ï¼Œè‡³äºé‡ç½ªï¼Œå› ä¸ºæ‰¾ä¸åˆ°æ¯”å¤„æ­»æ›´é‡çš„åˆ‘ç½šï¼Œæ‰€ä»¥ä¹Ÿæ˜¯å¤„æ­»ã€‚å¾·æ‹‰å¤æ³•å¦‚æ­¤ä¸¥é…·ï¼Œä»¥è‡³å†å²å­¦å®¶è¯´å®ƒä¸æ˜¯ç”¨å¢¨æ°´å†™çš„ï¼Œè€Œæ˜¯ç”¨è¡€å†™çš„ã€‚å¾·æ‹‰å¤æ³•åæ¥è¢«æ¢­ä¼¦ä¿®æ”¹ï¼Œä½†ç”±æ­¤äº§ç”Ÿäº†å•è¯draconianï¼Œå½¢å®¹ä¸¥å‰è‹›åˆ»ã€‚\n- draconianï¼š[drÉ™'konÉªÉ™n] adj. ä¸¥å‰çš„ï¼Œè‹›åˆ»çš„ã€‚\n\n#### exquisiteâ˜¢â˜¢\nex- è¡¨ç¤ºå¼ºè°ƒ\nquis- =\u003e to seek, æ¢æ±‚, è¯¢é—®\n-ite =\u003e \næ·±å…¥åœ°æ¢å¯»çš„ï¼Œç²¾ç›Šæ±‚ç²¾çš„ =\u003e very beautiful and delicate\n- An exquisite piece of china\n- An exquisite painting\n\n- ç”¨äºå½¢å®¹æƒ…æ„Ÿ, è¿˜æœ‰\"å¼ºçƒˆçš„\"çš„æ„æ€, \n\t- exquisite joy\n\t- The pain was quite exquisite\n\n- ç”¨äºå½¢å®¹å“è´¨, è¿˜æœ‰\"å®Œç¾çš„, ç²¾æ¹›çš„, å“è¶Šçš„\"çš„æ„æ€\n\t - A good comedian needs to have an exquisite sense of timing.\n\n\n#### haphazard\n- hap- æ˜¯è¿æ°”çš„æ„æ€, ä¹‹å‰èƒŒè¿‡çš„ mishap ä¹Ÿæœ‰è¿™ä¸ªè¯æ ¹.\n- not having an obvious order or plan\n\tæ— ç§©åºçš„ï¼Œæ— è®¡åˆ’çš„ï¼Œéšæ„çš„\n- He tackled the problem in a typically haphazard manner. åƒå¾€å¸¸ä¸€æ ·ï¼Œä»–å¤„ç†è¿™ä¸ªé—®é¢˜æ—¶ä¹Ÿå¾ˆæ²¡æœ‰ç« æ³•ã€‚\n\n![mishap](#mishap)\n- hazardï¼ˆå†’é™©ï¼‰ï¼šç”¨éª°å­æ¥ç©çš„èµŒåšæ¸¸æˆ\nè‹±è¯­å•è¯ hazard æ¥è‡ªé˜¿æ‹‰ä¼¯è¯­ al zahrï¼ˆthe diceï¼‰ï¼Œæ„æ€æ˜¯â€œéª°å­â€ã€‚åœ¨åå­—å†›ä¸œå¾æœŸé—´ï¼Œåå­—å†›åœ¨ä¸œæ–¹ä»é˜¿æ‹‰ä¼¯äººé‚£é‡Œå­¦ä¼šäº†ä¸€äº›ç”¨éª°å­æ¥ç©çš„æ¸¸æˆï¼Œä¹Ÿå°†è¿™ä¸ªè¯å¸¦å›äº†æ¬§æ´²ï¼ŒåŸæœ¬æŒ‡çš„æ˜¯ç”¨éª°å­æ¥ç©çš„èµŒåšæ¸¸æˆã€‚ç”±äºè¿™ç§æ¸¸æˆéƒ½éœ€è¦å†’é™©ã€èµŒè¿æ°”ï¼Œæ‰€ä»¥ hazard ä¸€è¯å°±è¡ç”Ÿå‡ºäº†â€œå†’é™©ã€èµŒè¿æ°”â€ç­‰å«ä¹‰ã€‚\n- hazardï¼š['hÃ¦zÉ™d] vt. èµŒè¿æ°”ï¼Œå†’â€¦â€¦çš„é£é™©ï¼Œä½¿é­å—å±é™© n. å†’é™©ï¼Œå±é™©ï¼Œå†’é™©çš„äº‹\n- hazardousï¼š['hÃ¦zÉ™dÉ™s] adj. æœ‰å±é™©çš„ï¼Œå†’é™©çš„ï¼Œç¢°è¿æ°”çš„\n- haphazardï¼š ['hÃ¦phÃ¦zÉ™d] adj. å¶ç„¶çš„ï¼›éšä¾¿çš„ï¼›æ— è®¡åˆ’çš„ n. å¶ç„¶ï¼›å¶ç„¶äº‹ä»¶ adv. å¶ç„¶åœ°ï¼›éšæ„åœ°\n\n#### estrangeâ˜¢\ne- strange =\u003e ä½¿ç–è¿œ, ä½¿ç–ç¦», ç¦»é—´\n- he is *estranged* from his wife\n\n\n#### fiascoâ˜¢\n- something planned that goes wrong and is a complete failure, usually in an embarrassing way\n\nfiasco - è¯¥è¯åŸä¸ºæ„å¤§åˆ©è¯­ï¼Œå­—é¢ä¹‰æ˜¯bottleï¼ˆç»ç’ƒç“¶ï¼‰æˆ–flaskï¼ˆé•¿é¢ˆç“¶ï¼‰ã€‚ä»19ä¸–çºªæœ«æœŸèµ·ï¼Œè‹±è¯­å¼€å§‹ç”¨fiascoæ¥è¡¨ç¤ºâ€œæƒ¨è´¥â€æˆ–â€œå®Œå…¨å¤±è´¥â€ã€‚é‚£ä¹ˆï¼Œâ€œæƒ¨è´¥â€ä¸â€œç»ç’ƒç“¶â€ä¹‹é—´ç©¶ç«Ÿæœ‰ä»€ä¹ˆè”ç³»å‘¢ï¼Ÿä¼—è¯´ä¸ä¸€ï¼Œä»¥ä¸‹ä¸¤ç§è¯´æ³•æ¯”è¾ƒå¯ä¿¡ã€‚\n\nä¸€è¯´ä¸å¨å°¼æ–¯ç»ç’ƒå¹åˆ¶å·¥ï¼ˆglassblowerï¼‰æœ‰å…³ã€‚å·¥äººåœ¨å¹åˆ¶ç»ç’ƒé¥°å“æ—¶ï¼Œå› æŠ€è‰ºä¸ç²¾å‡ºäº†å·®é”™æˆ–å‘ç°æœ‰ç‘•ç–µï¼Œä¾¿é©¬ä¸ŠæŠŠåºŸç»ç’ƒè½¬åˆ¶æˆè´¨é‡ç¨æ¬¡çš„æ™®é€šç»ç’ƒç“¶æˆ–é•¿é¢ˆç“¶ï¼Œæ„å¤§åˆ©è¯­ä½œfar fiascoï¼Œæ„å³â€œåˆ¶æˆç»ç’ƒç“¶â€ï¼Œä»¥åfiascoé€æ¸å¼•ç”³ä¸ºâ€œå¤±è´¥â€ã€‚\n\nä¸€è¯´èµ·æºäºå‰§é™¢ã€‚åœ¨æŸæ¬¡æˆå‰§è¡¨æ¼”æ—¶ï¼Œç»ç’ƒç“¶è¢«æ„å¤–æ‘”ç ´å¯¼è‡´æ¼”å‡ºå®Œå…¨å¤±è´¥ï¼Œæ„å¤§åˆ©äººä¹Ÿè¯´far fiascoï¼Œä»¥åæ¼”å‘˜å¿˜äº†å°è¯ï¼Œäººä»¬ä¹Ÿç”¨å®ƒä½œæ¯”ã€‚ä¹…è€Œä¹…ä¹‹ï¼Œfiascoå°±è¢«ç”¨ä»¥å–»æŒ‡â€œå®Œå…¨å¤±è´¥â€ã€‚\n\nä¾‹ \n- My math test was a complete fiasco. I only answered two questions. æˆ‘çš„æ•°å­¦æµ‹éªŒå½»åº•å¤±è´¥ã€‚æˆ‘åªå›ç­”äº†ä¸¤é“é¢˜ã€‚\n- The first lecture I ever gave was a total fiasco. æˆ‘è®²çš„ç¬¬ä¸€æ¬¡è¯¾å½»åº•å¤±è´¥äº†ã€‚\n- The party ended in fiasco. é‚£æ¬¡èšä¼šä»¥å®Œå…¨å¤±è´¥å‘Šç»ˆã€‚\n\n\n#### pos- æ”¾ç½®\n##### dispose\ndis- =\u003e åˆ†å¼€, æ•£å¼€ \nåˆ†å¼€æ‘†æ”¾, æœ‰åºæ”¾ç½® =\u003e åé¢å¤šæŒ‡\"æœ‰æ•ˆåœ°å¤„ç†, å¤„ç½®, æ¸…é™¤, è§£å†³, å‡»è´¥\"\næ³¨æ„, dispose åœ¨ä½¿ç”¨æ—¶éƒ½æ˜¯å›ºå®šæ­é…: **dispose of**\n1. If you **dispose of** something that you no longer want or need, you throw it away.\n\t- Just fold up the nappy and **dispose of** it in the normal manner.  \n\t- ...the safest means of **disposing of** nuclear waste. \n\t- Engine oil cannot be **disposed of** down drains.  \n2. If you **dispose of** a problem, task, or question, you deal with it.\n- You did us a great favour by **disposing of** that problem.  \n- The justices have been arguing about how the case should be **disposed of**. \n3. To **dispose of** a person or an animal means to kill them.\n\t- He alleged that they had hired an assassin to **dispose of** him.  \n\n##### expose\nex- å‘å¤– =\u003e å‘å¤–æ‘†æ”¾, å‘å¤–æ”¾ç½® =\u003e æš´éœ², æ­å‘, æ›å…‰\n\n##### impose\nim- \"into, in\" =\u003e æ‘†æ”¾åˆ°...é‡Œé¢ =\u003e å¼•ç”³ä¸º to apply authoritatively, å¼ºåˆ¶å®è¡Œ, å¼ºåŠ äº\n\n##### depose\nde- \"down\" =\u003e lay down, let fall, å°†(æƒè´µä¹‹äºº)ä»ä½ç½®ä¸Šæ‹¿ä¸‹æ¥ =\u003e ç½¢å…, ä½¿...å…èŒ, ä½¿...ä¸‹å°\n- Mr Ben Bella was deposed in a coup in 1965.\n- ...the deposed dictator. \n\n##### compose\ncom- =\u003e  together, with, =\u003e ä¸€èµ·æ‘†æ”¾, =\u003e åˆ›ä½œ, ç”±...ç»„æˆ\n- Air *is composed mainly of* nitrogen and oxygen. ç©ºæ°”ä¸»è¦ç”±æ°®å’Œæ°§æ„æˆã€‚\n- The committee *is composed of* MPs, doctors, academics and members of the public. å§”å‘˜ä¼šç”±è®®å‘˜ã€åŒ»ç”Ÿã€å­¦è€…å’Œæ™®é€šæ°‘ä¼—ç»„æˆã€‚\n- The audience *was* *composed* *largely* *of* young people. è§‚ä¼—ä¸­å¤§éƒ¨åˆ†éƒ½æ˜¯å¹´è½»äººã€‚ \n\nåæ¥åˆæœ‰äº†**ä½¿...é•‡å®šä¸‹æ¥**çš„æ„æ€\n**compose yourself** =\u003e to make yourself calm again after being angry or upset ä½¿è‡ªå·±é•‡å®šï¼›ä½¿è‡ªå·±å¹³é™ä¸‹æ¥\n- She finally stopped crying and *composed herself*. å¥¹ç»ˆäºåœæ­¢å“­æ³£ï¼Œå®‰é™äº†ä¸‹æ¥ã€‚\n**compose your features/thoughts** =\u003e to try to make yourself look or feel calm after being angry or upset ä½¿è¡¨æƒ…ï¼ˆæˆ–æ€ç»ªç­‰ï¼‰é•‡å®š\n- I tried to *compose my features* into a smile. æˆ‘æåŠ›ä½¿è¡¨æƒ…å¹³é™ä¸‹æ¥ï¼Œéœ²å‡ºä¸€ä¸å¾®ç¬‘ã€‚\n- He took a minute or two to *compose his thoughts* before he replied. ä»–ç”¨ä¸€ä¸¤åˆ†é’Ÿå¹³é™äº†æ€ç»ªåæ‰ä½œå‡ºå›ç­”ã€‚\n\n##### propose\npro- =\u003e forth, å‘å‰\n=\u003e æ”¾åˆ°å‰é¢ =\u003e å»ºè®®, æè®®, \n=\u003e æ±‚å©š\n=\u003e æå, æ¨è\n=\u003e è®¡åˆ’, æ‰“ç®—\n\n\n#### incontrovertible\nin + controvert + ible\nä¸å®¹ç½®ç–‘çš„ï¼›æ— å¯è¾©é©³çš„\n\n##### controvert\nåé©³, å¦å®š\n- This theory was subsequently *controverted* by several researchers in the same field. \n\tè¿™ä¸ªç†è®ºåæ¥è¢«åŒé¢†åŸŸçš„å‡ ä½ç ”ç©¶è€…æ‰€å¦å®šã€‚ \n\n\n#### nocturnal\nnoct- =\u003e night\nnocturnal =\u003e å¤œè¡Œæ€§çš„\ndi- =\u003e day\ndiurnal =\u003e æ˜¼è¡Œæ€§çš„\n\n#### scrappy\nscrap =\u003eåƒåœ¾, ç¢ç‰‡ =\u003escrappy: æ•£ä¹±çš„, ä¸è¿è´¯çš„, badly organized\nscrap =\u003e fight, quarrel =\u003e scrappy: å¥½æ–—çš„, çˆ±æ‰“æ¶çš„\n\n#### attenuateâ˜¢\nat + tenu + ate\ntenu =\u003e thin, fine, ç»†\n=\u003e å¼•ç”³ä¸º\"ä½¿å‡å°‘, ä½¿å‡å¼±, ä½¿é™ä½\"\n\n- Radiation from the sun is attenuated by the earth's atmosphere. åœ°çƒå¤§æ°”å‡å¼±äº†å¤ªé˜³è¾å°„ã€‚ \n- You could never eliminate risk, but preparation and training could attenuate it. \n\n\n#### chasmâ˜¢\n**ï¼ˆå²©çŸ³ã€åœ°é¢æˆ–å†°é¢çš„ï¼‰è£‚éš™ï¼›å³¡è°·ï¼›æ·±æ¸Š**\n- cha- \nè¡¨ç¤ºâ€œç©ºç™½ã€å·¨å¤§çš„ç©ºé—´â€ã€‚æºè‡ªå¸Œè…Šè¯­ khasma \"yawning gulf, \"\n\n\n##### chaosï¼ˆæ··æ²Œï¼‰ï¼šæ··æ²Œä¹‹ç¥å¡ä¿„æ–¯\nå¤å¸Œè…Šç¥è¯çš„ç¬¬ä¸€éƒ¨åˆ†æ˜¯åˆ›ä¸–é˜¶æ®µï¼Œå³ä»¥ç¥è¯æ–¹å¼è§£é‡Šä¸–ç•Œçš„æ¥æºã€‚åœ¨è¿™ä¸€é˜¶æ®µå‡ºç°çš„ç¥ç¥‡é€šå¸¸ç§°ä¸ºâ€œåŸå§‹ç¥â€æˆ–â€œè€ç¥â€ï¼Œä»–ä»¬åˆ†åˆ«æ˜¯ä¸–ç•ŒæŸä¸€éƒ¨åˆ†çš„æ‹ŸäººåŒ–ï¼Œåæ¥è¢«ç¬¬äºŒä»£çš„æ³°å¦ç¥æ—æ¨ç¿»ã€‚\nå¡ä¿„æ–¯ï¼ˆChaosï¼‰æ˜¯å¸Œè…Šç¥è¯ä¸­æœ€æ—©çš„çš„ç¥çµï¼Œä»£è¡¨å®‡å®™å½¢æˆä¹‹å‰æ¨¡ç³Šä¸€å›¢çš„æ™¯è±¡ã€‚æ ¹æ®å¤å¸Œè…Šè‘—åå†å²å­¦å®¶èµ«è¥¿å¥¥å¾·ï¼ˆHesiodï¼‰çš„ã€Šç¥è°±ã€‹å’Œæ—©æœŸå¸Œè…Šç¥è¯è®°è½½ï¼šå®‡å®™ä¹‹åˆåªæœ‰å¡ä¿„æ–¯ï¼Œç¥‚æ˜¯ä¸€ä¸ªæ— è¾¹æ— é™…ã€ä¸€æ— æ‰€æœ‰çš„è™šç©ºã€‚éšåç¥‚ä¾é æ— æ€§ç¹æ®–ä»è‡ªèº«å†…éƒ¨è¯ç”Ÿäº†å¤§åœ°å¥³ç¥ã€æ·±æ¸Šç¥ã€é»‘æš—ç¥ã€é»‘å¤œå¥³ç¥å’Œçˆ±ç¥ç­‰äº”å¤§åˆ›ä¸–ç¥ï¼Œä¸–ç•Œç”±æ­¤å¼€å§‹ã€‚\nå¡ä¿„æ–¯ï¼ˆChaosï¼‰åœ¨å¸Œè…Šè¯­ä¸­æ‹¼å†™ä¸º khaosï¼Œæœ¬æ„æ˜¯â€œè™šç©ºã€è£‚å¼€â€ï¼Œç”±è¯å¹² khaï¼ˆç©ºæ´ï¼‰å’Œåè¯è¯å°¾-os æ„æˆã€‚è¯¥è¯åœ¨æ‹‰ä¸è¯­ä¸­æ‹¼å†™å˜ä¸º chaosï¼Œå¹¶ç»ç”±æ³•è¯­è¿›å…¥è‹±è¯­ï¼Œå½¢æˆäº†è‹±è¯­å•è¯ chaosã€‚ç°åœ¨ï¼Œchaos å¸¸å¸¸è¢«ç”¨æ¥è¡¨ç¤ºâ€œæ··ä¹±ã€æ··æ²Œâ€ï¼Œè¯¥å«ä¹‰æºè‡ªèµ«è¥¿å¥¥å¾·çš„è¯´æ³•ã€‚ä»–å°† chaos æè¿°ç§©åºè¯ç”Ÿä¹‹å‰çš„å®‡å®™ï¼Œä¸ç§©åºè¯ç”Ÿä¹‹åçš„å®‡å®™ cosmosï¼ˆå¸Œè…Šè¯­ä¸º Kosmosï¼‰ç›¸å¯¹åº”ã€‚ä» chaos è¡ç”Ÿå‡ºå½¢å®¹è¯ chaotic å°±æ˜¯â€œæ··ä¹±çš„â€ä¹‹æ„ã€‚\nä¸ chaos åŒæºçš„å•è¯è¿˜æœ‰ chasmï¼ˆè£‚å£ã€æ·±å‘ï¼‰ï¼Œå®ƒæºè‡ªå¸Œè…Šè¯­ khasmaã€‚å¦å¤–ï¼Œå¸¸è§å•è¯ gasï¼ˆæ°”ä½“ï¼‰ä¹Ÿä¸ chaos åŒæºã€‚å®ƒæ¥è‡ªè·å…°è¯­ï¼Œè€Œåœ¨è·å…°è¯­ä¸­ï¼Œå­—æ¯ g çš„å‘éŸ³ååˆ†æ¥è¿‘å¸Œè…Šè¯­ä¸­çš„ khã€‚\n- chaosï¼š ['keÉªÉ’s] n. æ··æ²Œã€æ··ä¹±\n- cosmosï¼š['kÉ‘zmos] n. å®‡å®™ï¼Œå’Œè°ï¼Œç§©åº\n- chaoticï¼š [keÉª'É’tÉªk] adj. æ··ä¹±çš„ã€æ— ç§©åºçš„\n- chasmï¼š['kÃ¦zÉ™m] n. å³¡è°·ï¼›è£‚å£ï¼›åˆ†æ­§ï¼›æ·±å‘\n- gasï¼š[É¡Ã¦s] n. æ°”ä½“ï¼›ç“¦æ–¯ï¼›æ±½æ²¹ï¼›æ¯’æ°”\n\n#### dappled\næœ‰æ–‘ç‚¹çš„ï¼ŒèŠ±æ–‘çš„ï¼›æ–‘é©³çš„\n![](notes/2022/2022.7/assets/0002pS-4105.jpg)\n\n#### canvass\ncanvass - ç»†å¿ƒçš„äººå¯èƒ½ä¼šå‘ç°canvasså’Œå¦ä¸€ä¸ªè¯canvasåœ¨è¯å½¢ä¸Šæä¸ºç›¸ä¼¼ï¼Œä»…æœ‰ä¸€ä¸ªå­—æ¯ä¹‹å·®ã€‚å…¶å®ä½•æ­¢è¯å½¢ï¼Œåœ¨è¯æºä¸Šä¸¤è€…å°±æœ‰å¯†åˆ‡çš„äº²ç¼˜å…³ç³»ã€‚\n\ncanvasæºè‡ªæ‹‰ä¸è¯­cannabis 'hemp'ï¼ˆå¤§éº»ï¼‰ï¼Œä½†å´ç›´æ¥å€Ÿè‡ªå¤æ³•è¯­ï¼Œåœ¨ä¸­å¤è‹±è¯­ä½œcanevasï¼Œå› æ—©å…ˆç²—å¸†å¸ƒç³»ç”±å¤§éº»åˆ¶æˆï¼Œæ•…canvaså³è¢«ç”¨ä»¥è¡¨ç¤ºâ€œç²—å¸†å¸ƒâ€ï¼Œè€Œååˆç”±æ­¤å¼•ç”³å‡ºâ€œæ²¹ç”»å¸ƒâ€ã€â€œæ²¹ç”»â€ç­‰ä¹‰ã€‚è€Œcanvassåˆ™æ˜¯16ä¸–çºªæ—¶ä»canvasæ¼”å˜è€Œæ¥çš„ï¼Œä»ä¸€å¼€å§‹å°±ä½œä¸ºåŠ¨è¯ç”¨ã€‚è¿™ä¹Ÿè¯´æ˜ä¸ºä»€ä¹ˆcanvassçš„sæ˜¯åŒå†™çš„ã€‚canvassçš„åŸä¹‰æ˜¯to toss someone in a canvas sheet for pleasure or punishmentï¼ˆä¸ºäº†å–ä¹æˆ–ä½“ç½šè€ŒæŠŠæŸäººè£¹åœ¨å¸†å¸ƒåºŠå•é‡Œä½¿åŠ²æ‘‡ï¼‰ï¼Œæ­¤åè¯ä¹‰å‡ ç»å˜åŒ–ï¼Œç”±â€œç—›æ‰“â€è€Œâ€œç—›æ–¥â€ï¼Œç”±â€œç—›æ–¥â€è€Œâ€œï¼ˆè¯¦ç»†ï¼‰è®¨è®ºâ€ã€‚æ—§æ—¶ç²—å¸†å¸ƒä¸€åº¦è¢«ç”¨æ¥ç­›ä¸œè¥¿ï¼Œç”±æ­¤åˆå¼•ç”³å‡ºâ€œï¼ˆè¯¦ç»†ï¼‰æ£€æŸ¥ï¼ˆå¦‚é€‰ç¥¨ï¼‰â€ã€â€œå¾æ±‚æ„è§â€ã€â€œæ‹‰é€‰ç¥¨â€ç­‰ä¹‰ï¼Œå°¤ç”¨äºç¾å›½è‹±è¯­ã€‚\n\nä¾‹ \n- We'll have to *canvass* the entire area before the referendum. æˆ‘ä»¬å¿…é¡»åœ¨å…¨æ°‘å…¬å†³å‰åœ¨æ•´ä¸ªåœ°åŒºè¿›è¡Œæ¸¸è¯´ã€‚\n- Candidates *canvassed* the city's neighborhoods for votes.  å€™é€‰äººåˆ°åŸå¸‚çš„é‚»è¿‘åœ°åŒºæ‹‰é€‰ç¥¨ã€‚\n- Party members were out *canvassing* as soon as a date for the election was announced. é€‰ä¸¾æ—¥æœŸä¸€å®£å¸ƒï¼Œå…šå‘˜ä»¬ä¾¿å››å‡ºæ¸¸è¯´ã€‚\n- They decided to *canvass* opinions from the general public. ä»–ä»¬å†³å®šå¹¿æ³›å¾æ±‚å…¬ä¼—æ„è§ã€‚\n\n#### iniquity\nin- ä¸\niqu- =\u003e =equ, equal, å…¬å¹³, å…¬æ­£\n-ity\n=\u003e ç›¸å½“äº inequity, a very wrong and unfair action or situation\n\n- The writer reflects on human injustice and iniquity.\n\n\n#### headlong\nå¤´å‘å‰çš„, åŒ head-first =\u003e å¤´å‘å‰ä¸€è‚¡è„‘å‘å‰å†² \n=\u003e é€Ÿåº¦å¾ˆå¿«åœ°, adv.  hastily, hurriedly, helter-skelter\n- The car skidded and plunged headlong over the cliff.\n=\u003e é²è½åœ°, è½»ç‡åœ°, rashly, wildly, hastily, precipitately\n- Do not leap headlong into decisions\n\n\n#### turgid\nåŸæ¥æ˜¯æŒ‡(å™¨å®˜æˆ–è€…ç”Ÿç‰©ç»„ç»‡)è‚¿å¤§çš„, è‚¿èƒ€çš„, swollen, =\u003e åæ¥å¯ä»¥å¼•ç”³ä¸º\"æ–‡ç« , å†™ä½œ\"ä¸¥è‚ƒçš„, æ¯ç‡¥ä¹å‘³çš„(å……æ»¡äº†åºŸè¯, å› ä¸ºåºŸè¯è€Œè‚¿èƒ€)\n- a couple of pages of turgid prose.\n\nä¹Ÿå¯ä»¥æŒ‡æ°´æµåŠ¨ä¸ç•…çš„, (æ°´)æ­»çš„\n- The river rolled darkly brown and turgid.\n\n\n#### gainsay\ngain- =\u003e against, åå¯¹, e.g. against\nsay =\u003e è¯´\nåç€è¯´, å¯¹ç€è¯´ =\u003e  åé©³, åå¯¹, å¦è®¤\n\nå›ºå®šæ­é…: there's no gainsaying =\u003e æ— å¯è¾©é©³, æ— å¯å¦è®¤\n\n- Certainly **there's no gainsaying** (= it is not possible to doubt) the technical brilliance of his performance.\n- Who could possibly **gainsay** such a judgment? \n- **There is no gainsaying the fact that** they have been responsible for a truly great building.\n\n#### gratuitousâ˜¢â˜¢\næ¥è‡ª grat-, æ„Ÿè°¢ï¼Œè¯æºåŒ grace,gratitude. åŸæŒ‡è¡¨è¾¾æ„Ÿè°¢ï¼ŒæŠ¥ç­”ï¼Œå…è´¹ç»™äºˆã€‚åè¯ä¹‰è´¬ä¹‰åŒ–ï¼ŒæŒ‡æ— ç¼˜æ— æ•…çš„ï¼Œè«åå…¶å¦™çš„ã€‚\n\n - A lot of viewers complained that there was too much **gratuitous** sex and violence in the film. å¾ˆå¤šè§‚ä¼—æŠ±æ€¨è¯´å½±ç‰‡ä¸­æœ‰å¤ªå¤šæ— è°“çš„è‰²æƒ…å’Œæš´åŠ›é•œå¤´ã€‚ \n \n#### exasperateâ˜¢â˜¢\nex- =\u003e out, out of, thoroughly\nasper =\u003e rough\n-ate\n=\u003e to bring out the rough side of (sb) =\u003e æ¿€æ€’, provoke, irritate\n- The sheer futility of it all exasperates her.\n\n#### dismantle\ndis- mantle =\u003e å–ä¸‹ mantle =\u003e æ‹†å¼€, æ‹†å¸(æŸä¸ªéƒ¨ä»¶)\n=\u003e é€æ¸çš„åºŸé™¤, å–æ¶ˆ, è§£æ•£(ä¸€ä¸ªç³»ç»Ÿæˆ–è€…ç»„ç»‡)\n\n##### mantleâ˜¢\n- (å‰ä»»ç•™ç»™ç»§ä»»è€…çš„)è¡£é’µ, è´£ä»»\n- è¦†ç›–å±‚\n- åœ°å¹”\n- æŠ«é£, æ–—ç¯·\n\n#### hearken\nto listen, to hear =\u003e hear-ken\n\n#### hubrisâ˜¢\næ¥è‡ªå¸Œè…Šè¯­ hybris, å¯¹ç¥çš„æ”¾è‚†æ— ç¤¼ã€‚å¼•ç”³è¯ä¹‰å‚²æ…¢ï¼Œç‹‚å¦„ã€‚\næ¯”å¦‚å…¬å…ƒå‰ 480 å¹´ï¼Œæ³¢æ–¯ç‹è–›è¥¿æ–¯å¸¦é¢†å¤§å†›è¿›å†›å¸Œè…Šï¼Œå¯æ˜¯åœ¨è¾¾è¾¾å°¼å°”æµ·å³¡ï¼Œæ³¢æ–¯äººåˆšæ­å»ºçš„ä¸¤åº§æµ®æ¡¥éƒ½è¢«ç‹‚é£å¹å®ï¼Œæ„¤æ€’çš„è–›è¥¿æ–¯ä»¤äººæŠŠé“ç´¢æŠ›è¿›æµ·é‡Œï¼Œæƒ³è¦é”ä½å¤§æµ·ï¼Œå¹¶æ´¾äººé­æ‰“å¤§æµ· 300 ä¸‹ï¼Œä»¥æŠ¥å¤å¤§æµ·é˜»æ­¢ä»–å‰è¿›ã€‚ç¥æ€’äº†ï¼Œåæœæ˜¯è–›è¥¿æ–¯è¾“æ‰äº†æˆ˜äº‰ã€‚\n\n\n#### hallowâ˜¢\nhallowï¼š['hÃ¦lÉ™ÊŠ] vt. ä½¿...ç¥åœ£ï¼›æŠŠâ€¦è§†ä¸ºç¥åœ£ n. åœ£å¾’\n\nHalloweenï¼ˆä¸‡åœ£å¤œï¼‰ï¼šå¤ä»£è‹±å›½çš„è¨æ¸©èŠ‚\nä¸€è¯´èµ·â€œä¸‡åœ£èŠ‚â€ï¼Œå¾ˆå¤šä¸­å›½äººéƒ½ä¼šæƒ³åˆ°å—ç“œé¥¼ã€é¬¼æ€ªé¢å…·ã€å°å­©æŒ¨å®¶æŒ¨æˆ·è®¨ç³–æœç­‰åœºæ™¯ã€‚è¿™å…¶å®æ˜¯ä¸€ä¸ªå¸¸è§çš„è¯¯è§£ï¼Œä»¥ä¸Šæ´»åŠ¨åº†ç¥çš„æ˜¯æ¯å¹´çš„ 10 æœˆ 31 æ—¥æ™šä¸Šçš„ Halloweenï¼ˆä¸‡åœ£èŠ‚å‰å¤•ã€ä¸‡åœ£å¤œï¼‰ï¼Œå¹¶éæ¯å¹´ 11 æœˆ 1 æ—¥çš„â€œä¸‡åœ£èŠ‚â€ï¼ˆAllhallows's Dayï¼‰ã€‚Halloween æ˜¯â€œä¸‡åœ£èŠ‚â€ï¼ˆAllhallows's Dayï¼‰çš„å‰å¤œï¼Œä½†å®ƒçš„åº†ç¥ä¼ ç»Ÿå¹¶éæºè‡ªâ€œä¸‡åœ£èŠ‚â€ï¼Œè€Œæ˜¯æ¥è‡ªå¤ä»£å‡¯å°”ç‰¹äººçš„â€œè¨æ¸©èŠ‚â€ï¼ˆSamhainï¼Œä»²å¤èŠ‚ã€ç›¸å½“äºä¸­å›½çš„â€œé¬¼èŠ‚â€ï¼‰ã€‚\nåœ¨å¤ä»£å‡¯å°”ç‰¹äººçš„å†æ³•ä¸­ï¼Œæ¯å¹´åæœˆ 31 æ—¥æ˜¯ä¸€å¹´ä¸­çš„æœ€åä¸€å¤©ï¼Œæ˜¯å¤å¤©æ­£å¼ç»“æŸã€ä¸¥é…·å†¬å­£å¼€å§‹çš„ä¸€å¤©ã€‚å¤ä»£å‡¯å°”ç‰¹äººä¿¡å¥‰â€œå¾·é²ä¼Šâ€å®—æ•™ï¼Œç›¸ä¿¡æ•…äººçš„äº¡é­‚ä¼šåœ¨è¿™ä¸€å¤©å›åˆ°æ•…å±…ï¼Œåœ¨æ´»äººèº«ä¸Šæ‰¾å¯»ç”Ÿçµï¼Œå€Ÿæ­¤å†ç”Ÿï¼Œè€Œä¸”è¿™æ˜¯äººåœ¨æ­»åèƒ½è·å¾—å†ç”Ÿçš„å”¯ä¸€å¸Œæœ›ã€‚æ´»ç€çš„äººæƒ§æ€•äº¡é­‚æ¥å¤ºç”Ÿï¼Œäºæ˜¯äººä»¬å°±åœ¨è¿™ä¸€å¤©æ™šä¸Šç†„æ‰å®¶é‡Œçš„ç‚‰ç«å’Œçƒ›å…‰ï¼Œè®©äº¡é­‚æ— æ³•æ‰¾åˆ°å®¶é‡Œæ¥ï¼Œè¿˜æŠŠè‡ªå·±æ‰“æ‰®æˆå¦–é­”é¬¼æ€ªçš„æ¨¡æ ·ï¼ŒæŠŠäº¡é­‚å“èµ°ã€‚\nç½—é©¬äººå…¥ä¾µä¸åˆ—é¢ ç¾¤å²›åï¼Œå°†è¨æ¸©èŠ‚å’Œç½—é©¬çš„ä¸¤ä¸ªèŠ‚æ—¥åˆå¹¶ã€‚åŸºç£æ•™æˆä¸ºç½—é©¬å›½æ•™åï¼Œä¸ºäº†å‹åˆ¶è¿™ç§å¤ä»£å¼‚æ•™ä¼ ç»Ÿï¼Œå¸Œæœ›äººä»¬æ·¡å¿˜è¨æ¸©èŠ‚ï¼Œå°±æŠŠ11æœˆ1æ—¥å®šä¸ºâ€œä¸‡åœ£èŠ‚â€ï¼ˆAllHallow's Dayï¼‰ï¼Œç”¨æ¥çºªå¿µæ®‰é“åœ£å¾’ï¼Œhallowå³åœ£å¾’ä¹‹æ„ã€‚ç„¶è€Œï¼Œè¨æ¸©èŠ‚çš„ä¼ ç»Ÿä¾ç„¶æ²¡æœ‰ä»äººä»¬çš„è®°å¿†ä¸­æŠ¹æ‰ã€‚äººä»¬è™½ç„¶åœ¨ä¸‡åœ£èŠ‚å¯¹åŸºç£æ•™åœ£å¾’è¡¨è¾¾æ•¬æ„ï¼Œå´æ›´å–œæ¬¢åœ¨ä¸‡åœ£èŠ‚å‰ä¸€å¤œæŒ‰ç…§ä¼ ç»Ÿæ–¹å¼è¿›è¡Œåº†ç¥ï¼Œå¦‚åšå—ç“œç¯ã€åŒ–å¦†ã€å°å­©å­æŒ¨å®¶æŒ¨æˆ·è®¨ç³–åƒç­‰ã€‚åªæ˜¯è¿™ä¸ªå¤œæ™šä¸å†å«åšâ€œè¨æ¸©èŠ‚â€ï¼Œè€Œæ˜¯è¢«ç§°ä¸º**Halloweenï¼Œæ˜¯All-hallow eveçš„ç¼©å†™**ï¼Œæ„æ€å°±æ˜¯â€œä¸‡åœ£èŠ‚å‰å¤œâ€ï¼Œä½†å¾ˆå¤šä¸­å›½äººå¹¶ä¸æ˜ç™½äºŒè€…çš„å…³ç³»ï¼Œå¾€å¾€å°†Halloweenå’Œâ€œä¸‡åœ£èŠ‚â€æ··ä¸ºä¸€è°ˆã€‚\nHalloweenï¼š[ËŒhÃ¦lÉ™ÊŠ'iËn] n.ä¸‡åœ£èŠ‚å‰å¤œï¼Œé¬¼èŠ‚\nAllhallows's Dayï¼šä¸‡åœ£èŠ‚\n\n#### debonair\n(especially of men) attractive, confident, and carefully dressed\nï¼ˆå°¤æŒ‡ç”·äººï¼‰æœ‰é­…åŠ›çš„ï¼Œå…‰å½©ç…§äººçš„ï¼Œé£åº¦ç¿©ç¿©çš„\n- a debonair appearance/manner \n\tå…‰å½©ç…§äººçš„å½¢è±¡ï¼å¯Œæœ‰é­…åŠ›çš„ä¸¾æ­¢\n- a debonair young man é£åº¦ç¿©ç¿©çš„å¹´è½»äºº\n\nè‹±è¯­å•è¯ debonair æ¥è‡ªæ³•è¯­ï¼ŒåŸæœ¬æ˜¯é©¯é¹°æœ¯è¯­ï¼Œå­—é¢æ„æ€æ˜¯â€œå“ç§ä¸Šä½³çš„â€ï¼Œç”¨æ¥è¡¨ç¤ºè‰¯ç§çš„ã€ç»è¿‡ä¸¥æ ¼è®­ç»ƒçš„é¹°ã€‚æ³•å›½äººå°¤çˆ±é‚£ç§ç¿…è†€é•¿å¹¶ä¸”ç”Ÿæ€§å‚²æ…¢çš„é›Œæ€§çŒé¹°ï¼Œè®¤ä¸ºè¿™ç§çŒé¹°â€œde bonne airâ€ï¼Œæ„æ€æ˜¯â€œof good airâ€ã€‚è¿™é‡Œçš„ air å’Œç©ºæ°”æ— å…³ï¼Œè€Œæ˜¯è¡¨ç¤ºæ ·å­ï¼ˆè¡€ç»Ÿï¼‰ã€‚12 ä¸–çºªè¿›å…¥è‹±å›½åï¼Œè¡¨ç¤ºâ€œé©¯æœçš„ã€æ¸©é¡ºçš„ã€è°¦æ­çš„â€ã€‚è¯¥è¯åæ¥ä¸æ€ä¹ˆä½¿ç”¨ï¼Œåˆ°äº†ç°ä»£å†æ¬¡æµè¡Œï¼Œè¯ä¹‰æ¼”å˜ä¸ºâ€œå’Œè”¼çš„ã€ä»¤äººæ„‰å¿«çš„ã€å¿«æ´»çš„â€ã€‚\n\n\n#### impugn\nin- =\u003e in, into, on, upon\npugn =\u003e to fight\n=\u003e å¼•ç”³åˆ°è¨€è¯­ä¸Š =\u003e æŠ¨å‡», è´¨ç–‘, challenge, question, attack, dispute\n\n##### pugn-: to fight\n- **oppugn** =\u003e opãƒ»pugn =\u003e fight against, oppose, resist =\u003e å¯¹...æå‡ºè´¨ç–‘, å¯¹...æå‡ºæ€€ç–‘\n- **repugn** =\u003e reãƒ»pugn =\u003e rebel, disobey, oppose, resist, fight against =\u003e åæŠ—, åå¯¹\n- **repugnant** =\u003e reãƒ»pugnãƒ»ant =\u003e \"åæŠ—çš„\" =\u003eå¼•ç”³ä¸ºä»¤äººåŒæ¶çš„, ä»¤äººåæ„Ÿçš„, distasteful, disgust, dislike, hatred\n\t- a repugnant smell\n\t- I find your attitude toward women quite repugnant.\n- **pugnacious** =\u003e pugnãƒ»acious =\u003e å…·æœ‰fightçš„ç‰¹å¾çš„ =\u003e å¥½æ–—çš„, aggressive, contentious, irritable, belligerent\n\n\n#### merit\nIf something has ***merit***, it has good or worthwhile qualities.\n**ä¸å¯æ•°åè¯**\n- The argument seemed to have considerable *merit*.\n- Box-office success mattered more than artistic *merit*.\n- Your feature has the *merit* of simply stating what has been achieved.\n- åŒä¹‰è¯ï¼š worth, value, quality, credit\n\nThe ***merits*** of something are its advantages or other good points. **å¤æ•°åè¯**\n- They have been persuaded of the *merits* of peace.\n- ...the technical *merits* of a film.\n- It was obvious that, whatever its *merits*, their work would never be used.\n- åŒä¹‰è¯ï¼š advantage, value, quality, worth\n\nIf someone or something ***merits*** a particular action or treatment, they deserve it. **åŠ¨è¯**\n- He said he had done nothing wrong to *merit* a criminal investigation. \n- Such ideas *merit* careful consideration.\n- åŒä¹‰è¯ï¼š deserve, warrant, be entitled to, earn   \n\n\n#### noisome\n- late 14c., noisom, \"harmful, noxious\" (senses now obsolete), from noye, noi \"harm, misfortune\" (c. 1300), shortened form of anoi \"annoyance\" (from Old French anoier, see annoy) + -some. Meaning \"bad-smelling, offensive to the sense of smell\" is by 1570s. Related: Noisomeness.\n\nannoy + -some\n- od-,ol-,oz- = scent, è¡¨ç¤ºâ€œå‘³â€ï¼Œod-, ol- æºè‡ªæ‹‰ä¸è¯­, oz- æºè‡ªå¸Œè…Šè¯­ï¼Œéƒ½è¡¨ç¤ºâ€œå‘³é“â€ã€‚\n- -some è¡¨å½¢å®¹è¯ï¼Œâ€œå……æ»¡â€¦çš„ï¼Œå…·æœ‰â€¦å€¾å‘çš„â€ã€‚\n\n#### obloquyâ˜¢\nob- =\u003e against\nloqu =\u003e to speak\n=\u003e to speak against =\u003e Very strong public criticism or blame\n\n##### loqu-, locu-: to speak\n- loquacity\t\t=\u003e loquãƒ»acity =\u003e -acity è¡¨ç¤º\"æœ‰...å€¾å‘çš„\" =\u003e å¥½è¾©, å¤šå˜´\n- eloquent\t=\u003e eãƒ»loquãƒ»ent =\u003e e- è¡¨ç¤º\"å‘å¤–\" =\u003e é›„è¾©çš„, æœ‰è¯´æœåŠ›çš„, æœ‰å£æ‰çš„\n- eloquence\t=\u003e eãƒ»loquãƒ»ence =\u003e å£æ‰, é›„è¾©æœ¯\n- elocution\t=\u003e eãƒ»locuãƒ»tion =\u003e é›„è¾©æœ¯, æ¼”è¯´æ³•\n- locution\t\t=\u003e locuãƒ»tion =\u003e è¯­è¨€çš„è¡¨è¾¾æ–¹å¼, è¯­è¨€é£æ ¼\n- loquacious\t=\u003e loquãƒ»acious =\u003e -aciousè¡¨ç¤º\"æœ‰...ç‰¹å¾çš„\" =\u003e å¤šå˜´çš„, å¥½è¾©çš„\n- colloquy\t\t=\u003e colãƒ»loquãƒ»y =\u003e col- ä¸€èµ·, with, together =\u003e ä¸€èµ·è¯´ =\u003e è®¨è®º, è°ˆè¯, ä¼šè¯\n- **colloquial**\t=\u003e colãƒ»loquãƒ»ial =\u003e ä¼šè¯çš„ =\u003e å£è¯­åŒ–çš„, å£è¯­çš„\n- collocutor\t=\u003e colãƒ»locuãƒ»tor =\u003e å¯¹è¯è€…, è°ˆè¯çš„å¯¹æ‰‹\n- **colloquium**\t=\u003e colãƒ»loquãƒ»ium =\u003e è®¨è®ºä¼š\n- colloquia\t\t=\u003e colãƒ»loquãƒ»ia =\u003e å­¦æœ¯ç ”è®¨ä¼š, å­¦æœ¯ç ”è®¨ä¼šçš„æŠ¥å‘Š\n- obloquy\t\t=\u003e obãƒ»loquãƒ»y =\u003e è´£éª‚, å…¬å¼€çš„æ‰¹è¯„\n- **soliloquy**\t=\u003e soliãƒ»loquãƒ»y   =\u003e soli- å•ç‹¬çš„ =\u003e è‡ªè¨€è‡ªè¯­, ç‹¬ç™½\n- soliloquist\t=\u003e soliãƒ»loquãƒ»ist =\u003e ç‹¬è¯­è€…, è‡ªè¨€è‡ªè¯­çš„äºº\n- soliloquize\t=\u003e soliãƒ»loquãƒ»ize=\u003e è‡ªè¨€è‡ªè¯­, ç‹¬ç™½\n- somniloquy\t=\u003e somniãƒ»loquãƒ»y =\u003e somni- ç¡çœ  =\u003e n. è¯´æ¢¦è¯\n- interlocution\t\t=\u003e interãƒ»locuãƒ»tion =\u003e inter- åœ¨...ä¹‹é—´ =\u003e å¯¹è¯, äº¤è°ˆ\n- interlocutory\t\t=\u003e interãƒ»locuãƒ»tory =\u003e å¯¹è¯çš„, äº¤è°ˆçš„\n- interlocutor\t\t=\u003e interãƒ»locuãƒ»tor =\u003e å¯¹è¯è€…, å‚ä¸å¯¹è¯çš„äºº, ä»£è¨€äºº\n- grandiloquence\t=\u003e grandiãƒ»loquãƒ»ence =\u003e grandi- å¤§çš„ =\u003e è±ªè¨€å£®è¯­, å¤¸å¼ çš„è¨€è®º\n- grandiloquent\t=\u003e grandiãƒ»loquãƒ»ent =\u003e grandi- å¤§çš„ =\u003e å–å¼„è¾è—»çš„, è¨€è¾æµ®å¤¸çš„, è¿‡åˆ†åä¸½çš„\n- circumlocution\t=\u003e circumãƒ»locuãƒ»tion =\u003e è¿‚å›çš„è¯´æ³• \n- magniloquence\t=\u003e magniãƒ»loquãƒ»ence =\u003e å¤¸å¼ çš„è¯´æ³•\n\n#### phlegmatic\nphlegmï¼ˆç²˜æ¶²ï¼‰ï¼šå¯¼è‡´äººæ€§æƒ…å†·æ·¡çš„ç²˜æ¶²\næ ¹æ®å››ä½“æ¶²å­¦è¯´ï¼Œä½“å†…ç²˜æ¶²å æ¯”è¾ƒé«˜çš„äººæ€§æƒ…å†·æ·¡ã€ååº”è¿Ÿé’ã€‚å› æ­¤ï¼Œè‹±è¯­å•è¯ phlegmï¼ˆç²˜æ¶²ï¼‰çš„å½¢å®¹è¯ phlegmatic å°±äº§ç”Ÿäº†â€œå†·æ·¡çš„ã€è¿Ÿé’çš„â€ç­‰å«ä¹‰ã€‚\n- phlegmï¼š[flem] n. ç—°ï¼›ç²˜æ¶²\n- phlegmaticï¼š[fleg'mÃ¦tÉªk] adj. å†·æ·¡çš„ï¼›è¿Ÿé’çš„ï¼›å†·æ¼ çš„\n- phlegmyï¼š['flÉ›mi] adj. ç—°çš„ï¼›ç”Ÿç—°çš„ï¼›å«ç—°çš„\n\n\n#### providenceâ˜¢â˜¢\npro- =\u003e æå‰, ahead\nvid- =\u003e åŒ vis-,  to see, çœ‹\n-ence \nto see ahead =\u003e æœªåœå…ˆçŸ¥, ç¥çµæå‰å®‰æ’å¥½çš„ =\u003e å¤©å‘½, å¤©æ„, å¤©é“\n- These women regard his death as an act of providence\n\n##### providentialâ˜¢\npertaining to foresight =\u003e å¤©æ„çš„, ç¥åŠ©çš„ =\u003e å‡‘å·§çš„, æ—¶é—´æ­£å¥½çš„, lucky, timely\n - a providential opportunity æœºç¼˜å·§åˆ \n\n#### providentâ˜¢\nç›¸æ¯”ä¸Šé¢çš„ providential, è¿™ä¸ªç‰¹æŒ‡(åœ¨ç‰©è´¨å‡†å¤‡ä¸Š)æœªé›¨ç»¸ç¼ªçš„, (åœ¨ç»æµä¸Š)æœ‰è¿œè§çš„\n\n\n#### prudeâ˜¢\na person who is easily shocked by rude things, especially those of a sexual type\n\n- prudish\n\nä¸è¦å’Œ pedant å¼„æ··äº†\n\n\n#### rapacious\nrap- =\u003e to snatch, to seize, æŠ“æ•, æŠ¢å¤º, æ¥è‡ªæ‹‰ä¸è¯­ rapere\n-acious =\u003e æœ‰...ç‰¹å¾çš„\n=\u003e å¼ºå–è±ªå¤ºçš„, è´ªå©ªçš„, æ å¤ºçš„, grasping, insatiable, ravenous, greedy\n\n##### rap-\n- rapine noun. åŠ«æ , æŠ¢å¤º\n- rape\n- rapacity =\u003e è´ªå©ª, æ å¤º\n\n\n#### relinquish\nre- =\u003e back, against\nlinqu- =\u003e to leave\n-ish =\u003e åŠ¨è¯åç¼€, é€ æˆ...\n=\u003e abandon, desert =\u003e give up the pursuit or practice of, desist, cease from, æ”¾å¼ƒ(a responsibility or claim)\n- He has *relinquished* his claim to the throne\n- She *relinquished*  control of the family investments to her son. \n- è¿™ä¸ªæ”¾å¼ƒçš„ä¸œè¥¿å’Œ give up æœ‰æ‰€ä¸åŒ, æ›´ä¸ºæ­£å¼\n\n##### delinquentâ˜¢\nde- =\u003e completely\nlinqu- =\u003e to leave\n-ent =\u003e è¿™é‡Œæ˜¯åè¯åç¼€å’Œå½¢å®¹è¯åç¼€\n- è¢«é—å¼ƒä¹‹äºº =\u003e (é€šå¸¸æŒ‡é’å¹´)è¿æ³•è€…\n\t- juvenile delinquents\n- ä¸è‰¯çš„, è¿æ³•çš„(èƒŒå¼ƒäº†è‡ªå·±çš„è´£ä»»çš„, one who fails to perform a duty or discharge an obligation, offender of the law)\n\t- delinquent teenagers\n- åæ¥ä¹Ÿå¼•ç”³ä¸ºæ‹–æ¬ æ¬ æ¬¾çš„\n\t- She has been delinquent in paying her taxes.\n\n\n#### resonantâ˜¢\nresonant æ˜¯ resonate çš„å½¢å®¹è¯, \"å…±æŒ¯çš„\" \n=\u003e ä»å£°éŸ³è§’åº¦æ¥ç†è§£ -\u003e å£°éŸ³æ´ªäº®çš„, deep and strong, åƒé’ŸæŒ¯åŠ¨çš„æ—¶å€™çš„å£°éŸ³\n- a deep, **resonant** voice æ·±æ²‰è€Œæ´ªäº®çš„å—“éŸ³\n- a **resonant** concert hall å…±é¸£æ•ˆæœå¥½çš„éŸ³ä¹å…\n\n=\u003e ä»\"é¢‘ç‡ç›¸åŒ\"çš„è§’åº¦æ¥ç†è§£ =\u003e å¼•èµ·å…±é¸£çš„, å¼•èµ·è”æƒ³çš„\n- We felt privileged to be the first group of Western visitors to enter the historic palace, **resonant** with past conflicts.\n\n\n#### resourceful\nè¶³æ™ºå¤šè°‹çš„ï¼Œ è¿™é‡Œçš„ resource æŒ‡çš„æ˜¯\"è®¡è°‹ï¼Œè§£å†³é—®é¢˜çš„æ–¹æ³•ï¼Œè°‹ç•¥ï¼Œæ™ºæ…§\" =\u003e good at dealing with problems\n\n#### retardâ˜¢\nretard ä¸å•å•æ˜¯ç”¨æ¥éª‚äººçš„, ä½œä¸ºåŠ¨è¯, retard çš„æ„æ€æ˜¯\"é˜»ç¢, å‡ç¼“\"æŸä¸ªè¡ŒåŠ¨, æŸä¸ªè¿›ç¨‹\n- A rise in interest rates would severely **retard** economic growth.\n\n- æ‰€ä»¥ retarder è¿˜æœ‰\"å‡é€Ÿå™¨, é˜»æ»å‰‚\"çš„æ„æ€\n- retardant =\u003e èµ·é˜»æ»ä½œç”¨çš„(adj), é˜»æ»å‰‚(noun.)\n\n=\u003e (æ™ºåŠ›)è¢«å‡ç¼“äº†çš„ =\u003e noun. å¼±æ™º, ç¬¨è›‹\nretarded =\u003e offensive\n\n##### tardy\nç¼“æ…¢çš„, è¿Ÿç¼“çš„\n\n#### sartorialâ˜¢\næ¥è‡ªæ‹‰ä¸è¯­é‡Œé¢çš„\"sartor\"=\u003etailor, è£ç¼çš„, æ³›æŒ‡\"æœè£…çš„, åˆ¶è¡£çš„, è¡£ç€çš„\"\n- sartorial elegance\n\n\n#### sidestep\nå‘æ—è¾¹é€€ä¸€æ­¥ =\u003e å‘æ—è¾¹èº²å¼€ =\u003e ä¹Ÿå¼•ç”³ä¸º\"é€šè¿‡è®¨è®ºåˆ«çš„äº‹æƒ…æ¥å›é¿æŸä¸ªè¯é¢˜\"\n- The speaker sidestepped the question by saying that it would take him too long to answer it.\n\n\n\n#### slate\nslate åŸæœ¬æŒ‡çš„æ˜¯ä¸€ç§å²©çŸ³ =\u003e æ¿å²©, é¡µå²©, ä¸€ç§å¾ˆå®¹æ˜“åŠˆæˆä¸€ç‰‡ä¸€ç‰‡çš„å²©çŸ³ \n=\u003e å› æ­¤ slate ä¹Ÿå¯ä»¥ç”¨æ¥æŒ‡ä»£\"çŸ³æ¿\"\n- slate roof, çŸ³æ¿ç“¦å±‹é¡¶\n\n=\u003e å¤æ—¶äººä»¬è¿˜ä¼šåœ¨çŸ³æ¿ä¸Šå†™å­—, åœ¨é€‰ä¸¾é¦–é¢†çš„æ—¶å€™, ä¼šå…ˆæŠŠå€™é€‰è€…çš„åå­—å†™åœ¨çŸ³æ¿ä¸Š, å› æ­¤ slate ä¹Ÿç”¨æ¥æŒ‡ä»£\"å€™é€‰äººåå•\"\n- His novel was chosen from a slate of ten finalists.\n\n=\u003e be slated =\u003e å†™åœ¨çŸ³æ¿ä¸Šçš„ =\u003e è®¡åˆ’å¥½çš„, é¢„å®š, å®‰æ’\n- The meeting is slated for next Thursday\n- Jeff is slated to be the next captain.\n\n=\u003e slate è¿˜æœ‰\"æŠ¨å‡», æ‰¹è¯„\"çš„æ„æ€(informal), ä¹Ÿè®¸æ˜¯åœ¨çŸ³æ¿ä¸Šå†™åè¯çš„æ„æ€?\n- Her last book was slated by the critics.\n\n##### wipe the slate clean\n[idiom] to start a new and better way of behaving, forgetting about any bad experiences in the past:\n- A new relationship presents you with the opportunity to wipe the slate clean.\n\n\n#### spleenâ˜¢\næ¥è‡ªæ‹‰ä¸è¯­ splen, æ¥è‡ªå¸Œè…Š splen, æ¥è‡ª spelgh, è„¾ã€‚å› ä¸­ä¸–çºªåŒ»å­¦ç†è®ºè®¤ä¸ºè„¾æ˜¯äººä½“æ€’ç«å’Œæ€’æ°”éƒç§¯ä¹‹æ‰€ï¼Œå› è€Œå¼•ç”³è¯ä¹‰\"æ€’ç«ï¼Œæ€’æ°”\"ã€‚\n- spleenful =\u003e è„¾æ°”åçš„\n- splenetic =\u003e è„¾æ°”åçš„, æ˜“æ€’çš„, irritable, bad-tempered\n- splenic =\u003e å’Œè„¾è„ç›¸å…³çš„\n\n\n#### stonewall\nè¿™æ˜¯ä¸€ä¸ªå¤åˆè¯ï¼Œç”±stoneï¼ˆçŸ³ï¼‰å’Œwallï¼ˆå£ï¼Œå¢™ï¼‰åˆæˆï¼Œå­—é¢ä¹‰ä¸ºâ€œçŸ³å£â€ã€â€œçŸ³å¢™â€ã€‚ç¾å›½å—åŒ—æˆ˜äº‰ï¼ˆ1861-1865ï¼‰æ—¶ï¼Œå—å†›è‘—åå°†é¢†Thomas Jonathan Jackson (1824-1863)åœ¨å¸ƒå°”æºªç•”æˆ˜å½¹ï¼ˆthe Battle of Bull Runï¼‰ä¸­ç‡æ‰€éƒ¨ä¸€ä¸ªæ—…çš„å…µåŠ›ï¼Œç»„æˆä¸€é“åšå¦‚çŸ³å£çš„é˜²çº¿ï¼Œé¡¶ä½äº†ä¼˜åŠ¿åŒ—å†›çš„è¿›æ”»ï¼Œèµ¢å¾—äº†Stonewall Jacksonï¼ˆçŸ³å£æ°å…‹é€Šï¼‰çš„ç»°å·ã€‚\n\nstonewallé€šå¸¸å¤šç”¨äºå–»ä¹‰ã€‚æœ€åˆåªè¢«ä½œä¸ºæ¿çƒï¼ˆcricketï¼‰çš„ä¸€ä¸ªæœ¯è¯­ï¼Œè¡¨ç¤ºâ€œé˜²å®ˆæŒ¡å‡»â€ï¼Œ19ä¸–çºª80å¹´ä»£æ¾³å¤§åˆ©äºšå’Œè‹±å›½æ”¿ç•Œäººå£«æŠŠå®ƒè½¬ç”¨åˆ°æ”¿æ²»æ–¹é¢ã€‚æœ‰çš„è®®å‘˜åœ¨è®®ä¼šè®¨è®ºæ—¶å¯ä»¥æ»”æ»”ä¸ç»åœ°ä¸€å°æ—¶æ¥ç€ä¸€å°æ—¶åœ°æ¼”è®²æˆ–è´¨é—®ï¼Œä»¥æ­¤ç»„æˆä¸€é“æ— å½¢çš„çŸ³å¢™æ¥å»¶é˜»ä¼šè®®è®®ç¨‹çš„è¿›å±•ã€‚è¿™ç§ç”¨å†—é•¿å‘è¨€ç­‰æ‹–å»¶æ‰‹æ®µé˜»ç¢è®®äº‹çš„è¡Œä¸ºï¼Œäººä»¬ä¾¿ç”¨stonewallä¸€è¯æ¥ä½œæ¯”ã€‚\n\nåœ¨ç¾å›½è‹±è¯­ä¸­stonewallåŸå…ˆä¸èƒ½ç®—æ˜¯ä¸€ä¸ªå¸¸ç”¨è¯ï¼Œå°½ç®¡åœ¨ä»»ä½•ä¸€æœ¬ç¾å›½è¯å…¸ä¸­éƒ½èƒ½æŸ¥åˆ°ã€‚ä½†åœ¨20ä¸–çºª70å¹´ä»£è½°åŠ¨ä¸€æ—¶çš„æ°´é—¨äº‹ä»¶è°ƒæŸ¥çš„é«˜æ½®ä¸­ï¼Œç¾å›½æ€»ç»Ÿå°¼å…‹æ¾ï¼ˆRichard M. Nixon, 1913-1994ï¼‰ä½¿å®ƒçš„è¯ä¹‰è·å¾—è¿›ä¸€æ­¥å»¶ä¼¸ã€‚ä»–è®©ä»–çš„åŠ©æ‰‹ä»¬é¡¶ä½å‹åŠ›ï¼Œå¯¹è”é‚¦è°ƒæŸ¥äººå‘˜è®¾ç½®éšœç¢ï¼Œå°½é‡å»¶é˜»ä»–ä»¬çš„è°ƒæŸ¥ï¼ˆto stonewall itï¼‰ã€‚ç™½å®«æ‰€ä½œçš„åŠªåŠ›æ²¡æœ‰æˆåŠŸï¼Œæœ€åå°¼å…‹æ¾æ€»ç»Ÿè¢«è¿«è¾èŒï¼Œä»–çš„ä¸€äº›åŠ©æ‰‹è¢«åˆ¤äº†åˆ‘ã€‚stonewallä¸€è¯å´ä»æ­¤è¢«èµ‹äºˆäº†æ–°çš„å«ä¹‰ï¼Œä¸å†å›¿äºæ¿çƒå’Œè®®ä¼šï¼Œå¼€å§‹ç”¨äºå¹¿ä¹‰ä¸Šçš„â€œå¦¨ç¢è¡ŒåŠ¨â€å’Œâ€œè®¾ç½®éšœç¢â€ã€‚\n\nä¾‹ \n- He was **stonewalling** and everybody knew it. (CCE) ä»–æ˜¯åœ¨ç”¨æ‹–å»¶çš„åŠæ³•æ¥é˜»ç¢è®®äº‹ï¼Œè¿™ä¸€ç‚¹å¤§å®¶éƒ½çœ‹å¾—å‡ºæ¥ã€‚\n- Queries about civilian casualties during the bombing raid were **stonewalled** by government officials. (CID) å¯¹äºäººä»¬æå‡ºçš„å…³äºç©ºè¢­ä¸­å¹³æ°‘ä¼¤äº¡çš„è´¨ç–‘æ”¿åºœå®˜å‘˜é¿è€Œä¸ç­”ã€‚\n\n\n#### travesty\næ€»ç»“ä¸€ä¸‹å‡ ä¸ªæ„æ€ç›¸è¿‘çš„è¯æ±‡\n##### è¯å…¸çš„è§£é‡Š\n**travesty** \n- something that fails to represent the values and qualities that it is intended to represent, in a way that is shocking or offensive\n\n**parody**\n- writing, music, art, speech, etc. that intentionally copies the style of someone famous or copies a particular situation, making the features or qualities of the original more noticeable in a way that is humorous\n\n**burlesque**\n- a type of writing or acting that tries to make something serious seem stupid\n\n**caricature**\n- (the art of making) a drawing or written or spoken description of someone that usually makes them look silly by making part of their appearance or character more noticeable than it really is\n\n##### è¿›ä¸€æ­¥æ¯”è¾ƒ\n**Caricature**, **burlesque**, **parody**, **travesty** areÂ comparable as nouns meaning a grotesque or bizarre imitationÂ of something and as verbs meaning to make such anÂ imitation.\n\n**Caricature** implies ludicrous exaggeration orÂ distortion (often pictorial) of characteristic or peculiarÂ features (as of a person, a group, or a people) for the sake of satire or ridicule.\n\n**Burlesque** implies mimicryÂ (especially of words or actions in the theater) that arousesÂ laughter. The term usually also suggests distortion (asÂ by treating a trifling subject in mock-heroic vein or byÂ giving to a serious subject a frivolous or laughable turn) for the sake of the comic effect.\n\n**Parody** basically denotesÂ a writing in which the language and style of an authorÂ or work are closely imitated for comic effect or in ridicule.\n\n_Parody,_ like _caricature,_ may involveÂ exaggeration or, like _burlesque,_ distortion but ordinarily isÂ more subtle and sustained than the first and quieter andÂ less boisterous than the second.\n\nIn extended use _parody_ may apply, often withÂ more than a hint of bitterness or disgust, to a feeble or inappropriate imitation or to a poor inadequate substitute.\n\n**Travesty** is usually a harsher word than others of thisÂ group; it implies a palpably extravagant and often debasedÂ or grotesque imitation and more often and more intenselyÂ than parody suggests repulsion.\n\næ‰€ä»¥caricatureå’Œburlesqueéƒ½æ˜¯for funçš„, è€Œparodyå¸¦æœ‰ä¸€ä¸¢ä¸¢è´¬ä¹‰, travestyçš„è´¬ä¹‰æœ€å¼ºçƒˆ, ç±»ä¼¼äº\"é—¹å‰§\"\n\n#### whet\nwhet çš„æœ¬æ„æ˜¯ ç£¨(åˆ€), æŠŠåˆ€å˜é”‹åˆ©\n**whet one's appetite** =\u003e æŒ‘èµ·æŸäººçš„æ¬²æœ›, æ¿€èµ·æŸäººçš„æ¬²æœ›\n\n\n#### altruism\nå€Ÿè‡ªæ³•è¯­altruismeï¼Œè¿™æ˜¯æ³•å›½å“²å­¦å®¶å­”å¾·ï¼ˆAuguste Comte, 1798-1857ï¼‰äº1830å¹´æœæ’°çš„ä¸€ä¸ªè¯ï¼Œç”¨ä½œegoismï¼ˆåˆ©å·±ä¸»ä¹‰ï¼‰çš„åä¹‰è¯ï¼Œç”±æ„å¤§åˆ©è¯­altrui 'someone else'ï¼ˆåˆ«äººï¼‰æˆ–æ‹‰ä¸è¯­alter 'other'ï¼ˆåˆ«çš„ï¼‰åŠ åç¼€-ismeæ„æˆã€‚altruismé‡Šä¹‰ä¸ºâ€œåˆ©ä»–ä¸»ä¹‰â€ï¼Œä¹Ÿå¯æŒ‡â€œï¼ˆåŠ¨ç‰©çš„ï¼‰è‡ªæˆ‘ç‰ºç‰²è¡Œä¸ºâ€ã€‚\n\nä¾‹ \n- Nobody believes those people are donating money to the president's party purely out of altruism.  è°ä¹Ÿä¸ä¼šç›¸ä¿¡é‚£äº›äººææ¬¾ç»™æ€»ç»Ÿçš„æ”¿å…šçº¯ç²¹æ˜¯å‡ºäºæ— ç§ã€‚\n- I doubt whether her motives for donating the money are altruistic â€” she's probably looking for publicity. \n\tæˆ‘æ€€ç–‘å¥¹æé’±çš„åŠ¨æœºæ˜¯å¦æ˜¯æ— ç§çš„â€”â€”ä¹Ÿè®¸æ˜¯ä¸ºäº†å‡ºé£å¤´ã€‚\n\n#### diffuse\n![fus-](#fus-)\n\ndiffuse\"æ•£å°„\"çš„å«ä¹‰å¾ˆå¥½ç†è§£, é™¤äº†æ•£å°„æŸä¸ªç‰©è´¨æˆ–è€…å…‰çº¿, diffuse ä¹Ÿå¯ä»¥æŒ‡æ•£å¸ƒæŸç§æ€æƒ³, æŸä¸ªä¿¡æ¯\n- Television is a powerful means of diffusing knowledge.\n\nè€Œå¦‚æœæŸä¸€ç¯‡æ–‡ç« æ˜¯ diffuse çš„å°±ä¸æ˜¯ä¸€ä»¶å¥½äº‹äº†, è¯´æ˜å…¶æ€æƒ³ä¸æ˜ç¡®, ä¸»é¢˜å¾ˆå«ç³Š, =\u003e å«ç³Šçš„, è´¹è§£çš„, vague, not clear and difficult to understand\n- a diffuse literary style\n\n\n#### domineer\n- dom-,domin-,tam- = house, è¡¨ç¤ºâ€œå±‹ï¼Œå®¶ï¼Œæ§åˆ¶â€\n- -er æ˜¯æ–½åŠ¨è€…åè¯åç¼€ï¼Œè¡¨ç¤ºâ€œäººæˆ–ç‰©â€ï¼Œä¸€èˆ¬ç¼€äºåŠ¨è¯åï¼Œæ¥è‡ªå¤è‹±è¯­ã€‚\n\n- The hoover roared into life, ***domineering*** the room\" -dominating the room, becoming the center of attention in the room-\" like a proud king\" .  \n\tâ€œå¸å°˜å™¨å’†å“®ç€ï¼Œåœ¨æˆ¿é—´é‡Œæ¨ªè¡Œéœ¸é“çš„â€â€”å……æ–¥ç€æˆ¿é—´ï¼ŒæŠŠå®ƒå˜æˆäº†æ•´ä¸ªæˆ¿é—´é‡Œæ³¨æ„åŠ›çš„ä¸­å¿ƒâ€”â€œå°±åƒä¸€ä½å‚²æ…¢çš„å›½ç‹\n\n#### prevaricateâ˜¢â˜¢\n- 1580s, \"to go aside from the right course or mode of action\" (originally figurative, now obsolete), a back formation from prevarication or else from Latin praevaricatus, past participle of praevaricari \"***to make a sham accusation, deviate\" (from the path of duty)***, literally \"walk crookedly;\"\n- The meaning \"***to act or speak evasively, swerve from the truth***\" is from 1630s. Related: Prevaricated; prevaricating.\n\n- åœ¨åˆ«äººæŒ‡è´£ä»–çš„æ—¶å€™, åè€Œå»æ— ç«¯çš„æŒ‡è´£åˆ«äºº, pre- =\u003e åœ¨...ä¹‹å‰, vari =\u003e å˜åŒ–, vary, change\n- æªå¡, å«ç³Šå…¶è¾, evade, \n\n#### glaze\n\n![300](notes/2022/2022.7/assets/Pour-Mirror-Glaze-over-Cake.webp)\n\n![300](notes/2022/2022.7/assets/how-to-glaze-pottery-at-home-1.webp)\n\n- glaze ä½œä¸ºåŠ¨è¯, è¿˜æœ‰\"çœ¼ç¥å˜å‘†æ»\"çš„æ„æ€, \n\t- Among the audience, eyes **glazed** over and a few heads started to nod.\n\n\n#### mercenary\né™¤äº†ä½œä¸ºåè¯\"é›‡ä½£å…µ\", mercenary è¿˜å¯ä»¥ä½œä¸ºå½¢å®¹è¯: å”¯åˆ©æ˜¯å›¾çš„, æˆ–è®¸æ˜¯å› ä¸ºå”¯åˆ©æ˜¯å›¾çš„äººå°±åƒé›‡ä½£å…µä¸€æ ·, åªè¦ç»™é’±å¹²ä»€ä¹ˆéƒ½å¯ä»¥.\n- He had some mercenary scheme to marry a wealthy widow.\n\n\n#### emulationâ˜¢\n- imitative rivalry\n- effort to equal or excel in qualities or actions that one admires in another or others.\n\n- å…¶å®åœ¨è®¡ç®—æœºè½¯ä»¶é‡Œé¢æˆ‘å·²ç»è§è¿‡è¿™ä¸ªå•è¯äº†, emulation=\u003eä»¿çœŸ\n\n**emulate**\n- æ•ˆä»¿, ç«äº‰å¹¶è¯•å›¾è·Ÿä¸Š\n\n#### shopworn\nåœ¨å•†åº—é‡Œé¢æ”¾ä¹…äº†çš„(ä¸œè¥¿), ä¹Ÿå¼•ç”³ä¸º\"é™ˆè¯æ»¥è°ƒ\"\n\n\n#### spateâ˜¢\næœ¬æ„æ˜¯\"æ²³æµçŒ›æ¶¨\", åé¢å¼•ç”³ä¸º\"å¤§é‡(ä¸æ„‰å¿«çš„æ—¶é—´)çš„åŒæ—¶å‘ç”Ÿ\" (noun)\n![300](notes/2022/2022.7/assets/f1579b5e-760b-4118-b64b-a32967ae1e30-large16x9_thumb_41633.jpg)\n- Police are investigating **a spate of** burglaries in the Kingsland Road area.\n\n#### rash\nç–¹å­ =\u003e a rash of ä¹Ÿå¯ä»¥ç”¨äºå½¢å®¹ä»¤äººä¸å¿«çš„æ—¶é—´çš„çªç„¶å¤§é‡å‡ºç°\n- There has been **a rash of** robberies/ accidents / complaints in the last two years.\n\nå¾—äº† rash è®©äººå¾ˆçƒ¦èº =\u003e è¿˜èƒ½ç”¨äºå½¢å®¹äºº\"è½»ç‡çš„, é²è½çš„, æ¯›èºçš„\"\n- That was a rash decision.\n\n#### bulgeâ˜¢\n(èº«ä½“çš„æŸä¸ªéƒ¨åˆ†)é¼“èµ·æ¥, å‡¸å‡ºæ¥\n- Jiro waddled closer, his belly bulging and distended\n- His eyes seemed to bulge like those of a toad\nä¹Ÿå¯ä»¥ä½œåè¯, \"å‡¸èµ·\"\n- Why won't those bulges on your hips and thighs go?\n\n**be bulging with** =\u003e be full of ... (å¡æ»¡äº†ä»¥è‡³äºé¼“èµ·æ¥äº†)\n- a bulging briefcase\n\na sudden large increase of... =\u003e **a bulge in sth**\n- a bulge in aircraft sales\n\n#### mirage\n![mir-](#mir-)\nä»\"æµ·å¸‚èœƒæ¥¼\"å¼•ç”³ä¸º\"å¦„æƒ³, å¹»æƒ³\"\n- Immortality is just a mirage.\n\n\n#### denigrateâ˜¢\nde- =\u003e completely\nnigr- =\u003e black\n-ate\n=\u003e ä½¿...å®Œå…¨å˜é»‘, è¯çš„æ„æ€å’Œè¯çš„å­—é¢ç»„æˆéƒ½å’Œæ±‰è¯­é‡Œé¢çš„\"æŠ¹é»‘\"ä¸€æ ·, è´¬æŸ, è¯‹æ¯, disparage, run down\n\n\n#### adamant â˜¢\næ—©åœ¨ä¹”åŸæ—¶ä»£ï¼Œadamant ä¸€è¯å°±å·²æ˜¯è‹±è¯­çš„ä¸€åˆ†å­ï¼Œå®ƒæºäºå¸Œè…Šè¯­ adamasï¼ˆæœ€åšç¡¬çš„é‡‘å±ï¼‰ï¼Œä½†å´å€Ÿè‡ªå¤æ³•è¯­ adamauntï¼ˆæœ€åšç¡¬çš„çŸ³å¤´ï¼‰ã€‚å› æ­¤ï¼Œæœ‰å¥½å‡ ä¸ªä¸–çºª adamant ä¸€ç›´è¢«ä½œä¸º diamondï¼ˆé‡‘åˆšçŸ³ï¼‰çš„åŒä¹‰è¯ä½¿ç”¨ï¼ˆå…¶å®ä¸¤è€…ç³»åŒæºè¯ï¼‰ã€‚å®ƒè¢«å¹¿æ³›ç”¨ä½œå½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œåšç¡¬çš„â€ã€â€œåšå†³çš„â€æˆ–â€œå›ºæ‰§çš„â€ç­‰ä¹‰ï¼Œåˆ™æ˜¯ 20 ä¸–çºª 30 è‡³ 40 å¹´ä»£ä»¥åçš„äº‹ã€‚\n\nä¾‹ \n- The government remains adamant that it will not yield to pressure. æ”¿åºœçš„æ€åº¦ä»ç„¶åšå†³ï¼Œä¸æ„¿å±ˆæœäºå‹åŠ›ã€‚\n- We tried to negotiate, but they were adamant.  æˆ‘ä»¬æƒ³è°ˆåˆ¤ï¼Œä½†ä»–ä»¬å¾ˆå›ºæ‰§ã€‚\n- He's absolutely adamant in/about not allowing smoking in his house. ä»–åšå†³ä¸å…è®¸åœ¨ä»–çš„æˆ¿å­é‡ŒæŠ½çƒŸã€‚\n\n#### belligerent\nå¥½æˆ˜çš„, aggressive, hostile, animosity, combative\nè€Œç”¨äºæˆ˜äº‰ä¸­å¯ä»¥æŒ‡ä»£\"äº¤æˆ˜çš„\"\n- the belligerent countries =\u003e äº¤æˆ˜å›½\n\n\n#### coeval\nco- =\u003e with together\nev- =\u003e age\n-al =\u003e ...çš„\nåŒæ—¶ä»£çš„\n\n##### ev- \n- medieval\n- primeval\n- longeval =\u003e é•¿å‘½çš„\n- longevity =\u003e longãƒ»evãƒ»ity =\u003e é•¿å¯¿\n\n#### imperiousâ˜¢â˜¢\nimper- =\u003e åŒ empire, command, å‘½ä»¤, ç»Ÿæ²»\n-ious =\u003e å½¢å®¹è¯åç¼€\n- å‘½ä»¤çš„, ç»Ÿæ²»çš„ =\u003e ä¸“æ¨ªè·‹æ‰ˆçš„ï¼ˆæ‹¼éŸ³ï¼šzhuÄn hÃ¨ng bÃ¡ hÃ¹ï¼‰\ndomineering, dictatorial, bossy, haughty\n\n\n#### nonchalant\nnon- =\u003e ä¸\nchal =\u003e heat, to be warm, æ¯”å¦‚calorie\n-ant =\u003e ...çš„\nä¸çƒ­å¿ƒçš„ =\u003e å†·æ·¡çš„, æ¼ ä¸å…³å¿ƒçš„, æ¯«ä¸åœ¨ä¹çš„\n\n#### dexterous\nåœ¨å¤è‹±è¯­æ—¶æœŸ right çš„è¯å½¢ä¸º rihtï¼Œé‚£æ—¶å®ƒå°±å·²æœ‰äº†â€œå…¬ç†â€ã€â€œæ­£ç›´â€ã€â€œåˆé€‚çš„â€ã€â€œæ­£å½“çš„â€ã€â€œç›´çš„â€ç­‰æŠ½è±¡æ„ä¹‰äº†ã€‚åˆ°äº† 13 ä¸–çºªï¼Œäººä»¬å¼€å§‹æœ‰è¾ƒæ˜ç¡®çš„æ–¹å‘æ„Ÿï¼Œright è¢«ç”¨æ¥è¡¨ç¤ºâ€œå³â€ã€‚ç”±äºå¤§å¤šæ•°äººç”¨å³æ‰‹åšäº‹æ¯”è¾ƒçµæ´»ï¼Œæ‰€ä»¥è®¤ä¸ºç”¨å³æ‰‹æ˜¯æ­£ç¡®çš„ï¼Œäºæ˜¯ right åˆä»â€œå³çš„â€å¼•ç”³å‡ºâ€œæ­£ç¡®çš„â€ä¸€ä¹‰ã€‚\n\nä»¥ right æŒ‡æ”¿æ²»æ€åº¦çš„ä¿å®ˆæˆ–å³å€¾å¯ä»¥è¿½æº¯è‡³ 18 ä¸–çºªçš„æ³•å›½å¤§é©å‘½ã€‚åœ¨ 1789 å¹´çš„æ³•å›½å›½æ°‘ä¼šè®®ï¼ˆFrench National Assemblyï¼‰ä¸Šï¼Œæ”¿æ²»ä¸Šå€¾å‘äºä¿å®ˆçš„è´µæ—éƒ½ååœ¨ä¼šè®®å…çš„å³ä¾§ï¼ˆright wingï¼‰ï¼Œå³ä¸»å¸­å³è¾¹çš„å¸­ä½ï¼Œè€Œæ¿€è¿›çš„æ°‘ä¸»æ´¾åˆ™åœ¨å·¦ä¾§ï¼ˆleft wingï¼‰ï¼Œå³ä¸»å¸­å·¦è¾¹çš„å¸­ä½ã€‚ä»¥åçš„æ¬§ç¾ä¼šè®®æˆ–è®®ä¼šä»æ—§æ²¿ç”¨è¿™ç§åº§ä½å®‰æ’ã€‚right wing ä¹Ÿå› æ­¤è¢«ç”¨æ¥è¡¨ç¤ºâ€œï¼ˆæ”¿æ²»ä¸Šçš„ï¼‰å³ç¿¼ï¼ˆçš„ï¼‰â€æˆ–â€œå³æ´¾ï¼ˆçš„ï¼‰â€ï¼Œè€Œ left wing åˆ™æŒ‡â€œå·¦ç¿¼ï¼ˆçš„ï¼‰â€æˆ–â€œå·¦æ´¾ï¼ˆçš„ï¼‰â€ã€‚\n\n##### adroit / dexterous\nè‹±è¯­æœ‰ä¸¤ä¸ªå¤–æ¥è¯­å’Œ right ä¸€è¯æœ‰è¾ƒå¯†åˆ‡çš„å…³ç³»ã€‚ä¸€ä¸ªæ˜¯ **dexterous**/dextrousï¼Œæºäºæ‹‰ä¸è¯­ dexterï¼ˆå³ï¼‰ï¼›å¦ä¸€ä¸ªæ˜¯ **adroit**ï¼Œæºäºæ³•è¯­ droitï¼ˆå³ï¼‰ã€‚ä½†äºŒè¯éƒ½è¢«èµ‹äºˆâ€œçµå·§çš„â€æˆ–â€œæ•æ·çš„â€ä¸€ä¹‰ï¼Œå¯ä»¥è¯´æ˜¯å—äº†å¤§å¤šæ•°äººæƒ¯ç”¨å³æ‰‹è¿™ä¸€ç‚¹çš„å½±å“ã€‚ï¼ˆå‚è§ left, sinisterï¼‰\n\n#### sinisterâ˜¢\nsinister æœ¬æ˜¯ä¸ªæ‹‰ä¸è¯ï¼Œæ„æ€æ˜¯â€œå·¦çš„â€ã€â€œåœ¨å·¦è¾¹çš„â€ï¼Œ15 ä¸–çºªè¢«å¼•å…¥è‹±è¯­ï¼Œä½œä¸ºçº¹ç« å­¦çš„æœ¯è¯­ï¼Œè¡¨ç¤ºâ€œåœ¨ï¼ˆçº¹ç« ï¼‰æŒæœ‰äººå·¦è¾¹çš„â€ï¼Œå¦‚åœ¨ç›¾å¾½ï¼ˆcoat of armsï¼‰ä¸Šï¼Œa lion sinister on a field of blue æ˜¯æŒ‡â€œç›¾å¾½è“è‰²çº¹åœ°å·¦è¾¹çš„ç‹®å­â€ã€‚æ—©åœ¨å¤ç½—é©¬æ—¶ä»£ï¼Œsinister å…·æœ‰æ­£åä¸¤ä¹‰ï¼šâ€œå‰ç¥¥çš„â€å’Œâ€œä¸å‰ç¥¥çš„â€ã€‚å¤ç½—é©¬å åœå¸ˆé¢æœå—ï¼Œä¸œåœ¨å…¶å·¦ï¼Œæ•…è§†å·¦ä¸ºå‰ç¥¥ï¼›å¤å¸Œè…Šå åœå¸ˆé¢æœåŒ—ï¼Œè¥¿åœ¨å…¶å·¦ï¼Œæ•…è§†å·¦ä¸ºä¸å‰ç¥¥ã€‚å—£åï¼Œåä¸€ä¸ªè¯ä¹‰å äº†ä¸Šé£ã€‚ä» 16 ä¸–çºªèµ· sinister åœ¨è‹±è¯­ä¸­å°±è¢«èµ‹äºˆäº†â€œä¸ç¥¥çš„â€ã€â€œå…†å¤´åçš„â€è¿™ä¸€æ„ä¹‰ã€‚åœ¨å åœæœ¯ä¸­å·¦è¾¹çœ‹åˆ°çš„å¾å…†ï¼Œå¦‚é£é¸Ÿåœ¨å·¦è¾¹å‡ºç°ï¼Œä¸ºä»€ä¹ˆè¢«è®¤ä¸ºæ˜¯ä¸å‰åˆ©çš„å‘¢ï¼Ÿå¤å¸Œè…Šå†å²å­¦å®¶ã€ä¼ è®°ä½œå®¶æ™®å¢å¡”å…‹ï¼ˆPlutarch, 46?-120?ï¼‰è§£é‡Šè¯´ï¼Œå› ä¸ºè¥¿è¾¹ï¼ˆå åœå¸ˆçš„å·¦è¾¹ï¼‰æ˜¯æ—¥è½çš„æ–¹å‘ã€‚\n\næœ‰äººè®¤ä¸ºï¼Œsinister çš„è¯ä¹‰ä»â€œå·¦çš„â€å¼•ç”³ä¸ºâ€œä¸ç¥¥çš„â€æ˜¯å¯¹å·¦æ’‡å­çš„ä¸€ç§æ— ç†çš„åè§ã€‚æ³•è¯­å€Ÿç”¨è¯ **gauche** è¯ä¹‰çš„æ¼”å˜ä¹Ÿæœ‰ç±»ä¼¼æƒ…å†µã€‚gauche åŸä¹‰ä¸ºâ€œå·¦çš„â€ï¼Œå¯æ˜¯åœ¨è‹±è¯­ä¸­å´è¢«ç”¨ä»¥è¡¨ç¤ºâ€œä¸å–„äº¤é™…çš„â€ã€â€œä¸é›…è‡´çš„â€ã€â€œç¬¨æ‹™çš„â€ç­‰ä¹‰ã€‚ä¸æ­¤ç›¸åï¼Œdexterous/dextrousï¼ˆæºäºæ‹‰ä¸æ–‡ dexterï¼Œæ„ä¸ºâ€œå³â€ï¼‰å’Œ adroitï¼ˆæºäºæ³•è¯­ droitï¼Œä¹ŸæŒ‡â€œå³â€ï¼‰è¿™ä¸¤ä¸ªè¯åœ¨è‹±è¯­å‡ä¸ºè¤’ä¹‰è¯ï¼Œå‡è¡¨ç¤ºâ€œçµå·§çš„â€æˆ–â€œæ•æ·çš„â€ã€‚ç”šè€Œï¼Œè¿è¡¨ç¤ºâ€œå·¦å³ä¸¤æ‰‹éƒ½å–„äºä½¿ç”¨çš„â€ambidextrous ä¸€è¯ä¹ŸåŒ…å«æœ‰ dextrous è¿™ä¸€æˆåˆ†ã€‚æ‰€ä»¥è¿™ä¹Ÿéš¾æ€ªå·¦æ’‡å­å¯¹è¿™ç§è¯­è¨€ç°è±¡æœ‰çœ‹æ³•äº†ã€‚(æœ‰æ²¡æœ‰å¯èƒ½åªæ˜¯å› ä¸ºå¤§éƒ¨åˆ†äººçš„å·¦æ‰‹éƒ½å¾ˆç¬¨æ‹™å‘¢?)\n\nä¾‹ \n- The man was dressed in a black suit and wore dark glasses. There was something **sinister** about him. (LLA) é‚£ä¸ªç”·äººèº«ç©¿é»‘è¥¿è£…ï¼Œè¿˜æˆ´ç€å¢¨é•œï¼Œæµ‘èº«é€ç€ä¸€è‚¡é‚ªæ°”ã€‚\n- To the little girl, the old woman looked **sinister** and strange. åœ¨å°å¥³å­©çœ‹æ¥ï¼Œè€å¤ªå¤ªçš„æ ·å­å‡¶æ¶è€Œå¤æ€ªã€‚\n- His **sinister** laugh made me think of a villain. ä»–çš„å¥¸ç¬‘ä½¿æˆ‘è”æƒ³åˆ°äº†æ¶æ£ã€‚\n- \"The personnel director wants to see you.\" \"Oh dear, that sounds **sinister** (= as if there is going to be trouble).\" (CID) â€œäººäº‹å¤„é•¿è¦è§ä½ ã€‚â€â€œå™¢ï¼Œå¬èµ·æ¥ä¸å‰åˆ©ã€‚â€\n\n#### inchoateâ˜¢\næ¥è‡ªæ‹‰ä¸è¯­ incohare, æŒ‚ä¸Šï¼Œå¼€å§‹ï¼Œæ¥è‡ª in-, è¿›å…¥ï¼Œä½¿ï¼Œcohum, çš®å¸¦ï¼Œç‰›è½­ï¼Œè¯æºåŒ haw, hedge. å…¶åŸä¹‰ä¸ºç»™ç‰›æŒ‚ä¸Šè½­å¸¦ï¼Œä½¿ç‰›å¼€å§‹è€•ç”°ï¼Œåå¼•ç”³è¯ä¹‰å¼€ç«¯ã€‚\n\n\n#### superfluous\nsuper- =\u003e over\nflu =\u003e to flow\n-ous\n=\u003e to overflow =\u003e æº¢å‡ºæ¥çš„, è¿‡å¤šçš„, å¤šä½™çš„, è¿‡å‰©çš„\n- I rid myself of many **superfluous** belongings and habits that bothered me.\n\n\n#### crucify\næŠŠ...é’‰åœ¨åå­—æ¶ä¸Š =\u003e æŠ˜ç£¨, ä¸¥æƒ©, å¼ºçƒˆåœ°æ‰¹è¯„\n- She'll crucify me if she finds out you still here.\n\n#### excruciate\nex- =\u003e out, out from thoroughly\ncruciate =\u003e crucify\nthoroughly crucify =\u003e (ç²¾ç¥ä¸Šæˆ–è€…è‚‰ä½“ä¸Š)æ®‹é…·åœ°æŠ˜ç£¨\n\n#### coronation\ncorona- =\u003e å† , å†•\n-tion =\u003e åè¯åç¼€, è¡¨ç¤ºè¿‡ç¨‹\n=\u003e åŠ å†•å…¸ç¤¼\n\n- coronavirus\n- corona æ—¥å†•\n- coronary å† çŠ¶çš„, èŠ±å† çš„, å† å¿ƒç—…, å’Œå¿ƒè„ç›¸å…³çš„\n- coronal relating to the crown\n\n\n#### countenance\ncountenance å±…ç„¶å¯ä»¥æ˜¯åŠ¨è¯ =\u003e æ¥æ”¶, è®¤å¯, èµåŒ, approve of, give support to\n- The school will not **countenance** bad behaviour.\n\nå½“ç„¶ countenance å¯ä»¥æ˜¯åè¯, è¡¨ç¤º\"èµåŒ\"\nWe will not **give/lend countenance to** any kind of terrorism.\n\nè¿˜æœ‰ä¸€ä¸ªæ„æ€æ˜¯ the appearance or expression of someone's face, é¢å®¹ï¼›è„¸è‰²ï¼›é¢éƒ¨è¡¨æƒ…, ä¹Ÿè®¸èµåŒçš„æ„æ€æ˜¯ä»è¿™ä¸ªæ„æ€å¼•ç”³è¿‡å»çš„.\n- He was of noble countenance.\n\n#### dissoluteâ˜¢\n- ä¸è¦å’Œ\"dissolve(æº¶è§£)å¼„æ··äº†\"\ndissolute å­—é¢ä¸Šç†è§£æ˜¯\"æ¾æ•£çš„, loose\", å¼•ç”³åˆ°é“å¾·å“è¡Œä¸Š, =\u003e å“è¡Œä¸ç«¯çš„, æ”¾çºµçš„, æ”¾è¡çš„\n\n- He led a dissolute life, drinking, and womanizing till his death.\n\n#### goldbrick\n- to avoid performing work or duties; shirk\n- The soldiers **goldbricked** through drills.\n\ngoldbrick çš„å­—é¢æ„ä¹‰ä¸ºâ€œé‡‘ç –â€ï¼Œä½†å®é™…å«ä¹‰å´æ˜¯â€œå‡é‡‘ç –â€ã€‚è¯¥è¯æºå‡º 19 ä¸–çºªä¸­æœŸçš„ç¾å›½æ·˜é‡‘çƒ­ã€‚1848 å¹´ 1 æœˆ 24 æ—¥åœ¨åŠ åˆ©ç¦å°¼äºšå·å‘ç°äº†é»„é‡‘ã€‚æ¬¡å¹´ï¼Œæƒ³å‘è´¢çš„äººçº·çº·æ¶Œå‘è¥¿æµ·å²¸ï¼Œè¢«äººä»¬ç§°ä¸º forty-ninersï¼ˆ49 å¹´å†’é™©å®¶ï¼‰çš„æ·˜é‡‘è€…æ®ä¼°è®¡çº¦æœ‰ 8 ä¸‡åã€‚çŸ¿å·¥é‡‡å‡ºé‡‘å­ä»¥åï¼Œä¸ºäº†ä¾¿äºæ¬è¿ï¼Œå¾€å¾€æŠŠé‡‘å­é“¸æˆé‡‘ç –ï¼Œgoldbrick ä¸€è¯å°±åº”è¿è€Œç”Ÿäº†ã€‚å¼€åˆï¼Œgoldbrick ç¡®ä¸€åº¦æŒ‡â€œé‡‘ç –â€ã€‚åæ¥æœ‰çš„éª—å­åˆ©ç”¨ä¸€äº›äººçš„è´ªå©ªå¿ƒç†ï¼Œç”¨é“…æˆ–é“é“¸æˆå—ï¼Œç„¶ååœ¨è¡¨é¢é•€ä¸Šä¸€å±‚é‡‘ã€‚è¿™äº›å¤–è¡¨åƒæ˜¯çº¯é‡‘çš„é‡‘ç –ä½¿ä¸å°‘äººä¸Šäº†å½“ï¼Œå—äº†éª—ã€‚æœ‰è®°è½½è¯´ï¼Œåœ£è·¯æ˜“æœ‰ä¸€ä½åå« Patrick Burke çš„äººåœ¨ 1887 å¹´èŠ±äº† 3700 ç¾å…ƒä¹°äº†ä¸€å—å‡é‡‘ç –ã€‚ä¸ä¹…ï¼Œgoldbrick ä¸€è¯å°±å¼€å§‹ç”¨æ¥å–»æŒ‡â€œå‡é‡‘ç –â€ã€â€œå†’ç‰Œè´§â€ã€â€œè™šæœ‰å…¶è¡¨çš„ä¸œè¥¿â€ã€‚åœ¨ç¬¬ä¸€æ¬¡ä¸–ç•Œå¤§æˆ˜æœŸé—´ï¼Œå£«å…µä»¬æ¥è¿‡è¿™ä¸ªè¯ï¼Œç”¨æ¥æŒ‡é‚£äº›ç›´æ¥å¾è‡ªæ°‘é—´è€Œæœªå—è¿‡å†›äº‹è®­ç»ƒçš„å†›å®˜ï¼Œè¿™äº›äººå¾€å¾€å—åˆ°éƒ¨å±çš„è½»è§†ã€‚ä»¥åï¼Œgoldbrick çš„è¯ä¹‰åˆè¿›è€Œå¼•ç”³ä¸ºâ€œé€ƒé¿å·¥ä½œçš„äººâ€ã€â€œå·æ‡’çš„äººâ€ï¼Œåœ¨ç¬¬äºŒæ¬¡ä¸–ç•Œå¤§æˆ˜æœŸé—´éå¸¸é€šç”¨ï¼Œå¹¶ä¸”ä¸€ç›´æ²¿ç”¨è‡³ä»Šã€‚è¿™ä¸€ç±»äººæƒ³æ˜¾ç¤ºè‡ªå·±çš„èƒ½åŠ›ä»¥åšå¾—åŒäº‹çš„å¥½è¯„è€Œåˆå€Ÿæ•…ä»€ä¹ˆä¹Ÿä¸å¹²ï¼Œå› æ­¤äººä»¬å°±ä»¥æ—©æœŸå¼€å‘è¥¿éƒ¨é‚£äº›éª—äººçš„ goldbrick å–»ä¹‹ã€‚goldbrick åœ¨ä½œåŠ¨è¯ç”¨æ—¶åˆ™è¡¨ç¤ºâ€œé€ƒé¿å·¥ä½œâ€æˆ–â€œè¯ˆéª—â€ç­‰ä¹‰ã€‚\n\n#### lampoonâ˜¢\n\"**A personal satire; abuse; censure written not to reform but to vex**\", from French lampon, a word of unknown origin, said by French etymologists to be from lampons \"let us drink,\" which is said to have been a popular refrain(å‰¯æ­Œ) for scurrilous songs, in which case it would be originally a drinking song.\n\n#### leavenâ˜¢\næœ¬æ¥æ˜¯\"ä½¿å‘é…µ\"çš„æ„æ€, åˆå› ä¸ºå‘é…µçš„æ—¶å€™é¢å›¢ä¼š\"æ¶¨èµ·æ¥, å˜å¤§\" =\u003e æ‰€ä»¥å¼•ç”³ä¸º\"ä½¿å˜å¾—æœ‰è¶£, ä½¿å¹½é»˜\"çš„æ„æ€\n\n- Even a speech on a serious subject should **be leavened with** a little humour.\n\n\n#### lofty\n\"é«˜å‚²çš„, é«˜å°šçš„\"è¿™ä¸¤ä¸ªä¸­æ–‡è¯æ±‡é‡Œé¢éƒ½æœ‰\"é«˜\"è¿™ä¸ªå­—, ç”¨æ¥å½¢å®¹å‚²æ…¢å’Œå´‡é«˜, æœ‰æ„æ€çš„æ˜¯, è‹±è¯­å•è¯ lofty å’Œè¿™ä¸¤ä¸ªæ„æ€éƒ½å¯¹ä¸Šäº†:\n- lofty å¯ä»¥æ˜¯\"é«˜, high\"çš„æ„æ€: a lofty ceiling/mountain/wall\n- è¿˜å¯ä»¥å¼•ç”³åˆ°\"é«˜å°šçš„\"çš„æ„æ€: a lofty ideals\n- ä¹Ÿå¯ä»¥æŒ‡\"é«˜å‚²çš„, è‡ªå¤§çš„\": a lofty attitude/distain/contempt\n\n\n#### luminary\nluminary å¯ä¸æ˜¯\"å‘å…‰çš„ä¸œè¥¿çš„æ„æ€\", ä½†æ˜¯è¿™ä¸ªå­—é¢æ„æ€èƒ½å¾ˆå½¢è±¡åœ°å¼•å‡º luminary åœ°çœŸå®å«ä¹‰:\"ä¸“å®¶, çŸ¥åäººå£«, æ˜æ˜Ÿ\", star(æ˜æ˜Ÿ) æ˜¯é—ªé—ªå‘å…‰çš„, ä¹Ÿå°±æ˜¯ luminous çš„, æ‰€ä»¥ä¹Ÿæ˜¯ä¸€ä¸ª luminary\n\nLuminaries of stage and screen = famous actors\n\n\n#### malign\næœ‰å®³çš„, é‚ªæ¶çš„, evil\n- She describes pornography as \"a malign industry\".\nè¯½è°¤ï¼Œæ±¡è”‘ï¼Œä¸­ä¼¤\n- She has recently been maligned in the gossip columns of several newspapers. å¥¹æœ€è¿‘å—åˆ°å‡ å®¶æŠ¥çº¸æ¼«è°ˆä¸“æ çš„æ±¡è”‘ã€‚ \n\n##### mal-\n- malignity =\u003e the condition of being malign\n- malignant =\u003e æ¶æ„çš„, é‚ªæ¶çš„, (è‚¿ç˜¤, ç™Œç—‡)æ¶æ€§çš„\n- malignance =\u003e the condition of being maliganant\n\n#### mawkish\nshowing emotion or love in an awkward or silly way\næ— ç—…å‘»åŸçš„ï¼›å¤šæ„å–„æ„Ÿçš„\n- The film lapses into mawkish sentimentality near the end.\n\n1660s, \"sickly, nauseated\" (a sense now obsolete), from Middle English mawke \"maggot\" (early 15c.; see maggot), but the literal sense of \"maggoty\" is not found. Figurative meaning \"sickeningly sentimental, insipid\" is recorded by 1702\n\n#### mettleâ˜¢\nmetal çš„å˜ä½“.  èµ·åˆä¸¤ä¸ªå•è¯æ˜¯å®Œå…¨ä¸€æ ·çš„, å¯ä»¥æ¢ç€ç”¨, q å®ƒçš„æ¯”å–»ä¹‰å°±æ˜¯æ„æˆ\"ä¸€ä¸ªçš„ç²¾ç¥ç»„æˆ, é“å¾·ç»„æˆ\" =\u003e ç²¾ç¥, å‹‡æ°”, æ‰èƒ½, \"natural temperament,\" ç‰¹æŒ‡ \"ardent masculine temperament, spirit, courage\". \nThe spellings diverged early 18c. and this form took the figurative sense. Related: Mettled.\n\n- The team showed/proved its **mettle** in the final round. è¿åŠ¨é˜Ÿåœ¨æœ€åä¸€è½®ä¸­å±•ç°äº†ä»–ä»¬çš„æ‹¼æç²¾ç¥ã€‚\n- The real test of her political **mettle** came in the May elections. äº”æœˆä»½çš„é€‰ä¸¾æ˜¯å¯¹å¥¹æ”¿æ²»æ‰èƒ½çš„çœŸæ­£è€ƒéªŒã€‚ \n\n#### minutia, minutiae\nç»†ææœ«èŠ‚, triviality, nuance\n\n\n#### nonentity\nentity =\u003e å®ä½“, ç‹¬ç«‹çš„äº‹ç‰©, ç‹¬ç«‹çš„å­˜åœ¨\nnon + entity =\u003e éƒ½ä¸æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„äº‹ç‰© =\u003e æ— è¶³è½»é‡çš„äº‹ç‰©, å°äººç‰©, nobody\n\n#### omniscient\nomni- \"all\"\nscient- \"knowledge\"\n=\u003e å…¨çŸ¥çš„, æ— æ‰€ä¸çŸ¥çš„\n\n##### omni-: all\n- omnipotent =\u003e omniãƒ»potent =\u003e æ— æ‰€ä¸èƒ½çš„\n- omnidirectional =\u003e omniãƒ»directional =\u003e å…¨å‘çš„, æ‰€æœ‰æ–¹å‘çš„ \n- omnificent =\u003e omniãƒ»ficent =\u003e æœ‰æ— é™åˆ›é€ åŠ›çš„\n- omnipresent =\u003e omniãƒ»present =\u003e æ— æ‰€ä¸åœ¨çš„\n- omnivore =\u003e omniãƒ»vore =\u003e  æ‚é£ŸåŠ¨ç‰© (vor- \"eat\")\n\n##### vor-: eat\nvoracious =\u003e vorãƒ»acious =\u003e è´ªå©ªçš„\ndevour =\u003e deãƒ»vour =\u003e åé£Ÿ, æŒ¥éœ, åæ²¡\napivorous =\u003e apiãƒ»vorãƒ»ous =\u003e é£Ÿèœœçš„ api=bee \ncarnivore =\u003e carniãƒ»vorãƒ»e =\u003e é£Ÿè‚‰åŠ¨ç‰©\nherbivore =\u003e  =\u003e herbiãƒ»vorãƒ»e =\u003e é£Ÿè‰åŠ¨ç‰©\ninsectivore =\u003e  =\u003e insectiãƒ»vorãƒ»e =\u003e é£Ÿè™«åŠ¨ç‰©\n\n\n#### precipiceâ˜¢\n- æ‚¬å´–, å³­å£, \n- é™©å¢ƒ, (å¯ä»¥ç†è§£ä¸ºåœ¨æ‚¬å´–è¾¹ä¸Šæ‘‡æ‘‡æ¬²å )\n\nprecipice åœ¨è¯çš„ç»„æˆä¸Šå’Œ precipitate å·®ä¸å¤š:\n![precipitateâ˜¢](#precipitateâ˜¢)\n\n- We stand on the precipice of doom.\n\n#### presumeâ˜¢â˜¢\npre- =\u003e before\nsume =\u003e to take, obtain, buy\n\n1. **=\u003e to take for granted, overconfidently =\u003e æ“…è‡ªåšæŸäº‹, è¶ŠæƒåšæŸäº‹, å†’æ˜§åœ°åšæŸäº‹**\n(æ²¡æœ‰è¢«å…è®¸å°± take äº† sth, æ²¡æœ‰ç»™é’±å°± obtain äº† sth)\n\n- I wouldn't **presume** to tell you how to do your job, but shouldn't this piece go there? \n- I don't wish to **presume** (= make a suggestion although I have no right to), but don't you think you should apologize to her? æ•æˆ‘å†’æ˜§ï¼Œä½†ä½ éš¾é“ä¸è§‰å¾—åº”è¯¥å‘å¥¹é“æ­‰å—ï¼Ÿ\n- He **presumes** on her good nature (= takes unfair advantage of it). ä»–åˆ©ç”¨äº†å¥¹çš„å–„è‰¯æœ¬æ€§ã€‚ \n\n2. **to believe something to be true because it is very likely, although you are not certain\n\tå‡å®šï¼Œæ¨å®šï¼Œè®¤å®š**\n- I presume (that) they're not coming, since they haven't replied to the invitation. é‰´äºä»–ä»¬æ²¡æœ‰å›å¤é‚€è¯·ï¼Œæˆ‘è®¤ä¸ºä»–ä»¬ä¸ä¼šæ¥äº†ã€‚\n- You are Dr. Smith, I presume? æˆ‘æƒ³ä½ æ˜¯å²å¯†æ–¯åšå£«å§ï¼Ÿ \n\n##### sum-, sympt-: to take, obtain, buy\n###### assume\n- as- =\u003e to, toward, up to\n\n1. **=\u003e to arrogate, take upon oneself** \n- assume å’Œ presume çš„æ„æ€å¾ˆåƒ, éƒ½æ˜¯\"æ²¡æœ‰è¢«å…è®¸å°±æ“…è‡ª take sth\"çš„æ„æ€\n\n2. **=\u003e å†’å……, å‡è£…**\n- He assumed a look of indifference but I knew how he felt.\n\n3. **=\u003e å‡å®š, è‡†æ–­, æƒ³å½“ç„¶çš„è®¤ä¸º**\n- We mustn't assume the suspects' guilt\n\n4. **=\u003e to take or begin to have responsibility or control, sometimes without the right to do so, or to begin to have a characteristic**\n- The new president assumes office at midnight tonight.\n- The terrorists assumed control of the plane and forced it to land in the desert. \n\n###### consume\ncom- =\u003e with, together, ä¹Ÿå¯ä»¥æ˜¯å¼ºè°ƒ\nä¸€èµ·æ‹¿, æˆ–è€…(å¼ºè°ƒ)æ‹¿ =\u003e æ¶ˆè€—, åƒ, å–, (å¤§ç«, æƒ…ç»ª)åå™¬\n\n###### resume\nre- é‡æ–°\né‡æ–°è·å¾—, =\u003e æ¢å¤, é‡è¿”(æŸåœ°æˆ–è€…æŸä¸ªèŒä½), ä¸­æ–­åç»§ç»­\n\n###### æ´¾ç”Ÿè¯\n- **presumption**\n\tA presumption is something that is accepted as true but is not certain to be true.\n\t- ...the **presumption** that a defendant is innocent until proved guilty.\n- **presumptive**\n\tbelieved to be something, or likely to be true, based on the information that you have\n\tå¯æ®ä»¥æ¨å®šçš„ï¼›æ¨æµ‹ä¸ºçœŸçš„\n\t- **presumptive** signs of pregnancy\n- **presumptuous**\n\tIf you describe someone or their behaviour as presumptuous, you disapprove of them because they are doing something that they have no right or authority to do.\n\t[disapproval] å¼ºè°ƒpresumeé‡Œé¢çš„\"*without right*\"\n\t- It would be **presumptuous** to judge what the outcome will be\n- **assumption**\n\tsomething that you accept as true without question or proof\n\tå‡å®šï¼›å‡è®¾ï¼›è‡†æ–­\n\t- People tend to make **assumptions** about you when you have a disability.\n\n\n###### [presume, assume, what's the difference?](https://www.merriam-webster.com/words-at-play/assume-vs-presume)\nAssume and presume both mean \"to take something for granted\" or \"to take something as true.\" The difference between the words lies in the *degree of confidence* held by the speaker or writer. If he or she is making an informed guess **based on reasonable evidence**, **presume** is the word to use; if a guess is made **based on little or no evidence**, **assume** is usually used.\n\n\n#### proffer\n= pro + offer \nä¼¸å‡ºå»offer=\u003e\n=\u003e to offer sth by holding it out, or to offer advice or an opinion\n\n- He shook the warmly proffered hand\n- I didn't think it wise to proffer an opinion.\n\n#### promulgateâ˜¢\n- pro- =\u003e forth\n- mulgate =\u003e to milk (a cow, sheep, etc)\n=\u003e å»æŠŠä¹³æ±ä»åŠ¨ç‰©çš„ä¹³æˆ¿é‡Œé¢æŒ¤å‡ºæ¥ =\u003e ç”¨æ¥æ¯”å–»\"make known by open declaration, publish, announce\"\n\n- A new constitution was promulgated last month.\n\n\n#### propensity\npro- =\u003e forward\npens =\u003e to hang, cause to hang, weigh\n-ity =\u003e åè¯åç¼€, æŒ‡æŸç§æ€§è´¨\n=\u003e è”ç³»æ±‰è¯­è¯æ±‡\"å€¾å‘\", å‘ä¸€è¾¹å€¾æ–œ, æ‚¬æŒ‚ =\u003e (å°¤æŒ‡ä¸è‰¯çš„)å€¾å‘, å—œå¥½\n\n- Mr Bint has a **propensity** to put off decisions to the last minute.\n\n#### proscribeâ˜¢\n\"write in front of\" =\u003e (å®˜æ–¹)ç¦æ­¢, prohibit, ban, forbid\n\nIn Latin one of the 5 different meaning of the verb proscribere is:\n\u003e   To outlaw one by hanging up a tablet with his name and sentence of outlawry, confiscation of goods, etc.\n\nThat is where the meaning of the English verb proscribe is derived from.\n\nAnother meaning is:\n\u003e     To publish a person as having forfeited his property, to punish with confiscation, to confiscate one's property.\n\n[source](https://ell.stackexchange.com/a/30511/155475)\n\n#### protuberant\npro- =\u003e forth\ntuber =\u003eã€€swelling, è†¨èƒ€\n-ant =\u003e ...çš„\n=\u003e å‘å‰è†¨èƒ€çš„, å‘å‰å‡¸å‡ºçš„ =\u003e (ç‰¹æŒ‡äº”å®˜)çªå‡ºçš„\n\n- large protuberant eyes\n![bulgeâ˜¢](#bulgeâ˜¢)\n\n\n#### provisoryâ˜¢\nproviso æŒ‡çš„æ˜¯æ³•å¾‹æ¡æ¬¾é‡Œé¢çš„é™„åŠ æ¡ä»¶\næ‰€ä»¥ provisory å°±æ˜¯\"æœ‰æ¡ä»¶çš„, æœ‰å‰æçš„, containing a proviso\"\n\n- provisional æ˜¯æŒ‡ä¸´æ—¶çš„, æš‚æ—¶çš„, provisory ä¹Ÿæœ‰è¿™ä¸ªæ„æ€.\n\n\n#### rapprochementâ˜¢\n- an agreement reached by opposing groups or people\nï¼ˆä¸æ•Œå¯¹ç¾¤ä½“æˆ–æ•Œå¯¹ä¹‹äººè¾¾æˆçš„ï¼‰å’Œç¦ï¼Œå’Œè§£ï¼Œæ¢å¤å‹å¥½å…³ç³»\n\nè¿™ä¸ªæ˜¯ä¸€ä¸ªç›´æ¥ä»æ³•è¯­é‡Œé¢å€Ÿè¿‡æ¥çš„è¯: \"establishment of cordial relations,\" from French rapprochement \"reunion, reconciliation,\" å­—é¢æ„ä¹‰æ˜¯ \"a bringing near,\" ç”± rapprocher \"bring near,\" æ¼”å˜è€Œæ¥. å…¶ä¸­ re- \"back, again\" + aprocher (approach)\n\nè®°å¿†: r(e) appro(a)ch e ment\n\n#### recoilâ˜¢\n1. verb /rÉªËˆkÉ”Éªl/ **æ³¨æ„é‡éŸ³**\n- to move back because of fear or disgust (= dislike or disapproval)é€€ç¼©ï¼Œç•æƒ§ï¼›ï¼ˆå› ä¸ºåŒæ¶è€Œï¼‰é€€é¿\n\t- He leaned forward to kiss her and she recoiled in horror. ä»–ä¿¯èº«å»å»å¥¹ï¼Œå¥¹æƒŠæåœ°åé€€é¿å¼€ã€‚\n\t- I recoiled from the smell and the filth. é‚£å„¿åˆè„åˆè‡­ï¼Œæˆ‘èº²å¼€äº†ã€‚\n- to refuse to accept an idea or principle, feeling strong dislike or disapprovalï¼ˆå¯¹æƒ³æ³•ã€åŸåˆ™ç­‰ï¼‰åŒå¼ƒï¼Œæ·±æ¶ç—›ç»ï¼Œå¼ºçƒˆåå¯¹\n\t- She wondered how it would be to touch him and recoiled at the thought. å¥¹æƒ³çŸ¥é“æ‘¸ä¸€æ‘¸ä»–ä¼šæ˜¯ä»€ä¹ˆæ„Ÿè§‰ï¼Œä½†è¿™ä¸ªå¿µå¤´ä¸€è¿›å…¥è„‘æµ·ï¼Œå¥¹é©¬ä¸Šæ„Ÿåˆ°ä¸€é˜µåŒæ¶ã€‚\n\n2. noun [ U ] /ËˆriË.kÉ”Éªl/ **æ³¨æ„é‡éŸ³**\n\tthe sudden backward movement that a gun makes when it is firedï¼ˆæªã€ç‚®çš„ï¼‰åååŠ›ï¼Œåå†²\n\n\n#### reconditeâ˜¢\nre- ä¸€å† + cond-è— + -ite, è¡¨å½¢å®¹è¯ â†’ ä¸€å†è¢«è—èµ·æ¥çš„ â†’ æ·±å¥¥çš„ã€‚\n\n#### resurgence\nreappearance\nrevival\nreturn\nrenaissance\nresurrection\n\n#### septic\nåŒ–è„“çš„, æ„ŸæŸ“äº†çš„\nsepsis =\u003e è„“æ¯’ç—‡, è„“æ¯’ç—‡\n\n\n#### sophâˆ™ismâ˜¢\nn.è¯¡è¾©\nsoph- \n= wise, è¡¨ç¤ºâ€œæ™ºæ…§ï¼Œèªæ˜â€ã€‚\n-ism \næŠ½è±¡åè¯åç¼€ï¼Œè¡¨ç¤ºâ€œâ€¦ä¸»ä¹‰â€ï¼›â€œå®—æ•™â€ï¼›â€œåˆ¶åº¦ã€è¡Œä¸ºâ€ï¼›â€œâ€¦å­¦â€ã€â€œâ€¦æœ¯â€ã€â€œâ€¦è®ºâ€ã€â€œâ€¦æ³•â€ï¼›â€œç–¾ç—…åç§°â€ï¼›â€œæƒ…å†µã€çŠ¶æ€â€ç­‰ã€‚\n\nsophism - å…¬å…ƒå‰ 5 ä¸–çºªä¸­å¶è‡³å‰ 4 ä¸–çºªä¹‹é—´ï¼Œå¤å¸Œè…Šæœ‰ä¸€æ‰¹å“²å­¦å®¶ä»¥è®²æˆè¾©è®ºæœ¯ã€ä¿®è¾ã€ä¼¦ç†å­¦ç­‰çŸ¥è¯†ä¸ºèŒä¸šï¼Œå¸Œè…Šè¯­ç§°ä¹‹ä¸º sophistÄ“sï¼Œè‹±è¯­ä½œ sophistï¼Œæ±‰è¯­è¯‘ä¸ºâ€œæ™ºè€…â€æˆ–â€œæ™ºè€…æ´¾â€ã€‚ç”±äºä»–ä»¬åœ¨æ€æƒ³å€¾å‘ä¸Šæœ‰å…±é€šä¹‹å¤„ï¼Œé‚è¢«ç§°ä¸ºä¸€æ´¾ï¼Œä½†ä»–ä»¬å¹¶ä¸æ„æˆä¸€ä¸ªå›ºå®šçš„å­¦æ´¾ï¼Œä¹Ÿæ²¡æœ‰ç»Ÿä¸€çš„å­¦è¯´ã€‚åæ¥å› ä¸ºæŸæ‹‰å›¾ã€äºšé‡Œå£«å¤šå¾·æ‰¹è¯„ä»–ä»¬ä¸è¿½æ±‚çœŸç†è€Œæ˜¯æ±‚åœ¨è¾©è®ºä¸­ç”¨ä¸è¯šå®çš„æ‰‹æ®µè¾¾åˆ°å–èƒœçš„ç›®çš„ï¼Œæ‰€ä»¥äººä»¬æŠŠä»–ä»¬è´¬ç§°ä¸ºâ€œè¯¡è¾©å®¶â€ã€‚ä»–ä»¬ä¹‹ä¸­ä¹Ÿç¡®æœ‰äººæ“…é•¿è¯¡è¾©ï¼Œå› è€Œåœ¨å½“æ—¶å’Œåæ¥ä¸€äº›äººçš„å¿ƒç›®ä¸­ï¼Œâ€œæ™ºè€…â€ä¸€è¯ä¸è¿‡æ˜¯â€œè¯¡è¾©å®¶â€çš„åŒä¹‰è¯­ï¼Œsophist ä¹Ÿå› æ­¤è¢«èµ‹äºˆâ€œè¯¡è¾©è€…â€ä¸€ä¹‰ã€‚\n\n14ä¸–çºªæ—¶ä»sophistæ´¾ç”Ÿå‡ºåŠ¨è¯sophisticateï¼Œè¡¨ç¤ºâ€œè¯¡è¾©â€ã€â€œæºå‡â€ç­‰ä¹‰ï¼Œè€Œå½¢å®¹è¯sophisticatedä¹ƒæ˜¯sophisticateçš„è¿‡å»åˆ†è¯å½¢å¼ï¼ŒåŸä¹‰æ˜¯â€œæºå‡çš„â€ã€‚åˆ°äº†19ä¸–çºªæœ«sophisticatedçš„è¯ä¹‰å¼€å§‹æ‰¬å‡ï¼Œè¢«èµ‹äºˆâ€œè€äºä¸–æ•…çš„â€ã€â€œè€ç»ƒçš„â€ã€â€œé«˜é›…çš„â€ç­‰ä¹‰ã€‚è‡³äºâ€œå¤æ‚çš„â€ã€â€œç²¾å¯†çš„â€ã€â€œå°–ç«¯çš„â€ç­‰ä¹‰åˆ™æ˜¯ç¬¬äºŒæ¬¡ä¸–ç•Œå¤§æˆ˜ä¹‹åæ‰è§è¯¸ä½¿ç”¨çš„ã€‚å¦‚æœæˆ‘ä»¬å†å¾€ä¸Šæº¯æºï¼Œæˆ‘ä»¬ä¼šå‘ç°sophistå’Œsophisticatedçš„ç»ˆæè¯æºä¹ƒæ˜¯å¸Œè…Šè¯­sophÃ³s 'wise'ï¼ˆæœ‰æ™ºæ…§çš„ï¼›æ˜æ™ºçš„ï¼‰ã€‚å‡ºè‡ªæ­¤æºçš„è‹±è¯­å•è¯è¿˜æœ‰sophismï¼ˆè¯¡è¾©ï¼‰ï¼Œsophisticationï¼ˆå¤æ‚ç²¾å¯†ï¼‰ï¼Œsophistryï¼ˆè¯¡è¾©æœ¯ï¼‰\n\nä¾‹ \n- His witty conversation showed him to be very sophisticated. ä»–å¦™è¶£æ¨ªç”Ÿçš„è°ˆè¯æ˜¾ç¤ºå‡ºä»–æ˜¯ä¸ªè€äºä¸–æ•…çš„äººã€‚\n- I can't work this sophisticated new equipment. (FWF) æˆ‘ä¸ä¼šæ“ä½œè¿™ç§æ–°çš„ç²¾å¯†è®¾å¤‡ã€‚\n- He won the argument by sophistry. ä»–é è¯¡è¾©èµ¢å¾—é‚£åœºäº‰è®ºã€‚\n\n#### sophomore\nå¤§å­¦ä¸€å¹´çº§å­¦ç”Ÿåœ¨è‹±å›½å«first-year studentï¼Œåœ¨ç¾å›½åˆ™ç§°freshmanï¼›å¤§å­¦äºŒå¹´çº§å­¦ç”Ÿåœ¨è‹±å›½å«second-year studentï¼Œåœ¨ç¾å›½åˆ™ç§°sophomoreã€‚\n\nç¾å›½è‹±è¯­ä¹‹æ‰€ä»¥ç”¨ freshmanï¼Œæ˜¯å› ä¸ºä¸€å¹´çº§å­¦ç”Ÿæ˜¯ freshï¼ˆæ–°æ¥çš„ï¼Œåˆšåˆ°çš„ï¼‰ã€‚è€Œ sophomore å§‹è§äº 17 ä¸–çºªï¼Œ1688 å¹´ä¹‹å‰åœ¨å‰‘æ¡¥å¤§å­¦æ›¾è¢«ç”¨ä»¥æŒ‡â€œå¤§å­¦äºŒå¹´çº§å­¦ç”Ÿâ€ã€‚å®ƒæºè‡ªå¸Œè…Šè¯­ sophÃ³s 'wise'ï¼ˆèªæ˜çš„ï¼‰å’Œ mÅros 'foolish'ï¼ˆå‚»çš„ï¼‰ã€‚ç”±äºå¤§å­¦äºŒå¹´çº§å­¦ç”Ÿç²—çŸ¥çš®æ¯›ï¼Œæœ‰æ—¶ä¸å…è¦å–å¼„èªæ˜ï¼Œsophomore çš„å­—é¢å«ä¹‰å°±æ˜¯â€œå–å¼„èªæ˜çš„å‚»ç“œâ€ï¼ˆwise foolï¼‰ã€‚è¿™ä¸€è¯´æ³•å·²ç»è¢«å¹¿ä¸ºæ¥å—ã€‚åŸºäºè¿™ä¸€è¯´æ³•ï¼Œç”± sophomore è¡ç”Ÿçš„ sophomoric ç”¨ä»¥è¡¨ç¤ºâ€œä¸€çŸ¥åŠè§£è€Œåˆè¿‡äºè‡ªä¿¡çš„â€ã€â€œçŸ¥è¯†æµ…è–„å´è‡ªå‘½ä¸å‡¡çš„â€ã€â€œå¹¼ç¨šçš„â€ç­‰ä¹‰ï¼Œä¹Ÿå°±ä¸éš¾ç†è§£äº†ã€‚\n\nå…³äºsophomoreçš„ç”±æ¥è¿˜æœ‰ä¸€è¯´è®¤ä¸ºï¼Œè¯¥è¯ç³»ç”±sophismï¼ˆè¯¡è¾©ï¼‰ä¸€è¯å·²è¢«åºŸå¼ƒçš„å˜ä½“sophomåŠ -oræ„æˆã€‚\n\nfreshmanä¸sophomoreé™¤äº†åˆ†åˆ«æŒ‡å¤§å­¦ä¸€å¹´çº§å­¦ç”Ÿå’Œå¤§å­¦äºŒå¹´çº§å­¦ç”Ÿï¼Œåœ¨ç¾å›½è‹±è¯­ä¸­è¿˜å¯åˆ†åˆ«æŒ‡å››å¹´åˆ¶**é«˜ä¸­**çš„ä¸€å¹´çº§å­¦ç”Ÿå’ŒäºŒå¹´çº§å­¦ç”Ÿã€‚\n\nä¾‹ \n- They met in their freshman year at college and married soon after they graduated. ä»–ä»¬åœ¨å¤§å­¦ä¸€å¹´çº§æ—¶ç›¸é‡ï¼Œæ¯•ä¸šåä¸ä¹…å°±ç»“äº†å©šã€‚\n- Mary was elected president of the sophomore class. (NED) ç›ä¸½å½“é€‰äºŒå¹´çº§çš„ç­é•¿ã€‚\n\n#### philosopher\nsophism - è¡¨ç¤ºâ€œå“²å­¦â€å’Œâ€œå“²å­¦å®¶â€çš„ philosophy å’Œ philosopher æºè‡ªå¸Œè…Šè¯­ philÃ³sophosï¼Œç”± phÃ­los 'loving'å’Œ sophÃ³s 'wise'ä¸¤éƒ¨åˆ†æ„æˆã€‚å› æ­¤ï¼ŒæŒ‰å­—é¢åŸä¹‰è®²ï¼Œphilosophy æ˜¯ the love of wisdomï¼ˆå¯¹æ™ºæ…§çš„çƒ­çˆ±ï¼‰çš„æ„æ€ï¼Œè€Œ philosopher åˆ™æ˜¯ a lover of wisdomï¼ˆçƒ­çˆ±æ™ºæ…§çš„äººï¼‰ä¹‹ä¹‰ã€‚æ®è®¤ä¸º philosopher ä¸€è¯ç³»å¤å¸Œè…Šå“²å­¦å®¶ã€æ•°å­¦å®¶æ¯•è¾¾æ ¼æ‹‰æ–¯ï¼ˆPythagoras, 580?-500? BCï¼‰æ‰€æœæ’°ã€‚åœ¨å¤å¸Œè…Šäººä»¬é€šå¸¸éƒ½ç§°å“²å­¦å®¶ä¸º sophoiï¼Œç›¸å½“äºè‹±è¯­ sophist æˆ– wisemanï¼ˆå“²äººï¼‰ï¼Œä½†æ¯•è¾¾æ ¼æ‹‰æ–¯åˆ™è®¤ä¸ºè¯¥è¯è¿‡äºç‹‚å¦„ã€‚ä»–è¯´ï¼šâ€œé™¤äº†ä¸Šå¸ï¼Œæ²¡æœ‰ä¸€äººæ˜¯ sophÃ³sï¼ˆç›¸å½“äºè‹±è¯­ wiseï¼‰çš„ï¼Œå°±å«æˆ‘ philÃ³sophosï¼ˆç›¸å½“äºè‹±è¯­ lover of wisdomï¼‰å§ã€‚â€\n\næºäºå¸Œè…Šè¯­ phÃ­los 'loving'çš„è‹±è¯­ç»„åˆè¯­ç´  phil(o)-è¡¨ç¤ºâ€œçˆ±å¥½â€æˆ–â€œäº²â€ï¼Œå®ƒå‡ºç°åœ¨ä¸å°‘è‹±è¯­å•è¯ä¸­ï¼Œå¦‚ philatelyï¼ˆé›†é‚®ï¼‰ï¼Œphilobiblicï¼ˆæœ‰çˆ±ä¹¦ç™–çš„ï¼‰ï¼Œphilanthropyï¼ˆæ…ˆå–„ï¼‰ï¼Œphilanderï¼ˆç©å¼„å¥³æ€§ï¼‰ï¼Œphilologyï¼ˆè¯­æ–‡å­¦ï¼‰ç­‰ã€‚\n\n#### steadfastâ˜¢\nsteadfast æ˜¯ä¸€ä¸ªè¤’ä¹‰è¯, å¹¶ä¸”è¿™ä¸ªè¯è¡¨ç¤ºæŸä¸ªçŠ¶æ€å·²ç» staying the same for a long time å¹¶ä¸” not changing quickly or unexpectedly\nç±»ä¼¼äºæ±‰è¯­é‡Œé¢çš„\"åšå®šä¸ç§»çš„, æ¯«ä¸åŠ¨æ‘‡åœ°, åšå®šçš„\"\n- a steadfast ally\n\n\n#### sybariteâ˜¢\nåœ¨å¤å¸Œè…Šå—éƒ¨åŸé‚¦ä¸­ï¼Œæœ‰ä¸€åº§åŸå¸‚å«åšé”¡å·´é‡Œæ–¯ï¼ˆSybarisï¼‰ã€‚è¿™åº§åŸå¸‚å› å¯Œé¥¶ä¸å¥¢ç³œè€Œé—»åäºä¸–ã€‚ä»–ä»¬åƒçš„æ˜¯çè´µçš„æµ·é˜ï¼Œå®¶é‡Œå…»ç€é¹Œé¹‘ï¼Œå–œæ¬¢æŠŠç«ç‘°èŠ±ç“£æ’’åœ¨åºŠä¸Šç¡è§‰ã€‚ç”šè‡³å› ä¸ºæ‡’æƒ°ï¼Œä»–ä»¬è¿˜å‘æ˜äº†å¤œå£¶ï¼Œå¹¶ä¸”æŠŠå¤œå£¶è£…é¥°å¾—ååˆ†åç¾ï¼Œå®´ä¼šå’Œæ—…è¡Œæ—¶éƒ½éšèº«æºå¸¦ã€‚è¿™ç§ç©·å¥¢ææ¬²æœ€ç»ˆå¯¼è‡´äº†é”¡å·´é‡Œæ–¯çš„ç­äº¡ã€‚æ®è¯´æœ‰æ¬¡é”¡å·´é‡Œæ–¯å’Œé‚»è¿‘ä¸€ä¸ªå¼±å›½äº¤æˆ˜ã€‚å½“åŒæ–¹å†›é˜Ÿæ¥è¿‘æ—¶ï¼Œå¯¹æ–¹çš„å†›é¼“æ‰‹å¿½ç„¶å¥èµ·é”¡å·´é‡Œæ–¯èŠ‚æ—¥æ¸¸è¡Œæ—¶çš„æ›²ç›®ã€‚é”¡å·´é‡Œæ–¯çš„æˆ˜é©¬ä¸€å¬åˆ°è¿™äº›ä¹æ›²ï¼Œä¾¿æ•´é½åœ°è¿ˆå¼€èˆæ­¥ç¿©ç¿©èµ·èˆï¼Œæ ¹æœ¬ä¸å¬éª‘å…µçš„ä½¿å”¤ã€‚ä¸ºäº†åœ¨èŠ‚æ—¥æ¸¸è¡Œä¸­æ˜¾å¾—æ›´ä¼˜é›…ï¼Œé”¡å·´é‡Œæ–¯éª‘å…µé˜Ÿç‰¹æ„æŠŠæˆ˜é©¬è®­ç»ƒå¾—å¯ä»¥è·Ÿç€å›ºå®šçš„éŸ³ä¹èŠ‚æ‹èµ·èˆï¼Œæ²¡æƒ³åˆ°è¿™å´æˆäº†ä»–ä»¬çš„æ­»äº¡æ—‹å¾‹ã€‚é”¡å·´é‡Œæ–¯ç­äº¡äº†ï¼Œå´ç»™æˆ‘ä»¬ç•™ä¸‹äº†ä¸€ä¸ªè‹±è¯­å•è¯ sybariteï¼Œå®ƒæœ¬æŒ‡é”¡å·´é‡Œæ–¯äººï¼Œç°åœ¨ç”¨æ¥å½¢å®¹å¥¢ä¾ˆæ·«ä¹çš„äººã€‚\nsybariteï¼š['sÉªbÉ™,raÉªt] n.å¥¢ä¾ˆæ·«ä¹çš„äººï¼Œçºµæƒ…äº«ä¹çš„äººï¼Œé”¡å·´é‡Œæ–¯äºº\nsybariticï¼š[,sÉªbÉ™'rÉªtÉªk] adj.å¥¢ä¾ˆæ·«ä¹çš„ï¼ŒæŸ”å¼±çš„ï¼Œæ”¾çºµçš„\n\n\n#### terse\nters- =\u003e clean, wipe off, neat\n=\u003e æ‰€ä»¥terseå°±æ˜¯å¹²å‡€çš„, æ— ç´¯èµ˜çš„æ„æ€ =\u003eå¼•ç”³åˆ°è¯­è¨€ä¸Šå°±æ˜¯\"ç®€çŸ­çš„, ç®€è¦çš„\", åæ¥åˆé€æ¸æœ‰äº†\"ç”Ÿç¡¬çš„, ä¸å‹å¥½çš„\"çš„å«ä¹‰(brusque)\n\n#### understate\nunder + state =\u003e è½»ææ·¡å†™\n\n\n#### bogusâ˜¢\n- false, not real, or not legal\n\tå‡çš„ï¼›å‡å†’çš„ï¼Œä¼ªé€ çš„ï¼›éæ³•çš„\nbogusåŸæ˜¯åœ°é“ç¾è¯­ï¼Œäº§ç”Ÿäº19ä¸–çºªåˆå¶ã€‚å…³äºå…¶ç”±æ¥è¯´æ³•å¾ˆå¤šï¼Œä»¥ä¸‹ä¸¤ç§è¾ƒä¸ºå¯ä¿¡ï¼š\n\nå…¶ä¸€ï¼Œ1827å¹´5æœˆä¿„äº¥ä¿„å·ä½©æ©æ–¯ç»´å°”å¸‚ï¼ˆPainesvilleï¼‰è­¦å¯Ÿç ´è·äº†ä¸€èµ·ä¼ªå¸æ¡ˆã€‚åœ¨æ‰æ‹¿ç½ªçŠ¯çš„ç°åœºï¼Œä¸€å¤§ç¾¤äººå›´è§‚ä¸€å°åˆ¶é€ ä¼ªå¸çš„æœºå™¨ï¼Œè¿™å°é€ å¸æœºæ ·å­å¥‡ç‰¹ï¼Œäººç¾¤ä¸­æœ‰ä¸ªäººè¯´å®ƒå°±åƒä¸ªbogusã€‚ç¿Œæ—¥ï¼Œå½“åœ°ã€Šç”µè®¯æŠ¥ã€‹ï¼ˆTelegraphï¼‰æŠ¥é“æ­¤äº‹ç«Ÿç„¶ç”¨äº†bogusä¸€è¯ï¼Œç§°åˆ¶é€ ä¼ªå¸çš„æœºå™¨ä¸ºbogusï¼Œéšåæœ‰äººæŠŠä¼ªå¸å«åšbogus moneyæˆ–ç®€ç§°ä¸ºbogusã€‚å¤©é•¿æ—¥ä¹…ï¼Œå¤§å‡¡å‡çš„æˆ–ä¼ªé€ çš„ä¸œè¥¿äººä»¬å‡ä»¥bogusæ¥è¡¨ç¤ºã€‚ç¾å›½ä½œå®¶é©¬å…‹Â·åæ¸©æ›¾ç”¨è¿‡è¯¥è¯ï¼Œä½¿ä¹‹å¾—ä»¥æ¨å¹¿ã€‚\n\nå…¶äºŒï¼Œ1857å¹´ã€Šæ³¢å£«é¡¿ä¿¡ä½¿æŠ¥ã€‹ï¼ˆBoston Courierï¼‰ç§°ï¼Œè¯¥è¯æºå‡ºäºä¸€ä¸ªè‡­åæ˜­è‘—çš„éª—å­ï¼Œä»–æœ‰ä¸ªæ„å¤§åˆ©åå­—å«Borgheseã€‚è¯¥æŠ¥è¯´ï¼ŒBorgheseè¡Œéª—æœ‰æœ¯ï¼Œæ‰‹æ®µé«˜æ˜ã€‚ä»–ç­¾äº†è®¸å¤šç©ºå¤´æ”¯ç¥¨ï¼Œä½œæ¡ˆä¹‹åè¿…å³ç¦»å¼€ã€‚åˆ°äº†1837å¹´ï¼ŒBorgheseç”±äºå¼€äº†å¤§é‡ä¸€é’±ä¸å€¼çš„æ”¯ç¥¨ã€æ±‡ç¥¨åŠå„ç§ç¥¨æ®è€Œè‡­åè¿œæ‰¬äºç¾å›½å—éƒ¨å’Œè¥¿éƒ¨å„åœ°ã€‚ä»–çš„å¤§åBorgheseä¹Ÿå°±é€æ¸æˆäº†â€œä¼ªé€ çš„â€æˆ–â€œå‡çš„â€çš„åŒä¹‰è¯ï¼Œä»¥åå¾ˆå¯èƒ½ç”±äºæ³•è¯­bagasseï¼ˆåºŸç‰©ï¼‰ä¸€è¯çš„å½±å“è€Œè¢«ç¼©ç•¥ä¸ºbogusã€‚\n\nä¾‹ \n- He was arrested and charged with carrying a bogus passport. (CAE) ä»–è¢«æ•å¹¶è¢«æŒ‡æ§æŒå‡æŠ¤ç…§ã€‚\n- The man was arrested when he handed the cashier a bogus ten-dollar bill. (WBD) é‚£äººé€’ç»™å‡ºçº³å‘˜ä¸€å¼ åå…ƒçš„å‡é’ç¥¨æ—¶è¢«é€®æ•äº†ã€‚\n- She produced some bogus documents to support her claim. (CID) ä¸ºäº†è¯æ˜å¥¹çš„æ‰€æœ‰æƒï¼Œå¥¹å‡ºç¤ºäº†ä¸€äº›ä¼ªé€ çš„è¯ä»¶ã€‚\n- The museum quickly discovered that the painting was bogus. (NED) åšç‰©é¦†å¾ˆå¿«å°±å‘ç°è¿™å¹…ç”»æ˜¯èµå“\n\n\n#### intelligible\nintelligãƒ»ible\n- \"**able to understand, intelligent**,\" from Latin intelligibilis, \"that can understand; that can be understood\". In Middle English also \"to be grasped by the intellect\" (rather than the senses).\n\n\n#### limpidâ˜¢\n(æ¶²ä½“,æ°”ä½“ç­‰)æ¸…æ¾ˆçš„ï¼›æ¸…æ¾„çš„\n- lymph- \nåŸæ„è¡¨ç¤ºâ€œæ— è‰²æ¶²ä½“â€ã€‚ç°å¤šç”¨äºåŒ»å­¦è¯æ±‡ï¼Œè¡¨ç¤ºâ€œæ·‹å·´â€ï¼Œå› å…¶èƒ½åˆ†æ³Œæ— è‰²çš„æ·‹å·´æ¶²å¾—åã€‚\n- æ¥è‡ªæ‹‰ä¸è¯­ limpa, æ³‰æ°´ï¼Œæ°´ä»™å­, water goddess\n\n**Lympha**\nThe Lympha (plural Lymphae) is an ancient Roman **deity of fresh water**\n\n- ä¸è¦å’Œlimpå¼„æ··äº†å•Š, limpæ˜¯\"ç˜¸ç€èµ°\"å’Œ\"æŸ”è½¯çš„\"çš„æ„æ€, ä½†æ˜¯è¿™ä¸ªæ˜¯limp**i**d ä¸æ˜¯limp**e**d, åªæ˜¯è¯»èµ·æ¥ä¸€æ ·\n\n\n#### toady\næ—§æ—¶åº¸åŒ»è¡Œéª—æ—¶ï¼Œå¸¸å¸¸æŒ‡ä½¿å…¶ä¸‹äººå½“ä¼—åé£ŸèŸ¾èœï¼ˆtoadï¼‰æˆ–è£…ä½œåƒèŸ¾èœã€‚èŸ¾èœç´ è¢«è®¤ä¸ºæœ‰æ¯’ï¼Œä¸èƒ½é£Ÿç”¨ã€‚èŸ¾èœè¢«åé£Ÿä¹‹åï¼Œåº¸åŒ»å†è£…æ¨¡ä½œæ ·åœ°äºˆä»¥è§£â€œæ¯’â€ï¼Œè®©ä¸‹äººæœç”¨ä¸‡åº”çµè¯ï¼Œä»¥æ­¤æ˜¾ç¤ºä»–çš„åŒ»é“é«˜æ˜å’Œå¦™è¯çµéªŒã€‚åƒèŸ¾èœè€…å°±å«toad-eaterã€‚1744å¹´è‹±å›½å°è¯´å®¶è²å°”ä¸ï¼ˆHenry Fielding, 1707-1754ï¼‰æ›¾å¯¹è¯¥è¯çš„è¯ä¹‰ä½œäº†å¦‚ä¸‹è§£é‡Šï¼šâ€œtoad-eateræ˜¯ä¸ªéšå–»ï¼Œå–è‡ªå…³äºæ±Ÿæ¹–åŒ»ç”Ÿçš„ä¸‹äººåé£ŸèŸ¾èœä»¥ç¤ºå…¶ä¸»äººè§£æ¯’æœ‰æ–¹çš„æ•…äº‹ã€‚è¯¥æ¯”å–»æ˜¯åŸºäºè¿™æ ·ä¸€ç§è”æƒ³ï¼šå¤„äºéš¶å±åœ°ä½çš„äººï¼Œä¸ºäº†é¡ºåº”åº‡æŠ¤äººçš„å¿ƒæ„ï¼Œå–å¾—å…¶æ¬¢å¿ƒï¼Œè¢«è¿«åšå‡ºä»¤äººæ¶å¿ƒä¹‹è‡³çš„äº‹ã€‚â€æ®æ­¤ï¼Œtoad-eaterä¸€è¯ç”±â€œåƒèŸ¾èœè€…â€è½¬ä¹‰ä¸ºâ€œè°„åªšè€…â€æˆ–â€œé©¬å±ç²¾â€ï¼Œto eat someone's toadä¸€è¯­è¢«ç”¨ä»¥æ¯”å–»â€œæ‹æŸäººé©¬å±â€ï¼Œä¹Ÿå°±ä¸éš¾ç†è§£äº†ã€‚toad-eaterå§‹è§äº17ä¸–çºªï¼Œåˆ°äº†18ä¸–çºªç¼©ç•¥ä¸ºtoadyï¼ŒåŸä¹‰ä¹Ÿé€æ¸ä¸§å¤±ï¼Œå¦‚ä»Šä»…ç”¨äºå–»ä¹‰ã€‚\n\nä¾‹ \n- He was a dictatorial prime minister with a cabinet of weaklings and toadies. (CID) ä»–æ˜¯ä¸€ä¸ªç‹¬æ–­ä¸“è¡Œçš„é¦–ç›¸ï¼Œä»–çš„å†…é˜é‡Œéƒ½æ˜¯ä¸€å¸®æ€¯å¼±æ— èƒ½ã€é€¢è¿æ‹é©¬çš„äººã€‚\n- She gets good grades only because she toadies to the teacher. å¥¹æ˜¯é æ‹è€å¸ˆçš„é©¬å±æ‰å¾—é«˜åˆ†çš„ã€‚\n- She was always toadying to the boss, but she didn't get a promotion out of it! (CID) å¥¹æ€»æ˜¯æ‹è€æ¿çš„é©¬å±ï¼Œä½†å¥¹å¹¶æ²¡æœ‰å› æ­¤è€Œå¾—åˆ°æå‡ã€‚\n\n#### spurnâ˜¢\n- è½»è”‘åœ°æ‹’ç»ï¼›æ‘’å¼ƒ\nä¹ä¸€çœ‹å–spuræœ‰ç‚¹åƒ? =\u003e å…¶å®çš„ç¡®æœ‰ç‚¹å…³ç³»\n\nOld English spurnan \"**to kick (away), strike against; reject, scorn, despise**,\" from Proto-Germanic spurnon (source also of Old Saxon and Old High German spurnan, Old Frisian spurna, Old Norse sporna \"**to kick, drive away with the feet**\")\n\næŠ›å¼ƒ, è½»è”‘åœ°æ‹’ç», æ‘’å¼ƒ, æ–­ç„¶æ‹’ç»(å°±åƒç”¨è„šè¸¢å¼€ä¸€æ ·)\nShe spurned my offer to help.\n\n\n#### counterproductive\nèµ·åä½œç”¨çš„, å¦‚æœä½ æƒ³ç”¨ä¸€ä¸ªè¯æ¥è¡¨è¾¾\"èµ·åä½œç”¨çš„\", counterproductive å°±æ˜¯ä½ æƒ³è¦çš„è¯.\n- Improved safety measures in cars can be counterproductive as they encourage people to drive faster.\n\n\n#### censorious\noften criticizing other people =\u003e è¯´ä¸‰é“å››çš„, å–œæ¬¢æ‰¹è¯„å…¶ä»–äººçš„\n\n- Despite string principles he was never censorious.\n\n\n#### exactingâ˜¢\nexacting ä¸æ˜¯è´¬ä¹‰è¯(é«˜æ ‡å‡†çš„, è¦æ±‚ä¸¥æ ¼çš„), è€Œ demanding å¸¦ä¸€äº›è´¬ä¹‰(è¦æ±‚å¤šçš„)\n\n\n#### fleeting\nfleet é™¤äº†\"èˆ°é˜Ÿ, è½¦é˜Ÿ, æœºç¾¤\"çš„æ„æ€å¤–, è¿˜å¯ä»¥åšå½¢å®¹è¯\"å¿«é€Ÿçš„\"\næ‰€ä»¥ fleeting å°±æ˜¯\"è½¬ç¬å³é€çš„, short and quick\"\n- The girls caught only a fleeting glimpse of the driver\n\n#### quail\né¹Œé¹‘ =\u003e verb. å®³æ€•, é€€ç¼©\n- é¹Œé¹‘é•¿ä¸‹é¢è¿™ä¸ªæ ·å­\n![500](notes/2022/2022.7/assets/1800.jpg)\n- é¹Œé¹‘å–œæ¬¢è—åœ¨è‰ä¸›é‡Œé¢, ä¸ç»å¸¸è¢«äººè§åˆ°, å¹¶ä¸”é¹Œé¹‘å—æƒŠçš„æ—¶å€™å¸¸å¸¸è·‘å¼€æˆ–è€…å‘†ä½, è€Œä¸æ˜¯é£èµ°. \n- å°½ç®¡é¹Œé¹‘çœ‹èµ·æ¥èƒ–èƒ–çš„, å®ƒåœ¨è¿å¾™çš„æ—¶å€™æ˜¯å¯ä»¥é£èµ·æ¥çš„.\n![500](notes/2022/2022.7/assets/index%202.jpg)\n\n\n#### fusty\nfust- æœ¨æ£å„¿\næ¥è‡ªå¤æ³•è¯­ fuste, ç“¶å¡ï¼Œé…’å¡ï¼Œæ¥è‡ªæ‹‰ä¸è¯­ fustis, çŸ­æ£ï¼Œæœ¨æ£ï¼Œå…¶åŸä¹‰ä¸ºç“¶å¡å‘³çš„ã€‚åæ¥å¼•ç”³è¯ä¹‰éœ‰è‡­çš„ï¼Œå®ˆæ—§çš„ã€‚(æ¯”è¾ƒ corked.)\n- ç±»ä¼¼äºæ±‰è¯­é‡Œé¢\"è¿‚è…çš„\"\n- The **fusty** old establishment refused to recognize the demand for popular music. \n\n##### corked \n/ËˆkoÉškt/ adjective\n(of wine): having an unpleasant taste because of a damaged or decayed cork\n- corked wine\n\n\n#### enamoredâ˜¢\nenamo(u)r + ed\nè¿·æ‹çš„, å€¾å¿ƒçš„(like and admire a lot)\n\n##### enamour\n\"**to inflame with love, charm, captivate**,\" from Old French enamorer \"**to fall in love with; to inspire love**\", from en- \"**in**, **into**\"  + amor \"**love**,\" from amare \"**to love**\".\n\nSince earliest appearance in English, **it has been used chiefly in the past participle (enamored) and with *of* or *with***.\n\n#### prologue\nåºè¨€\n**interlude**\na short period when a situation or activity is different from what comes before and after it æ’æ›²ï¼Œé—´æ­‡\n**epilogue**\nåè®°\n\n**é¡ºåº:**\nprologue =\u003e ğŸ™â€â™‚ï¸ğŸƒâ€â™€ï¸ğŸ¤¾â€â™€ï¸ğŸ– =\u003e interlude =\u003e ğŸ‘»ğŸššğŸšğŸ¨ =\u003e epilogue\n\n#### burlesque\næ»‘ç¨½æ­Œèˆæ‚å‰§\n\n##### Burlesque vs Stripping\n- Strip routines typically are just dancing and taking off clothes. \n- Burlesque is a performance - the routines can take months to create. Costumes are involved, they typically tell a story or make a political statement. It's VERY rare that you'll see full nudity, or even nipples in a burlesque routine. The literal definition is 'the art of the tease'. It's about teasing the audience. On the contrary in many strip clubs there is no tease at all, the dances come out naked and stay that way.\n- Read more in this link:ã€€[ELI5: Burlesque vs Stripping : explainlikeimfive](https://www.reddit.com/r/explainlikeimfive/comments/23yicg/eli5_burlesque_vs_stripping/)\n\n\n#### doctrinaire \nadherent of doctrine, based on and following fixed beliefs rather than considering practical problems. =\u003e æ•™æ¡ä¸»ä¹‰çš„ï¼Œ è„±ç¦»å®é™…çš„\n\n- He is firm but not **doctrinaire**.\n\n#### dingy\ndark, depressing and possibly dirty, shabby, gloomy, dull\n\n#### gashâ˜¢\na long and deep cut, ç±»ä¼¼äºæ±‰è¯­é‡Œé¢çš„\"å£å­\", å”¯ä¸€ä¸åŒçš„æ˜¯, è‹±è¯­é‡Œé¢çš„â€œå£å­â€å¯ä»¥å½“åŠ¨è¯ç”¨\n\n- He gashed his leg while felling trees\n\t- æ³¨æ„ï¼Œ è¿™é‡Œ felling trees å¹¶ä¸æ˜¯æŒ‡\"ä»–ä»æ ‘ä¸Šæ‰ä¸‹æ¥äº†\"(è¿™é‡Œæ²¡æœ‰ off)ï¼Œ fell ä½œä¸ºåŠ¨è¯ï¼ˆä¸æ˜¯ fall çš„è¿‡å»å¼ï¼‰æœ‰â€ç å€’ï¼Œ ç ä¼â€œçš„æ„æ€ï¼Œ ä¹Ÿæœ‰å‡»å€’(æŸäºº)çš„æ„æ€\n\n#### lacerate\nlacerateç±»ä¼¼äºgashçš„åŠ¨è¯ç‰ˆæœ¬, åˆ’ä¼¤, to cut your body badly and deeply.\n\n#### antedate\nantedate = ante+date =\u003e å°±æ˜¯æŠŠ...çš„æ—¥æœŸå¾€å‰å†™(æ¯”å¦‚ä¸€ä¸ªcheckæœ¬æ¥æ˜¯1æœˆ10å·å†™çš„, ä½†æ˜¯ä½ å†™1æœˆ1å·, å°±æ˜¯antedate a check, Ante-dated cheques can be used when the contract is delayed **to avoid unnecessary trouble for the party**.)\n\n\n#### abstemiousâ˜¢\nabs- =\u003e off, away from\ntem- =\u003e strong drink, çƒˆé…’\n-ious =\u003e ...çš„\n=\u003e ç¦»å¼€é…’çš„, =\u003e å¯¹ç¾é£Ÿå’Œé…’æœ‰èŠ‚åˆ¶çš„, temperate, sparing, moderate, sober\n\n\n#### vicissitude\na passing from one state to another, a variation in circumstance, fortune, character, etc.  å˜è¿, \n- He experienced several great social vicissitudes in his life.\n- The vicissitudes of life... whether I get tenured or not tenured, whether I win the lottery or lose money\n- Many graduates prefer a safe civil-service career to the vicissitudes of starting a business\n\n#### vicariousâ˜¢\nvicarious çš„è¯æ ¹å’Œä¸Šé¢çš„ vicissitude ä¸€æ ·:\nvic- =\u003e vicis- \"a change, exchange, substitution\"\n- experienced as a result of watching, listening to, or reading about the activities of other people, rather than by doing the activities yourself. é—´æ¥æ„Ÿå—åˆ°çš„ï¼›é—´æ¥è·å¾—çš„\n\t- She took a vicarious pleasure in her friend's achievements.\n\t- She invents fantasy lives for her own vicarious pleasure.\n\t- Lots of people use television as their vicarious form of social life.\n\n#### jibe\n1. jibe = gibe =\u003e sneer, taunt, jeer, å˜²è®½, å˜²å¼„\n- a cheap jibe about his loss of hair.\n\n2. jibe with =\u003e be consistent with\n- The numbers don't jibe\n\n\n#### pleatâ˜¢\npleat æ˜¯ plait çš„å¦ä¸€ä¸ªå½¢å¼, ä½†æ˜¯é€æ¸å®ƒä»¬çš„æ„æ€æœ‰äº†åŒºåˆ«: \n- æœç´¢pleatä¼šå¾—åˆ°ä¸‹é¢è¿™å¼ å›¾\n![](notes/2022/2022.7/assets/c8884f32aa3b07a5af95268d60107dfd.png)\n- æœç´¢plaitåˆ™ä¼šå¾—åˆ°ä¸‹é¢è¿™å¼ å›¾\n![300](notes/2022/2022.7/assets/Basic-Plait-7.jpg)\n\n#### denude\nde- =\u003e away, ä¹Ÿå¯ä»¥è¡¨ç¤ºåŠ å¼º\nnude- =\u003e to strip\n=\u003e to strip or divest of all covering, lay bare\n=\u003e to remove the covering of something, especially land\n- Mining would denude the forest\n=\u003e å¼•ç”³ä¸º take away sth from\n- In such areas we see villages denuded of young people.\n\n#### mellifluousâ˜¢\nmelli- =\u003e honey, èœ‚èœœ\nflu- =\u003e flow, æµåŠ¨\n-ous\n=\u003e åƒèœ‚èœœä¸€æ ·(é¡ºæ»‘åœ°)æµåŠ¨çš„, åƒèœ‚èœœä¸€æ ·ç”œç¾çš„ =\u003e (å£°éŸ³)æ‚¦è€³çš„, (éŸ³ä¹)ä¼˜ç¾çš„, (æ°”å‘³)ç”œç¾çš„, (æ–‡ç¬”)æµç•…çš„, åæ­£å°±æ˜¯\"å…·æœ‰èœ‚èœœæµåŠ¨çš„æ€§è´¨çš„\"\n\n- a deep mellifluous voice =\u003e æµ‘åšæ‚¦è€³çš„å—“éŸ³(è¿™é‡Œè¯´æ˜äº†ç¿»è¯‘æˆ\"ç”œç¾çš„\"å¹¶ä¸æ˜¯å¾ˆæ°å½“, åœ¨æ±‰è¯­é‡Œé¢ç”œç¾çš„æœ‰ä¸€ç§å¨‡æ»´æ»´çš„æ„Ÿè§‰)\n- the mellifluous sound of the cello\n\n##### melli- \n- melliferous =\u003e äº§èœœçš„\n- mellifluence =\u003e the property of being mellifluous\n- mellifluent =\u003e mellifluous\n\n\n#### cronyism\ncrony =\u003e very close friend, å¯†å‹\ncronyism =\u003e \"å¯†å‹ä¸»ä¹‰\"? =\u003e æŒ‡é¢†å¯¼äººç»™è‡ªå·±çš„æœ‹å‹å®‰æ’å·¥ä½œ, ä»»äººä¸ºäº², ä»»ç”¨äº²ä¿¡\n\n#### downpour\nä¾§é‡sudden, unexpected, heavy rain\nç“¢æ³¼å¤§é›¨(pour), å€¾ç›†å¤§é›¨(down, pour), æ»‚æ²±å¤§é›¨\n\n#### effervesce\n![](notes/2022/2022.7/assets/coca-cola-with-ice-114028212-570941275f9b5814080dea61.jpg)\nv. å†’æ³¡æ³¡(åƒæ±½æ°´ä¸€æ ·)\n- ex- =\u003e out\n- ferv- =\u003e boil, ç…®æ²¸åä¼šå†’æ³¡æ³¡ =\u003e to bubble\n- -esce =\u003e è¡¨ç¤ºåŠ¨ä½œçš„èµ·å§‹\n![-esce](#-esce)\n\n\n#### unimpeachable\n- un- \n- impeach =\u003e å¼¹åŠ¾\n- -able\n=\u003e æ— æ³•å¼¹åŠ¾çš„ =\u003e å¼¹åŠ¾æ„å‘³ç€å®˜å‘˜çŠ¯äº†ç½ª =\u003e æ— æ³•å¼¹åŠ¾çš„å°±æ˜¯\"å“æ ¼é«˜å°šçš„, æ— å¯æŒ‘å‰”çš„, æ— æ³•æŒ‡æ‘˜çš„\", completely honest and reliable.\n\n- He is a man of **unimpeachable** integrity and character\n- **unimpeachable** proof =\u003e ç¡®å‡¿çš„è¯æ®\n\n![incontrovertible](#incontrovertible)\n\n#### prolix\npro- =\u003e forth\nlix =\u003e liquere, to flow\n=\u003e pour out  =\u003e è¯´è¯å°±åƒå€’æ°´ä¸€æ ·, ä¸€å‘ä¸å¯æ”¶æ‹¾ =\u003e verbose, lengthy, å•°å—¦çš„, é•¿ç¯‡å¤§è®ºçš„, å†—é•¿çš„\n\n- The author's **prolix** style has done nothing to encourage  sales of the book.\n\n#### nondescriptâ˜¢\nnon + descript\néƒ½æ²¡æœ‰ä»€ä¹ˆèƒ½å¤Ÿæè¿°å…¶ç‰¹ç‚¹çš„ä¸œè¥¿ =\u003e å¹³å¹³æ— å¥‡çš„, å¹³åº¸çš„, å¹³å¸¸çš„, ä¸èµ·çœ¼çš„, undistinguished, ordinary, dull, commonplace\n\n- Her clothes told me nothing: they were as nondescript as it was possible to be.\n\n![nonentity](#nonentity)\n\n#### categorical\nä¸æ˜¯\"ç±»åˆ«çš„\"çš„æ„æ€! åº”è¯¥æ˜¯ \"åƒç±»åˆ«ä¸€æ ·çš„, ç•Œé™åˆ†æ˜çš„, æ²¡æœ‰ä»»ä½•æ¨¡ç³Šç©ºé—´çš„, ç¡®å®šæ— ç–‘çš„, æ˜ç¡®çš„\"\n- without any doubt or possibility of being changed\n\tç¡®å®šæ— ç–‘çš„ï¼Œæ˜ç¡®çš„\n\n- a categorical statement/reply/assurance\n\n#### duplicity\ndishonest talk or behaviour, especially by saying different things to two people\n\ndu + plic =\u003e uplic- =\u003e two fold, duplicate\nity- \n=\u003e the state of being double, double-minded, treacherous\n\n#### epithetâ˜¢\nepi- =\u003e in addition, ä¾‹å¦‚ \"epilogue\"\nthet =\u003e to put, set\n=\u003e to put additionally, to add on, =\u003e é™¤äº†ä¸€ä¸ªäº‹ç‰©æœ¬èº«çš„åå­—ä»¥å¤–çš„æè¿° =\u003e descriptive name for a person or thing =\u003e an adjective added to a person's name or a phrase used instead of it, usually to criticize or praise them (è¤’è´¬çš†å¯)\n\n- The singer's 104-kilo frame earned him **the epithet of \"Man Mountain\"** in the press.\n\n#### gripeâ˜¢\næŠ±æ€¨, å‘ç‰¢éªš, a strong complaint, \n=\u003e gripe ä¹‹å‰è¿˜æœ‰è‚ ç»ç—›çš„æ„æ€(produce a gripping pain in the bowels) =\u003e (è‚šå­ç–¼å¾—)å‘ç‰¢éªš =\u003e å¼•ç”³åˆ°ä¸€èˆ¬çš„\"å‘ç‰¢éªš, æŠ±æ€¨\"\n\n#### intercessor\na person who intercedes =\u003e è°ƒè§£è€…, è¯´æƒ…è€…, æ±‚æƒ…è€…\n![intercedeâ˜¢](#intercedeâ˜¢)\n\n\n#### savvy\nè¿™ä¸ªå•è¯å¾ˆæœ‰æ„æ€, ä¸¤ä¸ª v è¿åœ¨ä¸€èµ·.\næ³¨æ„è¯»éŸ³/ËˆsÃ¦v.i/\n1. If you describe someone as having savvy, you think that they **have a good understanding and practical knowledge of something**.[informal]\n\t- He is known for his political **savvy** and strong management skills.\n\t- Synonyms: understanding, perception, grasp, ken  \n2. If you describe someone as savvy, you think that they **show a lot of practical knowledge**. [informal]\n\t- She was a pretty **savvy** woman.\n\t- Synonyms: shrewd, sharp, astute, knowing\n\nä¹‹æ‰€ä»¥è¿™ä¸ªè¯çœ‹èµ·æ¥å¾ˆä¸\"è‹±è¯­\", æ˜¯å› ä¸ºè¿™ä¸ªè¯æ˜¯æ³•è¯­æ··æ‚è¥¿ç­ç‰™è¯­(ä¸¤ä¸ªè¯­è¨€æ··åœ¨ä¸€èµ·å«\"pidgin\"), French savez(-vous)? \"**do you know**?\" or Spanish sabe (usted) \"**you know**,\"\n- savvyæ˜¯åŠ å‹’æ¯”æµ·ç›—é‡Œé¢Jackçš„å£å¤´ç¦…, ç›¸å½“äº\"æ‡‚ä¸?\", ä½ å¯ä»¥åœ¨æ²¹ç®¡ä¸Šçœ‹Captain Jackè¯´3åˆ†é’Ÿ\"savvy\" =\u003e  [Capt. Jack Sparrow all SAVVY moments. - YouTube](https://www.youtube.com/watch?v=xG6RHY_WJpM)\n\n\n#### effluvium\ne- =\u003e ex- \"out\"\nfluvium =\u003e fluere =\u003e flow\n=\u003e to flow out =\u003e åæ¥å¼•ç”³ä¸º(æ³„éœ², æ’æ”¾çš„)ä»¤äººä¸å¿«çš„ç‰©è´¨\n\n#### ruminate\nrumin- =\u003e ååˆ\n-ate\n=\u003e (åŠ¨ç‰©)ååˆ =\u003e å¼•ç”³åˆ°äººçš„æ€æƒ³è¿‡ç¨‹ =\u003e åå¤æ€è€ƒ, åå¤è€ƒè™‘, é•¿æ—¶é—´æ€è€ƒ\n- She **ruminated** for weeks about whether to tell him the truth or not.\n\nè‹±è¯­é‡Œé¢è¿˜æœ‰ä¸€ä¸ªè¯çš„æ„æ€å’Œruminateç±»ä¼¼:\n##### regurgitate\n1. to bring back swallowed food into the mouth\nï¼ˆä½¿ï¼‰ï¼ˆå’½ä¸‹çš„é£Ÿç‰©ï¼‰è¿”å›åˆ°å£ä¸­; ä¸æ˜¯ä¸ºäº†ç»§ç»­å’€åš¼, è€Œæ˜¯ä¸ºäº†åå‡ºæ¥, æ¯”å¦‚å–‚å¹¼å´½.\n- Owls **regurgitate** partly digested food to feed their young. çŒ«å¤´é¹°å°†åŠæ¶ˆåŒ–çš„é£Ÿç‰©åå‡ºæ¥å–‚å¹¼é¸Ÿã€‚\n\n2. [disapproving] If you regurgitate facts, you just repeat what you have heard without thinking about it.\n\tï¼ˆä¸åŠ æ€è€ƒåœ°ï¼‰é‡å¤ï¼›ç…§æ¬ï¼›ç…§æœ¬å®£ç§‘\n- Many students simply **regurgitate** what they hear in lectures. å¾ˆå¤šå­¦ç”Ÿåªä¼šé¹¦é¹‰å­¦èˆŒèˆ¬åœ°é‡å¤ä»è¯¾å ‚ä¸Šå¬æ¥çš„ä¸œè¥¿ã€‚\n\nåŸå°ä¸åŠ¨åœ°ä½¿ç”¨å­¦åˆ°çš„çŸ¥è¯†, è¿™ä¸ªå¼•ç”³ä¹‰å’Œ ruminate çš„å«ä¹‰å‡ ä¹æ˜¯ç›¸åçš„, ruminate knowledge æ˜¯ä¸ºäº†æ›´å¥½åœ°ç†è§£, è€Œ regurgitate knowledge æ˜¯å®Œå…¨æ²¡æœ‰ä»»ä½•ç†è§£çš„.\n\n#### bluffâ˜¢\nbluffï¼ˆå“å”¬ï¼‰ï¼šç©æ‰‘å…‹ç‰Œæ—¶çš„è™šå¼ å£°åŠ¿\nç©è¿‡æ‰‘å…‹ç‰Œçš„äººåº”è¯¥éƒ½çŸ¥é“ï¼Œåœ¨ç©ç‰Œæ—¶ï¼Œäººä»¬å¾€å¾€ä¼šè™šå¼ å£°åŠ¿ï¼Œæ˜æ˜æŠ“äº†ä¸€æ‰‹çƒ‚ç‰Œï¼Œå´æ‘†å‡ºä¸€å‰¯èƒ¸æœ‰æˆç«¹ã€å¿—åœ¨å¿…å¾—çš„æ¨¡æ ·ï¼Œå“å¾—å¯¹æ–¹ä¸æ•¢å‡ºæ‰‹ï¼Œä»è€Œåœ¨æ¸¸æˆä¸­è·åˆ©ã€‚è¿™ç§è™šå¼ å£°åŠ¿åœ¨è‹±è¯­ä¸­å°±å«åš bluffã€‚è¿™ä¸ªå•è¯æœ€æ—©å‡ºç°äºç¾å¼è‹±è¯­ä¸­ï¼Œå¯èƒ½æ¥è‡ªè·å…°è¯­ bluffenï¼ˆå¹å˜˜ï¼‰ã€‚å®ƒåŸæœ¬ä»…ä»…æ˜¯ä¸€ä¸ªç©æ‰‘å…‹ç‰Œçš„ä¸“ä¸šæœ¯è¯­ï¼Œä½†ç°åœ¨å·²ç»å¹¿æ³›åº”ç”¨äºå„ç§åœºæ™¯ã€‚\nbluffï¼š[blÊŒf] n.v.å“å”¬ï¼Œè™šå¼ å£°åŠ¿\n\n#### brazen\nbrazen - brazen æºè‡ªå¤è‹±è¯­ braes 'brass'ï¼ˆé»„é“œï¼‰ï¼Œæ‰€ä»¥æœ‰æ—¶ç”¨ä½œ brass çš„å½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œé»„é“œåˆ¶çš„â€æˆ–â€œé»„é“œèˆ¬çš„â€ï¼Œä½†åœ¨ç°ä»£è‹±è¯­ä¸­æ›´å¸¸ç”¨ä»¥è¡¨ç¤ºâ€œè„¸çš®åšçš„â€æˆ–â€œåšé¢œæ— è€»çš„â€ã€‚ä»¥ brassï¼ˆé»„é“œï¼‰å–»æŒ‡åšé¢œè¿™ä¸€ç”¨æ³•å¯ä»¥è¿½æº¯åˆ°ä¼Šä¸½èç™½æ—¶ä»£ï¼ˆ1558-1603ï¼‰ã€‚ã€Šç‰›æ´¥è‹±è¯­è¯å…¸ã€‹1642 å¹´çš„ä¸€æ¡å¼•è¯­å¯¹æ­¤ä½œäº†è§£é‡Šï¼šâ€œHis face is of brasse, which may be said either ever or never to blush.â€åšé¢œè€…ä¹Ÿè®¸ä»æœªè„¸çº¢è¿‡ï¼Œæ•…å…¶è„¸çŠ¹å¦‚é»„é“œåˆ¶çš„ã€‚æœ‰ä¸€çŸ­è¯­ as bold as brass å¸¸ç”¨ä½œ brazen çš„åŒä¹‰è¯­ï¼Œä¹Ÿè¡¨ç¤ºâ€œåšé¢œæ— è€»çš„â€ã€‚\n- é»„é“œåšçš„è„¸çš® =\u003e ä¸ä¼šè„¸çº¢çš„ =\u003e åšé¢œæ— è€»çš„\n\nä¾‹ \n- How can you believe such a brazen lie? (FWF) ä½ æ€ä¹ˆèƒ½ç›¸ä¿¡å¦‚æ­¤æ— è€»çš„è°è¨€å‘¢ï¼Ÿ\n- I could not do anything so brazen as that. (CCE) æˆ‘ä¸ä¼šåšå‡ºé‚£æ ·ä¸è¦è„¸çš„äº‹ã€‚\n- There were instances of brazen cheating in the exams. (CID) è€ƒè¯•ä¸­æœ‰æ˜ç›®å¼ èƒ†çš„ä½œå¼Šè¡Œä¸ºã€‚\n\n#### cavort\nto jump or move around in a playful way, sometimes noisily, and often in a sexual way\né›€è·ƒï¼›å¬‰æˆç©é—¹ï¼›ï¼ˆå¸¸æŒ‡ï¼‰è°ƒæƒ…ç©ä¹\n- They were spotted cavorting beside the swimming pool.\n\u003e Cavorting requires a good mood, lots of energy, and some running room. Children love to cavort, and so do parents when they win the lottery. The origins of the word are unclear, perhaps coming from the word curvet, meaning â€œleap gracefully or energetically,â€ and leaping is a great addition to any cavorting. There are lots of synonyms, so if you ever get tired of cavorting, you could always prance, frolic, lark, rollick, romp, or carouse. The choice is yours.\n\næœ‰å¯èƒ½æ˜¯ä» curvet è¿™ä¸ªå•è¯æ¥çš„, æ„æ€æ˜¯\"a leap by the horse\", æ‰€ä»¥åœ¨è‹±è¯­é‡Œé¢æ›´åƒæ˜¯\"é©¬è·ƒ\"\n\n\n#### croonâ˜¢\nä½å£°åŸå”±, ä½è¯­, to sing or hum in a quiet and gentle voice.\n- To croon is to sing a soft or emotional song. A father might croon a lullaby to his baby as she falls asleep. Elvis Presley was known to croon to the ladies.\n\næœ€å¼€å§‹çš„æ„æ€æ˜¯ to bellow like a bull, =\u003e åƒç‰›ä¸€æ ·å“å“å«\n\n\n#### default\ndefault è¿˜å¯ä»¥ä½œä¸ºåŠ¨è¯, è¡¨ç¤º\"fail to act (a legal responsibility)\", æ¯”å¦‚è¿çº¦, æ‹–æ¬ å€ºåŠ¡ç­‰ç­‰\n- People who default on their mortgage repayments may have their home repossessed.\n\n\n#### diatribe\ndia- =\u003e away \ntribe =\u003e to wear, rub\n=\u003e a wear away (of time),  a waste of time =\u003e å†™æ–‡ç« , è¯´è¯åªæ˜¯ä¸ºäº†æŠ¨å‡»æŸä¸ªäººæˆ–äº‹ =\u003e æ€’æ–¥, æª„æ–‡(noun)\n\n\n#### ensconceâ˜¢\nen- =\u003e make, put in\nsconce =\u003e \"small fortification, shelter\"\n=\u003e to cover with a fort =\u003e å®‰é¡¿, å®‰ç½® =\u003e (å¼•ç”³åˆ°äºº)\"å®‰å\", \"**ensconce yourself**\" =\u003e \"èˆ’èˆ’æœæœåœ°åç€\"\n\n- After dinner, I **ensconced myself** in an armchair with a book.\n\n#### evictâ˜¢\ne- =\u003e ex- =\u003e out\nvict =\u003e conquer\n=\u003e expel (by legal process), recover property by judicial means =\u003e to force sb to leave somewhere, usually because he/she has broken a law or contract.\n\n\n#### fecund\n\"å¤šäº§çš„, è‚¥æ²ƒçš„\"\nThe adjective fecund describes things that are highly fertile and that easily produce offspring or fruit. Rabbits are often considered to be fecund animals, and you may hear jokes in poor taste about people reproducing like rabbits if they have a lot of children.\n\n\u003e The word fecund comes from the Latin word fecundus, meaning fruitful. But the English word does not just describe something or someone fertile, the adjective fecund can also be used to describe someone who is innovative or highly intellectually productive. Your fecund imagination will be an asset if you have to tell ghost stories around the fire at camp while eating s'mores but that same fecund imagination could be less helpful if you're at home alone on a stormy night and you think you hear a knock at the door!\n\n#### giddyâ˜¢\nIf you've ever spun in circles until you fell to the ground laughing, you know how it feels to be giddy. This adjective can mean dizzy, elated, or â€” as in the spinning around example â€” a lightheaded, lighthearted combination of the two.\n- é™¤äº†\"æ™•\", giddyè¿˜ç”¨æ¥å½¢å®¹å› ä¸ºæ¿€åŠ¨é«˜å…´è€Œä¸èƒ½æ­£å¸¸æ€è€ƒçš„çŠ¶æ€\"é£˜é£˜ç„¶çš„\"\n\n\u003e The hackneyed phrase \"giddy as a schoolgirl\" calls forth the image of a kid giggling with her friends over some adolescent foolishness. Giddy has been used to describe someone incapable of serious thought or easily excited as far back as the 16th century. Given that, in modern usage, giddy describes someone silly and frivolous, it's interesting to know that the Old English source for this word has a slightly darker tinge: gidig means \"insane\" or \"god-possessed.\"\n\n#### incursionâ˜¢\nin- \ncurs- =\u003e run, è·‘ æ¯”å¦‚\"precursor\"\n-ion\n=\u003e run in (hostilely) =\u003e ä¾µçŠ¯, å…¥ä¾µ, ä»‹å…¥(noun)\n\nWhen an army crosses a border into another country for battle, they are making an **incursion** into enemy territory. An **incursion** is an invasion as well as an attack.\n\n**Incursion** can also be used to describe other things that rush in like an army such as an invasive species into a new region or floodwaters entering your home. When an airplane heads onto a runway it is not supposed to land on, risking airport safety, it is known as a runway **incursion**. And an **incursion** of cold air could make September feel like December.\n\n\n#### malaiseâ˜¢\nIf you are experiencing **malaise**, chances are you are feeling blue or looking green. Malaise is a slump; you're not feeling your best â€” either mentally or physically.\n\n\u003e Mal is French for \"**bad**,\" and aise means \"**ease**.\" When experiencing malaise, ease yourself down on the couch to recover. Malaise is frequently used figuratively to describe slumps that other things go through as well. The 20-year economic malaise in Japan is one example, but you'll also hear of educational malaise, political malaise, and even \"a general malaise.\" Wherever you turn, there's malaise.\n\n- a general feeling of **being ill** or **having no energy**, or an uncomfortable feeling that **something is wrong**, especially with society, and that you **cannot change** the situation\n\tèº«ä½“ä¸é€‚ï¼›èé¡ï¼›å¿ƒç¥ä¸å®ï¼›ï¼ˆå°¤æŒ‡å¯¹ç¤¾ä¼šçš„ï¼‰ä¸æ»¡ï¼Œæ— å¥ˆ\n\t- They claim it is a symptom of a deeper and more **general malaise** in society. \n\t- We were discussing the roots of the current **economic malaise**.\n\n#### myriad\næ¥è‡ªå¸Œè…Šè¯­ myrias, å¤§é‡çš„ï¼Œæ— æ•°çš„ï¼Œ**ä¸€ä¸‡**ï¼Œå¯èƒ½æ¥è‡ª meu, æµåŠ¨ï¼Œæµå‡ºï¼Œæ°´æµï¼Œè¯æºåŒ emanate, marine. å³ç”±æµåŠ¨çš„æ°´å¼•ç”³è¯ä¹‰ä¸°é¥¶çš„ï¼Œè®¸å¤šçš„ï¼Œæ— æ•°çš„ã€‚éœ€æ³¨æ„çš„æ˜¯ï¼Œè¯¥è¯åœ¨å¤å¸Œè…Šè¯­ä¸º**å•ä¸ªè¯æ‰€è¡¨ç¤ºçš„æœ€å¤§æ•°**ã€‚è¯ä¹‰æ¼”å˜æ¯”è¾ƒ abundant.\n- æ¯”æœ€å¤§çš„è®¡é‡å•ä½è¿˜å¤§ =\u003e ä¸å¯ä¼°é‡çš„, è®¸å¤š, æ— æ•°\n\n- Myriad comes from the Greek myrioi, the word for ten thousand, or less specifically, a countless amount. Myriad can be a noun, like *a myriad of choices*, or an adjective, like when you study *myriad subjects* in college. If you lift a rock you might find *a myriad of bugs*. Sticklers often look down their noses at using myriad as a noun, but that usage came first.\n\n\n#### parry\nparry å’Œ parachute çš„è¯æ ¹æ˜¯ä¸€æ ·çš„, para- è¡¨ç¤ºä¿æŠ¤, defend, åœ¨è¿™é‡Œ parry ä¿æŠ¤çš„æ–¹å¼æ˜¯\"èº²é¿, fence, dodge, avoid\", æ— è®ºæ˜¯ physically è¿˜æ˜¯ verbally.\n\n- Sword fighters **thrust** and **parry**. To thrust is to try to stab, and to parry is to avoid getting stabbed by blocking a thrust. Though it comes from fencing, parry is also handy in [dodgeball](https://www.youtube.com/watch?v=bJ1vEQKX-hE) and awkward conversations\n\n- The word parry means to block or evade a movement, like in fencing, but it can also refer to an evasion that is **verbal** rather than physical. If someone asks you who you have a crush on, but you donâ€™t want to answer, parry the question â€” change the subject or ask a question in return. When used in this way parry retains its sense of defending yourself through evasion.\n\n\n#### petulantâ˜¢\nè€å°å­©å­è„¾æ°”çš„, åè´¬ä¹‰çš„ä¸€ä¸ªè¯, å¯èƒ½æ˜¯å—å•è¯\"pet\"çš„å½±å“? pet =\u003e é™¤äº†\"å® ç‰©\"è¿˜æœ‰\"å® å„¿, æŒä¸Šæ˜ç \"çš„æ„æ€(åè´¬ä¹‰) =\u003e æŒä¸Šæ˜ç æ˜¯æƒ³è¦è¢«å® çˆ±çš„ =\u003e åƒå°å­©ä¸€æ ·peevish, è§‰å¾—è‡ªå·±ä¸æ˜¯æœ€é‡è¦çš„å°±ç”Ÿæ°”çš„\n- Choose the adjective petulant to describe a person or behavior that is **irritable in a childish way**.\n\nThe adjective, petulant, is a disapproving term used to describe a bad-tempered child, an adult behaving like an angry child or behavior of this type. Angry or annoyed mean the same thing, but if you choose the word, petulant, you are indicating that it is unreasonable or unjustified. Petulant came to English in the late 16th century from the Latin petulantem \"forward, insolent\" but was not recorded to mean childishly irritable until the late 1700s.\n\n\n#### preposterous\nå­—é¢ä¸Šç†è§£å°±æ˜¯ pre =\u003e before, poster =\u003e behind, ous =\u003e ...çš„, before-behind =\u003e é¢ ä¸‰å€’å››çš„, ä¸ç¬¦åˆå¸¸ç†çš„, =\u003e ååˆ†æ„šè ¢çš„, è’è°¬çš„\n\nTo a vegetarian, the idea of eating a 52-ounce T-bone steak would seem preposterous â€” absolutely absurd.\n\nWhen the word preposterous was first used, it meant reversing the normal order of things â€” putting what was last first, and vice versa. **Imagine putting on your underwear over your pants and you'll see that there's a kind of absurdity in something that's backwards**, which is why preposterous came to mean \"ridiculous.\" The word is often used as part of an exclamation: a chef who is asked to cook with nothing but jelly beans might exclaim, \"**That's preposterous**!\"\n\n#### refractoryâ˜¢\n\"stubborn, obstinate, perverse, resisting, unyielding,\" \nfrom past participle stem of refringere \"**to break up**\". The notion is said **to be \"breaking back\" all attempts to enforce obedience**.\n\"å®ä¸ºç‰ç¢\", å³ä½¿è¦ break å¾ˆå¤šä¸œè¥¿ä¹Ÿè¦...çš„ =\u003e difficult to deal with, unwilling to obey\n\n\n#### retouch\n\"é‡æ–°ç¢°\" =\u003e æ¶¦è‰², ä¿®æ•´, ä¿®é¥°\n- We had the wedding photos retouched to make it seem like a sunny day.\n\n#### retrenchâ˜¢\nre- =\u003e back\ntrench =\u003e to cut, æ¯”å¦‚ truncate\n=\u003e to cut backwards =\u003e å‰Šå‡, å‡å°‘(å¼€æ”¯)\n\n\n#### rickety\nrickets æ˜¯ä½å»ç—…, ä½å»ç—…æ˜¯æŒ‡å„¿ç«¥çš„éª¨éª¼å˜å¾—æŸ”è½¯å’Œè„†å¼±ï¼Œé€šå¸¸æ˜¯ç”±äºç»´ç”Ÿç´  D çš„æç«¯å’Œé•¿æœŸç¼ºä¹æ‰€è‡´ã€‚ç½•è§çš„é—ä¼ é—®é¢˜ä¹Ÿä¼šå¼•èµ·ä½å»ç—…ã€‚\n\nrickety å°±æ˜¯\"æ¢äº†ä½å»ç—…ä¸€æ ·çš„\" =\u003e å¿«è¦æ•£æ¶äº†çš„, æ‘‡æ‘‡æ™ƒæ™ƒçš„, ä¸ç»“å®çš„\n- a rickety chair.\n\n- ä¸€ä¸ªé•¿å¾—å¾ˆåƒçš„å•è¯:ã€€cricket =\u003e æ¿çƒè¿åŠ¨, èŸ‹èŸ€\n\n#### sepulchral\nSomething that reminds you of death is sepulchral. A dreary, misty graveyard at night usually feels sepulchral. é˜´æ£®ææ€–çš„\n\n- The curtain rose to reveal a gloomy, sepulchral set for the play.\n\nA sepulchre is a tomb or a crypt â€” a kind of stone room meant for burying a dead body. Something that's sepulchral reminds you of a sepulchre, either because it looks or feels like an actual tomb, or simply because it makes you think of death or dying. An empty building might be sepulchral, or a gloomy gathering. The Latin root word is sepelire, \"to bury or embalm.\"\n\n#### shipshape\n- ship, èˆ¹ï¼Œshape, å½¢çŠ¶ï¼Œå¸ƒç½®ã€‚æ¯”å–»ç”¨æ³•ï¼Œå› èˆ¹è¡Œæµ·ä¸Šå¤šé£æµªï¼Œæ‰€ä»¥èˆ¹ä¸Šçš„ç‰©å“æ‘†æ”¾å¿…é¡»ç‰¢å›ºæ•´é½ï¼Œå› è€Œå¼•ç”³è¯¥è¯ä¹‰ã€‚\n- The builders have gone, but it'll take a while to get things **shipshape** again.\n\n#### snubâ˜¢\nTo **snub** is to ignore or refuse to acknowledge someone. If you want to snub **your** former best friend, you can refuse to even look at her when you pass in the hallway.\n\n- I think she felt **snubbed** because Anthony hadn't bothered to introduce himself. å†·è½, æ€ æ…¢, å¿½è§†\n\nWhen you **snub** someone, you deliver an insult by pretending to not even notice someone that you know. Thereâ€™s an element of disdain and rejection to a **snub**, as if youâ€™re too good to even acknowledge the person. As a noun, a **snub** is that act of cold rejection. Your former friend probably noticed the **snub**, and sheâ€™ll probably **snub** you from now on. **Snub** also means \"very short,\" like the nose on a bulldog.\n\n**å—¤ä¹‹ä»¥é¼»**æœ‰ç‚¹ä¸ä¸€æ ·, ä¹Ÿæœ‰ç‚¹ç›¸ä¼¼(å†·è½, å¥šè½, å‚²æ…¢):\nå—¤ä¹‹ä»¥é¼»æ˜¯ä¸€ä¸ªæ±‰è¯­æˆè¯­ï¼Œè¯»éŸ³ä¸ºchÄ« zhÄ« yÇ bÃ­ï¼Œæ„æ€æ˜¯ï¼šç”¨é¼»å­è½»è”‘åœ°å­æ°”ï¼Œè¡¨ç¤º**ç§ä¸èµ·**ï¼›ç”¨é¼»å­å­æ°”ï¼Œè¡¨ç¤º**çœ‹ä¸èµ·**ï¼›ç”¨é¼»å­å­å£°å†·ç¬‘ï¼Œè¡¨ç¤º**è½»è”‘**ã€‚\n\n#### thick-skinned\nè¿™ä¸ªå•è¯ä¸èƒ½ç¿»è¯‘æˆ\"åšè„¸çš®çš„\", å› ä¸ºåœ¨æ±‰è¯­é‡Œé¢\"åšè„¸çš®çš„\"é€šå¸¸æ˜¯è´¬ä¹‰çš„.\næˆ–è€…è¯´, thick-skinnedå¯ä»¥ç†è§£æˆåè¤’ä¹‰çš„\"è„¸çš®åš\" =\u003e ä¸åœ¨ä¹å¤–ç•Œçš„æ‰¹è¯„, ä¸ä¼šè½»æ˜“è¢«å›°éš¾æ‰“å‡»\n\n##### [Is \"thick-skinned' a positive comment in American English?](https://www.quora.com/Is-thick-skinned-a-positive-comment-in-American-English)\nâ€œThick-skinnedâ€ means someone is not upset or offended over trivial things. They may even shrug off insults. It's **generally positive** but it's a quality that if taken too far becomes insensitivity. **It doesn't mean â€œshamelessâ€**.\n\nThe opposite â€” â€œthin-skinnedâ€ â€” is always negative. Someone who is thin-skinned takes offense too easily and interprets even positive criticism as an attack. ç±»ä¼¼äº\"ç»ç’ƒå¿ƒçš„\"?\n\nBritish English has the term â€œ**brass necked**â€ meaning â€œshamelessâ€. For example: â€œYour brother has got a real brass neck. I can't believe he's handing out business cards at your dadâ€™s funeral!â€\n\n#### trifle\ntrifleæ˜¯ä¸€ç§ç”œç‚¹:\n![300](notes/2022/2022.7/assets/retro-trifle-0566615.jpg)\nä¹Ÿè®¸æ˜¯å› ä¸º trifle æ˜¯\"å°\"ç”œç‚¹? (ä¸è¿‡çœ‹èµ·æ¥å¹¶ä¸å°å•Š), æ‰€ä»¥ trifle åˆç”¨æ¥é˜²æ³›æŒ‡çç¢çš„ä¸œè¥¿, \"å°é›¶ç¢, å°ç©æ„å„¿\" unimportant things\n- I brought a few trifles back from India - pieces of jewellery and fabric mainly.\n\ntrivial =\u003e having little value or importance\n\n#### unanimous\nun- =\u003e one, æ¥è‡ªæ‹‰ä¸è¯­ unus\nanim- =\u003e life, spirit, ç”Ÿå‘½, ç²¾ç¥ç­‰\n-ous\n=\u003e \"åˆä¸€çš„, æ‰€æœ‰äººå°±åƒæ˜¯åŒä¸€ä¸ªäººä¸€æ ·, æ²¡æœ‰ä»»ä½•å†²çª\" =\u003e å…¨éƒ¨åŒæ„çš„, æ„è§ä¸€è‡´çš„, ä¸€è‡´é€šè¿‡çš„\n\n##### anim-ï¼ˆç”Ÿå‘½ï¼‰ï¼šä»£è¡¨ç”Ÿå‘½ä¹‹æºçš„çµé­‚\nå¤ä»£äººè®¤ä¸ºç”Ÿå‘½çš„æœ¬è´¨æ˜¯å› ä¸ºçµé­‚çš„å­˜åœ¨ã€‚åœ¨æ‹‰ä¸æ–‡ä¸­ï¼Œçµé­‚åˆ†ä¸ºé˜´æ€§å’Œé˜³æ€§ä¸¤ä¸ªå•è¯ï¼Œæ—¢é˜´æ€§çš„**anima**ï¼ˆé˜¿å°¼ç›ï¼‰å’Œé˜³æ€§çš„**animus**ï¼ˆé˜¿å°¼å§†æ–¯ï¼‰ã€‚è¡¨ç¤ºç”Ÿå‘½çš„è¯æ ¹**anim**å°±æ¥è‡ªè¿™ä¸¤ä¸ªæ‹‰ä¸æ–‡ã€‚ç”±äºç”Ÿå‘½å’Œçµé­‚å¯†ä¸å¯åˆ†ï¼Œæ‰€æœ‰è¯æ ¹ anim æ—¢æœ‰â€œç”Ÿå‘½â€ã€â€œèƒ½åŠ¨â€çš„å«ä¹‰ï¼Œä¹Ÿæœ‰â€œç²¾ç¥â€ã€â€œå¿ƒâ€çš„å«ä¹‰ã€‚\n- anim-ï¼šç”Ÿå‘½ï¼Œèƒ½åŠ¨ï¼Œç²¾ç¥ï¼Œå¿ƒ\n- animaï¼š ['Ã¦nÉªmÉ™] n. çµé­‚ï¼Œç”Ÿå‘½ï¼›ç¥åœ£ä¹‹çµ\n- animusï¼š['Ã¦nÉªmÉ™s] n. æ•Œæ„ï¼›æ„å›¾, åŸºæœ¬æ€åº¦ï¼›å¥³æ€§çš„ç”·æ€§æ„å‘(å¡å°”è£æ ¼æå‡ºçš„ä¸€ä¸ªå¿ƒç†å­¦æ¦‚å¿µ)\n- **animosity**ï¼š['Ã¦nÉ™'mÉ‘sÉ™ti] n. æ†æ¶ï¼Œä»‡æ¨ï¼Œæ•Œæ„\n- animalï¼š['Ã¦nÉªm(É™)l] n. åŠ¨ç‰©ï¼Œ**æœ‰ç”Ÿå‘½èƒ½åŠ¨çš„**\n- animateï¼š['Ã¦nÉªmet] vt. ä½¿æœ‰ç”Ÿæ°”ï¼›ä½¿æ´»æ³¼ï¼›é¼“èˆï¼›æ¨åŠ¨ adj. æœ‰ç”Ÿå‘½çš„\n- animationï¼š[,Ã¦nÉª'meÊƒÉ™n] n. åŠ¨ç”»ï¼ŒåŸæ„æ˜¯ä½¿å…¶å…·æœ‰ç”Ÿå‘½ï¼Œä½¿å…¶åŠ¨èµ·æ¥\n- unanimousï¼š[juË'nÃ¦nÉªmÉ™s] adj. å…¨ä½“ä¸€è‡´çš„\n- equanimityï¼š[,É›kwÉ™'nÉªmÉ™ti] n.ï¼ˆå¿ƒæƒ…ï¼‰å¹³é™å¦ç„¶\n\n#### amorphous\na- =\u003e æ²¡æœ‰\nmorph- =\u003e form, shape, æºè‡ªå¸Œè…Šè¯­\"morphe\" \n-ous\n=\u003e æ²¡æœ‰å½¢çŠ¶çš„, æ— å®šå½¢çš„, having no fixed form or shape\n\n##### morph-ï¼ˆå½¢æ€ï¼‰ï¼šæ¢¦ç¥æ‘©å°”ç”«æ–¯\næ‘©å°”ç”«æ–¯ï¼ˆMorpheusï¼‰æ˜¯å¸Œè…Šç¥è¯ä¸­çš„æ¢¦ç¥ï¼Œæ˜¯ç¡ç¥ Hypnos çš„å„¿å­ï¼ŒæŒç®¡äººä»¬çš„æ¢¦å¢ƒã€‚æ‘©å°”ç”«æ–¯èƒ½å¤Ÿå½¢æˆã€å¡‘é€ äººä»¬çš„æ¢¦å¢ƒï¼Œè¿˜èƒ½ä»¥å„ç§å½¢æ€å‡ºç°åœ¨äººä»¬çš„æ¢¦å¢ƒä¸­ã€‚æ‘©å°”ç”«æ–¯é€šè¿‡æ¢¦ï¼Œå‘äººä»¬ä¼ é€’ç¥çš„æ—¨æ„ã€‚æ‘©å°”ç”«æ–¯çš„å½¢è±¡é€šå¸¸æ˜¯ä¸€ä¸ªèƒŒé•¿åŒç¿¼çš„ä¿Šç¾ç”·å­ã€‚ç”±äºå¤ªå¿™ï¼Œæ‘©å°”ç”«æ–¯æ²¡æœ‰ç»“å©šï¼Œä¸è¿‡ä¹Ÿæœ‰äººè¯´å½©è™¹å¥³ç¥ä¼Šé‡Œä¸è·Ÿä»–æ˜¯ä¸¤å£å­ã€‚\næ¢¦ç¥çš„åå­— Morpheus åœ¨å¸Œè…Šè¯­ä¸­æ˜¯â€œå½¢æ€åˆ¶é€ è€…â€ä¹‹æ„ï¼Œæ¥è‡ªå¸Œè…Šè¯­ morpheï¼ˆå½¢æ€ï¼‰ã€‚è‹±è¯­å•è¯ morphineï¼ˆå—å•¡ï¼‰å°±æºè‡ªæ¢¦ç¥çš„åå­— Morpheusï¼Œå› ä¸ºå—å•¡å…·æœ‰æ¢¦å¢ƒä¸€æ ·çš„æ­¢ç—›ä½œç”¨ã€‚è‹±è¯­è¯æ ¹ morpho-/-morphï¼ˆå½¢æ€ï¼‰åŒæ ·æºè‡ªå¸Œè…Šè¯­ morpheï¼ˆå½¢æ€ï¼‰ï¼Œåœ¨ç§‘å­¦é¢†åŸŸåº”ç”¨æå…¶å¹¿æ³›ã€‚\n- morpho-/-morphï¼šå½¢æ€ï¼Œæ€\n- morphineï¼š ['mÉ”ËfiËn] n. å—å•¡\n- morphicï¼š['mÉ”:fik] adj. å½¢æ€å­¦çš„ï¼Œè¯­å½¢å­¦çš„\n- amorphousï¼š[É™'mÉ”rfÉ™s] adj. æ— å®šå½¢çš„\n- morphologyï¼š [mÉ”r'fÉ‘lÉ™dÊ’i] n. å½¢æ€å­¦ï¼Œå½¢æ€è®ºï¼›è¯æ³•ï¼Œè¯æ€å­¦\n\n#### canonâ˜¢\ncanon â‰  cannon\ncannonæ˜¯åŠ å†œç‚®çš„æ„æ€, ä¹Ÿå°±æ˜¯ä¸‹é¢è¿™ä¸ªç©æ„å„¿\n![300](notes/2022/2022.7/assets/Cannon-Antietam-National-Battlefield-Maryland.webp)\n~~è€ŒCanonåˆ™æ˜¯ä½³èƒ½ç›¸æœºçš„æ„æ€~~\nCanon, æ³¨æ„å°‘äº†ä¸€ä¸ªn, (one â€œnâ€) refers to **a collection of rules or texts that are considered to be authoritative**. Shakespeare and Chaucer are part of the canon of Western literature, so you might read their work in an English class.\n\nA canon can also be a body of work, like the Shakespeare canon, which includes all of the Bard's plays and poems. These days, many schools and colleges include more diverse and underrepresented authors in literature classes and encourage students to read works not included in the standard literary canon. The literary canon can change with time, and so can the cultural canon. Don't confuse this word with cannon with two n's, the big gun that shoots bowling-size balls at the enemy.\n\nCanonæ˜¯ä¸€ä¸ªæœ‰å®—æ•™èƒŒæ™¯çš„è¯æ±‡:\n- a Christian priest with special duties in a cathedral \n\tå¤§æ•™å ‚æ•™å£«\n- a rule, principle, or law, especially in the Christian Church\n\tåŸåˆ™ï¼›å‡†åˆ™ï¼›æ³•è§„ï¼›ï¼ˆå°¤æŒ‡ï¼‰åŸºç£æ•™æ•™è§„\n\nåº”è¯¥æ˜¯åæ¥æ‰æœ‰äº†\"ä½œå“å…¨é›†\"è¿™ä¸ªæ„æ€\n\n\n#### despotâ˜¢\næš´å›\nè‹±è¯­å•è¯ despot æ¥è‡ªå¸Œè…Šè¯­çš„ despotesï¼Œæœ¬æ„æ˜¯â€œä¸€å®¶ä¹‹ä¸»ã€é¢†ä¸»â€ã€‚è¯¥è¯çš„å‰ä¸€åŠæ¥è‡ª domesticï¼ˆå®¶åº­çš„ã€å›½å†…çš„ï¼‰ï¼Œåä¸€åŠæ¥è‡ª potentï¼ˆæœ‰åŠ›çš„ï¼‰ã€‚å¤å¸Œè…Šçš„ä¸€å®¶ä¹‹ä¸»å¯¹äºå®¶ä¸­æˆå‘˜å’Œå¥´éš¶æ‹¥æœ‰ç»å¯¹æƒå¨ï¼Œå› æ­¤ despot ä¸€è¯å«æœ‰â€œç‹¬è£ã€æš´è™â€çš„å«ä¹‰ã€‚åœ¨æ‹œå åº­å¸å›½ï¼Œdespot æ›¾è¢«ç”¨äºå®«å»·è´µæ—çš„ç§°å·ã€è¯¸ä¾¯å›½äº²ç‹çš„ç§°å·ï¼Œç”šè‡³è¢«ç”¨ä½œæ‹œå åº­å¸å›½çš‡å¸çš„ç§°å·ã€‚ç°åœ¨ï¼Œdespot å¸¸ç”¨æ¥è¡¨ç¤ºé‚£äº›ç‹¬è£ã€æš´è™çš„ä¸€å›½ä¹‹ä¸»ã€‚\n- despotï¼š ['despÉ’t] n. æš´å›ï¼Œä¸“åˆ¶å›ä¸»ï¼Œç‹¬è£è€…\n- despoticï¼š[dÉª'spÉ‘tÉªk] adj. æš´è™çš„ï¼Œæš´å›çš„ï¼›ä¸“æ¨ªçš„\n- despotismï¼š ['despÉ™tÉªz(É™)m] n. ç‹¬è£ï¼Œä¸“åˆ¶ï¼Œç‹¬è£æ”¿æ²»\n\n#### impeccable\nim- =\u003e not, opposite\npecc- =\u003e to stumble, sin\n-able\n=\u003e faultless, æ— æ‡ˆå¯å‡»çš„, perfect\n\n##### pecc-\npeccadillo æ¥è‡ªè¥¿ç­ç‰™è¯­, è¿‡å¤±, å°é”™è¯¯, \npeccable å®¹æ˜“çŠ¯é”™çš„\n\n- [incontrovertible](#incontrovertible)\n- [unimpeachable](#unimpeachable)\n\n#### detain\nde- =\u003e from, away\ntain =\u003e to hold\n=\u003e to hold off, keep back, withhold =\u003e å…³æŠ¼, æ‹˜ç•™, (ä¸ä¸€å®šæ˜¯æ‰§æ³•æœºå…³, æ¯”å¦‚åŒ»é™¢å¼ºåˆ¶è®©ä¸€ä¸ªç—…äººç•™åœ¨é‚£é‡Œä¹Ÿå«detain, å¯ä»¥ç¿»è¯‘ä¸º\"ç•™é™¢è§‚å¯Ÿ\", dischargeä¹Ÿæ˜¯è¿™æ ·, æ—¢å¯ä»¥ç”¨äºåŒ»é™¢ä¹Ÿå¯ä»¥ç”¨äºç›‘ç‹±)\n- A suspect has been detained by the police for questioning.\n\n=\u003e (çŸ­æ—¶é—´çš„)è€½æ, å»¶è¯¯\n- Thank you. We won't detain you any further.\n\n\n#### taciturn\ntac-,tic-,retic- \n= silent, è¡¨ç¤ºâ€œå®‰é™â€ã€‚æºè‡ªæ‹‰ä¸è¯­ tacere \"to be silent.\"\n\nSomeone who is taciturn is reserved, not loud and talkative. The word itself refers to the trait of reticence, of seeming aloof and uncommunicative. A taciturn person might be snobby, naturally quiet, or just shy.\n\nHaving its origin in the Latin tacitus, \"silent,\" taciturn came to be used in mid-18th-century English in the sense \"habitually silent.\" Taciturnity is **often considered a negative trait**, as it suggests someone uncommunicative and too quiet. Jane Austen wrote, \"We are each of an unsocial, taciturn disposition, unwilling to speak, unless we expect to say something that will amaze the whole room, and be handed down to posterity with all the Ã©clat of a proverb.\"\n\n- reticent =\u003e unwilling to speak about your thoughts or feelings\n\tæ²‰é»˜å¯¡è¨€çš„ï¼›ä¸æ„¿äº¤è°ˆçš„\n- reticence\n- tacit\n\t- ä¸è¯´è¯ =\u003e é»˜è®¤çš„, æš—ä¸­çš„\n\t- Something tacit is **implied or understood without question**. Holding hands might be a tacit acknowledgment that a boy and girl are dating.\n\t- The adjective tacit refers to information that is **understood without needing to acknowledge it**. For example, since we know that the sky is blue, that kind of assumption is tacit. Lawyers talk about \"tacit agreements,\" where parties give their silent consent and raise no objections.\n\n#### stoke\nTo stoke is to **poke a fire and fuel it so that it burns higher**. Stoke can also mean \"**incite**\"(figuratively) â€” a principal's impassive silence in the face of requests for more tater tots might stoke the flames of student anger.\n![](notes/2022/2022.7/assets/Pasted%20image%2020220723211533.png)\nWhen a surfer says, \"I am so stoked,\" it means she is excited â€” the fire of enthusiasm is burning hotter. It's interesting to reflect on how many words in our language have to do with the tending of fires, an activity that has become much less common in recent human history.\n\nç…½åŠ¨ =\u003e æœ‰è¶£çš„æ˜¯æ±‰è¯­é‡Œé¢çš„è¿™ä¸ªè¯ä¹Ÿå’Œç«æœ‰å…³, åªä¸è¿‡æ±‰è¯­æ˜¯æ‰‡é£, è‹±è¯­æ˜¯\"æ‹¨æ—ºï¼ˆç‚‰ç«)\"\nincite, stir up, instigate; incite; arouse; foment; provoke\n\n#### foment\nStand outside the school cafeteria passing out flyers with nutritional details on school food, and you may foment a revolution â€” foment means **stirring up something undesirable**, such as trouble.\n\nYou would never say, \"Hooray, we fomented a revolution.\" Instead you'd say, \"Those good for nothing scalawags fomented the rebellion.\" **Don't confuse foment and ferment.** Ferment can mean \"to stir up\" in a good way â€” a football game can ferment excitement in a town, or foment trouble through traffic tie-ups and litter.\n\n#### supersede\nsuper- =\u003e above\nsede- =\u003e to sit\n=\u003e ååœ¨...çš„å¤´ä¸Š, =\u003e å–ä»£è€çš„äº‹ç‰©\n\n- Hand tools are relics of the past that have now been **superseded** by the machine.\n\n\n#### aversion\nåŒæ¶, \"å\"æ„Ÿ\na- =\u003e off, away, \nvers =\u003e to turn\n-ion\n=\u003e a turning away from =\u003e çœ‹åˆ°ä¸å–œæ¬¢çš„ä¸œè¥¿æƒ³è¦èº²å¼€ =\u003e åŒæ¶, åæ„Ÿ, ç—›æ¨, strong dislike of sth\n\n#### deferâ˜¢\ndefer é™¤äº†\"å»¶æœŸ\"çš„å«ä¹‰ä»¥å¤–, \"**defer to** someone\"  è¿˜å¯ä»¥è¡¨ç¤º\"(å‡ºäºå°Šæ•¬æˆ–è€…æƒå¨è€Œ)æœä»\"çš„æ„æ€, \n- Doctor are encouraged to **defer to** experts.\n\næ‰€ä»¥ **deference** å°±æ˜¯åè¯ç‰ˆæœ¬çš„\"é¡ºä», å°Šæ•¬, æœä»\"\n\n- She covered her head out of deference to Muslim custom.\n\n\n#### opprobriousâ˜¢\nop- =\u003e in front of, before\nprobr =\u003e probum, reproach, infamy\n-ious\n=\u003e reproach in front of..., expressing scorn, disgrace, contempt\n=\u003e è°´è´£çš„, æ¶æ¯’çš„, ä»¤äººä¸é½¿çš„\n- Opprobrious is a **heavy-duty** word to describe something taunting or shameful. Opprobrious words criticize in a mean, hurtful way.\n\n- Opprobrious comes from the Latin opprobare which means \"to reproach or taunt.\" If someone is being opprobrious, she's being abusive and mean. **Insults are opprobrious, while constructive criticism is not**. No one wants to be treated in an opprobrious way. We can also use this word for bad behavior that causes shame â€” someone cheating on a test is opprobrious. **Opprobrious actions are disgraceful, ignominious, and inglorious**.\n\n#### daisâ˜¢\ndaisæ˜¯13ä¸–çºªå€Ÿè‡ªå¤æ³•è¯­deisçš„ï¼Œæ‰€ä»¥åŸè¯å½¢ä¹Ÿæ˜¯deisï¼ŒåŸæŒ‡è®¾åœ¨å¹³å°ä¸Šä¸“ä¾›è´µå®¾ä½¿ç”¨çš„æ¡Œå­ï¼Œå–çš„æ˜¯æ‹‰ä¸è¯­discusçš„å¦ä¸€è¯ä¹‰â€œæ¡Œå­â€ã€‚åˆ°äº†16ä¸–çºªdeisä»è‹±è¯­é‡Œæ¶ˆå¤±äº†ï¼Œåªä¿ç•™åœ¨è‹æ ¼å…°è¯­é‡Œã€‚åˆ°äº†19ä¸–çºªï¼Œè‹æ ¼å…°å°è¯´å®¶åŠè¯—äººå¸å„ç‰¹ï¼ˆSir Walter Scott, 1771-1832ï¼‰æ‰åˆèµ·ç”¨äº†è¿™ä¸ªè¯ï¼Œä½†ç”¨çš„æ˜¯è¿‘ä»£æ³•è¯­çš„æ‹¼æ³•daisï¼Œä»æŒ‡â€œè®²å°â€æˆ–â€œä¸»å¸­å°â€ã€‚\n![](notes/2022/2022.7/assets/dais_noun_004_1024.jpg)\n![400](notes/2022/2022.7/assets/lectern-podium-and-dais.webp)\n\n\n#### abstainâ˜¢\nabs- =\u003e off, away from\n-tain =\u003e to hold, ä¾‹å¦‚\"contain\"\n=\u003e withhold, to hold back, refrain, keep off\n=\u003e æˆ’, æˆ’ç» (æŸä¸ªä¸è‰¯å—œå¥½)\n- to abstain from alcohol/smoking/sex\n=\u003e (é€‰ä¸¾æ—¶)å¼ƒæƒ\n\n- abstain å•è¯çš„æ„é€ å’Œ withhold éå¸¸åƒ, withhold é‡Œé¢çš„ with-è¡¨ç¤º\"å‘å, ç›¸å\"\n\n##### -tain: to hold\n- attain =\u003e atãƒ»tain =\u003e at- è¡¨ç¤ºåŠ å¼º, è¾¾åˆ°, è·å¾—\n- obtain =\u003e obãƒ»tain =\u003e ob- ä¹Ÿè¡¨ç¤ºåŠ å¼º, è¾¾åˆ°, å¾—åˆ°\n- contain =\u003e conãƒ»tain =\u003e con- è¿™é‡Œä¹Ÿåº”è¯¥è¡¨ç¤ºå¼ºè°ƒ, åŒ…å«, å®¹çº³\n- maintain =\u003e mainãƒ»tain =\u003e main- -\u003e hand =\u003e ä¿æŒ, ç»´æŠ¤\n- entertain =\u003e enterãƒ»tain =\u003e hold together?\n- detain =\u003e deãƒ»tain =\u003e de- =\u003e off, æ‹˜ç•™, è€½æ\n- pertain =\u003e perãƒ»tain =\u003e per- through -\u003e hold through, =\u003e belong to, te attached legally\n- retain =\u003e reãƒ»tain =\u003e re- back =\u003e to hold back, ä¿ç•™\n- sustain =\u003e susãƒ»tain =\u003e sus- -\u003eunder, beneath =\u003e åœ¨ä¸‹é¢ hold, æ”¯æŒ, æ”¯æ’‘\n\n#### forbearâ˜¢\nfor- =\u003e å®Œå…¨, very much\nbear =\u003e å¿å—\n=\u003e å®Œå…¨å¿å—, å®Œå…¨å…‹åˆ¶ =\u003e è‡ªåˆ¶, å…‹åˆ¶\nto prevent yourself from saying or doing something, especially in a way that shows control, good judgment, or kindness to others\n\n- forbearance =\u003e noun.\n\n\n#### illuminati\n- å…‰ç…§ä¼š, å…‰æ˜ä¼šï¼ˆæ‹‰ä¸è¯­ï¼šIlluminatiï¼‰æ˜¯ 1776 å¹´ 5 æœˆ 1 æ—¥å¯è’™è¿åŠ¨æ—¶æˆç«‹äºå·´ä¼åˆ©äºšçš„ä¸€ä¸ªç§˜å¯†ç»„ç»‡ã€‚è¯¥ç»„ç»‡ç»å¸¸è¢«å„ç§é˜´è°‹è®ºæŒ‡æ§å‚ä¸æ§åˆ¶å…¨ä¸–ç•Œçš„äº‹åŠ¡ï¼Œé€è¿‡æŒæ¡è´§å¸å‘è¡Œæƒã€ç­–åˆ’å†å²äº‹ä»¶ï¼Œå¹¶å®‰æ’æ”¿åºœå’Œä¼ä¸šä¸­çš„ä»£ç†äººï¼Œä»¥è·å¾—æ”¿æ²»æƒåŠ›å’Œå½±å“åŠ›ï¼Œæœ€ç»ˆå»ºç«‹ä¸€ä¸ªâ€œæ–°ä¸–ç•Œç§©åºâ€\n- æˆ–è€…, æŒ‡çš„æ˜¯æ¼«å¨é‡Œé¢çš„ç§˜å¯†è‹±é›„ç»„ç»‡: \n\tå½“å½“å½“~ ä½ èƒ½è®¤å‡ºå‡ ä¸ª?\n\t![](notes/2022/2022.7/assets/Illuminati_(comics).jpg)\n\n#### husbandâ˜¢\nhusband è¿˜å¯ä»¥æ˜¯ä¸ªåŠ¨è¯, è¡¨ç¤º\"èŠ‚çº¦åœ°ä½¿ç”¨\"\n- husband precious resources\n\n\n#### disabuse\ndis- =\u003e apart\nabuse =\u003e ä¾®è¾±, æ¯è°¤\n=\u003e \"æ¶ˆé™¤æ¯è°¤, è®©æ¯è°¤å’Œå—å®³è€…åˆ†å¼€\" =\u003e free from mistake, fallacy, or deception\n\n- He thought that all women liked children, but she soon disabused him of that (idea/notion).\n\n#### puckish\n- liking to make jokes about other people and play silly tricks on them é¡½çš®çš„ï¼Œæ·˜æ°”çš„\n\npuckã€æ·˜æ°”å°å¦–ã€‘ + -ish å½¢å®¹è¯åç¼€ã€‚\nPuck æ˜¯å‡¯å°”ç‰¹ç¥è¯å’Œè‹±å›½æ°‘é—´æ•…äº‹é‡Œæ¶ä½œå‰§çš„å°ç²¾çµï¼Œåˆå« Robin Goodfellow. èå£«æ¯”äºšçš„ã€Šä»²å¤å¤œä¹‹æ¢¦ã€‹ä¸­ï¼Œæ­£æ˜¯è¿™ä¸ªå®¶ä¼™å°†å¹´è½»çš„æ‹äººä»¬çš„ç”Ÿæ´»å¼„å¾—ä¸€å›¢ç³Ÿã€‚\n\n#### labileâ˜¢\nprone to lapse =\u003e changing often or easily\n\n- emotionally labile characters\n\n#### minuscule\nextremely small\n- The film was shot in 17 days, a miniscule amount of time.\n\n- åŸæ¥æŒ‡çš„æ˜¯å°å†™å­—æ¯ \"minuscula\"ï¼Œåœ¨æ—©æœŸçš„æ‹‰ä¸å­—æ¯ä½“ç³»ä¸­å¹¶æ²¡æœ‰å°å†™å­—æ¯ï¼Œå…¬å…ƒ4ä¸–çºª--7ä¸–çºªçš„å®‰å¡å°”å­—ä½“å’Œå°å®‰å¡å°”å­—ä½“æ˜¯å°å†™å­—æ¯å½¢æˆçš„è¿‡æ¸¡å­—ä½“ã€‚å…¬å…ƒ8ä¸–çºªï¼Œæ³•å›½å¡ç½—ç³ç‹æœæ—¶æœŸï¼Œä¸ºäº†é€‚åº”æµç•…å¿«é€Ÿçš„ä¹¦å†™éœ€è¦,äº§ç”Ÿäº†å¡ç½—ç³å°å†™å­—ä½“ï¼Œä¼ è¯´å®ƒæ˜¯æŸ¥ç†ä¸€ä¸–å§”æ‰˜è‹±å›½å­¦è€…å‡¡Â·çº¦å…‹åœ¨æ³•å›½è¿›è¡Œæ–‡å­—æ”¹é©æ•´ç†å‡ºæ¥çš„ã€‚å®ƒæ¯”è¿‡å»çš„æ–‡å­—å†™å¾—å¿«ï¼Œåˆä¾¿äºé˜…è¯»ï¼Œåœ¨å½“æ—¶çš„æ¬§æ´²å¹¿ä¸ºæµä¼ ä½¿ç”¨ã€‚å®ƒä½œä¸ºå½“æ—¶æœ€ç¾è§‚å®ç”¨çš„å­—ä½“ï¼Œå¯¹æ¬§æ´²çš„æ–‡å­—å‘å±•èµ·äº†å†³å®šæ€§çš„å½±å“ï¼Œå½¢æˆäº†è‡ªå·±çš„é»„é‡‘æ—¶ä»£ã€‚[Source](http://www.0755tt.com/courseware/ad/b/b_1/b_1_1/b_1_1_01/b_1_1_01_03.htm)\n\n\n#### anomalyâ˜¢\nå¼‚å¸¸ï¼Œ è¿™ä¸ªå•è¯ä¹ä¸€çœ‹å¥½åƒæ˜¯ a+normal ç»„æˆçš„ï¼Œä½†æ˜¯å®é™…ä¸Šæ˜¯ an+homalosï¼ˆhomosï¼‰\n- an- =\u003e not\n- homalos =\u003e even, from \"homos\" =\u003e same\nnot even, not the same, unevenness, derivation from the common rule.\n\n- å½¢å®¹è¯: anomalous\n\n\n#### defuseâ˜¢\nde- =\u003e remove\nfuse =\u003e ç‚¸å¼¹çš„å¼•ä¿¡\n=\u003e ç§»é™¤ç‚¸å¼¹çš„å¼•ä¿¡ =\u003e æ‹†é™¤ç‚¸å¼¹\n=\u003e æ‹†é™¤ç‚¸å¼¹ä¹Ÿå°±è§£é™¤äº†ä¸€ä¸ªç´§å¼ çš„æƒ…å†µ =\u003e å¼•ç”³ä¸º\"å¹³æ¯æŸä¸ªå±é™©æˆ–è€…ç´§å¼ çš„æƒ…å†µ\"\n- defuse the crisis/tension\n\n- è¿™ä¸ªè¯æ˜¯è¿‘ä»£æ‰å‡ºç°çš„(è¦å…ˆæœ‰ç‚¸å¼¹æ‰èƒ½é€ è¿™ä¸ªè¯)\nä¸è¦å’Œ diffuse å¼„æ··äº†\n![diffuse](#diffuse)\n\n#### impenetrable\nim + penetrat(e) + able\n=\u003e æ— æ³•ç©¿é€çš„\n\n=\u003e å¼•ç”³åˆ°æ€æƒ³, æ–‡å­—, =\u003e ä¸€ä¸ªè´¹è§£çš„æƒ…å†µ, æ–‡å­—, æ€æƒ³å°±åƒä¸€å›¢æ— æ³•è¢«ç†æ™º\"åˆºç©¿\"çš„è¿·é›¾ =\u003e è´¹è§£çš„, çœ‹ä¸ç ´çš„, impossible to understand\n\n\n\n\n#### bumble\nTo bumble is to **move or speak in an awkward, fumbling way**. You might bumble your way through your first dance performance, tripping over your own two feet.\n\nWhen you bumble, you walk unsteadily or speak with a stutter. You can also bumble something, or completely mess it up. An inexperienced teacher might bumble her attempts at managing a huge class of middle school students, and you might worry that you'll bumble your first interview as a radio reporter. Bumble was first used in the 1500's, and it's probably an imitative word, or one that sounds like what it means.\n\n##### bumblebee\nå¤§é»„èœ‚, \nä¸ºä»€ä¹ˆå¤§é»„èœ‚å« bumblebee å‘¢? å…¶å®å¤§é»„èœ‚æœ¬æ¥ä¸å«è¿™ä¸ªåå­—, Darwin ç»™å¤§é»„èœ‚èµ·çš„åå­—åŸæ¥å« humblebee =\u003e å› ä¸ºèœœèœ‚ä¸€ç›´éƒ½åœ¨å—¡å—¡å«(hum)\n- [How the humblebee became the bumblebee](https://www.theguardian.com/environment/2010/aug/01/humblebee-bumblebee-darwin)\n\n\n\n#### hangdog\nåœ¨ä¸­ä¸–çºªçš„æ¬§æ´²ï¼Œç»™äººç±»é€ æˆæ­»äº¡æˆ–ä¼¤å®³çš„åŠ¨ç‰©ï¼Œåƒäººä¸€æ ·ï¼Œä¹Ÿè¦å—åˆ°èµ·è¯‰å’Œå®¡è®¯ã€‚å› è¿™äº›ç½ªè¡Œè€Œå—åˆ°èµ·è¯‰å¹¶è¢«åˆ¤æ­»åˆ‘çš„åŠ¨ç‰©æœ‰è€é¼ ã€çŒªã€ç‹—åŠæ¯ç­åº„ç¨¼çš„å®³è™«ã€‚æœ‰è®°è½½è¯´ï¼Œ1595å¹´åœ¨è·å…°è¥¿éƒ¨åŸå¸‚è±é¡¿ï¼ˆLeydenï¼‰æœ‰ä¸ªå°å­©è¢«ç‹—å’¬ä¼¤æ‰‹æŒ‡è‡´æ­»ï¼Œè¿™æ¡ç‹—å› æ­¤è¢«äººä»¬åŠæ­»ã€‚ç‹—è¢«åŠæ­»ä¹‹äº‹èå£«æ¯”äºšåœ¨ä»–çš„å‰§ä½œä¸­æ›¾æåˆ°è¿‡äº”æ¬¡ã€‚hangdogä¸€è¯å¾ˆå¯èƒ½å³ç”±æ­¤è€Œæ¥ï¼Œå¸¸ç”¨äºa hangdog lookè¿™ä¸€æ­é…ï¼Œ17ä¸–çºªæœ«æ­¤è¯­åŸæŒ‡â€œå‘æ€¯çš„æ ·å­â€ï¼Œå¦‚ä»Šå¤šè¡¨ç¤ºâ€œç¾æ„§çš„ç¥æ€â€æˆ–â€œè‡ªè§‰æœ‰ç½ªçš„æ ·å­â€ï¼Œhangdogç°åœ¨å¸¸ç”¨ä½œå½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œç¾æƒ­çš„â€æˆ–â€œæ„Ÿåˆ°æœ‰ç½ªçš„â€ã€‚\n\nä¾‹ a hangdog look/expression ç¾æ„§çš„ç¥æƒ…ï¼è¡¨æƒ…\n\nA hangdog look is one that betrays a feeling of shame, embarrassment, or fear. Your hangdog expression after sneaking a whoopee cushion onto your teacher's chair is a dead giveaway that you're guilty.\n\nUse the adjective hangdog to describe someone's cowering appearance or the sheepish look on her face. You might have a hangdog look if you're afraid of getting in trouble, or if you regret your actions. The now-obsolete root noun hang-dog was used in the 17th century to mean \"a despicable, low person,\" or someone who's \"only fit to hang a dog,\" or sometimes \"only fit to be hung (like a dog).\"\n\n- è¿˜çœŸæœ‰å‡ åˆ†ç¥ä¼¼\n![300](notes/2022/2022.7/assets/35F42BC200000578-0-image-m-18_1467669584591.jpg)![](notes/2022/2022.7/assets/d50f38c61b29bbecdaf63075ca4d39b8.jpg)\n\n#### kindredâ˜¢\nYour **kindred** are your people. If you say are going to visit your kindred during the holidays, that means you are going to visit your relatives.\n\nThe word kindred can be used as either an **adjective** or a **noun**. **The noun version is somewhat archaic** â€” you are more likely to encounter this word in classic literature than in casual conversation. You may be more familiar with the adjective version of the word, which has gained popular usage in the term â€œ**kindred spirit**â€ or â€œ**kindred soul**,â€ which is used to describe those who share similar attitudes, characteristics, or beliefs.\n\n\"of a similar **kind**\" =\u003e è¿™æ ·è¦å¥½è®°ä¸€ç‚¹\n\n- They sell dried fruit and nuts and other **kindred** products.\n\n\n#### mash \u0026 smash\nmash = make sth into a paste during **cooking**\nsmash = fighting, destroying something\n\nmash means to make something into a paste so you can eat it (usually potatoes or vegetables)\nsmash means to crush something into small pieces by hitting/punching/destroying it\n- [Source](https://hinative.com/en-US/questions/15936585)\n\n#### obeisanceâ˜¢\nobeisance ä¸æ˜¯ obey çš„åè¯, obedience æ‰æ˜¯ obey çš„åè¯å½¢å¼.\n\n- An obeisance is an act, usually physical, showing dutiful obedience. A supplicant might perform obeisance, touching his face to the ground, before humbly asking for help. obeisanceæ˜¯å‡ºäºç¤¼ä»ªå’Œå°Šæ•¬çš„æ‰“æ‹›å‘¼\n\n- Obeisance is often used in **historical or religious contexts** and often refers to **bowing or kneeling**. Figuratively, it means an act of respect though sometimes with the **negative connotation of slavishly doing as expected**. Your boyfriend might bring you and your mother flowers **in obeisance to** the idea that the parents should be courted as much as the child. Consumers who want this software must show obeisance to the Internet â€” it can't be bought in a store or anywhere else.\n\n#### prudent \u0026 prudish\nprudishæ˜¯ä»prudeæ¥çš„, ä½†æ˜¯prudentä¸æ˜¯ä»prudeæ¥çš„, å³ä½¿å®ƒä»¬é•¿å¾—æ›´åƒ.\n\n- **prudent**\nprudentæ˜¯ä¸€ä¸ªè¤’ä¹‰è¯\n\nDescribe an action as prudent if it is the wise thing to do under the existing circumstances. If you're getting in trouble, it is probably prudent to keep your mouth closed and just listen.\n\nIf you show good and careful judgment when handling practical matters, you can be described as prudent. Similarly, a wise and well-thought-through decision or action can be called prudent. The word comes from a contracted form of the Latin prÅvidÄ“ns, from the verb \"to foresee.\" The English word provident, \"wise in planning for the future,\" is the non-contracted descendent of the same Latin root.\n\n- **prudish**\nprudish åˆ™å’Œ prude ä¸€æ ·, éƒ½æ˜¯åè´¬ä¹‰çš„.\n\nTo be prudish is to be extremely proper, almost a little too proper. To be called prudish isn't a compliment.\n\nTo be proper is to be polite and have good manners. To be prudish is to take being proper to an exaggerated or ridiculous degree. For example, it's definitely a bad idea to use a naughty word in class, but a friend who scolds you when you use it privately could be considered prudish. They're going a little too far. Prudish behavior is also called priggish, prim, prissy, puritanical, and straight-laced. Others usually think prudish people should lighten up.\n\n\n\n#### repealâ˜¢\nappeal æœ‰\"å‘¼å\"çš„æ„æ€, repeal çš„æ„æ€å’Œ appeal ç›¸å, å°±æ˜¯\"ä¸å®£ä¼ äº†\", recall ä¸€ä¸ª appeal =\u003e åºŸé™¤, æ’¤é”€(ä¸€ä¸ªæ³•æ¡ˆ, ä¸€æ¡æ³•å¾‹)\n\n\n\n#### suffuse\n![fus-](#fus-)\nThe verb suffuse means to **spread and fill a space**, like the way the smell of wildflowers might suffuse a meadow.\n\nSuffuse is a synonym for steep. Like tea whose flavor grows stronger the more it steeps, when you suffuse something it spreads throughout until an area is full, or even overly full. Another synonym, infuse, looks a lot like suffuse. Both words come from the Latin word fundere, which means \"to pour.\"\n\n#### wrongheaded\næ‰§è¿·ä¸æ‚Ÿçš„\n\nSomething that's wrongheaded is **foolish, misguided, and stubborn**. A wrongheaded politician might run for president despite polls showing there's no way he can win.\n\nA wrongheaded entrepreneur may go ahead with her plans to open an ice cream shop for dogs despite being advised not to by everyone she knows. You might feel angry about a judge's wrongheaded decision in an important court case. Anyone who uses bad judgement is wrongheaded, especially when the mistake seems obvious. The adjective wrongheaded has been around since the 1730's.\n\n\n#### babble\nç±»ä¼¼äºå©´å„¿è¯´è¯çš„æ–¹å¼ =\u003e å˜Ÿå›”, å•Šå§å•Šå§, =\u003e å¼•ç”³åˆ°å…´å¥‹å«ç³Šéš¾æ‡‚çš„è¯´è¯æ–¹å¼, ä¹±å“„å“„çš„å£°éŸ³\n=\u003e è¿˜å¯ä»¥ç”¨æ¥å½¢å®¹æºªæµçš„\"æ½ºæ½ºä½œå“\", \n\n- To babble is **to talk on and on without a particular goal**. It might drive you crazy when your little sister babbles endlessly about her favorite video game.\n- The children babbled excitedly among themselves. \n- She was babbling something about her ring being stolen.\n\n#### jabber\nto speak quickly and excitedly, which is very difficult to understand.\nè¿™ä¸ªä¹Ÿæ˜¯æœ‰ç‚¹æ‹Ÿå£°çš„æ„Ÿè§‰(echoic), åŠ å§åŠ å§, å•Šå§å•Šå§, å½é‡Œå’•å™œ\n\"æ€¥ä¿ƒè€Œå«æ··ä¸æ¸…åœ°è¯´\"\n\nWhen someone starts to jabber, they start talking on and on about this or that, or that or this, in an excited, sometimes incoherent way. Jabber is a close cousin to **blabber**.\n\nWhen someone jabbers, sometimes their words seem to fly out of their mouths like quick punches (jabs!) from a boxer. Some examples of jabber? You know, like when someone has a hobby that you donâ€™t really care about or understand but they wonâ€™t quit talking about it? Yeah, they jabber. Or your best friend is relating, without end, his excitement about the coming tiddlywinks championship and you comprehend neither the game nor its importance? That friend jabbers, too.\n\nHe's always blabbering on about computers.\n\n\n#### besiegeâ˜¢\nsiege =\u003e å›´æ”», å›´å›°, (åè¯)\nbesiege =\u003e å›´æ”», å›´å›° (åŠ¨è¯)\n\n#### beleaguerâ˜¢\n- besiege, surround, blockade\n- be- =\u003e around\n- leaguer =\u003e to camp \n=\u003e åœ¨...å‘¨å›´å®‰è¥æ‰å¯¨, =\u003e å›´æ”»\n=\u003e å¼•ç”³ä¸º trouble persistently, harass, å›°æ‰°, ä½¿çƒ¦æ¼\n\nWe have issues in our community that continue to **beleaguer** and plague us.\n\n#### hedonismâ˜¢\nhedon- =\u003e æ¥è‡ªå¸Œè…Šè¯­é‡Œé¢çš„ hedone, pleasure, \n-ism\n=\u003e å¿«ä¹ä¸»ä¹‰ =\u003e äº«ä¹ä¸»ä¹‰\n\n\n#### euphemismâ˜¢\neuphemism å§‹è§äº 17 ä¸–çºªï¼Œæºè‡ªå¸Œè…Šè¯­ euphÄ“mismÃ³s 'speaking fair, speaking with good words'ï¼Œå…¶ä¸­ eu-ç›¸å½“äº goodï¼ŒphÄ“mÄ“ç›¸å½“äº speechï¼Œå…¶æˆåˆ†çš„å«ä¹‰å¤šå°‘è¯´æ˜äº†è¯¥è¯çš„ç”¨æ³•ã€‚euphemism å°±æ˜¯æ±‰è¯­ä¸­çš„â€œå©‰è¨€â€ã€â€œå§”å©‰è¯­â€æˆ–â€œå§”å©‰è¯´æ³•â€ã€‚å§”å©‰è¯­çš„ä½œç”¨åœ¨äºæ›¿ä»£ç›´æˆªäº†å½“ã€ä»¤äººä¸æ‚¦æˆ–ç²—ä¿—æ— ç¤¼çš„è¯´æ³•ã€‚euphemism çš„åä¹‰è¯ dysphemismï¼ˆç²—ç›´è¯­ï¼‰ç³»ç”±å‰ç¼€ dys-ï¼ˆåçš„ï¼‰å’Œ euphemism åˆæˆï¼Œå®ƒäº§ç”Ÿäº 19 ä¸–çºªæœ«æœŸã€‚\n\nä¾‹\n- 'Maiden lady' is a euphemism for 'old maid'. â€œè€å°å§â€ï¼ˆæˆ–â€œæœªå©šå¦‡å¥³â€ï¼‰æ˜¯â€œè€å¤„å¥³â€çš„å§”å©‰è¯­ã€‚\n- 'Large' is a word often used as a euphemism for the word 'fat'. \n- The article made so much use of euphemism that often its meaning was unclear. \n- \"Beautician\" is the euphemism for a hairdresser. \n\n\n#### cacophony\ncaco- =\u003e harsh, bad, evil\nphony =\u003e sound \n=\u003e bad sound =\u003e a unpleasant mixture of loud sounds\n=\u003e å˜ˆæ‚çš„å£°éŸ³, å–§åš£, \n\nå¦‚æœè¯´ symphony æ˜¯ä¹å™¨\"ä¸€èµ·(sym-)\"æ¼”å¥çš„ä¼˜ç¾ä¹æ›², é‚£ä¹ˆ cacophony å°±æ˜¯å˜ˆæ‚çš„å–§åš£, ä¸¤è€…çš„æ„æ€åŸºæœ¬ä¸Šæ˜¯ç›¸åçš„.\n\n#### menstruationâ˜¢\nmenstru- =\u003e from Latin \"mensruus\", which means \"monthly\", from mensis \"month\"\n-ation\n=\u003e æ¯æœˆçš„äº‹ =\u003e æœˆäº‹, æœˆç»\n\n\n#### claspâ˜¢\nåªè¦ç”¨ä¸€ä¸ª\"ç¯\"ç´§ç´§ç®ä½æŸä¸ªä¸œè¥¿å°±å«\"clasp\", æ‰€ä»¥å¯ä»¥æ˜¯\"æŠ±ä½, æŠ“ä½, æ¡ä½...\"\nA bracelet is held together by a clasp. A girl who gets a nice one from her boyfriend might clasp her arms around him. A clasp is a fastener. To clasp is to hold tightly.\n\nIn all uses of the word, clasp means to hold together tightly. You want your bracelet or belt clasp to be strong so it doesn't come apart. And when you take a child on a walk across a busy intersection, you clasp their hand tightly. The word is not related to the word **clap**, but if you clap your hands together, then keep them there, you turn a clap to a clasp.\n\n#### commiserateâ˜¢\ncom + miser + ate =\u003e ä¸€èµ·æ‚²ä¼¤ =\u003e è¡¨ç¤ºåŒæƒ…, æƒ‹æƒœ, to express sympathy to someone about some bad luck.\n\n- I began commiserating with her over the defeat.\n\n#### conjureâ˜¢\ncon- =\u003e with, together\njure =\u003e to swear (an oath) \n=\u003e ä¸€èµ·å¿µå’’è¯­, =\u003e ç”¨é­”æ³•å˜å‡º, å¬å”¤å‡º, å˜æˆæ³•\n\n- The magician conjured up a dove from his hat.\n\nconjurer, conjuror =\u003e é­”æœ¯å¸ˆ, å˜æˆæ³•çš„äºº\n\n#### conspicuousâ˜¢\ncon- =\u003e è¿™é‡Œè¡¨ç¤ºå¼ºè°ƒ\nspicu =\u003e to look at, observe\nous\n=\u003e å¾ˆå®¹æ˜“å°±çœ‹åˆ°çš„ =\u003e æ˜¾çœ¼çš„, é†’ç›®çš„\n\n- In China, her blonde hair was conspicuous.\n\n\n#### crass\næ¥è‡ªæ‹‰ä¸è¯­ crassus =\u003e solid, thick, fat, dense =\u003e å¼•ç”³ä¸ºstupid and without considering how other people might feel.\n\nA crass comment is very stupid and shows that the speaker doesn't care about other people's feelings. In today's day and age, you don't have to wear black to a funeral, but to show up in clown pants is simply crass.\n\nThe source of this adjective is Latin crassus, \"thick, dense, fat.\" A similar development of meaning can be seen in English dense in the sense of \"stupid, slow to understand,\" from Latin densus, \"thick, dense,\" and in English thick, which can also be used to mean \"stupid.\"\n\n\n#### curtail\ncur- =\u003e to cut, from Latin curtus\n-tail \n=\u003e cut short, cut off the end of, æŠŠå°¾å·´å‰ªçŸ­ =\u003e å‡å°‘, reduce or limit.\n\n=\u003e è¿™ä¸ªå•è¯å¬èµ·æ¥æ¯”è¾ƒå®˜æ–¹, æ‰€ä»¥å¹³æ—¶ä¸æ€ä¹ˆè§åˆ°, ä½†æ˜¯åˆæ²¡é‚£ä¹ˆå®˜æ–¹, æ‰€ä»¥å¹³æ—¶è¿˜æ˜¯å¯ä»¥ç”¨\n\nTo curtail something is to **slow it down**, **put restrictions on** it, or **stop it entirely**. If I give up cake, I am curtailing my cake-eating.\n\nCurtail is an **official-sounding word** for stopping or slowing things down. The police try to curtail crime â€” they want there to be less crime in the world. A company may want to curtail their employees' computer time, so they spend more time working and less time goofing around. Teachers try to curtail whispering and note-passing in class. When something is curtailed, it's either stopped entirely or stopped quite a bit â€” it's cut short.\n\n#### beseechâ˜¢\nbe- + seek =\u003e to entreat, beg urgently\n\nIf you're begging for something but you want to sound **formal and a little old-fashioned**, say \"I beseech you!\" It really captures how urgent and desperate you are, yet perhaps saves a shred of your dignity.\n\næ‰€ä»¥beseechæ˜¯æœ‰ç‚¹ç‚¹ç¤¼è²Œçš„\"æ³è¯·\", æ²¡æœ‰é‚£ç§å‘èº¬å±ˆè†çš„æ„Ÿè§‰.\n\n##### entreat\nè¿™ä¸¤ä¸ªè¯çš„ç»„æˆæ–¹å¼å…¶å®æŒºåƒçš„:\nen- + treat =\u003e to treat sb in a certain way,  to treat =\u003e æ‹›å¾…å¯¹æ–¹, ç»™å¯¹æ–¹å¥½å¤„, ä¸ºäº†è®©å¯¹æ–¹åŒæ„è‡ªå·±çš„è¯·æ±‚ =\u003e æ³è¯·, æ³æ±‚, è¯·æ±‚, to try **very hard** to persuade someone to do something.\n\n- We would spend every meal time **entreating** the child to eat her vegetables.\n\n\n#### derideâ˜¢\nde+ride? ä¸éª‘? å…¶å®åœ¨è¿™é‡Œ rid æ˜¯ laugh çš„æ„æ€, å’Œ ridicule ä¸€æ ·.\nde- =\u003e down\nride =\u003e redere, to laugh\n=\u003e å±…é«˜ä¸´ä¸‹åœ°å˜²ç¬‘ =\u003e laugh at in contempt, mock, ridicule, scorn by laughter.\n\n- He derided my singing as pathetic.\n\n#### desiccateâ˜¢\nThe verb desiccate means to dry out, dry up and dehydrate. It's helpful to desiccate weeds but certainly not crops.\n\nAs anyone who's been stuck in the desert will tell you, being desiccated by the burning sun isn't much fun. Stemming from the Latin word desiccare, which means to \"dry up,\" desiccate also means to preserve something by drying it out. Without desiccation, raisins or beef jerky would not be possible!\n\n\ndesiccative, desiccant =\u003e å¹²ç‡¥å‰‚, å°±æ˜¯é£Ÿå“åŒ…è£…è¢‹é‡Œé¢è£…ç€ç¡…èƒ¶çš„é‚£ä¸ªå°è¢‹è¢‹\n\n##### desiccate? dehydrate?\nDesiccate is narrower in its range of reference and implies a complete deprivation of moisture, especially of vital juices, and often therefore, in its common extended use, a withering or shriveling. It is applicable to animal and vegetable products preserved by thorough drying or it may be applied to persons or to their attitudes, activities, or expression which have lost all their spiritual or emotional freshness or vitality. Desiccate é€šå¸¸æŒ‡ä»£å¯Œæœ‰æ´»åŠ›çš„ï¼Œå¯Œæœ‰ç”Ÿå‘½åŠ›çš„ç‰©è´¨è¢«è„±æ°´ï¼Œä¹Ÿå¯ä»¥è¢«ç”¨ä½œæ¯”å–»ä¹‰ï¼Œè¡¨ç¤ºæŸç§ç‰©è´¨çš„æ¯ç«­ï¼š\n- The global economy is desiccating by the day.\n- He was politically and emotionally desiccated by the scandal.\n\nDehydrate implies extraction or elimination of water; it is often preferred to desiccate, of which it is a close synonym, when the reference is to foods. è€Œ Dehydrate å°±æ˜¯\"è„±æ°´\"ï¼Œç”¨æ¥æŒ‡ä»£å¹¶ä¸”åªç”¨æ¥æŒ‡ä»£â€œè„±æ°´ï¼Œå¹²ç‡¥â€è¿™ä¸ªè¿‡ç¨‹ã€‚\n\n#### desultoryâ˜¢\nwithout a clear plan or purpose and showing little effort or interest. æ•£æ¼«çš„ï¼Œæ¼«æ— ç›®çš„çš„ï¼Œå¿ƒä¸åœ¨ç„‰çš„\n- skipping about, jumping, flitting, æ¥è‡ª desultor, é©¬æˆå›¢é‡Œé¢åœ¨å‡ åŒ¹é£å¥”çš„é©¬ä¸Šé¢è·³æ¥è·³å»çš„äºº, \n- de- =\u003e down, sul =\u003e to jump, leap.\n\n\n#### diffident\nlacking confident, distrustful (of oneself), wanting confidence in another's power.\ndif- =\u003e away, \nfid =\u003e to trust, æ¯”å¦‚ fidelity\n-ent \n=\u003e å¯¹è‡ªå·±ä¸ä¿¡ä»»çš„ =\u003e ä¸è‡ªä¿¡çš„, ç¾æ€¯çš„, \n\nYou shouldn't be so diffident about your achievements - you've done really well!\n\n#### effulgent\nef- =\u003e ex-, out\nfulg =\u003e to shine, flash, æ•£å‘å…‰è¾‰\n-ent\n=\u003e å…‰èŠ’å››å°„çš„, ç’€ç’¨çš„, ç»šçƒ‚çš„, ç¿çƒ‚çš„, ç‚«è€€çš„, to shine out, to gleam forth.\n\n- an effulgent canopy of stars\n- her effulgent beauty\n- an effulgent smile\n\n![resplendentâ˜¢](#resplendentâ˜¢)\n\n\n#### engross\nen- =\u003e ä½¿...\ngross =\u003e å¤§ = greate\n=\u003e ä½¿...å¤§? =\u003e å…¶å®æ˜¯ç”¨å¤§å†™å­—æ¯ä¹¦å†™çš„æ„æ€ \n=\u003e é‚£ä¸ºä»€ä¹ˆè¿˜æœ‰\"ä½¿...ç€è¿·, ä½¿...å…¨ç¥è´¯æ³¨\"çš„æ„æ€å‘¢?\n=\u003e engross è¿˜æœ‰ä¸€ä¸ªæ„æ€æ˜¯\"to write or type out formally (a deed, agreement, or other document) preparatory to execution\", ä¹Ÿè®¸æ˜¯å› ä¸º engross çš„éƒ½æ˜¯ä¸€äº›å¾ˆé‡è¦çš„æ–‡ä»¶, éœ€è¦å…¨ç¥è´¯æ³¨?\n![300](notes/2022/2022.7/assets/young-girl-coloring-engross-drawing-52772758.jpg)\n\nEngross is a verb that means to consume all of your attention or time. Once you engross yourself in the culture of high salaries and unlimited spending accounts, it's hard to go back to cooking at a sandwich shop.\n\n\n#### fawn\nfawnæ˜¯å°é¹¿çš„æ„æ€\n![300](notes/2022/2022.7/assets/Pasted%20image%2020220725154544.png) ![300](notes/2022/2022.7/assets/fawn-dingel.webp)\nè€Œ fawn, fawn over \"å·´ç»“\"è¿™ä¸ªå«ä¹‰æ¥è‡ªå¦ä¸€ä¸ªè¯æº, ç”¨æ¥å½¢å®¹\"å°ç‹—æ‘‡å°¾å·´å¼€å¿ƒçš„æ ·å­\", å¼•ç”³ä¸º\"court flavor, grovel, act slavishly\", æ±‰è¯­é‡Œé¢ä¹Ÿæœ‰ç±»ä¼¼çš„è¯: \"æ‘‡å°¾ä¹æ€œ\" (æ±‰è¯­æˆè¯­ï¼Œæ‹¼éŸ³ä¸º yÃ¡o wÄ›i qÇ liÃ¡nï¼ŒæŒ‡åƒç‹—é‚£æ ·æ‘‡ç€å°¾å·´ä¹æ±‚ä¸»äººçˆ±æ€œã€‚æŒ‡å‘èº¬å±ˆè†åœ°çŒ®åªšã€è®¨å¥½ï¼Œä»¥æ±‚å¾—åˆ°ä¸€ç‚¹å¥½å¤„ã€‚å‡ºè‡ªå”Â·éŸ©æ„ˆã€Šåº”ç§‘ç›®æ—¶ä¸äººä¹¦ã€‹)\n\n#### germinate\nå¼€å§‹å½¢æˆï¼›èŒå‘\ngerminate å¯ä»¥çœ‹ä½œ germ çš„åŠ¨è¯, germ æ˜¯ç§å­çš„æ„æ€(ç°åœ¨ä¸»è¦æŒ‡ç»†èŒäº†)\n\n![germaneâ˜¢](#germaneâ˜¢)\n\n\n#### ill-bred\nå’Œæ±‰è¯­é‡Œé¢\"æ²¡æ•™å…»\"æ˜¯ä¸€æ¨¡ä¸€æ ·çš„\n\n\n#### inimicalâ˜¢\nhostile, enemy-like =\u003e å¯ä»¥ç”¨ enemy æ¥è¾…åŠ©è®°å¿†, è¯æ ¹æ˜¯ä¸€æ ·çš„, å°±æ˜¯ä¸¤ä¸ª e éƒ½å˜æˆäº† i\n\n\n#### insouciantâ˜¢\næ¼«ä¸ç»å¿ƒçš„, æ— å¿§æ— è™‘çš„, æ•£æ¼«çš„, nonchalant, casual, carefree\nin- =\u003e not\nsouc =\u003e care, ä¾‹å¦‚ solicit\n-ant\n=\u003e ä¸å…³å¿ƒçš„, =\u003e æ¼«ä¸ç»å¿ƒçš„\n\nOnly people with no real troubles can afford to be insouciant during times like these. Runway models are great at looking insouciant, strolling the catwalk apparently without a care in the world.\n\nSome prefer their musical idols to be insouciant, seeming not to care what their fans think or want. Others like them more eager to please, happy to take requests and engage. The two obvious examples are Louis Armstrong and Miles Davis. Armstrong would smile and encourage the audience to participate, while Davis was the insouciant master who showed no concern for or interest in what his listeners might prefer: some people found his insouciant manner irresistible.\n\n#### moratoriumâ˜¢\nmora- =\u003e pause, delay\ntor(y)\n-ium\n=\u003e æš‚åœ, é—´æ­‡\n\nA moratorium is **the suspension of a particular activity**â€“â€“you could have a moratorium on fishing, baking, the use of candles, the wearing of matching socks.\nGenerally, moratoriums go into effect when something becomes seen as being not okay for now, but might go back to being okay later. After the water fountain started to burble up green sludge, the principal put a moratorium on drinking any water at school until the fountains were fixed and the water tested.\nè¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒformalçš„è¯, é€šå¸¸æ˜¯ä¸€ä¸ªoffcial agreement\n- a five-year worldwide **moratorium** on nuclear weapons testing\n\n\n#### mordantâ˜¢\nmord- =\u003e mordere, to bite, nip, sting\n=\u003e å°–åˆ»çš„, å°–é”çš„, è¾›è¾£çš„ \n=\u003e å¯ä»¥çœ‹åˆ°æ±‰è¯­å’Œè‹±è¯­éƒ½å–œæ¬¢ç”¨\"å°–\"æ¥å½¢å®¹è¯­è¨€çš„å†·é…·ä¸åˆ»è–„, æˆ–è€…é­è¾Ÿå…¥é‡Œ, ä¸€é’ˆè§è¡€, é€å½», åˆ‡ä¸­è¦å®³, å……æ»¡æ¶æ„çš„è¯å°±åƒé’ˆä¸€æ ·è®©äººåˆºç—›, é­è¾Ÿå…¥é‡Œçš„è¯­è¨€ä¹Ÿç›´å‡»é—®é¢˜çš„ç—‡ç»“.\n\n- A wicked, mordant sense of humour has come to the fore in Blur's world\n\n\n#### ostracize\nå…¬å…ƒå‰5ä¸–çºªï¼Œå¤å¸Œè…Šé›…å…¸äººæ°‘æ¨ç¿»åƒ­ä¸»çš„ç‹¬è£ç»Ÿæ²»åï¼Œå»ºç«‹äº†æ°‘ä¸»åˆ¶åº¦ã€‚ä¸ºäº†ä¿å«æ°‘ä¸»åˆ¶åº¦ï¼Œé¿å…æœ‰é‡å¿ƒçš„æ”¿æ²»å®¶æ¢å¤åƒ­ä¸»æ”¿æ²»ï¼Œé›…å…¸äººæ°‘å®æ–½ä¸€é¡¹ç§°ä¸ºâ€œé™¶ç‰‡æ”¾é€æ³•â€çš„æ”¿æ²»åˆ¶åº¦ã€‚æ‰€æœ‰çš„é›…å…¸å…¬æ°‘åœ¨ä¸€ç‰‡é™¶ç‰‡ä¸Šåˆ»ä¸Šä»–è®¤ä¸ºå¯èƒ½å±å®³é›…å…¸æ°‘ä¸»æ”¿æ²»çš„äººçš„åå­—ï¼Œå°†é™¶ç‰‡æŠ•å…¥ç¥¨ç®±ã€‚å¦‚æœæœ‰äººè·å¾—è¶…è¿‡6000å¼ é€‰ç¥¨ä¸”å¾—ç¥¨æ•°ç¬¬ä¸€ï¼Œåˆ™è¢«æ”¾é€ï¼ŒæœŸé™ä¸º10å¹´ã€‚\n\né™¶ç‰‡æ”¾é€æ³•æœ‰åŠ©äºé›…å…¸å…¬æ°‘è¡¨è¾¾è‡ªå·±çš„æ”¿æ²»æ„è§ï¼Œçº¦æŸå®˜å‘˜è¡Œä¸ºï¼Œä½†è¿™ç§æ–¹å¼ç®€å•ç²—æš´ï¼Œåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºå…¬æ°‘çš„æƒ…ç»ªã€‚å› æ­¤é™¶ç‰‡æ”¾é€æ³•å¾ˆå®¹æ˜“æˆä¸ºæ”¿å®¢å…šæ´¾æ–—äº‰çš„å·¥å…·ã€‚ä¾‹å¦‚ï¼Œé›…å…¸æ”¿æ²»å®¶é˜¿é‡Œæ–¯æå¾·æ›¾åœ¨å‚åŠ é™¶ç‰‡æ”¾é€æŠ•ç¥¨çš„è·¯ä¸Šï¼Œè¢«ä¸€ä¸ªç›®ä¸è¯†ä¸çš„è·¯äººæ‹¦ä¸‹ï¼Œè¯·ä»–å¸®å¿™åœ¨é™¶ç‰‡ä¸Šåˆ»ä¸‹é˜¿é‡Œæ–¯æå¾·çš„åå­—ã€‚é˜¿é‡Œæ–¯æå¾·é—®ä»–ä¸ºä»€ä¹ˆæƒ³æ”¾é€é˜¿é‡Œæ–¯æå¾·ã€‚é‚£äººå›ç­”â€œä¸ä¸ºä»€ä¹ˆï¼Œæˆ‘ç”šè‡³ä¸è®¤è¯†è¿™ä¸ªäººã€‚åªæ˜¯åˆ°å¤„éƒ½åœ¨è°ˆè®ºä»–ï¼Œè¯´ä»–æ˜¯ä»€ä¹ˆâ€˜æ­£ä¹‰ä¹‹å£«â€™ï¼Œæˆ‘å®åœ¨æ˜¯å¬çƒ¦äº†ã€‚â€é˜¿é‡Œæ–¯æå¾·å¹³é™åœ°å¸®ä»–åœ¨é™¶ç‰‡ä¸Šåˆ»ä¸‹è‡ªå·±çš„åå­—ã€‚æŠ•ç¥¨ç»“æœæ­æ™“ï¼Œè¢«æ”¾é€çš„æ­£æ˜¯é˜¿é‡Œæ–¯æå¾·ã€‚å…¬å…ƒå‰ 415 å¹´ï¼Œé›…å…¸å¹³æ°‘é¢†è¢–æµ·æŸæ³¢æ‹‰æ–¯è¢«æ”¾é€ï¼Œåæ¥å¤–å›½å¤–è¢«æ”¯æŒå¯¡å¤´æ”¿æ²»çš„æ¿€è¿›åˆ†å­æš—æ€ã€‚æ­¤äº‹åœ¨é›…å…¸äººæ°‘ä¸­é€ æˆæå¤§éœ‡åŠ¨ã€‚ä»æ­¤åï¼Œé™¶ç‰‡æ”¾é€æ³•è‡ªç„¶ç»ˆæ­¢ã€‚\n\nè‹±è¯­å•è¯ ostracize æ­£æ˜¯æ¥è‡ªé™¶ç‰‡æ”¾é€æ³•ã€‚å®ƒæºè‡ªå¸Œè…Šè¯­ ostrakizeinï¼Œè€Œè¯¥è¯æºè‡ªå¸Œè…Šè¯­ ostrakon ï¼ˆé™¶ç‰‡ï¼Œç“¦ç‰‡ï¼Œè´å£³ï¼‰ã€‚è‹±è¯­ä¸­ oysterã€ostracean ç­‰å•è¯å‡ä¸æ­¤åŒæºã€‚\n\nostracizeï¼š ['É‘strÉ™saÉªz] vt. æ”¾é€ï¼Œæ’æ–¥ï¼Œæ’æŒ¤\nostracismï¼š ['É’strÉ™sÉªz(É™)m] n. æ’æ–¥ï¼Œæ”¾é€ï¼Œé™¶ç‰‡æ”¾é€æ³•\noysterï¼š ['É’ÉªstÉ™] n.ç‰¡è›ï¼Œç”Ÿèšï¼Œæ²‰é»˜å¯¡è¨€ä¹‹äºº\n\n\n#### slouchâ˜¢\nç°ä»£ç¤¾ä¼šæœ€å¸¸è§çš„å§¿åŠ¿ä¹‹ä¸€: slouch\n![](notes/2022/2022.7/assets/38755492_l.jpg)\n![](notes/2022/2022.7/assets/index%203.jpg)![](notes/2022/2022.7/assets/index-1.jpg)\n\n#### snob\næ—§æ—¶åœ¨ç‰›æ´¥ã€å‰‘æ¡¥ç­‰è‹±å›½å¤§å­¦çš„å­¦ç”Ÿåå†Œä¸­ï¼Œå‡ºèº«é«˜è´µçš„å­¦ç”Ÿå§“ååé¢æ ‡æœ‰ NOB çš„å­—æ ·ï¼ŒNOB æ˜¯ nobilityï¼ˆé«˜è´µçš„å‡ºèº«ï¼Œè´µæ—èº«ä»½ï¼‰ä¸€è¯çš„ç®€ç•¥å½¢å¼ï¼›å‡ºèº«å¹³æ°‘çš„æ™®é€šå­¦ç”Ÿå§“ååˆ™è¢«æ ‡ä»¥ s. nob.ï¼Œè¿™æ˜¯æ‹‰ä¸è¯­ sine nobilitate 'without nobility'ï¼ˆæ— é«˜è´µå‡ºèº«ï¼‰çš„ç¼©ç•¥ã€‚æ®è®¤ä¸ºï¼Œè‹±è¯­ snob ä¸€è¯å¯èƒ½å³ç”±æ­¤è€Œæ¥ï¼Œå› æ­¤æœ€åˆå«æœ‰ä½è´±è€…æˆ–å¹³æ°‘ä¹‹æ„ã€‚\né•¿æœŸä»¥æ¥å‰‘æ¡¥å¸ˆç”Ÿæ›¾ä¸€ç›´ç”¨è¯¥è¯æ¥æŒ‡â€œå¸‚æ°‘â€ï¼ˆtownsmanï¼‰ï¼Œä»¥åˆ«äºâ€œç©¿é•¿è¢çš„å¤§å­¦å¸ˆç”Ÿâ€ï¼ˆgownsmanï¼‰ã€‚snob çš„ä»Šä¹‰æ®è¯´æ˜¯è‹±å›½å°è¯´å®¶è¨å…‹é›·ï¼ˆWilliam Makepeace Thackeray, 1811-1863ï¼‰æœ€å…ˆä½¿ç”¨çš„ã€‚1847 å¹´ä»–å‡ºç‰ˆäº†è‘—åæ•£æ–‡é›†ã€ŠåŠ¿åˆ©äººè„¸è°±ã€‹ï¼ˆBook of Snobsï¼‰ï¼Œè¿™æ˜¯ç”± 45 ä¸ªç‰¹å†™ç»„æˆçš„è‹±å›½ç¤¾ä¼šå„é˜¶å±‚åŠ¿åˆ©äººçš„è‚–åƒã€‚ä»–æŠŠè‹±ç‹ä¹”æ²»å››ä¸–ï¼ˆGeorge IV, 1762-1830ï¼‰ä¹Ÿç§°ä½œ snobï¼Œå› ä¸ºä»–ä»¥â€œæ¬§æ´²ç¬¬ä¸€ç»…å£«â€è‡ªè¯©ï¼Œä½†èº«ä¸Šå´ä¸æ¯«æ²¡æœ‰ç»…å£«çš„ç‰¹å¾ã€‚ç»è¨å…‹é›·è¿™ä¹ˆä¸€ç”¨ï¼Œsnob æˆäº†ä¸€ä¸ªå¸¸ç”¨è¯ï¼Œç°é€šå¸¸å¤šæŒ‡â€œåŠ¿åˆ©çš„äººâ€ã€â€œè‡ªä»¥ä¸ºæ‡‚è¡Œçš„äººâ€æˆ–â€œè‡ªå‘½ä¸å‡¡çš„äººâ€ã€‚intellectual snob æ˜¯â€œè‡ªä»¥ä¸ºå¾ˆæœ‰å­¦è¯†çš„äººâ€ï¼Œacademic snob æ˜¯â€œè‡ªå°ä¸ºå­¦è€…çš„äººâ€ï¼Œmusic snob æŒ‡â€œè‡ªä»¥ä¸ºæ‡‚éŸ³ä¹çš„äººâ€ï¼Œwine snob æŒ‡â€œè‡ªå‘½ä¸å‡¡ã€éä¸Šç­‰é…’ä¸å–çš„äººâ€ï¼Œè€Œ snob appeal/value åˆ™æ˜¯â€œå¯¹åŠ¿åˆ©é¡¾å®¢çš„å¸å¼•åŠ›ï¼ˆä»·å€¼ï¼‰â€ã€‚\n\nä¾‹ \n- He's too much of a snob to mix with that earthy crowd. (FWF) ä»–è¿™ä¸ªäººåŠ¿åˆ©é€é¡¶ï¼Œä¸å±‘ä¸é‚£äº›ç²—äººä¸ºä¼ã€‚\n- A Rolls-Royce has snob appeal. (LDC) åŠ³æ–¯è±æ–¯æ±½è½¦å¯¹åŠ¿åˆ©é¡¾å®¢æ˜¯æœ‰å¸å¼•åŠ›çš„ã€‚\n- John is a snob who acts as though he is better than we are. (NED) çº¦ç¿°æ˜¯ä¸ªè‡ªå‘½ä¸å‡¡çš„äººï¼Œå¥½åƒæ¯”æˆ‘ä»¬éƒ½é«˜æ˜ä¼¼çš„ã€‚\n\nå½¢å®¹è¯: snobbish\n\n#### tortuous\ntort- =\u003e From Latin torquere \"to twist,\" æ‰­æ›², æ¯”å¦‚ contort, distort\n-uous\n=\u003e å¼¯å¼¯æ›²æ›²çš„, æ›²æŠ˜çš„, æ‰­æ›²çš„ =\u003e å¼•ç”³åˆ°è¨€è¯­, æ‹å¼¯æŠ¹è§’çš„, \n- He took a tortuous route through back streets.\n- ...these long and tortuous negotiations aimed at ending the conflict. \n\nIt is important not to confuse it with **torturous**, which means characterized by great pain. \"The contemporary string quartet was **tortuous** in its tonal shifts, but only **torturous** at the point where the violinist ran her nails up and down a chalkboard.\"\n\n#### twig\n![400](notes/2022/2022.7/assets/labeledTwig-621x1024.jpg)\n\n#### stintâ˜¢\n- He has just finished **a stint of compulsory military service**.\n- Perhaps her most productive period was **her five-year stint as a foreign correspondent** in New York.\n\nThe noun stint means **a set amount of time in which you do something** â€” often work of some sort. \"She served **a stint in the army**, followed by **a stint in an office setting**, before settling on a career as a lounge singer.\" Unlike a project or vocation, a stint can refer to the stretch of time spent doing a particular job. You apply for a job, but you refer to your past stint in the Peace Corps.\n\n- æ¥è‡ªå¤è‹±è¯­styntan, ä½¿é’åŒ–, ä½¿ç¼©çŸ­. ä¸æ˜¯å¾ˆç†è§£è¿™ä¸¤ä¸ªæ„æ€ä¹‹é—´çš„è”ç³», éš¾é“æ˜¯\"å·¥ä½œäº†ä¸€æ®µæ—¶é—´äº†è¢«'ç£¨é’äº†, ç£¨çŸ­äº†'?\"\n\n - The bride's parents did not **stint on the champagne** - there was plenty for everyone.\n- Don't **stint yourself** - take another slice of cake.\n\nAs a verb, stint means **to be sparing or frugal**, or restrict in a stingy manner (\"to skimp\"). \"The school board chose to make cuts at the administrative level, rather than **stint on** the children's education.\"\n\n\n#### waylay\nèººåœ¨è·¯è¾¹(å‡†å¤‡åŸ‹ä¼æŸäºº) =\u003e ambush\n\n- A man on his way to deposit $12,000 in a bank was **waylaid** by two men who snatched his bag. \n- I meant to leave earlier but I was **waylaid** on the way out of a meeting by my manager.\n\nTo waylay, or to be waylaid, is usually not a good thing: Mom would not be proud. Robbers waylay their victims. Outlaws waylaid stagecoaches in the Old West. The verb's origin, from wegelage, means \"lying in wait, with evil or hostile intent.\" You might also use waylay to show someone being interrupted from finishing the task at hand: \"I shouldâ€™ve been studying, but was waylaid by my friend's invitation to go bungee jumping.\"\n\n\n#### vociferousâ˜¢\nvoci =\u003e to speak\nfer =\u003e to carry\n-ous\n=\u003e to shout, yell, cry out\n=\u003e æŠ±ç€æŸä¸ªè§‚ç‚¹å¤§å£°ç–¾å‘¼çš„ =\u003e\nIf you describe someone as vociferous, you mean that they **speak with great energy and determination, because they want their views to be heard**. \n- He was a vociferous opponent of Conservatism.\n- His resentment of her behaviour was becoming more vociferous.\n\n\n#### supplantâ˜¢\nsup- =\u003e under\nplant =\u003e sole of the foot(è„šåº•)\n=\u003e to trip up, overthrow, defeat, dispossess =\u003e \"ä»æ ¹åŸºæ€èµ·, æ€ç¿»\" =\u003e å–ä»£, replace, oust, displace, supersede\n\nPrinted books will soon be supplanted by e-books.\n\n\n#### discern\ndis- =\u003e apart, åˆ†å¼€ \n-cern =\u003e to separate\n=\u003e to separate apart =\u003e å°†ç‰©ä½“ä»èƒŒæ™¯(å…¶ä»–ä¸œè¥¿)åˆ†å¼€ =\u003e è¾¨åˆ«å‡º, çœ‹å‡º\n- I could just discern a figure in the darkness.\n- It is difficult to discern any pattern in these figures.\n\n#### instillâ˜¢\nin-  =\u003e in\nstill =\u003e a drop æ¯”å¦‚ distill\n=\u003e put in by drops, to drip, trickle =\u003e to introduce liquid/feelings... little by little.\n=\u003e é€æ¸çŒè¾“\n- It is part of a teacher's job to **instill** confidence in/into his or her students.\n\n- Parents work hard to develop, or instill, **positive beliefs and values** in their children. Interestingly, there's no corresponding word for when parents pass down their bad habits.\n\n- Instill comes from the Latin verb stillare, meaning \"to drip.\" For some people, this word provides an apt metaphor for the way that parents and teachers cultivate understanding in young learners, patiently introducing wisdom \"drop by drop.\" (Of course, for others, instill conjures up the image of a persistently dripping faucet that just won't be quiet.)\n\n\n#### shred\n![](notes/2022/2022.7/assets/Should-I-Shred-My-Mail.jpg)\n\nshred æ—¢å¯ä»¥æŒ‡è¿™ä¸ªåŠ¨ä½œ, ä¹Ÿå¯ä»¥æŒ‡ shredded åçš„ç»†é•¿æ¡\n\n#### dogged\nè¿™é‡Œçš„ dog å°±æ˜¯æŒ‡ dog, ç‹—ç‹—æœ‰æ—¶å¾ˆå›ºæ‰§, åšæŒä¸æ‡ˆ(æ¯”å¦‚å¿ çŠ¬å…«å…¬æ¯å¤©éƒ½å»ç­‰å¾…ä¸»äºº), dogged å°±æ˜¯æœ‰è¿™ä¸ªç‰¹è´¨çš„äºº.\n\n- Her ambition and **dogged determination** ensured that she rose to the top of her profession.\n\n#### execrateâ˜¢\nexecrate = ex + sacrare + ate \n- ex- =\u003e out\n- ecr =\u003e sacr =\u003e holy\n- -ate\n=\u003e to devote off or away, to curse, ä½¿å…¶ä¸å†ç¥åœ£, å’’éª‚, æ†æ¶, è°´è´£, loathe, detest, abhor, curse, denounce, damn\n\n##### consecrate\ncon- =\u003e with, together\nsecr- =\u003e sacr-, holy\nate\n=\u003e æŠŠ...ç¥åœ£åŒ–, make or declare sacred by certain ceremonies and rites. æ¯”å¦‚æŠŠä¸€ä¸ªæ–°ä¿®å»ºçš„æ•™å ‚ç¥åœ£åŒ–\n\n#### indemnityâ˜¢\nin- =\u003e not, opposite of, without\ndemn =\u003e damnum, damage\n-ity\n=\u003e security or exemption against damage =\u003e åæ¥å¼•ç”³åˆ°æŸååçš„è¡¥å¿é‡‘, èµ”æ¬¾, ä¿é™©çš„èµ”æ¬¾.\n\nIndemnity is protection against loss or harm â€” it is **most often used in insurance**.\n\nIf you suffer an injury or there's damage to your house, an indemnity makes up for the loss â€” if it's part of your insurance. An indemnity may also keep something or someone from being held responsible for harm. Protection indemnity is mainly offered for unlikely events. If you regularly crash hot-air balloons, you wonâ€™t get indemnity for the next one you rent. In fact, the balloon rental company will probably demand their own indemnity in case you crash again.\n\n#### coltish\ncolt æŒ‡çš„æ˜¯å°é©¬é©¹\n![](notes/2022/2022.7/assets/istockphoto-1007782950-612x612.jpg)\ncoltishå°±æ˜¯\"åƒå°é©¬é©¹ä¸€æ ·çš„\",  full of energy but clumsy or awkward, because they lack physical skill or control. \n\nAn energetic, playful person can be described as coltish. A coltish preschooler might skip happily across the room and then slide to a stop in her socks.\n\nThere's something a little young and awkward implied in the word coltish, which arose in the 14th century from the sense of a colt, or young horse, as a lively, frolicking, long-legged creature. Skinny-legged teenagers dashing around a mall are coltish, and a soccer team of five year-olds is made up of happy, coltish players.\n\n\n#### Ã©clat\nWhen you do something with Ã©clat, you do it with great style or an amazing effect. A skilled magician performs all of her tricks with Ã©clat.\n\nEclat is the gusto or flair with which you make an entrance at a party or sing a song at your school talent show. It's also a certain measure of success, especially the type that other people consider you to have â€” your skill on the soccer field might lend you a certain amount of Ã©clat among your classmates, for example. The word Ã©clat comes from the French Ã©clat, which means \"splinter or fragment,\" but also \"flash of brilliance.\"\n\n\n#### spliceâ˜¢\nè¿™ä¸ªå•è¯çœ‹èµ·æ¥å¥½åƒæ˜¯è¡¨ç¤º\"åˆ†å¼€\"çš„å«ä¹‰, ä½†æ˜¯å®ƒçš„æ„æ€æ˜¯ to join two piece of rope, film, etc. together at their ends to form one long piece. =\u003e å¼•ç”³ä¸ºç»“å©š\n\n- Scientists have discovered how to splice pieces of DNA.\n- He taught me to edit and splice film.\n- An old friend of mine, newly spliced, recently invited me to dinner in his new marital home.\n\n\n#### coda\nCoda comes from the Latin word cauda, which means â€œtailâ€.\n\nA coda is a passage at the end of a piece of music that brings the music to a close. \n\nIn the song â€œHey Judeâ€ by The Beatles, the final â€œnana na naâ€ part is considered a coda, and it is almost four minutes long.\n[The Beatles - Hey Jude - YouTube](https://youtu.be/A_MjCqQoLLA?t=239)\n\n#### discrete\nä¸è¦å’Œ discreet ææ··äº†\n- discrete: ç‹¬ç«‹çš„, å„è‡ªçš„, ç‹¬ç«‹çš„\n- discreet: å®¡æ…çš„, è°¨æ…çš„, å°å¿ƒçš„\n\ndiscrete =\u003e discretionary\n\n#### badger\nç¾\nç¾ä¹‹æ‰€ä»¥è¢«ç§°ä¸ºbadgerï¼Œæ˜¯å› ä¸ºå®ƒçš„å‰é¢ä¸Šæœ‰é†’ç›®çš„ç™½è‰²æ¡çº¹ï¼Œå°±åƒæ˜¯ä¸€ä¸ªå¾½ç« ï¼ˆbadgeï¼‰ã€‚\n![](notes/2022/2022.7/assets/_123042157_f086f397-3f9d-4827-a4d6-f41e34de0cae.jpg)\n\nbadgerï¼š['bÃ¦dÊ’É™] n.ç¾vt. çº ç¼ ä¸ä¼‘ï¼›åµç€è¦ï¼›çƒ¦æ‰°\n\nä¸­ä¸–çºªæ—¶æµè¡Œä¸€ç§æ®‹å¿çš„ç‹—å’¬ç¾æ¸¸æˆã€‚äººä»¬å°†æŠ“æ¥çš„ç¾æ”¾åˆ°ä¸€ä¸ªç›’å­é‡Œï¼Œç„¶åå°†ä¸€åªç‹—æ”¾å…¥ç›’å­é‡Œï¼Œè®©ç‹—åå¤å»å’¬ç¾ï¼Œæ¯æ¬¡å’¬ä½ç¾åï¼Œç‹—ä¸»äººå°±å°†å®ƒä»¬åˆ†å¼€ï¼Œå¦‚æ­¤åå¤ï¼Œä»¥åœ¨è§„å®šæ—¶é—´å†…å’¬ä½ç¾æ¬¡æ•°æœ€å¤šä¸ºèƒœã€‚ç”±äºåœ¨è¿™ç§æ¸¸æˆä¸­ï¼Œç‹—ä¼šåå¤å»å’¬ç¾ï¼Œå› æ­¤badgerä¸€è¯è¡ç”Ÿå‡ºâ€œçƒ¦æ‰°ã€çº ç¼ ä¸ä¼‘â€ä¹‹æ„ã€‚\n\n\n\n#### contravene\ncontra- =\u003e against \nvene =\u003e to come\n=\u003e to come against, oppose, come or be in conflict with\n\n- The company knew its actions **contravened** international law.\n- The Board has banned the film on the grounds that it **contravenes** criminal libel laws.\n- He said the article did not **contravene** the industry's code of conduct.\n\nå¯ä»¥çœ‹åˆ° contravene çš„éƒ½æ˜¯æŸä¸ªè§„åˆ™å’Œæ³•å¾‹\n\nTo contravene means to go against or defy. You might contravene your parents' ban on sweets when your friend offers to share her candy because chocolate tastes too good to resist!\n\nIf you contravene something in practice, you act in direct violation of a particular law or rule. Think about the times when someone has told you not to cross a line and you do anyway. You can also contravene in words though, which means you contradict or argue against a statement. Let's say you're debating gun control. If your opponent says that for the safety of all, it should be legal to carry a concealed weapon wherever you go, you might answer that the more concealed weapons there are, the more violence. You are contravening your opponent's argument.\n\n#### diaphanous\n- dia- \nè¡¨ç¤ºâ€œç©¿è¿‡ï¼ŒäºŒè€…ä¹‹é—´â€ã€‚\n- phan- \n= show, è¡¨ç¤ºâ€œæ˜¾ç¤ºâ€ã€‚æºè‡ªå¸Œè…Šè¯­ phainein \"to bring to light, cause to appear, show\"\n- -ous \nè¡¨å½¢å®¹è¯ï¼Œè¡¨ç¤ºâ€œâ€¦çš„â€\n\n![](notes/2022/2022.7/assets/erwin-blumenfeld--diaphanous-coronet-magazine.jpg)\n\nIf a dress is so see-through that light shines through it, it's diaphanous. You could also call it \"sheer\" or \"transparent,\" but diaphanous sounds much fancier.\n\nIf you want a classic example of diaphanous clothing, check out all those nineteenth century Romantic paintings of goddesses clad in lightweight gowns flouncing around in the middle of forests at night. Those gowns are diaphanous, and so are the fluttery translucent muslin curtains in your kitchen window and the gauzy tutu your little sister loves to wear. The Greek root, diaphanes, \"see-through,\" combines dia-, \"through,\" and phainesthai, \"to show.\"\n\n![](notes/2022/2022.7/assets/2000.webp)\nä½ çŸ¥é“å—, æ˜Ÿäº‘æœ‰å‘å…‰çš„(Emission Nebula)å’Œä¸å‘å…‰çš„(Reflection nebula)ä¸¤ç§, é‚£äº›ä¸å‘å…‰çš„æ˜Ÿäº‘æŠ˜å°„äº†å…¶ä»–æ˜Ÿä½“çš„å…‰çº¿, æ‰€ä»¥æ‰èƒ½è¢«æˆ‘ä»¬çœ‹åˆ°. [Source](https://en.wikipedia.org/wiki/Reflection_nebula)\n\n#### gossamer\nGossamer is **something super fine and delicate** â€” like a spider web or the material of a wedding veil.\n\nThe original gossamer, from which these meanings come from, is the fine, filmy substance spiders excrete to weave their webs. A dress can be gossamer-like, if its fabric is so sheer as to be see-through, or almost. Your chances of going to a good college are \"gossamer thin\" if you've never cracked a book in high school.\n\nadj: very delicate and light. ç²¾å·§è½»ç›ˆçš„ï¼›è½»è–„ç²¾è‡´çš„\n- gossamer wings\n- a gossamer veil\n- ...the daring gossamer dresses of sheer black lace.\n\n\n#### dullard\na boring, unintelligent, and unimaginative person\n-ard æ˜¯ä¸€ä¸ªè´¬ä¹‰åç¼€, è¡¨ç¤º\"ä¸å¥½çš„äºº\", ç›¸å½“äºæ±‰è¯­é‡Œé¢çš„\"...é¬¼\"\n- coward =\u003e èƒ†å°é¬¼\n- drunkard =\u003e é…’é¬¼\n- sluggard =\u003e æ‡’é¬¼\n\n#### earnestâ˜¢\nIf you are earnest, you pursue your purpose in a **steady, sincere, and eager way**. The phrase \"**in earnest**\" uses earnest as a noun, as in, \"Once you stop fooling around and start studying in earnest, you'll find you learn the material quickly.\" Oscar Wilde's classic play The Importance of Being Earnest plays on the fact that Ernest is also a man's name.\n\n(be) in earnestç›¸å½“äº\"éƒ‘é‡å…¶äº‹åœ°(çš„), è®¤çœŸåœ°(çš„), å½“çœŸåœ°(çš„)\"\n\nHe was a very **earnest** young man.\nThese fanatics are **in deadly earnest** when they say they want to destroy all forms of government.\nThe election campaign has begun **in earnest**.\nI thought he was joking - I didn't realize he was **in earnest**.\n\n\n#### elicit\nelicitæ˜¯ä¸€ä¸ªä¸»åŠ¨çš„è¿‡ç¨‹, éœ€è¦ä½ å…ˆè¿›è¡ŒæŸä¸ªåŠ¨ä½œ, ç„¶åå¯¹è±¡ç»™å‡ºæŸç§response, å¦‚æœä½ ä»€ä¹ˆéƒ½æ²¡æœ‰åš, åªæ˜¯çœ‹ç€æŸä¸ªäº‹ä»¶å‘ç”Ÿ, é‚£ä¹ˆè¿™å°±ä¸æ˜¯elicit.\nWhen you elicit, you're bringing out a **response** of some sort. A good comedian elicits a lot of laughs.\n\nElicit has to do with creating or provoking a response. A great speech will elicit cheers â€” a bad speech will elicit boos. Teachers try to elicit responses from students. If a friend smiles at you, it will probably elicit a smile of your own. In court, a lawyer might try to elicit mistakes and inconsistencies in the testimony of a witness. In all cases, whatever is elicited is some kind of response.\n\n#### estimableâ˜¢\nestimate + able? å¯ä¼°è®¡çš„?\nå…¶å® estimate åœ¨ä»¥å‰çš„æ„æ€è¿˜æœ‰\"ç§°èµ...çš„ä»·å€¼\"çš„æ„æ€, æ˜¯ä» esteem æ¥çš„, æ‰€ä»¥ estimable å°±æ˜¯ deserving praise, admiration çš„æ„æ€\nThis is a word for **people** who deserve respect. A hardworking scholar who has written several books might be ***estimable***. **Things** can be ***estimable***, too. You might describe an impressive book, restaurant, or film as ***estimable***. Estimable is related to esteem, which can be used to mean â€œregard highly.â€ Being ***estimable*** is the opposite of being disgraceful.\n\n#### facileâ˜¢\nfrom French *facile* \"easy,\" (è¨€è¯­æˆ–è€…ç†è®º)è½»ç‡çš„, æœªç»æ·±æ€ç†Ÿè™‘çš„, ä¿¡å£å¼€æ²³çš„, éšæ„çš„\n\n- a facile explanation\n- We must avoid facile recriminations about who was to blame.\n\n\n#### fracasâ˜¢\nä¸è¦æ··æ·†äº† fracas å’Œ farce\nfarce æ˜¯ \"é—¹å‰§\"\nfracas æ˜¯ \"a noisy argument or fight\"\n\n- He was injured in a Saturday-night fracas outside a disco. \n- The prime minister has joined the fracas over the proposed changes.\n- No one had prepared anything so the meeting was a bit of a farce.\n\n\n#### hale\nç”¨æ¥å½¢å®¹è€å¹´äººèº«ä½“æ£’, ä½ è¿™è€èº«æ¿å­çœŸå¥½, è¯»éŸ³ä¸Šå’Œ healthy å‰åŠæˆªæŒºåƒçš„.\nè¿˜æœ‰ä¸€ä¸ªé€šå¸¸å½¢å®¹è€å¹´äººçš„æ˜¯ sprightly =\u003e lively and active, ç²¾ç¥çŸé“„çš„, æ³¨æ„å®ƒè™½ç„¶æœ‰ ly ä½†æ˜¯æ˜¯ä¸€ä¸ªå½¢å®¹è¯:\n- He's a sprightly old man of 75.\n\n\n#### harrowâ˜¢\nTo harrow is to **cause worry and upset**, the way a truly scary movie might harrow you, making it hard to sleep without turning on the light.\n\nHarrow is an uncommon verb that was originally used in a religious context. You're much more likely to hear the adjective harrowing used for things that are extremely distressing. But if your cat torments you nightly with her incessant meowing, you might try yelling, \"Why do you harrow me?\" In agriculture, harrow has a completely different meaning: it's a device that helps up break up the soil. And if you harrow your land, you use such a device.\n\n\n#### incendiaryâ˜¢\nin- =\u003e ä½¿...\ncend =\u003e =cand, to shine, glow\niary\n=\u003e person who sets malicious fires, ä¹Ÿå°±æ˜¯ä½¿...ç‡ƒèµ·æ¥(çš„äºº) \n=\u003e åæ¥å¼•ç”³ä¸ºèƒ½å¼•èµ·ç‡ƒçƒ§çš„, e.g. an incendiary bomb, ç‡ƒçƒ§å¼¹ \n=\u003e å¼•ç”³åˆ°è¯­è¨€ä¸Š, æœ‰ç…½åŠ¨æ€§çš„, incendiary remarks, ç…½åŠ¨æ€§çš„è¨€è®º\n- æœ‰è¶£çš„æ˜¯æ±‰è¯­\"ç…½åŠ¨æ€§çš„\"ä¹Ÿå’Œç«æœ‰å…³.\n\n#### irradicable\n= ineradicable =\u003e in + eradicable\n\n\n#### macabre\nåœ¨æ¬§æ´²å†å²ä¸Šæœ€çŒ–ç—çš„ç˜Ÿç–«è«è¿‡äº 14 ä¸–çºªè”“å»¶äºæ•´ä¸ªæ¬§æ´²çš„é»‘æ­»ç—…ï¼ˆBlack Deathï¼‰ï¼Œæ­»äº¡äººæ•°ä¹‹å¤šè¶…è¿‡å†å²ä¸Šä»»ä½•æµè¡Œç—…æˆ–æˆ˜ç¥¸ã€‚æ³•å›½ç¼–å¹´å²å®¶å‚…åè¨ï¼ˆJean Froissartï¼‰è¯´ï¼Œçº¦æœ‰ä¸‰åˆ†ä¹‹ä¸€çš„æ¬§æ´²äººæ­»äºè¿™æ¬¡æµè¡Œç—…ã€‚å¦æœ‰èµ„æ–™è¯´ï¼Œè¿™æ¬¡å¤§ç˜Ÿç–«å¤ºèµ°äº†ä¸‰åˆ†ä¹‹äºŒçš„æ¬§æ´²äººçš„æ€§å‘½ã€‚é™¤æ­¤è€Œå¤–ï¼Œä» 1337 å¹´è‡³ 1453 å¹´è‹±æ³•ä¸¤å›½ä¹‹é—´æ—¶æ–­æ—¶ç»­çš„ç™¾å¹´æˆ˜äº‰ä¹Ÿåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¢å¤§äº†äººå£çš„æ­»äº¡ç‡ã€‚ç„šåŒ–å°¸ä½“çš„ç«å †å‡ ä¹éšå¤„å¯è§ã€‚å› æ­¤ï¼Œä¸­ä¸–çºªæœ«æœŸäººä»¬æ—¶å¸¸æƒ³åˆ°æ­»äº¡ï¼Œæ­»äº¡ä¹Ÿå°±æˆäº†å½“æ—¶è¥¿æ¬§æˆå‰§ã€è¯—æ­Œã€éŸ³ä¹å’Œç¾æœ¯çš„ä¸€ä¸ªæ™®é€šä¸»é¢˜ã€‚æœ€é£è¡Œçš„ä¸€ç§é¢˜ææ˜¯åœ¨æˆå‰§é‡Œå’Œç”»é¢ä¸Šè¡¨ç°ç”Ÿè€…å’Œæ­»è€…å…±èˆï¼Œè±¡å¾æ­»äº¡çš„éª·é«…å¸¦é¢†ä¼—äººä¸€æ­¥æ­¥èµ°å‘åŸå¢“ã€‚è¿™ç§èˆè¹ˆå¤æ³•è¯­ä½œ danse macabreï¼Œè‹±è¯­ä½œ dance macabreï¼Œæ„æ€æ˜¯ dance of deathï¼ˆæ­»äº¡ä¹‹èˆï¼‰ï¼Œè‹¥ç…§å­—é¢ä¹‰è®²åˆ™æ˜¯ dance of the Maccabeesï¼ˆé©¬å¡æ¯”å®¶æ—ä¹‹èˆï¼‰ã€‚å®ƒå¯èƒ½èµ·æºäº 14 ä¸–çºªå¾·å›½ä¸€å‡ºæ®ã€Šåœ£ç»æ—§çº¦Â·æ¬¡ç»ã€‹ï¼ˆOld Testament Apocryphaï¼‰é‡Œæœ‰å…³ Maccabee å®¶æ—çš„æ•…äº‹ç¼–å†™è€Œæˆçš„é“å¾·å‰§æˆ–å¥‡è¿¹å‰§ã€‚è¿™ä¸ªå®¶æ—ä¸ºäº†æ‹¯æ•‘å™åˆ©äºšçŠ¹å¤ªäººé¢†å¯¼äº†ä¸€åœºé•¿è¾¾è¿‘ 30 å¹´çš„è§£æ”¾æˆ˜äº‰ï¼Œå…¬å…ƒå‰ 142 å¹´å»ºç«‹äº†ä¸€ä¸ªç”± Maccabee å®¶æ—åè£”ç»Ÿæ²»çš„çŠ¹å¤ªå›½å®¶ï¼Œå…¬å…ƒå‰ 63 å¹´ä¸ºç½—é©¬äººæ‰€ç­ã€‚Maccabee å®¶æ—çš„æ•…äº‹å……æ»¡äº†é˜´æƒ¨çš„æ°”æ°›ï¼Œè¯»èµ·æ¥ä»¤äººæ¯›éª¨æ‚šç„¶ã€‚å¤šæ•°å­¦è€…è®¤ä¸ºï¼Œdanse macabre å¾—åäºæ•…äº‹ä¸­ä¸ƒä½æ®‰éš¾çš„ Maccabee å…„å¼Ÿçš„èˆè¹ˆï¼Œè€Œ macabre åˆ™æ˜¾ç„¶ä¸º Maccabee ä¹‹è®¹è¯¯ã€‚macabre ç›´åˆ° 19 ä¸–çºªæœ«æœŸæ‰ä½œä¸ºå½¢å®¹è¯å‡ºç°äºè‹±è¯­ä¹‹ä¸­ï¼Œå¹¶è¢«èµ‹äºˆâ€œä»¥æ­»äº¡ä¸ºä¸»é¢˜çš„â€ã€â€œé˜´æƒ¨çš„â€ã€â€œä»¤äººæ¯›éª¨æ‚šç„¶çš„â€ç­‰ä¹‰ã€‚\n\nä¾‹ \n- Retrieving the mangled bodies from the wreckage was a macabre task. (CAE) æŠŠæ®‹ç¼ºä¸å…¨çš„å°¸ä½“ä»æ®‹éª¸ä¸­æŒ–å‡ºæ˜¯ä¸€é¡¹ä»¤äººæ¯›éª¨æ‚šç„¶çš„å·¥ä½œã€‚\n- The macabre story of headless ghosts frightened the children. (FWF) ææ€–çš„æ— å¤´é¬¼æ•…äº‹æŠŠå­©å­ä»¬ç»™å“ç€äº†ã€‚\n- The film contains a macabre account of life in Auschwitz and other concentration camps. (CID) å½±ç‰‡è®°è½½äº†å¥¥æ–¯ç»´è¾›é›†ä¸­è¥å’Œå…¶ä»–é›†ä¸­è¥çš„ææ€–ç”Ÿæ´»ã€‚\n\n#### nonplusâ˜¢\nTo *nonplus* is to baffle or confuse someone to the point that they have nothing to say. Something weird and mysterious can *nonplus* you, like a play that is performed entirely by chickens.\n\nIf you know a little French or Latin, you'll recognize that \"non plus\" means \"**no more**.\" When something bewildering nonpluses you, **there's no more you can say or do about it**. A goal of getting poor grades, running with a bad crowd, and refusing to eat would leave your parents nonplussed. Sometimes people misuse nonplus to mean \"unimpressed,\" but that's not correct: to nonplus is to puzzle, confuse, and dumbfound.\n\n- he was **nonplussed** by the sudden announcement\n- æ³¨æ„è¿‡å»å¼æ˜¯ä¸¤ä¸ªs: nonplu==ss==ed\n\n#### peripatetic\n- **peri-** \nè¡¨ç¤ºâ€œå‘¨å›´ï¼Œé è¿‘â€ã€‚\n- **pat-** \n= walk, è¡¨ç¤ºâ€œèµ°â€ã€‚æºè‡ªå¸Œè…Šè¯­ patein \"to tread, walk.\"\n- **-etic** \n  è¡¨å½¢å®¹è¯ï¼Œé€šå¸¸æ”¾åœ¨ä¸€ä¸ªåè¯å‰ï¼Œâ€œä¸â€¦ç›¸å…³çš„ï¼Œâ€¦çš„â€ã€‚\n  \n- æ¥è‡ªå¸Œè…Šè¯­ peripatein, èµ°åŠ¨ï¼Œè®²å­¦ï¼Œæˆè¯¾ï¼Œæ¥è‡ª peri-, åœ¨å‘¨å›´ï¼Œ-pat, èµ°åŠ¨ï¼Œè¯æºåŒ path, foot. è¯¥è¯åŸç”¨äºå½¢å®¹å¤å¸Œè…Šå“²å­¦å®¶äºšé‡Œå£«å¤šå¾·ç»™å¼Ÿå­è®²è¯¾æ—¶ï¼Œå–œæ¬¢è¾¹èµ°è¾¹è®²ï¼Œåå¼•ç”³è¯ä¹‰å·¡å›å·¥ä½œçš„ï¼ŒæµåŠ¨çš„ç­‰ã€‚\n\n\ntravelling around to different places, usually because you work in more than one placeï¼ˆé€šå¸¸æŒ‡å› å·¥ä½œè€Œï¼‰å·¡æ¸¸çš„ï¼ŒæµåŠ¨çš„\n- a peripatetic music teacher æµåŠ¨çš„éŸ³ä¹æ•™å¸ˆ\n\n\n#### precariousâ˜¢\nGrab for the adjective precarious when something is **unstable, dangerous or difficult and likely to get worse**. Are you totally broke and the people you owe money to keep calling? You're in a precarious financial situation!\n\nThe Latin root of precarious means \"**obtained by asking or praying**.\" This fits well as precarious always signals that help is needed desperately. If your life is precarious or you are in a precarious situation, things could become difficult, maybe even dangerous, for you. If your footing or hold on something is precarious, it is unstable or not firmly placed, so that you are likely to slip or lose your grip.\n\n\n#### riftâ˜¢\nrift æœ¬æ¥æ˜¯ç”¨æ¥å½¢å®¹åšç¡¬çš„ç‰©ä½“(æ¯”å¦‚åœ°é¢æˆ–è€…å²©çŸ³)ä¸Šçš„è£‚ç—•çš„, ä½†æ˜¯å’Œä¸­æ–‡é‡Œé¢ä¸€æ ·, è¿™ä¸ªè¯ä¹Ÿèƒ½å¤Ÿç”¨æ¥æè¿°äººé™…å…³ç³»é‡Œé¢çš„\"è£‚ç—•\"=\u003e \n- The marriage caused a **rift** between the brothers and they didn't speak to each other for ten years.\n- The interview reflected a growing **rift** between the President and the government.\n- He has warned that the serious **rifts** within the country could lead to civil war.\n- They hope to heal the **rift** with their father.\n\n\n#### be hoist by/with one's own petard\nè¿™æ˜¯ä¸€ä¸ªè‹±è¯­ä¿—è¯­, æ¥è‡ªèå£«æ¯”äºšçš„è‘—åæˆå‰§\u003cå“ˆå§†é›·ç‰¹\u003e, hoistè™½ç„¶ç°åœ¨çš„æ„æ€æ˜¯\"ç”¨ç»³å­åŠèµ·æ¥\", åœ¨è¿™é‡Œçš„æ„æ€æ˜¯\"è¢«ç‚¸é£\", petardæ˜¯ç‚¸å¼¹çš„æ„æ€, æ•´ä¸ªå¥å­å­—é¢çš„å«ä¹‰å°±æ˜¯\"è¢«è‡ªå·±çš„ç‚¸å¼¹ç‚¸é£\" =\u003e è¢«è‡ªå·±çš„é˜´è°‹å®³æ­», ä¹Ÿå°±æ˜¯æ±‰è¯­é‡Œé¢çš„\"æ¬èµ·çŸ³å¤´ç ¸è‡ªå·±çš„è„š\"\n\n#### rileâ˜¢\næ¥è‡ª roil, åæ¥è¯»éŸ³åœ¨ç¾å›½ä¹‹é—´å˜æˆäº†rile, æ„æ€æœ‰äº†ç»†å¾®çš„åŒºåˆ«, rileå°±æ˜¯roilå¯¹æ–¹çš„æƒ…ç»ª, è®©å¯¹æ–¹æ¼æ€’, æ„¤æ€’.\n\n##### roilâ˜¢\nroil æ˜¯\"to (cause to) move quickly in a twisting circular movement\"çš„æ„æ€, æ¯”å¦‚:\n- Fierce winds roiled the sea. å¼ºé£æ…åŠ¨ç€å¤§æµ·ã€‚\n- A massive tower of smoke roiled skyward. ä¸€ä¸ªå·¨å¤§çš„çƒŸæŸ±ç¿»è…¾ä¸Šå‡ç€ã€‚ \nå¼•ç”³ä¸º\"to cause something to stop working in the usual or expected way\" ä½¿â€¦åœæ­¢æ­£å¸¸è¿ä½œ\n- Fears about Japan **roiled** world financial markets last week. ä¸Šä¸ªæ˜ŸæœŸå¯¹æ—¥æœ¬çš„æ‹…å¿§è®©ä¸–ç•Œé‡‘èå¸‚åœºåœæ­¢äº†æ­£å¸¸è¿ä½œã€‚\n- The immigration debate has **roiled** the country for more than a year. æœ‰å…³ç§»æ°‘çš„è¾©è®ºè®©å›½å®¶ä¸€å¹´å¤šéƒ½æ²¡èƒ½æ­£å¸¸è¿è½¬ã€‚\n\n#### squelchâ˜¢\nsquelch å½¢å®¹çš„æ˜¯èµ°åœ¨ä¸‹é›¨å¤©çš„æ³¥åœ°é‡Œé¢, è„šä¸‹å‘å‡º biajibiaji ä¸€æ ·çš„å£°éŸ³çš„æƒ…å½¢, to make a sucking sound like the one produced when you are walking on soft, wet groundï¼ˆå¦‚èµ°åœ¨æ¹¿è½¯åœŸåœ°ä¸Šä¼¼çš„ï¼‰å‘å§å”§å£°ï¼Œå‘æ‰‘å“§å£°\n- He got out of the car and **squelched** through the mud to open the gate.\n- As the hikers walked down the path by the house, she could hear the **squelch** of their boots in the mud.\n- He **squelched** across the turf.\n- His sodden trousers were clinging to his shins and his shoes **squelched**.\nä¹Ÿè®¸æ˜¯å› ä¸ºè¿™ä¸ªå£°éŸ³å’ŒæŒ¤å‹è½¯çš„ä¸œè¥¿çš„æ—¶å€™çš„å£°éŸ³å¾ˆç›¸ä¼¼, æ‰€ä»¥ squelch åˆæœ‰ put a stop to çš„æ„æ€\nYou can squelch an idea or a rebellion. This word has several meanings, but it's usually a verb for crushing things. A mean remark could squelch your self-confidence, and a powerful military could squelch an invading country.\n\n\n#### disenchantâ˜¢\ndis + enchant =\u003e ä¸å†æŠ±æœ‰å¹»æƒ³çš„ =\u003e  å¹»æƒ³ç ´ç­äº†çš„, å¤±æœ›çš„, æ„Ÿåˆ°å¹»ç­çš„.\n\n- she is disenchanted with the marriage\n\n#### inception\næˆ‘è®°ä½äº†ç›—æ¢¦ç©ºé—´, å´è¿˜ä¸çŸ¥é“ç›—æ¢¦ç©ºé—´ç”µå½±è‹±æ–‡å•è¯çš„æ„æ€: Inception =\u003e å¼€ç«¯, æˆç«‹, å»ºç«‹, åˆ›ç«‹\nThe inception is the beginning. Since its inception, Wikipedia has been created by its users.\n![](notes/2022/2022.7/assets/MV5BMjAxMzY3NjcxNF5BMl5BanBnXkFtZTcwNTI5OTM0Mw@@._V1_FMjpg_UX1000_.jpg)\nInception sounds like conception, but their meanings are distinct. Conception usually refers to the moment of becoming pregnant. Inception refers more to the beginning, to entering upon an undertaking. Inception implies the start of a specific thing like a campaign or a company. Subsequent events take place after the inception. At the moment of conception, most women are at the inception of motherhood.\n\n\n#### wanting\nè¿™æ˜¯ä¸€ä¸ªå½¢å®¹è¯, å’Œ want çš„æ„æ€æœ‰ç‚¹åƒ, ä½†æ˜¯ç”¨æ³•æœ‰ç‚¹æœ‰è¶£:\n- He analyzed his game and found it **wanting**\n- Eleanor was scrutinized, too, and often found **wanting**.\nç±»ä¼¼äº inadequate, disappointing, è¿™é‡Œçš„ wanting çš„æ„æ€æ˜¯\"ä¸è¾¾æ ‡çš„\"\nè¦æ˜¯æƒ³è¦æŒ‡ä»£ wanting çš„ä¸œè¥¿, å¯ä»¥ç”¨ be wanting in ...\n- He is **wanting** in moral constraints.\n- She is a little **wanting** in charms.\n\n#### colossal\nåœ¨çˆ±ç´æµ·å’Œåœ°ä¸­æµ·ä¹‹é—´æœ‰ä¸€ä¸ªå²›åå«ç½—å¾—å²›ï¼ˆRhodesï¼‰ã€‚æ®å²æ–™è®°è½½ï¼Œå…¬å…ƒå‰4ä¸–çºªæ—¶ï¼Œç½—å¾—å²›æ›¾æ˜¯åœ°ä¸­æµ·ä¸œéƒ¨ä¸€ä¸ªäº¤é€šæ¢çº½ï¼Œé‚£é‡Œä¸ä»…å•†ä¸šç¹è£ï¼Œè€Œä¸”é›•åˆ»è‰ºæœ¯ä¸šä¹Ÿå¾ˆå…´æ—ºå‘è¾¾ã€‚å…¬å…ƒå‰292å¹´ï¼Œç½—å¾—å²›äººå‡»è´¥äº†é©¬å…¶é¡¿äººçš„å…¥ä¾µï¼Œä¸ºäº†åº†ç¥èƒœåˆ©ï¼Œä»–ä»¬æŠŠåœ¨æˆ˜äº‰ä¸­ç¼´è·çš„å…µå™¨éƒ½ç†”åŒ–äº†ï¼Œè¯·å¸Œè…Šé›•åˆ»å®¶å¡ç‘æ–¯ï¼ˆCharesï¼‰åˆ¶ä½œä¸€ä¸ªé’é“œå¤ªé˜³ç¥å·¨åƒã€‚è¿™åº§å·¨å‹å¡‘åƒå†æ—¶12å¹´ï¼ˆ292-280 BCï¼‰æ‰å‘Šå®Œå·¥ã€‚æ®å¤ç½—é©¬å²å­¦å®¶æ™®æ—å°¼ï¼ˆPliny, 23-79ï¼‰æ‰€è¿°ï¼Œå¡‘åƒèº«é«˜çº¦100è‹±å°ºï¼ˆä¸€è¯´120è‹±å°ºï¼‰ï¼ŒçŸ—ç«‹åœ¨æµ·æ¸¯å…¥å£å¤„ã€‚åäººå°†è¿™ä¸€å£®è§‚å»ºç­‘è¿åŒåŸƒåŠé‡‘å­—å¡”ã€å·´æ¯”ä¼¦ç©ºä¸­èŠ±å›­ã€æ‘©ç´¢æ‹‰æ–¯é™µå¢“ç­‰èª‰ä¸ºä¸–ç•Œä¸ƒå¤§å¥‡è§‚ï¼Œä½†åœ¨å…¬å…ƒå‰224å¹´è¿™åº§å¤ªé˜³ç¥åƒåœ¨ä¸€åœºåœ°éœ‡ä¸­å€’å¡Œäº†ã€‚å¤äººæŒ‰å²›åRhodesç§°æ­¤å¡‘åƒä¸ºColossus of Rhodesï¼Œæˆ–ç®€ç§°ä¹‹ä¸ºColossusã€‚Colossusæ˜¯æ‹‰ä¸è¯­ï¼Œæºäºå¸Œè…Šè¯­kolossÃ³sï¼Œæœ‰â€œå·¨å‹å¡‘åƒâ€ä¹‹æ„ã€‚ä»¥åColossusåœ¨è‹±è¯­ä¸­æˆäº†â€œå·¨å‹å¡‘åƒâ€çš„ä»£ç§°ï¼Œè¿˜å¯å–»æŒ‡â€œæé‡è¦çš„äººæˆ–ç‰©â€ï¼Œæ‹¼å†™ä¹Ÿç”±å¤§å†™å˜ä¸ºå°å†™ã€‚colossalä¸€è¯ä¾¿æ˜¯18ä¸–çºªæ—¶ä»colossusæ´¾ç”Ÿå‡ºæ¥çš„å½¢å®¹è¯ï¼Œæ„ä¸ºâ€œå·¨åƒçš„â€ï¼Œéšåå¤šä½œâ€œå·¨å¤§çš„â€ã€â€œåºå¤§çš„â€è§£ï¼Œåªå–colossusâ€œå¤§â€çš„æ¶µä¹‰ã€‚\n![](notes/2022/2022.7/assets/colossus-of-rhodes-5.jpg)\nä¾‹ \n- There was a colossal statue of the king in the middle of the square. (LLA) åœ¨å¹¿åœºä¸­å¤®æœ‰ä¸€åº§å›½ç‹çš„å·¨åƒã€‚\n- The Colossus of Rhodes was a very large bronze statue of Apollo at the entrance to Rhodes port in ancient times. (CID) ç½—å¾—å²›å·¨åƒæ˜¯å¤æ—¶çŸ—ç«‹åœ¨ç½—å¾—å²›æµ·æ¸¯å…¥å£å¤„çš„ä¸€åº§é˜¿æ³¢ç½—é’é“œå·¨å‹å¡‘åƒã€‚\n- It was a colossal waste of time. (CAE) è¿™åœ¨æ—¶é—´ä¸Šæ˜¯æå¤§çš„æµªè´¹ã€‚\n- Rembrandt was an artistic colossus. (LDC) ä¼¦å‹ƒæœ—æ˜¯ä½è‰ºæœ¯å¤§å¸ˆã€‚\n\n#### aboveboard\nå…‰æ˜æ­£å¤§çš„\n\"in open sight, without trickery or disguise,\" 1610s, from above and board. \"A figurative expression borrowed from gamesters, who, when they put their hands under the table, are changing their cards.\"\n\n#### grandstandâ˜¢\n![](notes/2022/2022.7/assets/Hoosier_Lottery_Grandstand_rec.jpg)\n\n#### equivocateâ˜¢\nequi- =\u003e equal\nvoc- =\u003e å£°éŸ³, å«å–Š\n-ate\n=\u003e è¯´æ¨¡æ£±ä¸¤å¯çš„è¯, å«ç³Šå…¶è¾ \n- She accused the minister of **equivocating**, claiming that he had deliberately avoided telling the public how bad the problem really was.\n- He is **equivocating** a lot about what is going to happen if and when there are elections. \n- He had asked her once again about her finances. And again she had **equivocated**. \n\nWhen you are unwilling to make a decision and almost intentionally go back and forth between two choices, you are equivocating. When politicians equivocate, they are often afraid of upsetting, and thus alienating, voters with their decisions.\nA key part of equivocate is the root vocate, which comes from the Latin vocare or \"voice.\" When you give your voice to two opposing views in order to mislead or keep your options open, you're equivocating. Think of the expression, to talk out of both sides of your mouth. If you want to go to a party and your parents keep saying \"maybe, it depends,\" tell them to stop equivocating and give you a straight answer.\n\n#### disarray\narray æƒ³å¿…æ˜¯ä¸€ä¸ªå¾ˆæ•´é½çš„æƒ…å†µ, é‚£ä¹ˆ disarray å°±æ˜¯ array çš„åä¹‰è¯ =\u003e æ··ä¹±, å‡Œä¹±, æ‚ä¹±\n- Her clothes were in disarray.\n- Ever since the oil crisis, the industry has been in (the state of) disarray.\n\n#### anterior\nå‰ç«¯çš„, å‰é¢çš„, å…ˆå‰çš„\nante- =\u003e before æ¯”å¦‚ä¹‹å‰èƒŒè¿‡çš„antediluvian\n**åé¢çš„**ï¼šposterior\n**é‡Œé¢çš„**ï¼šinterior\n**å¤–é¢çš„**ï¼šexterior\n\næ›´é«˜ç­‰çš„ï¼šsuperior\næ›´ä½ç­‰çš„ï¼šinferior\n\n\n#### pandemonium \npanãƒ»demonãƒ»ium\nåœ¨è‹±å›½è¯—äººå¼¥å°”é¡¿ï¼ˆJohn Milton, 1608-1674ï¼‰æœ€äº«ç››åçš„å²è¯—ã€Šå¤±ä¹å›­ã€‹ï¼ˆParadise Lostï¼‰ä¸­ï¼ŒPandemonium æ˜¯ capital of Hellï¼ˆåœ°ç‹±ä¹‹éƒ½ï¼‰ï¼Œå³æ’’æ—¦çš„å®«æ®¿ï¼Œé­”é¬¼èšé›†çš„åœ°æ–¹ã€‚æ˜¾ç„¶ï¼Œè¿™æ˜¯è¯—äººä»¿ pantheonï¼ˆä¸‡ç¥æ®¿ï¼‰åˆ›é€ çš„ä¸€ä¸ªæ‹‰ä¸è¯ï¼Œç”± panï¼ˆä¸€åˆ‡ï¼‰å’Œ demoniumï¼ˆé­”é¬¼ï¼‰ç»„åˆè€Œæˆï¼Œå…¶ä¸­-ium ä¹ƒæ‹‰ä¸è¯­åç¼€ï¼Œåœ¨è‹±è¯­çš„æ‹‰ä¸è¯­å€Ÿè¯ä¸­å¸¸å«æœ‰åœ°ç‚¹ä¹‹ä¹‰ï¼Œè¯¸å¦‚ auditoriumï¼ˆç¤¼å ‚ï¼›å¬ä¼—å¸­ï¼‰ï¼Œsanatoriumï¼ˆç–—å…»é™¢ï¼‰ï¼Œgymnasiumï¼ˆä½“è‚²é¦†ï¼‰ç­‰ã€‚ä½†è‹¥è¿›è€Œè¿½æœ¬æº¯æºï¼Œæˆ‘ä»¬ä¼šå‘ç° pandemonium çš„ç»ˆæè¯æºä¹ƒæ˜¯å¸Œè…Šè¯­ pÃ¢n 'all'å’Œ daÃ­mÅn 'demon'çš„ç»„åˆï¼Œå­—é¢ä¹‰ä¹Ÿæ˜¯ all demonsï¼ˆä¸€åˆ‡é­”é¬¼ï¼‰ã€‚18 ä¸–çºªä»¥åï¼Œå‡¡æ˜¯åäººé›†ä¸­çš„åœ°æ–¹ï¼Œå……æ»¡é‚ªæ¶æˆ–æ··ä¹±å˜ˆæ‚çš„åœ°æ–¹ï¼Œéƒ½å¯ä»¥ç”¨ pandemonium æ¥è¡¨ç¤ºã€‚åˆ°äº† 19 ä¸–çºªä¸­æœŸä¹‹åï¼Œè¯¥è¯åˆè¿›è€Œå¼•ç”³ä¸ºâ€œå¤§æ··ä¹±â€æˆ–â€œå˜ˆæ‚éªšä¹±â€ï¼Œä¸å†æŒ‡åœ°ç‚¹ï¼Œè·Ÿé­”é¬¼åŠåœ°ç‹±ä¹Ÿå·²æ²¡æœ‰ä»€ä¹ˆè”ç³»äº†ã€‚\n\nä¾‹ \n- Pandemonium broke out when the results were announced. \n- Pandemonium reigned in the classroom until the teacher arrived. æ•™å¸ˆåˆ°æ¥ä¹‹å‰æ•™å®¤é‡Œä¹±å“„å“„çš„ã€‚\n- When the verdict was read, pandemonium erupted in the courtroom. è£å†³å®£è¯»ä¹‹åï¼Œæ³•åº­ä¸€ç‰‡æ··ä¹±ã€‚\n- There was sheer pandemonium in the dance hall when someone shouted 'Fire!'.\n\n#### debark\ndebark å’Œ embark æ˜¯ä¸€å¯¹åä¹‰è¯ï¼Œæ˜¾ç„¶è¿™é‡Œçš„ bark æ˜¯äº¤é€šå·¥å…·çš„æ„æ€ï¼Œ æ¥è‡ªæ³•è¯­ barqueï¼Œ â€œsmall shipâ€\ndebark å°±æ˜¯ä»èˆ¹ä¸Šä¸‹æ¥ï¼Œåæ¥æ³›æŒ‡ä»å…¶ä»–äº¤é€šå·¥å…·ä¸Šé¢ä¸‹æ¥ \nembark å°±æ˜¯ç™»ä¸Šèˆ¹ï¼Œåæ¥ä¹Ÿæ³›æŒ‡å…¶ä»–äº¤é€šå·¥å…·ï¼Œä¹Ÿå¯æŒ‡ä»£å¼€å§‹ä¸€æ®µæ—…é€”\n- ç”±äºbarkè¿˜æœ‰æ ‘çš®çš„æ„æ€ï¼Œ æ‰€ä»¥debarkè¿˜æœ‰â€œå»é™¤æ ‘çš®â€çš„æ„æ€\n\n#### convoke\ncon + voke =\u003e to call together, æŠŠå¤§å®¶å¬é›†åˆ°ä¸€èµ·, =\u003e å¬é›†....(å¼€ä¼š), å¬å¼€ä¼šè®®\n\nHe has convoked a summit conference in Brussels.\n\n\n#### hodgepodge\nå¤§æ‚çƒ©\n\nA hodgepodge is **a random assortment of things**. A dorm room might be furnished with a hodgepodge of milk crates, antique mirrors, and a poster of a kitten hanging on a branch with one paw.\n\nHodgepodge is a funny-sounding word for a somewhat funny occurrence â€” a grouping of things or people that don't fit together. If you made a stew with bacon, oatmeal, and chocolate cake, youâ€™ve made a hodgepodge (and a bellyache waiting to happen). The piles of stuff stacked in attics tend to be a hodgepodge. British people call it a hotchpotch. A hodgepodge can also be called a mishmash.\n\nNew Age thinking seems to be a hodgepodge of old and new ideas.\n\n\n#### hike\né™¤äº†\"è¿œè¶³\", hike è¿˜å¯ä»¥ç”¨æ¥å½¢å®¹è´¹ç”¨æˆ–è€…ä»·æ ¼çš„çŒ›å¢\n- The recent **hike** in train fares came as a shock to commuters.\n- Retailers have **hiked (up)** prices again.\n- ...a sudden 1.75 per cent **hike** in interest rates.\n- His economic plan, with its tax **hikes** and spending cuts, will slow the economy.\n- It has now been forced to **hike** its rates by 5.25 per cent. \n- The federal government **hiked** the tax on hard liquor. \n\n\n#### cherubic\né•¿ç›¸åƒ cherub ä¸€æ ·çš„, cherub æ˜¯ä»€ä¹ˆå‘¢?\n![](notes/2022/2022.7/assets/index%204.jpg)\ncherub æ˜¯å°å¤©ä½¿, æ‰€ä»¥ cherubic å°±æ˜¯å¨ƒå¨ƒè„¸çš„, é•¿è€…å¯çˆ±èƒ–ä¹ä¹çš„åœ†è„¸è›‹çš„.\n\n#### commencement\nA commencement is the act of starting out, or blazing a new trail.\n- Would passengers please turn off their mobile phones before the **commencement** of the flight.\n- All should be at least 16 years of age at the **commencement** of this course. \n\nThe suffix -ment makes the word commencement a noun â€” a thing, an activity, a start. The word can be used for the beginning of anything, from a business meeting to a vacation trip to a marriage. Anything that begins has a moment of commencement. That's why a graduation ceremony is called a commencement â€” **a graduate is embarking on a new life, and the commencement ritual marks the official beginning of that life**.\n\n#### adjournâ˜¢\nad- =\u003e to\n-journ =\u003e day\n=\u003e to another day. The notion is of setting a date for re-meeting.\nä¼‘ä¼š, ä¼‘åº­\n- The meeting was adjourned until Tuesday.\n\n#### dandy\nåœ¨å½¢å®¹è¡£ç€å¤–è¡¨çš„æ—¶å€™, dandyæ˜¯ä¸€ä¸ªåè¯.\nA man who is very concerned with how he looks can be called a dandy. The term is rather old-fashioned â€” it was commonly used to refer to such men in the 1800s, like the famous dandy Beau Brummell.\n\ndandyè¿˜å¯ä»¥åšä¸€ä¸ªå½¢å®¹è¯, è¿™æ—¶å€™å°±ä¸å•å•ç”¨æ¥å½¢å®¹å¤–è¡¨äº†:\nAs an adjective, dandy means **excellent**. If you think your new car is dandy, you're excited to own such a great car. In modern use, dandy is often used sarcastically, with just a small change in wording or emphasis: \"My new car is just dandy. It's broken down twice today already!\" The word dandy is also frequently used in the phrase \"fine and dandy\".\n\n\n#### dearth\ndear + åè¯åç¼€-th =\u003e dear è¿™è¿™é‡Œæ˜¯\"è´µ\"çš„æ„æ€, ç‰©ä»¥ç¨€ä¸ºè´µ, å½“ä¸€ä¸ªä¸œè¥¿å¾ˆè´µçš„æ—¶å€™è¯´æ˜å®ƒååˆ†ç¨€å°‘, æ‰€ä»¥è¿™ä¸ªå•è¯çš„æ„æ€æ˜¯ \"ä¸è¶³, ç¼ºä¹, ç¼ºå°‘, a lack of sth\"\n- a dearth of new homes in the reigion.\n\n#### debutâ˜¢\næ¥è‡ªæ³•è¯­, æ‰€ä»¥è¯»éŸ³æ¯”è¾ƒå¥‡æ€ª /ËˆdeÉª.bju/\n\nA debut is a **first appearance**, a launch, or public introduction. So before you make your big debut at the office, check and make sure you don't have spinach in your teeth.\n\nPerhaps youâ€™ve heard of debutantes making their official debut into society, or actresses and actors making their debut on stage. A fun fact: **debut** and **premiere** are often thought to be interchangeable, but theyâ€™re not. A debut, as you now know, is a first public appearance. But a premiere, while also a â€œfirst,â€ isn't necessarily live. When a movie opens or an interview is broadcast for the first time, they're called premieres.\n\n##### debutante\nA debutante is usually a wealthy girl whose parents wish to introduce her to society in a BIG way â€” in \"a debutante ball\" that looks like something out of a scene from Gone with the Wind. ç¿»è¯‘: æ‰å¼€å§‹ç¤¾äº¤çš„å¯Œå®¶åƒé‡‘? \n\nIn the United States, debutante balls usually, but not always, take place in the South and are a way to introduce wealthy young women to especially eligible young bachelors. The word debutante is derived from the French word debut, meaning â€œa first performance or showing.â€ The original French word debutante referred to a new actress making her first appearance on the stage. So, think of a debutante as a young woman making her debut in society.\n\n#### epitomizeâ˜¢\nepitomize æ¥è‡ª epitome, epitome æ˜¯\"**å…¸èŒƒ, the best possible example**\"çš„æ„æ€, epitomize å°±æ˜¯\"**to be the perfect example of a quality or type of thing**\"\n\n- With little equipment and unsuitable footwear, she epitomizes the inexperienced and unprepared mountain walker.\n\n\n#### fetter\nfetter æ˜¯è„šé•£çš„æ„æ€, ç°åœ¨å¤šç”¨äºæ¯”å–»ä¹‰, å½¢å®¹å›°æ‰°æŸäººçš„æ·é”, ä¹Ÿå¯ä»¥ä½œä¸ºä¸€ä¸ªåŠ¨è¯, è¡¨ç¤º\"æŸç¼š, \"\n- ...the fetters of social convention. \n- ...a private trust which would not be fettered by bureaucracy.\n- The black mud fettered her movements. \n\n- fetter å’Œ feet é•¿å¾—æŒºåƒçš„.\n\n#### hackneyed\n14 ä¸–çºªä¼¦æ•¦ä¸œåŒ—éƒŠæœ‰ä¸€ä¸ªåå« Hackney çš„å°æ‘åº„ï¼ˆä»Šä¸ºä¸€è‡ªæ²»åŒºï¼‰å› ç››äº§å¥½é©¬è€Œéè¿©é—»åã€‚è¯¥åœ°æ‰€è‚²ä¹‹é©¬è†˜è‚¥ä½“å£®ï¼ŒæŠ¬è…¿é«˜ï¼Œå–„äºå¥”è·‘ï¼Œé€‚ç”¨äºé©¾è½¦æˆ–æ—¥å¸¸éª‘ç”¨ã€‚ä¹…è€Œä¹…ä¹‹ï¼Œè¿™ç§é©¬å°±è¢«å–åä¸º hackneyï¼Œå‡ºç§Ÿçš„é©¬ä¹Ÿå« hackneyï¼Œå‡ºç§Ÿé©¬è½¦åˆ™ç§° hackney carriage/coach æˆ–ç®€ç§° hackneyã€‚åˆ°äº† 1637 å¹´æŸ¥ç†ä¸€ä¸–ç»Ÿæ²»æ—¶æœŸï¼Œå‡ºç§Ÿé©¬è½¦åœ¨ä¼¦æ•¦è¡—å¤´å‡ ä¹éšå¤„å¯è§ï¼Œå¯è¯´æ˜¯æ³›æ»¥æˆç¾ã€‚äºæ˜¯ hackney ä¸€è¯åˆä»â€œç­‹ç–²åŠ›å°½çš„å‡ºç§Ÿé©¬åŒ¹â€ï¼ˆworn-out horseï¼‰è½¬æŒ‡â€œå¹³åº¸æ— å¥‡çš„äº‹ç‰©â€ã€‚\nåˆ°äº† 18 ä¸–çºªï¼Œä» hackney æ´¾ç”Ÿå‡ºäº†å½¢å®¹è¯ hackneyedï¼Œè¡¨ç¤ºâ€œé™ˆè…çš„â€ã€â€œå¹³åº¸çš„â€ã€â€œè€ç”Ÿå¸¸è°ˆçš„â€ç­‰ä¹‰ã€‚ä¸æ­¤åŒæ—¶ï¼Œhackney å¸¸è¢«ç¼©ç•¥ä¸º hackï¼Œä»æŒ‡â€œå‡ºç§Ÿçš„é©¬â€ã€â€œå‡ºç§Ÿé©¬è½¦â€æˆ–å¼•ç”³ä¸ºâ€œé›‡ä½£æ–‡äººâ€ï¼Œå¦‚ä»Šåœ¨ç¾å›½è‹±è¯­è¿˜ç”¨ä»¥æŒ‡â€œå‡ºç§Ÿè½¦â€ã€‚\n\nä¾‹ \n- Politicians all use the same **hackneyed** expressions. (LLA) æ”¿å®¢ä»¬è¯´çš„éƒ½æ˜¯é‚£å¥—é™ˆè¯æ»¥è°ƒã€‚\n- All those slogans we used to chant sound so **hackneyed** now. æˆ‘ä»¬è¿‡å»å–Šçš„é‚£äº›å£å·å¦‚ä»Šå¬èµ·æ¥é™ˆè…å¾—å¾ˆã€‚\n- One needs a special license to drive a **hack**. (FWF) å¼€å‡ºç§Ÿæ±½è½¦éœ€æŒæœ‰ç‰¹æ®Šæ‰§ç…§ã€‚\n- We rode around the park in a **hack**. æˆ‘ä»¬åç€å‡ºç§Ÿé©¬è½¦æ¸¸è§ˆäº†å…¬å›­ã€‚\n\n#### hamstring\nYour hamstrings are **groups of muscles and tendons between your hips and knees**. If you pull a hamstring while running or jumping, you'll feel pain at the back of your thigh. Ouch!\n\n![](notes/2022/2022.7/assets/iStock-900945864_480x480.webp)\n\nThe hamstring muscle group is **one of the most powerful in your body** â€” attached to the knee and hip, these are the muscles and tendons that make it possible for you to run, walk, and jump. It's fairly common for athletes to injure their hamstrings and be (temporarily) immobilized. Fittingly, hamstring is also **a verb** meaning \"**render powerless**.\" So an astronaut might complain that a lack of funding will hamstring NASA, making planned Mars voyages impossible.\n\n\n- The company **was hamstrung by** traditional but inefficient ways of conducting business. è¿™å®¶å…¬å¸è¢«å…¶ä¼ ç»Ÿä½†ä½æ•ˆçš„ç»è¥æ–¹å¼æ‰€æŸç¼šã€‚ \n- If he becomes the major opposition leader, he could **hamstring** a conservative-led coalition.\n\n\n#### hoodwink\nhood å°±æ˜¯ä¸€ä¸ªå¤´å¥—, æˆ–è€…è¿å¸½è¡«çš„å¸½å­\nwink å°±æ˜¯çœ¨çœ¼, å’Œçœ¼ç›ç›¸å…³\nhoodwink å°±æ˜¯å¥—ä¸Šå¤´ç½©, è¢«é®è”½äº†åŒçœ¼, =\u003e æ¬ºéª—\n\n##### blindfold\nä¸€ä¸ªç±»ä¼¼çš„å•è¯æ˜¯ blindfold, å°±æ˜¯ç»™...å¸¦ä¸Šçœ¼ç½©, ä½†æ˜¯è¿™ä¸ªå•è¯æ²¡æœ‰æ¬ºéª—çš„æ„æ€.\n\n#### inimitableâ˜¢\nin + imitable\n=\u003e æ— æ³•æ¨¡ä»¿çš„, =\u003e very unusual or of very high quality and therefore impossible to copy. å¯ä»¥ç¿»è¯‘ä¸º\"æ— ä¸ä¼¦æ¯”çš„\"\n\n- He was describing, in his own **inimitable** style, how to write a best-selling novel.\n\n- unique, unparalleled, unrivalled, incomparable\n\n#### inexorableâ˜¢\n ä¸å¯é˜»æ‹¦çš„\n- the inexorable progress of science ä¸å¯é˜»æŒ¡çš„ç§‘å­¦è¿›æ­¥\nin- not\nexorable =\u003e able to be entreated, able to be moved by entreaty, è¿™é‡Œçš„entreatæŒ‡çš„æ˜¯\n\n#### persecuteâ˜¢\nè¿™ä¸ªå•è¯å’Œ prosecute å¾ˆåƒ, ä½†æ˜¯ä¸¤è€…çš„å«ä¹‰æœ‰æ‰€ä¸åŒ.\n\u003e One you do in court, the other you do if you're a jerk\n\nprosecute æ˜¯åœ¨æ³•åº­ä¸Š\"èµ·è¯‰\", ä¸ç®¡è¢« prosecute çš„äººæœ‰æ²¡æœ‰ç½ª, ä¸€åˆ‡éƒ½æ˜¯å…¬å¼€é€æ˜, å…¬æ­£çš„. \nä½†æ˜¯ persecute æ˜¯è¿«å®³, éªšæ‰°, çº ç¼ , æ˜¯ä¸æ­£å½“çš„, æ˜¯å•å•å› ä¸ºç§æ—, å®—æ•™æˆ–è€…æ”¿æ²»ä¿¡ä»°è€Œè¿›è¡Œçš„ä¸æ­£å½“è¡Œä¸º.\n\n**Prosecute** is most often used to refer to bringing legal action against someone else, and is related to the Latin word for \"pursue.\" It is often confused with **persecute** which means \"to harass, torment, or punish, especially for one's beliefs.\" If you find yourself frequently one the wrong side of prosecution, you might end up feeling persecuted. \n\n#### reciprocate\nreci- =\u003e å‘å, å¾€å›\nproc- =\u003e å‘å‰, å»\n-ate \n=\u003e to move forwards and backwards, å¾€è¿”è¿åŠ¨(è¿™ä¸ªæ„æ€ç°åœ¨è¿˜åœ¨ä½¿ç”¨, ç”¨åœ¨æœºå™¨çš„é›¶éƒ¨ä»¶ä¸Š), =\u003e è¿™å’Œäººé™…å…³ç³»å¾ˆåƒ: æˆ‘å¸®ä½ ä¸ªå¿™, ä½ å¸®æˆ‘ä¸ªå¿™, æˆ‘è¯·ä½ åƒé¡¿é¥­, ä½ å†è¯·æˆ‘åƒé¡¿é¥­, éƒ½æ˜¯è¿™ç§å¾€è¿”è¿›è¡Œçš„åŠ¨ä½œ =\u003e æ‰€ä»¥å¼•ç”³ä¸º\"å›æŠ¥, é…¬ç­”, å›ç¤¼, to behave in the same way as someone else\"\n- Their attraction to each other as friends is reciprocated.\n- He reciprocated the party leader's good wishes.\n- Some electric razors have reciprocating heads.\n\n\n#### strutâ˜¢\nto walk in a proud way trying to look important.\n- He struts around town like he owns the place.\n\nä¹Ÿå¯ä»¥æŒ‡æˆ¿å±‹/è½¦è¾†çš„\"æ”¯æŸ±, æ’‘æ†, a strong rod\"\n\n##### strut your stuff\nç±»ä¼¼äº\"éœ²ä¸€æ‰‹\", å°±æ˜¯è‡ªä¿¡çš„å±•ç¤ºè‡ªå·±æœ€æ“…é•¿çš„/æœ€æ‹¿æ‰‹, è‡ªè±ªçš„ä¸œè¥¿æˆ–è€…æŠ€èƒ½.\n\nHe was the type of guy who liked to show off and strut his stuff.\n\n\n#### unexceptionableâ˜¢\nun + exception + able\n- æ— æ‡ˆå¯å‡»çš„, åœ¨è¿™é‡Œexceptionå¯ä»¥ç†è§£ä¸ºç¼ºé™·, å¯ä»¥æŒ‡è´£çš„åœ°æ–¹\n\n- åä¹‰è¯: exceptionable\n\n[unimpeachable](#unimpeachable)\n[incontrovertible](#incontrovertible)\n[impeccable](#impeccable)\n\n#### exponentâ˜¢\né™¤äº†æ•°å­¦é‡Œé¢çš„æŒ‡æ•°, è¿™ä¸ªå•è¯è¿˜èƒ½ä»£è¡¨\"æ‹¥æŠ¤è€…\"\nAn exponent is a person who is a big promoter of something. Are you an exponent of the four-day school and work week?\n\nYou may already know the mathematical meaning of exponent: a numeric notation showing how many times a number is multiplied by itself. How did exponent come to mean a strong advocate or promoter of something? Well, its Latin ancestor was a verb meaning \"to put forth\" and it's easy to see how this could be generalized to refer to people. After all, aren't you an exponent of freedom of expression?\n\n#### blatant\nblatant ä¸€è¯ç”± 16 ä¸–çºªè‹±å›½è¯—äººåŸƒå¾·è’™â€¢æ–¯å®¾å¡ ï¼ˆEdmund Spenserï¼‰æœæ’°ã€‚æ–¯å®¾å¡åœ¨å…¶é•¿ç¯‡å²è¯—ã€Šä»™åã€‹ä¸­åˆ›é€ äº†è¿™ä¸ªè¯ï¼Œç”¨æ¥å½¢å®¹ä¸€å¤´é•¿æœ‰åƒæ¡èˆŒå¤´ã€ä»£è¡¨â€œè¯½è°¤â€çš„æ€ªå…½ã€‚å…¶è¯æºå¾ˆæœ‰å¯èƒ½æ˜¯æ‹‰ä¸è¯­ blatireï¼ˆå–‹å–‹ä¸ä¼‘ï¼‰ã€‚\n- very obvious and intentional, when this is a bad thing æ˜ç›®å¼ èƒ†çš„ï¼Œå…¬ç„¶çš„\n- **a blatant lie** å¼¥å¤©å¤§è°\n- The whole episode was **a blatant attempt** to gain publicity. æ•´ä¸ªäº‹ä»¶å®Œå…¨æ˜¯æ—¨åœ¨å®£ä¼ çš„éœ²éª¨ç‚’ä½œã€‚\n\n#### screen\nscreen é™¤äº†å±å¹•çš„æ„æ€è¿˜æœ‰ä»¥ä¸‹å«ä¹‰:\n- æ”¾æ˜ , ä½ å¯ä»¥ screen a film\n- å±é£, \n- ç”±å±é£è¿™ä¸ªå«ä¹‰å¼•ç”³ä¸º\"é®æŒ¡\" She raised her hands to screen her eyes from the bright light.\n- æƒ³è±¡åŒ»ç”Ÿé€šè¿‡ X å…‰ç‰‡æ¥æ£€æŸ¥ä½ æœ‰æ²¡æœ‰ç–¾ç—… =\u003e æ£€æŸ¥, æµ‹è¯•\n\tWomen over 50 should be screen for breast cancer.\n- é™¤äº†åŒ»å­¦æ£€æŸ¥, screen ä¹Ÿå¯ä»¥æŒ‡å…¶ä»–æ£€æŸ¥, ä½ ç”šè‡³å¯ä»¥ screen ä½ çš„æ¥ç”µå†³å®šè¦ä¸è¦æ¥ç”µè¯\n\tCompletely unsuitable candidates were screened out (=tested and refused) in the first interview.\n\n\n#### allay\nal- =\u003e =a-: down, aside\nlay =\u003e to lay\nlay æ˜¯æ”¾ç½®çš„æ„æ€, å½“ç„¶ä¹Ÿæ˜¯ lie çš„è¿‡å»å¼, å¯ä»¥è¿™æ ·è®°å¿†: ä¸€ä¸ªç—…äººæŒ£æ‰ç€è¦åèµ·æ¥, å¦ä¸€ä¸ªäººå®‰æŠšä»–é‡æ–°è®©ä»–èººä¸‹, æˆ–è€…æŠŠä¸€ä¸ªå¿«è¦æ‰ä¸‹å»çš„ä¸œè¥¿é‡æ–°å®‰æ”¾å¥½. =\u003e To allay someone's fears or doubts means to make them to feel it less or feel calm again.\n\n- The government is trying to allay public fears/concern about the spread of covid.\n\n\n#### argot\né¦–å…ˆæ³¨æ„è¿™ä¸ªå•è¯é‡Œé¢çš„ t ä¸å‘éŸ³\nargot ç±»ä¼¼äºæ±‰è¯­é‡Œé¢çš„\"é»‘è¯\", å°±æ˜¯åœˆå†…äººæ‰æ‡‚çš„è¯, ä¸€äº›ä¸æ­£å¼çš„, æ¯” slang æ›´å°ä¼—çš„, æ¯” jargon æ›´ä¸ä¸“ä¸šçš„ä¸šå†…åè¯.\n\nStackExchange ä¸Šé¢æœ‰ [å…³äºè¿™ä¸ªçš„è®¨è®º](https://linguistics.stackexchange.com/questions/2812/argot-vs-jargon)\n\n\u003e Based on just the definitions you quote, computer professionals do not speak argot, they speak jargon. **The jargon of computer professionals was *not* constructed for the purpose of hiding the meaning of what they are saying from outsiders - it may have that effect, but that was not the purpose**. The purpose is to have short hand words that have specific defined meanings that allow for more efficient communication. For example the word \"file\" can replace the phrase \"a block of information stored as a unit on an information storage device\". So jargon is a matter of efficiency.\n\u003e \n\u003e From your definitions \"argot\" has the purpose of **secrecy** that would prevent eavesdroppers from understanding the meaning of the conversation.\n\u003e \n\u003e **Slang** is ad-hoc but is inherently formed out of the intent to **broadly communicate**. ä¹Ÿå°±æ˜¯è¯´ slang è™½ç„¶æœ‰ argot é‡Œé¢\"ä¸æ­£å¼\"çš„å«ä¹‰åœ¨, ä½†æ˜¯ä¸å±€é™äºä¸€ä¸ªå°ç¾¤ä½“, åªè¦æ˜¯ native speaker éƒ½å¬å¾—æ‡‚.\n\u003e \n\u003e Jargon is driven from the attempt not so much to broadly communicate, as to **DEEPLY** communicate - **to provide more content in the same amount of verbal space**.\n\næ€»ç»“ä¸€ä¸‹: \n|  | æ­£ä¸æ­£å¼ | ä½¿ç”¨äººç¾¤ |   å®¹ä¸å®¹æ˜“æ‡‚   |\n| --------- | ---- | ---- | ---- |\n| **argot:**| informal(ad-hoc)|small group of people | hard to understand|\n| **slang**|informal(ad-hoc)|large group of people | easy to understand|\n| **jargon** |formal(æœ‰æ˜ç¡®çš„å®šä¹‰)| small group of people |hard to understand|\n| **Plain English** |formal(æœ‰æ˜ç¡®çš„å®šä¹‰)| large group of people |easy to understand|\nå…¶å®ä½¿ç”¨äººç¾¤å’Œå®¹ä¸å®¹æ˜“æ‡‚æ˜¯ç­‰ä»·çš„, æ‰€ä»¥å¦‚æœæˆ‘ä»¬åŠ ä¸Šæœ€åçš„ English, ä¹Ÿå°±æ˜¯ä¸€èˆ¬çš„è¯, å°±æ¶µç›–äº†æ‰€æœ‰çš„ 2x2=4 ç§ç»„åˆ, çœŸæ˜¯å¥‡å¦™.\n\n\n#### barbarous\nbarbarian æŒ‡çš„æ˜¯é‡è›®äºº, æœªå¼€åŒ–çš„äºº, ç²—äºº, æ‰€ä»¥ barbarious å°±æ˜¯åƒ barbarian ä¸€æ ·çš„äººæˆ–äº‹, =\u003e ç²—é‡çš„, é‡è›®çš„, æ®‹å¿çš„, æš´è™çš„\n\n#### bungleâ˜¢\nTwo prisoners **bungled** an escape bid after running either side of a lamp-post while handcuffed.\n\n- mess up, blow, ruin, spoil\n\n\n#### circumscribe\ncircum + scribe =\u003e to encompass, confine, restrain mark out bounds or limits for.\nè¿™ä¸ªå•è¯åœ¨æ•°å­¦é‡Œé¢æ˜¯\"åšå¤–æ¥åœ†\"çš„æ„æ€, ä»è¯çš„ç»„æˆä¸Šçœ‹æ˜¯å¾ˆå½¢è±¡çš„. ç°åœ¨ä¸€èˆ¬ä½¿ç”¨çš„è¯ä¹‰æ˜¯å¼•ç”³ä¹‰ =\u003e ä¹Ÿå°±æ˜¯é™åˆ¶, çº¦æŸ, æŠ‘åˆ¶, å¯ä»¥ç†è§£ä¸ºåˆ’å®šäº†æ´»åŠ¨èŒƒå›´, æ´»åŠ¨å—é™åˆ¶çš„æ„æ€.\n\nThere are laws circumscribing the right of individual citizens to cause bodily harm to others.\n\n#### congenial \u0026 genialâ˜¢\nä¸¤è€…è¯éƒ½è¡¨ç¤º kind, friendly and pleasant, ä½†æ˜¯å®ƒä»¬æŒ‡ä»£çš„å¯¹è±¡æœ‰æ‰€ä¸åŒã€‚\n- genial é€šå¸¸æŒ‡ä»£äººçš„æ€§æ ¼, æ¯”å¦‚\"He is a genial host.\" \n- congenial é€šå¸¸æŒ‡ä¸€ä¸ªäººçš„æ€§æ ¼ç»™å…¶ä»–äººå¸¦æ¥çš„æ„Ÿè§‰, æˆ–è€…æŒ‡ä¸€ä¸ªæ°”æ°›å¾ˆå’Œè°å‹å¥½.\n- genial applies to individuals, while congenial is generally reserved for persons collectively or for environments.\n- ä»è¯æ ¹ä¸Šæˆ‘ä»¬å¯ä»¥è¿™æ ·ç†è§£: con- -\u003e with, together, ä¸€ç¾¤äººåœ¨ä¸€èµ·çš„æ—¶å€™, éœ€è¦å¤§å®¶éƒ½å¾ˆ genial æ‰èƒ½å½¢æˆä¸€ä¸ª congenial çš„æ°›å›´.\n\nè¿™ä¸ªå›ç­”æŠŠä¸¤è€…çš„åŒºåˆ«è¯´æ˜çš„å¾ˆå…¨é¢:ã€€[meaning - Is there any difference between \"congenial\" and \"genial\"? - English Language \u0026 Usage Stack Exchange](https://english.stackexchange.com/a/589162/452046)\n\n#### defraud \u0026 fraudâ˜¢\n**Fraud** is a noun for the practice of lying to someone in order to gain something, either money or some other beneficial intangible. It is also the word for a person who commits fraud. Another term for this kind of person is a **fraudster**. This term is mainly used in British English, but can be found in some US publications as well.\n\n**Defraud** is a verb that describes a practice of lying to someone or an institution to steal money specifically. This includes acts like identity theft and electronic hacking.\n\nA person who defrauds someone else is a **defrauder**.\n\n#### deplorable\nde- =\u003e entirely\nplor =\u003e weep, cry out \nable\n=\u003e å¯æ‚²çš„, (ç³Ÿç³•åˆ°æç‚¹ä»¥è‡³äºæ„Ÿåˆ°æ‚²ä¼¤), very bad, æå…¶æ¶åŠ£çš„\n\n- They are forced to live in deplorable conditions.\n\n\n#### embed\nä¹‹å‰è¿™ä¸ªè¯éƒ½æ˜¯åœ¨ç¼–ç¨‹æ—¶å€™æ‰é‡åˆ°çš„. å½“ç„¶å®ƒè¿˜æœ‰å…¶ä»–å«ä¹‰:\nThe verb embed means to **implant something or someone** â€” like to embed a stone into a garden pathway or to embed a journalist in a military unit.\nWhen you stick something firmly within a particular environment, you are embedding it. If you are an archeologist, you might spend a lot of your time looking for pottery shards embedded in the earth. If you are a web site designer, you might embed video clips on web pages. And if your newspaper is covering a war overseas, you might consider embedding a journalist in a military troop in order to have a source reporting back from the front lines.\n\n#### be of French/German/Chinese/etc. extraction\nç¥–ç±æ˜¯....\n\n\n#### voracious \u0026 ferocious  â˜¢\nä¸‹é¢æ˜¯ä¸€ä¸ªè‹±è¯­æ¯è¯­è€…çš„ç†è§£:\nè¿™ä¸¤ä¸ªå•è¯æ›´ä¾§é‡äº\"è´ªå©ª\"\n- **Voracious** - closest synonym is insatiable. This word is almost always used as an adjective in conjunction with the word appetite.\n- **Rapacious** - closest synonym is greedy; a word not used in common parlance. I would expect to see this word used only in literature and journalism.\nä¸‹é¢è¿™ä¸¤ä¸ªå•è¯åˆ™æ›´ä¾§é‡äº\"å‡¶çŒ›, æ®‹æš´\"\n- **Ferocious** - closest synonym is fierce. It is often (though not always) used as an adjective to describe nature (i.e. a ferocious animal or a ferocious storm).\n- **Vicious** - closest synonym is cruel. Usually refers to the actions of a person.\n\n#### imbroglioâ˜¢\nim- =\u003e in\n-broglio =\u003e to confuse, æ¥è‡ªboil\nthe state of being in a confusing situation =\u003e æ··ä¹±å±€é¢, é”™ç»¼å¤æ‚çš„å±€é¢ \n- æƒ³è±¡æ°´æ²¸è…¾æ—¶å€™çš„æ··ä¹±åœºæ™¯\n\nDeng said it might be better to let \"future generations, which may be wiser\" to tackle the sovereignty imbroglio.\n\n#### paroxysm\nè¿™ä¸ªå•è¯é•¿å¾—å¾ˆä¸ä¸€æ ·.\nA paroxysm is a convulsion or sudden fit, brought on because you're freaking out or coming down with something.\n\nParoxysm is from the Greek word paroxysmos, which basically means \"to irritate.\" If you're irritated to the point of having a wild fit, like if you see someone trying to steal your car, you might go into a paroxysm of rage. When the clowns performed their act, the audience went into a paroxysm of giggles. A paroxysm can be medical, too, like when an illness suddenly attacks, and you get symptoms like chills and a fever right away.\n\nå½¢å®¹è¯: paroxysmal\n\n#### municipal\næ¥è‡ªæ‹‰ä¸è¯­ municeps, å¸‚æ°‘ï¼Œè‡ªæ²»é•‡å…¬æ°‘ï¼Œ\n- æ¥è‡ª munus, å…±åŒèŒè´£ï¼Œå…±åŒè´£ä»»ï¼Œç›¸äº’ç»™äºˆï¼Œç¤¼ç‰©, è¯æºåŒ common, mutual.\n- -cep, æ‰¿æ‹…ï¼Œè¯æºåŒ capable, accept. \nè¯¥è¯åŸæŒ‡å¤ç½—é©¬æ—¶æœŸäº«æœ‰ç½—é©¬å…¬æ°‘çš„ç‰¹æƒä½†æ˜¯æŒ‰ç…§è‡ªå·±çš„æ³•å¾‹è¿›è¡Œç®¡ç†çš„ç‰¹åˆ«è‡ªæ²»é•‡ã€‚åè¯ä¹‰é€šç”¨åŒ–ï¼Œå¼•ç”³è¯ä¹‰å¸‚æ”¿çš„ï¼Œå¸‚æ”¿å½“å±€çš„ã€‚\n\n##### munificent\nmuni- =\u003e ç¤¼ç‰©, è¿™é‡Œå¯ä»¥ç†è§£ä¸º\"å¥½å¤„\"\nfic- =\u003e to make\n-ent\n=\u003e present-making, èƒ½makeå¾ˆå¤šå¥½å¤„çš„,  =\u003e æ…·æ…¨çš„, å¤§æ–¹çš„, \n\nIf you give your best friend a bracelet for her birthday, then youâ€™re a good friend. If you give her a diamond bracelet, a racehorse, and an oil well, then youâ€™re a munificent friend, meaning you are very lavish when it comes to giving gifts. (And itâ€™s possible you may also be broke.)\n\nIf youâ€™re the generous type, you may already know that the word munificent traces back to the Latin word munificus, meaning â€œgenerous or bountiful,\" which in turn originated from the word munus, meaning â€œgift or service.â€ Put those two concepts together and you have big-time gift giving on a lavish scale. Use the word munificent to describe instances of over-the-top generosity â€” think Oprah on a gift-giving binge at Christmastime.\n\n##### communeï¼ˆå…¬ç¤¾ï¼‰\nåœ¨æ¬§æ´²å°å»ºæ—¶æœŸï¼Œå›½å®¶çš„åœŸåœ°è¢«åˆ†å°ç»™å„ä¸ªè¯¸ä¾¯ã€‚åœŸåœ°æˆäº†å°å»ºå›ä¸»å’Œé¢†ä¸»çš„ç§äººè´¢äº§ã€‚åæ¥ï¼Œéšç€èµ„æœ¬ä¸»ä¹‰å·¥å•†ä¸šçš„å…´èµ·ï¼Œæ–°å…´èµ„äº§é˜¶çº§é€æ¸å‘å±•å£®å¤§ã€‚ä»–ä»¬å®šå±…åœ¨åŸå¸‚é‡Œï¼Œé€šè¿‡èµä¹°å’Œæˆ˜äº‰æ‰‹æ®µä»å°å»ºé¢†ä¸»æ‰‹ä¸­å¤ºå–äº†åŸå¸‚çš„ä¸»æƒï¼Œå»ºç«‹äº†ç”±å…¨ä½“å¸‚æ°‘å…±åŒæ²»ç†çš„è‡ªæ²»åŸå¸‚ã€‚åœ¨æ³•è¯­ä¸­ï¼Œè‡ªæ²»åŸå¸‚çš„è¿™ç§æ²»ç†æœºæ„è¢«ç§°ä¸º communeï¼Œæ¥è‡ªæ‹‰ä¸è¯­ communisï¼Œç”± comï¼ˆå…±åŒï¼‰+muniaï¼ˆèŒè´£ã€å…¬èŒã€åŠŸèƒ½ï¼‰æ„æˆï¼Œè¡¨æ˜è‡ªæ²»åŸå¸‚çš„ä¸»æƒå±äºå…¨ä½“å¸‚æ°‘ï¼Œæ²»ç†èŒè´£ç”±å…¨ä½“å¸‚æ°‘æ‰¿æ‹…ï¼Œè€Œä¸æ˜¯æŸä¸ªäººç‹¬æ½å¤§æƒã€‚\n1871 å¹´ï¼Œæ³•å›½å·´é»äººæ°‘èµ·ä¹‰ï¼Œæ¨ç¿»äº†èµ„äº§é˜¶çº§ä¸´æ—¶æ”¿åºœï¼Œå»ºç«‹äº†ä¸–ç•Œä¸Šç¬¬ä¸€ä¸ªæ— äº§é˜¶çº§æ”¿æƒçš„é›å½¢â€”â€”Paris Communeï¼Œä¸­æ–‡è¯‘ä¸ºâ€œå·´é»å…¬ç¤¾â€ã€‚ä»æ­¤ä»¥åï¼Œcommuneï¼ˆå…¬ç¤¾ï¼‰æˆä¸ºç¤¾ä¼šä¸»ä¹‰å›½å®¶çš„ä¸€ç§ç‹¬ç‰¹ç»„ç»‡å½¢å¼ï¼Œæ–°ä¸­å›½æˆç«‹åä¹Ÿæ›¾ç»å†è¿‡å»ºè®¾â€œäººæ°‘å…¬ç¤¾â€çš„é˜¶æ®µã€‚\næºè‡ªæ‹‰ä¸è¯­ communis çš„è‹±è¯­å•è¯è¿˜æœ‰ communityã€commonã€communism ç­‰ã€‚æ¥è‡ªæ‹‰ä¸è¯­è¯æ ¹ munia çš„è‹±è¯­å•è¯è¿˜æœ‰ municipalï¼ˆå¸‚æ”¿çš„ï¼‰ã€municipalityï¼ˆå¸‚æ”¿å½“å±€ï¼‰ã€‚\n- communeï¼š['kÉ’mjuËn] n. å…¬ç¤¾ï¼Œè‡ªæ²»åŸå¸‚\n- communalï¼š['kÉ’mjÊŠn(É™)l] adj. å…¬å…±çš„ï¼Œå…¬æœ‰çš„ï¼Œå…¬ç¤¾çš„\n- communityï¼š[kÉ™'mjuËnÉªtÉª] n. ç¤¾åŒºï¼Œç¤¾ä¼šï¼Œå…±åŒä½“ï¼Œå›¢ä½“\n- commonï¼š['kÉ’mÉ™n] n. æ™®é€šï¼Œå¹³æ°‘ adj. å…±åŒçš„ï¼Œæ™®é€šçš„\n- communismï¼š['kÉ’mjÊŠnÉªz(É™)m] n. å…±äº§ä¸»ä¹‰\n- communistï¼š['kÉ’mjÊŠnÉªst] n. å…±äº§ä¸»ä¹‰è€… adj. å…±äº§ä¸»ä¹‰çš„\n\n- municipalï¼š[mjÊŠ'nÉªsÉªp(É™)l] adj. å¸‚æ”¿çš„ï¼Œå¸‚çš„ï¼Œå†…æ”¿çš„\n- municipalityï¼š[mjÊŠ,nÉªsÉª'pÃ¦lÉªtÉª] n.å¸‚æ”¿å½“å±€ï¼Œå¸‚æ°‘ï¼Œè‡ªæ²»å¸‚æˆ–åŒº\n\n\n#### pilloryâ˜¢\npillory æ˜¯å¤ä»£çš„ä¸€ç§åˆ‘å…·, é•¿ä¸‹é¢è¿™ä¸ªæ ·å­, ä¸‹é¢æœ‰ä¸ªæŸ±å­, æ‰€ä»¥è¯å½¢ä¸Šçœ‹èµ·æ¥å’Œ pillar å¾ˆåƒ:\n![300](notes/2022/2022.7/assets/TitusOates-pilloried_300dpi.jpg)\n- å¦‚ä»Špilloryè¿™ä¸ªåˆ‘ç½šå·²ç»åºŸé™¤äº†, pilloryä¹Ÿå¼•ç”³å‡ºäº†(å…¬å¼€)æŠ¨å‡», ä¸¥å‰æ‰¹è¯„, è¾±éª‚çš„æ„æ€. (å°±æ˜¯åƒè¢«æˆ´ä¸Šäº†pilloryäº†ä¸€æ ·, æ‰€ä»¥ä¸€èˆ¬æŒ‡å…¬å¼€çš„ç¾è¾±, æ‰¹è¯„)\n\n- A man has been forced to resign as a result of being pilloried by some of the press.\n\n#### probityâ˜¢\n- prob-  =\u003e test, è¡¨ç¤ºâ€œæµ‹è¯•ï¼Œè¯æ˜â€ï¼Œå¤åˆè¯æ ¹ï¼Œç”± pro- å‘å‰ + be- å­˜åœ¨ç»„æˆã€‚\n- -ity  =\u003e è¡¨åè¯ï¼ŒæŒ‡å…·å¤‡æŸç§æ€§è´¨ã€‚\n\næ¥è‡ª probe, è¯•æ¢ï¼Œæ£€éªŒï¼Œ-ity, åè¯åç¼€ã€‚å³ç»å¾—èµ·æ£€éªŒçš„ï¼Œå¼•ç”³è¯ä¹‰æ­£ç›´ï¼Œè¯šå®ã€‚\n\nHer **probity** and integrity are beyond question.\n\n\n#### et cetera\nAlso etcetera, from Latin **et cetera**, literally \"**and the others**,\" from et \"**and**\" + neuter plural of ceterus \"**the other, other part, that which remains**,\" \netc. å°±æ˜¯et ceteraçš„ç¼©å†™, æ‰€ä»¥etc. çš„è¯»éŸ³æ˜¯ /et ËˆsedÉ™rÉ™/\n\n\n#### reprobate\nprobateç°åœ¨çš„æ„æ€æ˜¯\"éªŒè¯é—å˜±çš„æœ‰æ•ˆæ€§\"(verb \u0026 noun), ä¹Ÿå°±æ˜¯prove to be worthy, é‚£ä¹ˆåŠ ä¸Šå‰ç¼€re- =\u003e opposite of, reversal of previous conditions, å°±æ˜¯æ²¡\"rejected as worthless, rejected by god\"çš„æ„æ€, å†å¼•ç”³åˆ°äººä¸Šé¢å°±æ˜¯\"å •è½è€…, æ²¡æœ‰é“å¾·åº•çº¿çš„äºº\"\n\n- â€œHe was just an old reprobate who lived poor and died broke,â€ Grandma said.\n- â€œThose old reprobates, they live in my building, you know...â€\n\n#### bad egg / good egg\næœ‰è¶£çš„æ˜¯è‹±è¯­é‡Œé¢çš„ bad egg å°±æ˜¯æ±‰è¯­é‡Œé¢çš„\"åè›‹\", åœ¨è‹±è¯­é‡Œé¢è¿™ä¸ªè¯´æ³•æ˜¯ [informal + somewhat old-fashioned](https://www.merriam-webster.com/dictionary/bad%20egg) \n- é‚£ä¹ˆæˆ–è®¸æ±‰è¯­é‡Œé¢çš„åè›‹å°±æ˜¯ä»è‹±è¯­ç›´è¯‘è¿‡æ¥çš„?\n- å¦å¤–, è‹±è¯­é‡Œé¢è¿˜æœ‰ä¸€ä¸ªè¯´æ³•æ˜¯ Good egg, å°±æ˜¯ bad egg çš„åä¹‰è¯.\n\n [**Origin**](https://www.idioms.online/bad-egg/)  \n- Egg has been used to describe people since the 1600s but this idiom arose during the mid-1800s. It alludes to an egg which seems perfectly fine on the outside but when broken open turns out to be rotten. The antonym, good egg, arose later.\n- The allusion is clearly to the disappointment felt when cracking or shelling an egg, only to find that it is bad.\n**ä¾‹å¥**\n- Iâ€™m telling you, Robert is just a bad egg. I wouldnâ€™t trust him if I were you.â€\n- â€œItâ€™s disappointing when someone you think is a good friend turns out to be a bad egg.â€\n- â€œIâ€™m not surprised at all that he lied. I always knew he was a bad egg.â€\n\n\n#### slack\næ¾çš„, æˆ–è€…ä½œä¸ºåè¯\n- These tent ropes are too slack - they need tightening.\n- The men pulled on the ropes to take up the slack (= to tighten them).\nè§æ¡çš„ï¼Œä¸æ™¯æ°”çš„ï¼›å†·æ¸…çš„ï¼›æ‡ˆæ€ çš„, æˆ–è€…ä½œä¸ºåŠ¨è¯\n- Business is always slack at this time of year. \n- Discipline in Mr Brown's class has become very slack recently.\n- Everyone **slacks off/up** at the end of the week.\n\n**slacks**\na pair of trousers, that are not part of a suitï¼ˆä¸å±äºå¥—è£…ä¸€éƒ¨åˆ†çš„ï¼‰é•¿è£¤, éš¾é“æ˜¯å› ä¸ºé•¿è£¤éƒ½æ¾æ¾å®å®?\n- wool slacks ç¾Šæ¯›é•¿è£¤\n\n\n##### cut sb some slack\nto not judge someone as severely as you usually would because they are having problems at the present time\nç»™â€¦æ–¹ä¾¿ï¼›å¯¹â€¦ç½‘å¼€ä¸€é¢, \n- \"Andrew's late again.\" \"**Cut him some slack** - his wife just had a baby.\" â€œå®‰å¾·é²åˆè¿Ÿåˆ°äº†ã€‚â€â€œå¯¹ä»–å°±ç½‘å¼€ä¸€é¢å§â€”â€”ä»–å¦»å­åˆšç”Ÿå°å­©ã€‚â€\n\næˆ–è®¸å¯ä»¥ç†è§£ä¸º\"é‡ç»³å­çš„é•¿åº¦çš„æ—¶å€™ä¸è¦åˆšåˆšå¥½, ç•™ä¸€äº›ä½™é‡, è¿™æ ·å°± slack ä¸€ç‚¹\", ç»³å­æ¯”å–»æ ‡å‡†, æ„æ€æ˜¯åœ¨æ ‡å‡†ä¸Šå¯¹æŸäººæ¾ä¸€ç‚¹, å› ä¸ºå®ƒä»¬æœ‰ç‰¹æ®Šæƒ…å†µ.\n\n\n#### surlyâ˜¢\nsurly æ˜¯\"sirly\"çš„å˜å½¢, sir+ly, like a sir, è¯ä¹‰è´¬ä¹‰åŒ–, å˜æˆäº†åè„¾æ°”çš„, ä¸å‹å¥½çš„, ç²—é²æ— ç¤¼çš„, æœ‰è¶£çš„æ˜¯, ç°åœ¨è¿™ä¸ªè¯çš„æ„æ€å’Œ\"sir\"å®Œå…¨ä¸æ²¾è¾¹äº†, åè€Œæ›´åƒæ˜¯ç²—äºº, boorish.\n- Surly describes behavior nobody wants to be around. Think of the irritable old guy who lives on your street and always seems to be simmering with some sullen nasty anger, whose every utterance he spits out with a rude snarl. He's the poster boy for surly.\n\n- Surly behavior is always frowned upon, but the word's origins are in the behavior of English nobility. Surly's roots are in sirly, as in sir, meaning **arrogant, haughty, and superior**. Its current meaning implies all that and more, none of it appealing â€” rude, snotty, sullen, mean and cranky can be added to the list. Generally speaking, if you find yourself in a surly mood, avoid your friends and loved ones.\n\n##### lordly\nused to decribe someone who behaves as if they are better than other people\nå‚²æ…¢çš„ï¼Œé«˜å‚²çš„\n- a lordly air é«˜å‚²çš„ç¥æƒ…\n\n#### air\nnoun (MANNER)\n- manner or appearance ç¥æ€ï¼Œæ ·å­ï¼›é£åº¦\n- She has an air of confidence about her. å¥¹ä¸€å‰¯è‡ªä¿¡çš„æ ·å­ã€‚\n\n#### votaryâ˜¢\nvow + -ary =\u003e one consecrated by a vow, å®£èª“äº†çš„äºº, æœ€åˆæŒ‡çš„æ˜¯ monk or nun (å®£èª“å¿ è¯šäºæŸä¸ª religion çš„äºº), åæ¥å¼•ç”³åˆ°è¿½éšæŸä¸€ä¸ª cause æˆ– person çš„äºº, è¿½éšè€…, ä»°æ…•è€…, æ‹¥æŠ¤è€…\n\"How could you, a votary of non-violence, exhort others to take up arms and join this war?\" he wrote to him.\n\n#### anathema\nè‹±è¯­å•è¯ anathema æ¥è‡ªå¸Œè…Šè¯­ anathemaï¼Œç”± anaï¼ˆupï¼‰+ thema ï¼ˆto put, to placeï¼‰æ„æˆï¼Œå­—é¢æ„æ€å°±æ˜¯â€œä¸Šäº¤ç»™ä¸Šå¸ï¼ˆç”±å…¶å¤„ç½®ï¼‰â€ã€‚è¿™ä¸ªå¸Œè…Šè¯­å®é™…ä¸Šæ˜¯å¤ä»£å¸Œè…Šäººåœ¨ç¿»è¯‘å¸Œä¼¯æ¥è¯­çš„ã€Šæ—§çº¦ã€‹æ—¶å¯¹å¸Œä¼¯æ¥è¯­ heremï¼ˆæˆ– cheremï¼‰çš„ç¿»è¯‘ã€‚herem åœ¨å¸Œä¼¯æ¥è¯­ä¸­æœ€æ—©æŒ‡ä¸ç¬¦åˆçŠ¹å¤ªæ•™ä¿¡ä»°ã€ä¸Šå¸æ†æ¶çš„â€œå½“ç­ä¹‹ç‰©â€ï¼Œå¦‚å¼‚æ•™å¾’ç”¨æ¥å´‡æ‹œå…¶ä»–ç¥çµçš„å»ºç­‘ã€å™¨å…·ï¼Œä»¥åŠå…¶ä»–ä¸çŠ¹å¤ªæ•™ä¹‰ä¸ç¬¦çš„è´¢ç‰©ã€‚çŠ¹å¤ªäººæ‰“è´¥å¼‚æ•™å¾’åæ•è·çš„è¿™äº›ç‰©å“ä¸å¯æ‹¿å›å®¶ç§è‡ªäº«ç”¨ï¼Œè€Œåº”è¯¥çŒ®ç»™ä¸Šå¸ï¼Œç”±ä¸Šå¸æ¥å¤„ç½®ã€‚â€œçŒ®ç»™ä¸Šå¸â€çš„æ–¹å¼ä¸€èˆ¬æ˜¯çƒ§æ‰æˆ–ç ¸ç¢ã€‚ä¸ herem å¯¹åº”çš„å¸Œè…Šè¯­ anathema ä¹Ÿå°±å«æœ‰â€œä¸Šå¸æ†æ¶ä¹‹ç‰©ã€å¼‚æ•™å¾’æ‰€ç”¨ä¹‹ç‰©â€çš„å«ä¹‰ã€‚\nåœ¨å®—æ•™é¢†åŸŸï¼Œanathema è¡¨ç¤ºä¸€ç§éå¸¸ä¸¥æ ¼çš„æƒ©ç½šâ€œé©å‡ºæ•™é—¨â€ï¼Œä»…ä»…é€‚ç”¨äºä¸¥é‡è¿åæ•™è§„çš„ä¿¡å¾’ï¼Œç›¸å½“äºå®£å¸ƒè¯¥äººæ˜¯â€œä¸Šå¸æ†æ¶ä¹‹ç‰©â€ã€‚åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ï¼Œanathema è¡¨ç¤ºâ€œéå¸¸è®¨åŒçš„äººæˆ–ç‰©â€ã€‚\n- anathemaï¼š[É™'nÃ¦Î¸É™mÉ™] n. å’’é€ï¼Œé©å‡ºæ•™é—¨ï¼›è¢«è¯…å’’è€…ï¼Œéå¸¸è®¨åŒçš„äººæˆ–ç‰©\n\n#### apoplecticâ˜¢\napoplexy æ˜¯\"ä¸­é£, è„‘å’ä¸­\"çš„æ„æ€, ä¹Ÿæœ‰\"ç‹‚æ€’(extreme anger)\"çš„æ„æ€, è¿™ä¸¤ä¸ªå•è¯çš„è”ç³»å¯èƒ½æ˜¯\"è€äººæƒ…ç»ªæ³¢åŠ¨å¤§äº†(æ¯”å¦‚éå¸¸ç”Ÿæ°”), å°±å¯èƒ½ä¸­é£\"?\næ€»ä¹‹ apoplectic å°±æ˜¯\"**extremely and obviously angry**\"çš„æ„æ€.\n\n- He was apoplectic with rage/fury\n\n#### galvanizeâ˜¢\nè¿™ä¸ªå•è¯æ¥è‡ªæ„å¤§åˆ©ç§‘å­¦å®¶**Luigi Aloisio Galvani**, ä»–æ˜¯ç”Ÿç‰©ç”µç ”ç©¶é¢†åŸŸçš„å…ˆé©±, ä»–åœ¨è§£å‰–é’è›™çš„æ—¶å€™å‘ç°è§£å‰–åˆ€æ¥è§¦é’è›™è…¿ä¸Šçš„ç¥ç»è‚Œè‚‰ä¼šä½¿é’è›™çš„è‚Œè‚‰æŠ½æ. \ngalvanize å°±æ˜¯\"åˆºæ¿€æŸäºº\"çš„æ„æ€(ä¾‹å¦‚ä½¿æŸäººçªç„¶å…´å¥‹èµ·æ¥/æ‰“èµ·ç²¾ç¥), å¾ˆå®¹æ˜“æƒ³åˆ°è¿™æ˜¯åœ¨æ¨¡æ‹Ÿäººè§¦ç”µçš„æ ·å­(simulated by galvanic electricity)\n\n - Western charities were galvanized by TV pictures of starving people. \n- The prospect of his mother coming to stay galvanized him into action and he started cleaning the house.\n\nè¿™ä¸ªå•è¯ä¹Ÿå¯ä»¥æŒ‡\"ç”µé•€\" ä¾‹å¦‚é•€é”Œ, é•€é”¡\n\n\n#### immureâ˜¢\nim- =\u003e in\nmure =\u003e wall, æ¯”å¦‚ mural, å£ç”»\n=\u003e enclose with walls, shut up, confine, \n=\u003e å›šç¦, å®‰è‘¬, =\u003e (æ¯”å–»ä¹‰)é™åˆ¶...çš„å‘å±•, æ¡æ¢\n- The aristocracy chose to **immure** its dead in church vaults or specially constructed mausoleums. è´µæ—é€‰æ‹©å°†é€è€…å®‰è‘¬åœ¨æ•™å ‚çš„åœ°çª–æˆ–ä¸“é—¨å»ºé€ çš„é™µå¢“ä¸­ã€‚\n- The false uncle sealed the mouth of the underground chamber and **immured** Aladdin in the darkness.\n- Constantly imitating past masters does not take cooking any further forward - it **immures** it in history.\n\n\nWhen you immure someone or something, you put it behind a wall, as in a jail or some other kind of confining space.\n\nYou may recognize the -**mur**- in immure as the root for \"wall,\" as in mural, which is a painting on a wall, or **intramural**, literally \"inside the walls,\" as, for instance, the walls of a school â€” intramural sports are played among teams from the same school. You don't need a jail to immure someone. Rapunzel was immured in her tower. At the end of Shakespeare's Romeo and Juliet, the lovers are immured in the tomb.\n\n#### aphorism\naphorism - ä¸–ç§°â€œåŒ»å­¦ä¹‹çˆ¶â€çš„å¤å¸Œè…ŠåŒ»å¸ˆå¸Œæ³¢å…‹æ‹‰åº•ï¼ˆHippocrates, 460?-377?BCï¼‰æ›¾å†™äº†ä¸€æœ¬åä¸º Aphorismoiï¼ˆã€Šæ ¼è¨€é›†ã€‹ï¼‰çš„ä¹¦ã€‚ä¹¦ä¸­æ”¶å½•çš„å¤´æ¡æ ¼è¨€æ˜¯æœ€æœ‰åçš„ä¸€æ¡ï¼Œè¯‘æˆè‹±è¯­ä½œ Art is long, life is shortï¼ˆè‰ºæœ¯é•¿å­˜ï¼Œç”Ÿå‘½çŸ­æš‚ï¼‰ï¼Œè¿™ä¸€æ ¼è¨€ä¸€ç›´æµä¼ è‡³ä»Šã€‚è‹±è¯­ä¸­æ„ä¸ºâ€œæ ¼è¨€â€æˆ–â€œè­¦å¥â€çš„ aphorism ä¸€è¯å³æºå‡ºè¯¥ä¹¦åã€‚\n\nä¾‹\n- \"A man is known by the company he keeps\" is an aphorism. â€œè§‚å…¶äº¤å‹ï¼ŒçŸ¥å…¶ä¸ºäººâ€æ˜¯ä¸€å¥æ ¼è¨€ã€‚\n- Oscar Wilde was famous for such aphorisms as 'Experience is the name everyone gives to their mistakes'. (CID) å¥¥æ–¯å¡Â·ç‹å°”å¾·å› è¯¸å¦‚â€œç»éªŒæ˜¯äººä»¬ç”¨æ¥æ–‡é¥°è‡ªå·±è¿‡å¤±çš„åè¯â€è¿™æ ·çš„è­¦å¥è€Œè‘—ç§°ã€‚\n\n#### gaffeâ˜¢\nå‡ºä¸‘ï¼›å¤±ç¤¼ï¼›å¤±è¨€\nA gaffe is a mistake that embarrasses you in front of others. If you run into a friend out with her grey-haired father, and you blurt out, \"Oh, hi, you must be Tara's grandfather!\" then you've made a gaffe.\n\nGaffe rhymes with laugh, and you'll be lucky if that's how people respond to your social blunder. A gaffe seems to occur most often when you literally don't know your audience â€” you make a joke about the mayor; you didn't know you were talking to his sister. That's definitely a gaffe. And who knew your hosts come from a culture that takes offense if you refuse to try every dish?\n\n#### faux pasâ˜¢\n/ËŒfoÊŠ ËˆpÉ‘Ë/\nå¤±è¨€ï¼›å¤±ç¤¼, \"å‡ºæ´‹ç›¸?\"\nIf you misread a party invitation and arrive in a penguin costume, only to realize that the other guests are wearing elegant gowns and tuxedos, you'll understand what it means to commit a faux pas, or an awkward social mistake.\n\nFaux pas literally means \"false step\" in French, and that's a great description of what you do when you make a faux pas. It's a matter of stepping in the wrong direction, or saying exactly the wrong thing. A faux pas can offend people sometimes, but more often it's just embarrassing for everyone involved.\n\n\n#### blackmail\nè‹±è¯­å•è¯ blackmail ç”± blackï¼ˆé»‘è‰²çš„ï¼‰+mailï¼ˆé‚®ä»¶ï¼‰æ„æˆï¼Œä¸ºä»€ä¹ˆæ˜¯â€œæ•²è¯ˆå‹’ç´¢â€è€Œä¸æ˜¯â€œé»‘è‰²é‚®ä»¶â€çš„æ„æ€å‘¢ï¼Ÿéš¾é“æ•²è¯ˆå‹’ç´¢æ—¶è¦ç»™å¯¹æ–¹å‘é»‘è‰²é‚®ä»¶å—ï¼Ÿå…¶å®ï¼Œblackmail ä¸­çš„ mail ä¸ç°ä»£è‹±è¯­ä¸­è¡¨ç¤ºâ€œé‚®ä»¶â€çš„ mail æ¯«æ— å…³ç³»ï¼Œå®ƒæºè‡ªå¤æ—¶è‹æ ¼å…°æ–¹è¨€ï¼ŒæŒ‡çš„æ˜¯â€œåœ°ç§Ÿâ€æˆ–â€œç¨é‡‘â€ã€‚16 ä¸–çºªæ—¶è‹æ ¼å…°å†œæ°‘å‘åœ°ä¸»äº¤ç§Ÿæ—¶ï¼Œä»¥ç™½é“¶å½¢å¼ç¼´çº³çš„åœ°ç§Ÿå«åš white mailï¼Œè€Œé‚£äº›æ²¡æœ‰ç™½é“¶çš„ç©·å›°å†œæ°‘åªèƒ½ä»¥ç‰²ç•œæˆ–å†œäº§å“å½¢å¼ç¼´çº³åœ°ç§Ÿï¼Œè¿™ç§åœ°ç§Ÿå°±å«åš black mailã€‚å†œæ°‘ç¼´çº³ black mail æ—¶ï¼Œåœ°ä¸»å¾€å¾€ä¼šä»¥å‹ä½ç‰²ç•œæˆ–å†œäº§å“ä»·æ ¼ä¸ºæ‰‹æ®µï¼Œå¯¹å†œæ°‘è¿›è¡Œç™¾èˆ¬åˆéš¾å’Œæ•²è¯ˆå‹’ç´¢ï¼Œå› æ­¤ black mail é€æ¸äº§ç”Ÿäº†â€œæ•²è¯ˆå‹’ç´¢â€çš„å«ä¹‰ã€‚å¹¶ä¸”å½“æ—¶è‹æ ¼å…°å’Œè‹±æ ¼å…°äº¤ç•Œå¤„ç›—åŒªæµè¡Œï¼Œäººä»¬è¢«è¿«å‘ç›—åŒªç¼´çº³ä¿æŠ¤è´¹æ‰èƒ½æ±‚å¾—ä¸€æ—¶å¹³å®‰ã€‚è¿™ç§ä¿æŠ¤è´¹ä¹Ÿè¢«ç§°ä½œ black mailã€‚ç”±äºè¿™ä¸¤ä¸ªåŸå› ï¼Œåˆå†™åœ¨ä¸€èµ·çš„è‹±è¯­å•è¯ blackmail å°±å®Œå…¨ç”¨æ¥è¡¨ç¤ºâ€œæ•²è¯ˆå‹’ç´¢â€äº†ã€‚\n- blackmailï¼š['blÃ¦kmeÉªl] n.æ•²è¯ˆå‹’ç´¢ï¼Œæ•²è¯ˆå‹’ç´¢æ‰€å¾—vt.æ•²è¯ˆï¼Œå‹’ç´¢\n\n- Don't think you can blackmail me (into doing that). I'll report you to the police!\n- Threatening a scandal, he blackmailed the firm into paying him for keeping quiet.\n- She's always using emotional blackmail and playing on other people's feelings. \n- He accused his mother of using emotional blackmail to stop him leaving home.\n\n#### barefaced\nbare + face + ed=\u003e ä¸é®ä½è‡ªå·±çš„è„¸çš„ =\u003e not trying to hide your bad behaviour =\u003e ä¸è¦è„¸çš„, åšé¢œæ— è€»çš„, åšè„¸çš®çš„\n\n- That's a barefaced lie!\n\n![effronteryâ˜¢](#effronteryâ˜¢)\n\n\n#### apocryphalâ˜¢\n- apocryphalï¼š[É™'pÉ’krÉªf(É™)l] adj. ä¼ªçš„ï¼Œå¯ç–‘çš„, æœæ’°çš„\nã€Šåœ£ç»â€¢æ—§çº¦ã€‹æ˜¯çŠ¹å¤ªæ•™å’ŒåŸºç£æ•™çš„ç»å…¸è‘—ä½œï¼Œæ˜¯ç”¨çŠ¹å¤ªäººæ‰€ä½¿ç”¨çš„å¸Œä¼¯æ¥æ–‡å­—ç¼–å†™çš„ã€‚åŸºç£æ•™ä¼ åˆ°æ¬§æ´²åï¼Œè¿™éƒ¨ç»å…¸è‘—ä½œä¹Ÿè¢«ç¿»è¯‘æˆæ¬§æ´²è¯­è¨€ç‰ˆæœ¬ï¼Œå…ˆåå‡ºç°äº†å¸Œè…Šæ–‡å’Œæ‹‰ä¸æ–‡çš„ç‰ˆæœ¬ã€‚ä½†æ˜¯ï¼Œåœ¨è¿™ä¸¤ä¸ªç‰ˆæœ¬ä¸­ï¼Œå´å¢åŠ äº†ä¸€äº›ä¸æ˜¯ä»å¸Œä¼¯æ¥è¯­ç¿»è¯‘è¿‡æ¥çš„å†…å®¹ï¼Œè€Œæ˜¯ç”¨å¸Œè…Šæ–‡å’Œæ‹‰ä¸æ–‡ç›´æ¥ç¼–å†™çš„å†…å®¹ï¼Œå¦‚ã€Šç¦§å¹´ä¹¦ã€‹ã€ã€Šæ‰€ç½—é—¨è¯—ç¯‡ã€‹ã€ã€Šä»¥è¯ºä¹¦ã€‹ç­‰ã€‚åä¸–çš„äººä»¬å¯¹è¿™éƒ¨åˆ†å†…å®¹çš„ä½œè€…å’Œæƒå¨æ€§å­˜æœ‰ç–‘é—®ï¼Œå› æ­¤åœ¨åç»­ç‰ˆæœ¬ä¸­æ²¡æœ‰å°†è¿™äº›å†…å®¹æ”¶å½•è‡³ã€Šåœ£ç»ã€‹æ­£å†Œã€‚è¿™äº›å› ä¸ºä½œè€…å’Œæƒå¨æ€§å­˜ç–‘è€Œæœªè¢«æ”¶å½•è‡³ã€Šåœ£ç»ã€‹æ­£å†Œçš„åŸºç£æ•™è‘—ä½œå°±è¢«ç§°ä¸º apocryphaï¼Œç”± apoï¼ˆawayï¼‰+ krypteinï¼ˆto hideï¼‰æ„æˆï¼Œå­—é¢æ„æ€å°±æ˜¯â€œæš—è—çš„ã€éšæ™¦çš„ã€ä¸å…¬å¼€çš„â€ï¼Œè¡¨ç¤ºè¿™éƒ¨åˆ†å†…å®¹æ²¡æœ‰å¾—åˆ°ç¡®è®¤ï¼Œä¸é€‚åˆå…¬å¸ƒã€‚\n- apocryphaï¼š[É™'pÉ’krÉªfÉ™] n. ä¼ªç»ã€æ—ç»ï¼Œä½œè€…ï¼ˆæˆ–çœŸå®æ€§ã€æƒå¨æ€§ï¼‰å¯ç–‘çš„è‘—ä½œ\n\n#### fail-safe\nvery unlikely to fail ä¸‡æ— ä¸€å¤±çš„ï¼Œä¸‡å…¨çš„\n- a fail-safe plan \n\nIf something is fail-safe, it has been designed so that if one part of it does not work, the whole thing does not become dangerous.\n- a fail-safe device æ•…éšœä¿æŠ¤è£…ç½®\n\n\n#### enmity\n- è¿™ä¸ªå•è¯å’Œ enemy å¾ˆåƒ, è¡¨ç¤º\"æ•Œæ„\"\n- è¿™ä¸ªå•è¯ä¹Ÿå’Œ amity å¾ˆåƒ. å…¶å® amity å°±æ˜¯ enmity å»é™¤ negative prefix, è¡¨ç¤º\"å‹å¥½, å’Œç¦\"\n\n\n#### methodical\nmethodæ˜¯æ–¹æ³•, + -ical =\u003e äººåšäº‹æœ‰æ¡ç†çš„, äº•ç„¶æœ‰åºçš„\n\n- a methodical approach\n- Tom is a very methodical person and writes lists for everything.\n\n#### solventâ˜¢\nsolventæ˜¯æº¶è§£çš„ä»‹è´¨ =\u003e æº¶å‰‚\nç”¨äºå•†åŠ¡ =\u003e æœ‰å¿è¿˜èƒ½åŠ›çš„\n\nå…¶ä¸­çš„è”ç³»åœ¨å“ªé‡Œ? \n- èƒ½å¤Ÿå¿è¿˜å€ºåŠ¡çš„ \u003c=\u003e èƒ½å¤Ÿ\"æº¶è§£\"å€ºåŠ¡çš„?(ä½¿å€ºåŠ¡æ¶ˆå¤±)\n- èƒ½å¤Ÿå¿è¿˜å€ºåŠ¡çš„ \u003c=\u003e èƒ½å¤Ÿ\"solve\"å€ºåŠ¡çš„?(ä½¿å€ºåŠ¡è¢«è§£å†³)\n\ndissolve æ˜¯æº¶è§£çš„åŠ¨è¯å½¢å¼\n\n#### stentorian\næ–¯å±¯æ‰˜è€³ï¼ˆStentorï¼‰æ˜¯å¸Œè…Šç¥è¯ä¼ è¯´ä¸­ä¸€åå‚åŠ ç‰¹æ´›ä¼Šæˆ˜äº‰çš„å¸Œè…Šå†›äººï¼Œå¤©ç”Ÿä¸€å‰¯å¤§å—“é—¨ï¼Œå£°å¦‚æ´ªé’Ÿï¼Œä¸€ä¸ªäººçš„å£°éŸ³æ¯”å¾—ä¸Š 50 äººï¼Œå› æ­¤åœ¨å†›ä¸­æ‹…ä»»ä¼ ä»¤å®˜ã€‚æ®è¯´å¤©åèµ«æ‹‰æ›¾ç»åŒ–èº«ä¸ºä»–çš„å½¢è±¡ï¼Œç”¨ä»–çš„å¤§å—“é—¨æ¥é¼“åŠ±å¸Œè…Šå°†å£«ã€‚æ–¯å±¯æ‰˜è€³åæ¥ä¸ç¥ä½¿èµ«å°”å¢¨æ–¯æ¯”èµ›è°çš„å—“é—¨æ›´å¤§ã€‚ç»“æœæ–¯å±¯æ‰˜è€³æ¯”è¾“äº†ï¼ŒåŠ›ç«­è€Œäº¡ã€‚ä½†ä»–å‡­å€Ÿè‡ªå·±çš„å¤§å—“é—¨åå‚é’å²ï¼Œè‹±è¯­å•è¯ stentorian å°±æºè‡ªä»–çš„åå­— Stentorã€‚\n- stentorianï¼š [sten'tÉ”ËrÉªÉ™n] adj.ï¼ˆå£°éŸ³ï¼‰æ´ªäº®çš„ï¼Œå“äº®çš„\n\n#### zenith\næœ€é«˜ç‚¹, é¼ç››æ—¶æœŸ, é¡¶å³°\n\n##### nadir\næœ€ä½è°·, æœ€ç³Ÿç³•çš„æ—¶æœŸ\n\n**è¯æº:** \né˜¿æ‹‰ä¼¯äººåœ¨å†å²ä¸Šå¯¹å¤©æ–‡å­¦å’Œæ•°å­¦çš„å‘å±•ä½œå‡ºè¿‡å·¨å¤§çš„è´¡çŒ®ã€‚è®¸å¤šå€Ÿè‡ªé˜¿æ‹‰ä¼¯è¯­çš„å¤©æ–‡å­¦å’Œæ•°å­¦æœ¯è¯­è‡³ä»Šä»åœ¨è‹±è¯­ä¸­ä½¿ç”¨ï¼Œzenith å³ä¸ºå…¶ä¸­ä¹‹ä¸€ï¼Œå®ƒæºè‡ªé˜¿æ‹‰ä¼¯è¯­ samt arrÄs 'path/way over the head'ï¼ˆå¤´é¡¶ä¸Šçš„é“è·¯ï¼‰ä¸­çš„ samt 'path/way'ï¼ˆé“è·¯ï¼‰ã€‚é‚£ä¹ˆ samt æ˜¯æ€ä¹ˆæ¼”å˜æˆ zenith çš„å‘¢ï¼Ÿä¸­ä¸–çºªçš„è¥¿ç­ç‰™æ›¾æ˜¯ä¼Šæ–¯å…°æ•™æ–‡åŒ–ä¸åŸºç£æ•™æ–‡åŒ–å¯†åˆ‡æ¥è§¦çš„åœ°æ–¹ã€‚å½“ samt ä¼ å…¥è¥¿ç­ç‰™è¯­æ—¶ï¼Œå¾ˆå¯èƒ½æ˜¯æ–‡ç‰è¯¯å°† samt ä¸­çš„ m æŠ„æˆ niï¼Œè‡´ä½¿ samt å˜å½¢ä¸º zenitã€‚åœ¨æ—©æœŸçš„æ‰‹ä¹¦ä¸­æ˜¯å¾ˆå®¹æ˜“å‡ºæ­¤ç±»é”™è¯¯çš„ã€‚ä»¥åè¿›å…¥æ³•è¯­ä½œ cenit/cenithï¼Œ14 ä¸–çºªæœ«è¿›å…¥è‹±è¯­ï¼Œåœ¨ä¹”åŸçš„ä½œå“ä¸­å†™æˆ cenythï¼Œåˆ°äº†èå£«æ¯”äºšæ—¶ä»£è¯å½¢æ‰æ¼”å˜ä¸º zenithï¼Œè¯ä¹‰ä¹Ÿéšä¹‹å‘ç”Ÿäº†å˜åŒ–ï¼Œç”±â€œå¤´é¡¶â€åˆ°â€œå¤©é¡¶â€ï¼Œå¹¶è¿›è€Œå¼•ç”³ä¸ºâ€œé¡¶å³°â€æˆ–â€œé¡¶ç‚¹â€ã€‚zenith çš„åä¹‰è¯ nadirï¼ˆå¤©åº•ï¼Œæœ€ä½ç‚¹ï¼Œæœ€ç³Ÿçš„æ—¶åˆ»ï¼‰ä¹Ÿå‡ºè‡ªé˜¿æ‹‰ä¼¯è¯­ï¼Œæ˜¯ä»é˜¿æ‹‰ä¼¯è¯­ nazÄ«r as-samt 'opposite the zenith'ä¸­çš„ nazÄ«r 'opposite'è¡å˜è€Œæ¥çš„ã€‚\n\nä¾‹ \n- Her dancing career is now past its zenith. \n- He was then at the zenith of his career. \n- At its zenith the Roman Empire covered almost the whole of Europe. \n- Their relationship has reached its nadir. \n\n\n#### aberrant\nab- =\u003e off, away from\nerr- =\u003e wander, mistake\n-ant\n=\u003e wandering from the usual course, to wander away, go astray.\n\n#### abnegate\nab- =\u003e off, away from\nneg =\u003e to deny\n-ate\n=\u003e deny (something) to oneself \n=\u003e å½“ deny çš„å¯¹è±¡æ˜¯\"è¯±æƒ‘, äº«å—\"çš„æ—¶å€™, å¯¹åº”ä¸­æ–‡é‡Œé¢çš„\"å…‹åˆ¶\"\n=\u003e å½“ deny çš„å¯¹è±¡æ˜¯\"responsibility, obligation\"çš„æ—¶å€™, å¤§æ¦‚å¯ä»¥ç¿»è¯‘æˆ\"ä¸æ„¿æ‰¿æ‹…ï¼ˆè´£ä»», ä¹‰åŠ¡...ï¼‰\"\n- â€œIt is not the intention of the Myanmar government to apportion blame or to **abnegate** responsibility. We condemn all human rights violations and unlawful violence.â€\n=\u003e å½“ deny çš„å¯¹è±¡æ˜¯\"æƒåŠ›\"çš„æ—¶å€™, å¯¹åº”ä¸­æ–‡é‡Œé¢çš„\"æ”¾å¼ƒ(æƒåŠ›)\"\n- Itâ€™s not a matter of **abnegating** rights, O.K.?\n\n=\u003e å½“ç„¶ abnegate çš„å¯¹è±¡è¿˜å¯ä»¥æ˜¯ god, religion, position ç­‰ç­‰...\n\n##### abnegate? abdicate?\nWhat's the difference between abnegate and abdicate? \nBoth mean to renounce power or authority, but **abdicate** is usually reserved for **higher offices of power**. The king abdicates the throne. The CEO, who gives up day-to-day responsibility? He abnegates responsibility.\n\n\n\n#### gastronomy\nGastronomy is all about food â€” the study of food, the history of food, making good food â€” how we have come to eat what we eat.\nç¾é£Ÿå­¦\ngastro- =\u003e èƒƒ\nnomy =\u003e ç§‘å­¦, æŸä¸€é¢†åŸŸçš„çŸ¥è¯†\n=\u003e å…³äºèƒƒçš„çŸ¥è¯†, å…³äºèƒƒçš„ç§‘å­¦ =\u003e ç¾é£Ÿå­¦\n\n\n#### blight\nblightæŒ‡çš„æ˜¯æ¤ç‰©çš„ä¸€ç§ç–«ç—…\"æ¯èç—…\", æ˜¯ç”±å¾®ç”Ÿç‰©å¼•èµ·çš„, é¡¾åæ€ä¹‰å¾—äº†è¿™ç§ç—…çš„æ¤ç‰©ä¼šå¾ˆå¿«åœ°æ¯èæ­»å».\n![](notes/2022/2022.7/assets/Pasted%20image%2020220729195253.png)\n1845 åˆ° 1849 å¹´å‘ç”Ÿåœ¨çˆ±å°”å…°çš„\"å¤§é¥¥è’\"(The Great Famine)å°±æ˜¯ç”±åœŸè±†æ¯èç—…(potato blight)ç›´æ¥å¯¼è‡´çš„. è¿™æ¬¡é¥¥è’å¯¼è‡´è¶…è¿‡ 100 ä¸‡äººæ­»äº¡, çˆ±å°”å…°äººå£é”å‡ 20~25%, å¯¹çˆ±å°”å…°çš„ç¤¾ä¼šå’Œå†å²é€ æˆäº†æ·±è¿œçš„å½±å“.\n\nå› ä¸ºè¿™ä¸ªç—…æ€ä¼¤åŠ›å¾ˆå¼º, æ‰€ä»¥ blight åˆå¼•ç”³ä¸º\"something that spoils or has a very bad effect on something, of for a long time\"\n- His arrival **cast a blight on** the wedding day.\n\næˆ–è€…ä¹Ÿå¯ä»¥ä½œä¸ºåŠ¨è¯, è¡¨ç¤º to spoil something\n- A broken leg blighted her chance if winning the championship.\n\n\n#### flush, blush\nå®ƒä»¬éƒ½æœ‰\"è„¸çº¢\"çš„æ„æ€, æœ‰ä»€ä¹ˆåŒºåˆ«å—?\nIf a face is flushed, it would be from **exertion or anger**. If a face is blushing, it would be from **embarrassment**. Both imply a roseate complexion, so in that sense they are the same, but they imply **different causes** for the redness.\n- æ‰€ä»¥ flush ä¸€èˆ¬æŒ‡æƒ…ç»ªæ¿€åŠ¨æˆ–è€…èº«ä½“æ´»åŠ¨å¸¦æ¥çš„\"è„¸çº¢\"\n- blush æŒ‡çš„æ˜¯å› ä¸ºå°´å°¬, ç¾æ„§è€Œè„¸çº¢\n\n#### inadvertentâ˜¢\næ— æ„çš„, ä¸æ˜¯æ•…æ„çš„\nin + advertent\næ˜¯ä»inadvertence back-formationæ¥çš„\né‚£ä¹ˆåé¢çš„è¿™ä¸ª advertent æ˜¯ä»€ä¹ˆæ„æ€å‘¢?\n=\u003e æ¥è‡ª Latin *advertere* \"to direct one's attention to\", å­—é¢ä¸Šçš„æ„æ€å°±æ˜¯\"to turn toward\", è¿™ä¹Ÿæ˜¯ advertise è¿™ä¸ªå•è¯çš„è¯æº\nad- =\u003e to, toward\nvertere =\u003e  to turn\n- è½¬è¿‡èº«æ¥é¢å¯¹ =\u003e æ³¨æ„åˆ°æŸäº‹, æ¯”å¦‚è¯´æˆ‘çœ‹åˆ°äº†å·¦è¾¹æœ‰ä¸€æ£µæ¼‚äº®çš„æ¨±èŠ±æ ‘, è‡ªç„¶æƒ³è¦è½¬è¿‡èº«èµ°è¿‘ç‚¹ä»”ç»†æ¬£èµ.\n\nWhen your actions are inadvertent you're not paying attention to their consequences. Remember that inadvertent ends with -ent by remembering this sentence: â€œWe inadvertently ripped the tent.â€\n\n- In this he failedâ€“though he did achieve a certain belated, inadvertent triumph.\n- Even we humans have achieved the dubious technical distinction of being able to make our own disasters, both intentional and inadvertent.\n\n\n#### abstruseâ˜¢\nab- =\u003e off, away from\ntruse =\u003e to thrust, push\n=\u003e to thrust away, =\u003e å¼•ç”³åˆ°ç²¾ç¥ä¸Š \"éš¾æ‡‚çš„, æ™¦æ¶©çš„\"\n\n- The passage can be cryptic, **abstruse**, arcane; these are symptoms of the curse of knowledge.\n- Blacks and whites alike scratched their heads at Grabarekâ€™s **abstruse** testimony, but it was clear the mayor was no friend of Fuller.\n\n It is useful when describing something that is overly confusing, or if someone is deliberately making a story or a situation more complicated than necessary. It sounds and looks like obtuse, but abstruse is almost its opposite. Obtuse is dull or lacking a sharpness of intellect. While Abstruse is president of the chess club, Obtuse is hanging out by the parking lot smoking cigarettes.\n \n **synonyms**: deep, recondite esoteric\n\n#### obtrusiveâ˜¢\næ¥è‡ªobtrude\nob- =\u003e in front of\ntrude =\u003e to thrust, push\n=\u003e to push ... in front of (everyone's attention), thrust forward forcibly or unduly =\u003e ä½¿...è¿‡åˆ†åœ°æ˜¾çœ¼, æ‰çœ¼, æ‰°ä¹±, \n- He didn't want to **obtrude on/upon** her privacy.\n- A 40 watt bulb would be quite sufficient and would not obtrude.\nobstrusive å°±æ˜¯ obstrude çš„å½¢å®¹è¯, =\u003e æ‰çœ¼çš„, è¿‡åˆ†æ˜¾çœ¼çš„.\n\n#### ad-libâ˜¢\nè¿™ä¸ªå•è¯æ—¢å¯ä»¥æ˜¯åŠ¨è¯, åˆæ˜¯åè¯, åˆæ˜¯å½¢å®¹è¯\n\n- ä½œä¸º**åŠ¨è¯**, å®ƒçš„åŒä¹‰è¯æœ‰:\nextemporize, improvise \n\n- ä½œä¸º**å½¢å®¹è¯**, å®ƒçš„åŒä¹‰è¯æœ‰:\nextemporaneous, extemporary, extempore, impromptu, off-the-cuff, offhand, offhanded, unrehearsed, unprepared\n\n#### amicable\nè¿™ä¸ªå•è¯ä¸èƒ½ç®€å•åœ°ç†è§£ä¸º\"friendly\", å®ƒç‰¹æŒ‡åœ¨å†²çªæ—¶ä¿æŒçš„å‹å–„æ°›å›´, å¯ä»¥ç†è§£ä¸ºæ±‰è¯­é‡Œé¢çš„\"ä¸ä¼¤å’Œæ°”çš„\"\nWhen people have an amicable relationship, they are **pleasant to each other and solve their problems without quarrelling**.\n\nThe adjective amicable means \"friendly\" â€” but **in particular, use it when describing relations one might otherwise expect to be unfriendly.** The end of a romantic relationship that's less than amicable might involve broken dishes or broken bones.\n\nAmicable, not surprisingly, comes from the Latin word for \"friend,\" amicus. Perhaps the things most commonly described as amicable are **divorces**. The parties in a divorce often tend to be so childish and the proceedings so messy that it's nice to have a word that reflects the absence of those qualities. Other nouns that commonly pair with amicable include **relationship, split, parting, solution,** and **breakup**.\n\n- The meeting ended on reasonably **amicable** terms.\n- Our discussions were **amicable** and productive\n\n##### amicable? amiable?\nAmicable refers to a friendliness or goodwill **between people or groups**. Amiable refers to **one person's friendly disposition.** A group might have an amicable meeting, because the people there are amiable. \n\n\namicable çš„åä¹‰è¯å¯ä»¥æ˜¯ acrimonious, =\u003e full of anger, arguments and bad feelings. æ¥è‡ªå•è¯ acrid.\n\n\n#### atrophy\na- =\u003e not, without\ntrophy =\u003e nourishment\n=\u003e a wasting away through lack of nourishment\n=\u003e èç¼©, è¡°é€€ (verb \u0026 noun)\n\n\n#### awash\nè¢«æ°´æ·¹æ²¡çš„\n=\u003e be awash with å¼•ç”³ä¸º\"å……æ–¥, æ³›æ»¥\", æ±‰è¯­é‡Œé¢çš„æ³›æ»¥ä¹Ÿæ˜¯ç”¨æ°´æ¥æ¯”å–»æŸä¸ªäº‹ç‰©å¾ˆå¤š, ä½†æ˜¯ awash æ²¡æœ‰\"æ³›æ»¥\"çš„è´¬ä¹‰è‰²å½©åœ¨.\n\n- a company awash with cash\n- The city is awash with drugs.\n\n\n#### barb\nå€’åˆº, è”ç³» barbed wire\n\nè¿˜å¯ä»¥ç”¨æ¥ä»£æŒ‡\"å¸¦åˆºçš„è¯\"\n- The **barb** stung her exactly the way he hoped it would.\n\n\n#### belaborâ˜¢\nbe + labor =\u003e to exert one's strength upon\n=\u003e å¼•ç”³ä¸º to explain something more than necessary\n- There is no need to belabor the point.\n\n\n#### be on/riding the crest of a wave\nto be very successful for a limited of time.\n\n- The band are riding the crest of a wave with the success of their new single.\n- Mrs Singh is still riding the crest of a wave of popularity.\n\nåœ¨æ±‰è¯­é‡Œé¢å¯ä»¥ç¿»è¯‘æˆ\"å¦‚æ—¥ä¸­å¤©\", ä¸¤è€…éƒ½æ˜¯æ¯”å–»çš„ç”¨æ³•.\n\n\n#### gargantuan\ngargantuanï¼ˆå·¨å¤§çš„ï¼‰ï¼šæ³•å›½åè‘—ã€Šå·¨äººä¼ ã€‹çš„ä¸»äººå…¬é«˜åº·å¤§\nè‹±è¯­å•è¯ gargantuan æ¥è‡ªæ³•å›½è®½åˆºä½œå®¶æ‹‰ä¼¯é›·ï¼ˆRabelaisï¼‰çš„ä½œå“ã€Šå·¨äººä¼ ã€‹ï¼ˆGargantua and Pantagruelï¼‰ä¸­ä¸»äººå…¬çš„åå­— gargantuaï¼ˆé«˜åº·å¤§ï¼‰ï¼Œgargantua çš„æœ¬æ„æ˜¯â€œå¤§å–‰å’™â€ã€‚é«˜åº·å¤§æ˜¯ä¸€ä¸ªé£Ÿæ¬²å·¨å¤§çš„å·¨äººå›½ç‹ï¼Œä»–å‡ºç”Ÿæ—¶è¦å– 17913 å¤´æ¯ç‰›çš„å¥¶ï¼Œè¡£æœè¦ç”¨å‡ ä¸‡å°ºå¸ƒï¼Œèƒ–å¾—æœ‰åå…«å±‚ä¸‹å·´ï¼Œä»–æŠŠå·´é»åœ£æ¯é™¢çš„å¤§é’Ÿæ‘˜ä¸‹æ¥å½“é©¬é“ƒé“›ï¼Œä»–çš„ä¸€æ³¡å°¿æ·¹æ­»äº† 260416 äººã€‚åœ¨å°è¯´ä¸­ï¼Œæ‹‰ä¼¯é›·ç—›å¿«æ·‹æ·³åœ°æ‰¹åˆ¤æ•™ä¼šçš„è™šä¼ªå’Œæ®‹é…·ï¼Œç‰¹åˆ«ç—›æ–¥äº†å¤©ä¸»æ•™æ¯’å®³å„¿ç«¥çš„ç»é™¢æ•™è‚²ã€‚é«˜åº·å¤§åŸæœ¬èªæ…§è¿‡äººï¼Œä½†å‡ åå¹´çš„ç»é™¢æ•™è‚²å´è¦æŠŠä»–å˜æˆå‘†å¤´å‘†è„‘ï¼Œç³Šé‡Œç³Šæ¶‚ï¼Œåªæœ‰åœ¨æ¥å—äººæ–‡ä¸»ä¹‰æ•™è‚²ä¹‹åæ‰å˜æˆåå‰¯å…¶å®çš„â€œå·¨äººâ€ã€‚\n- gargantuanï¼š [gÉ‘Ë'gÃ¦ntjÊŠÉ™n] adj.å·¨å¤§çš„ï¼Œåºå¤§çš„\n\n\n#### acrimoniousâ˜¢\nacrimonious å’Œ acrid çš„æ„æ€å·®ä¸å¤š, åªä¸è¿‡ acrid æ˜¯å½¢å®¹æ„Ÿå®˜çš„, acrimonious æ˜¯æ¯”å–»çš„ç”¨æ³•, ç”¨æ¥å½¢å®¹è¨€è¯­çš„.\n**acrid**\n- Sharp, strong and bitter to the taste, usually unpleasant.\n**acrimonious**\n- bitter and angry\n\n- I inhale deeply, and yes, smell faintly the sweet **acrid** smell of alcohol.\n- A hundred yards away a dump of Wellington boots, gas masks and capes was fired, and **acrid** smoke enveloped the line of men pushing forward to the bridge.\n- â€œLet me handle him,â€ urged a hatchet-faced man with sunken **acrimonious** eyes and a thin, malevolent mouth.\n- Relying on bottled oxygen as an aid to ascent is a practice thatâ€™s sparked **acrimonious** debate ever since the British first took experimental oxygen rigs to Everest in 1921.\n\n#### abateâ˜¢\na- =\u003e to, è¿™é‡Œåº”è¯¥æ˜¯è¡¨ç¤ºå¼ºè°ƒ\nbate =\u003e to beat\n=\u003e beat down, cast down, strike down =\u003e put an end to\n\n- The storm had abated; I was facedown, almost totally buried in sand.\n- Adrenaline had numbed her body for hours, abating all the usual signs of fatigue, but suddenly everything returned in a rush.\n\n#### aggregate \u0026 aggravate\nTo **aggregate** is to collect many units into one. If you're writing a novel, you might create a character who is an aggregate of five or six real people.\n\nPeople who chew with their mouths open often **aggravate** the people near them, meaning that they exasperate their neighbors.\n\n#### turnip\nTurnips are **a root vegetable commonly associated with potatoes or beets**, but their closest relatives are radishes and arugula\n![](notes/2022/2022.7/assets/index%205.jpg)\nèŠœè, åˆç§°ä¸ºè”“èã€è‘‘ã€è¯¸è‘›èœã€å¤§å¤´èœã€åœ†èœå¤´ã€åœ†æ ¹\nWÃº jÄ«ng\nåœ¨å¤ä»£ä¸­å›½ä¸‰å›½æ—¶æœŸèœ€å›½è¯¸è‘›äº®å°†å…¶ä½œä¸ºå†›ç²®ï¼Œè€Œåç¬¬ä¸€æ¬¡ä¸–ç•Œå¤§æˆ˜æ—¶æœŸçš„å¾·å›½ï¼Œä¹Ÿå°†èŠœèä½œä¸ºä¸»è¦çš„åº”æ€¥ç²®é£Ÿè§£å†³å†›ç²®é—®é¢˜ã€‚å°†èŠœèçš„å†…éƒ¨æŒ–ç©ºï¼Œé‡Œé¢å¡å…¥æ£‰å¸ƒå·ï¼Œä¹Ÿå¯å½“æˆç¯æ¥ä½¿ç”¨ã€‚èŠœèå¯é£Ÿç”¨çš„éƒ¨åˆ†æ˜¯çƒèŒï¼Œå»ºè®®ä»¥ç”Ÿé£Ÿä¸ºä½³ï¼Œä¸ä»…å¯ç»´æŒå®ƒæ¸…è„†ã€é²œç”œçš„å£æ„Ÿï¼Œè¿˜å¯é¿å…ç»´ç”Ÿç´  C ç­‰è¥å…»ç´ åœ¨çƒ¹è°ƒè¿‡ç¨‹ä¸­æµå¤±ã€‚ èŠœèä¸èåœåŒå±åå­—èŠ±ç§‘ï¼Œå¹¶ä¸”èåœéƒ¨åˆ†å“ç§è·ŸèŠœèçš„å½¢çŠ¶å¾ˆç›¸ä¼¼ï¼Œéƒ½æ˜¯åœ†çƒçŠ¶ï¼Œæ‰€ä»¥æœ‰äº›äººå°±ä¼šå°†å…¶æ··æ·†ã€‚ä½†æ˜¯ä¸¤ç§æ¤ç‰©è¿˜æ˜¯æœ‰åŒºåˆ«çš„ã€‚\n\n\n#### abrogateâ˜¢\nab- =\u003e off, away from\nrogate =\u003e rog + ate, to propose (a law), ask, request, å…¶ä¸­ rog çš„æ„æ€æ˜¯\"move in a straight line\" =\u003e æ‰‹ä¼¸å‡ºå»å°±æ˜¯ \"to stretch out (the hand)\" =\u003e å¼•ç”³ä¸º to propose, ask.\n=\u003e æŠŠä¼¸å‡ºå»çš„æ‰‹ç¼©å›æ¥ =\u003e å¼•ç”³ä¸º\"annul, repeal\", å¤šç”¨äº formal çš„åœºåˆ, æ¯”å¦‚å›½å®¶ abrogate æ³•å¾‹, å›½é™…ç»„ç»‡ abrogate æ¡çº¦, æ€»ç»Ÿ abrogate æ³•è§„\n\n\n#### allude / allure\n**allude** =\u003e make a more or less disguised reference to\n- â€œHe alluded to the problem but did not mention itâ€\n\n**allure** =\u003e dispose or incline or entice to, the power to entice or attract through personal charm\n- Sheâ€™s actually smiling, coquettishly even; thereâ€™s a hint of her former small-screen mannequinâ€™s allure, flickering over her face like momentary static. [The Handmaid's Tale]\n- The young man in the picture exuded virile allure.\n\n#### aloft / aloof\nSomeone who's **aloof** isn't warm and friendly, instead being distant and reserved. That emotionally cold and detached fellow who keeps to himself, drinking espresso and reading French philosophy, would best be described as aloof.\n- As he lost his **aloof**, thorny manner, he was welcomed by the fashionable crowd.\n\nSomething up in the air or really high is **_aloft**._ _Aloft_ has a soft, floaty sound to it, and it's a great word for talking about flying birds, airborne ballet dancers, and soaring spitballs.\n- The nose of the plane rose up and we were **aloft**.\n\n\n#### appropriate\nappropriate ç”¨åœ¨é’±æ¬¾ä¸Šé¢ä¸ä¸€å®šå°±æ˜¯\"æŒªç”¨, ä¾µå\"çš„æ„æ€. å¦‚æœæ”¿åºœ appropriate äº†æŸä¸ª fund ç”¨äºæŸä¸ªé¡¹ç›®, åˆ™ appropriate çš„æ„æ€æ˜¯\"æ‹¨æ¬¾, reserve\"çš„æ„æ€\n\n#### observeâ˜¢\nobserve æœ‰ä¸¤ä¸ªæ„æ€æˆ‘ä¹‹å‰æ²¡æœ‰æ³¨æ„åˆ°; \n\n**to make a remark about something**\nè¯´ï¼Œè®²ï¼›è¯„è®ºï¼Œè¯„è¿° formal\n- \"I've always found German cars very reliable,\" he observed. â€œæˆ‘ä¸€ç›´è®¤ä¸ºå¾·å›½æ±½è½¦å¾ˆå¯é ï¼Œâ€ä»–è¯´é“ã€‚\n-  She observed that it would soon be time to stop for lunch. å¥¹è¯´å¾ˆå¿«å°±åˆ°åœä¸‹æ¥åƒåˆé¥­çš„æ—¶é—´äº†ã€‚\n\n**to obey a law, rule, or custom**\néµå®ˆï¼Œå¥‰è¡Œï¼ˆæ³•å¾‹ã€è§„åˆ™æˆ–ä¹ ä¿—ï¼‰formal\n- People must observe the law. Nobody should be an exception. äººä»¬å¿…é¡»éµçºªå®ˆæ³•ï¼Œè°éƒ½ä¸åº”è¯¥ä¾‹å¤–ã€‚\n- The old people in the village still observe the local traditions. æ‘é‡Œçš„è€äººä»ç„¶éµå®ˆå½“åœ°çš„ä¼ ç»Ÿã€‚\n- Do you observe Passover? ä½ ä»¬è¿‡é€¾è¶ŠèŠ‚å—ï¼Ÿ\n\n#### byzantine\n![](notes/2022/2022.7/assets/web3-christy-pantocrator-dianelos-georgoudis-cc-by-sa-3-0.webp)\næ‹œå åº­çš„, å› ä¸ºæ‹œå åº­æ—¶ä»£çš„è‰ºæœ¯é”™ç»¼å¤æ‚, ååˆ†ç²¾ç¾, æ‰€ä»¥byzantine åˆä½œä¸ºä¸€èˆ¬å½¢å®¹è¯, è¡¨ç¤ºvery complicated, difficult to understand, even secretive\n\næ‹œå åº­ï¼ˆByzantine Empireï¼‰æ˜¯ä¸€ä¸ªå¤å¸Œè…ŠåŸå¸‚ï¼Œä¹Ÿä¸ºç°ä»ŠåœŸè€³å…¶ä¼Šæ–¯å¦å¸ƒå°”ï¼ˆå›å£«å¦ä¸å ¡ï¼‰çš„æ—§åï¼Œç›¸ä¼ æ˜¯ä»å¢¨ä¼½æ‹‰æ¥çš„æ®–æ°‘äºå…¬å…ƒå‰ 667 å¹´å»ºç«‹çš„ã€‚ç›´è‡³ 4 ä¸–çºªä¸­æœŸï¼Œè¯¥åŸå‘å±•æˆä¸œç½—é©¬å¸å›½ï¼ˆå³æ‹œå åº­å¸å›½ï¼‰çš„ä¸­å¿ƒï¼Œæ›´åä¸ºå›å£«å¦ä¸å ¡ï¼Œç›´è‡³ 1453 å¹´åˆæ›´åä¸ºç§‘æ–¯å¦ä¸åˆ©è€¶ï¼ˆå›å£«å¦ä¸å ¡çªå¥è¯­å‘éŸ³ï¼‰ã€‚ \n\n#### baroque\nå·´æ´›å…‹è‰ºæœ¯ç®€ç§°å·´æ´›å…‹ï¼ˆæ„å¤§åˆ©è¯­ï¼šBarocco æ³•, è‹±è¯­ï¼šBaroqueï¼‰æ˜¯å¯¹æ¬§æ´² 17 ä¸–çºªæ—¶æµè¡Œè‰ºæœ¯çš„æ€»ç§°ï¼ŒåŸæœ¬æ˜¯æ„å¤§åˆ©æˆå‰§ä¸­çš„ä¸€ç§è¡¨æ¼”æ‰‹æ³•ï¼Œæˆå‰§å®¶éœ€è¦è§‚å¯Ÿå‰§æƒ…æ˜¯å¦å¤„äºå†—é•¿æ¯ç‡¥çš„æ°›å›´ä¹‹ä¸­ï¼Œå¦‚æœå¤„äºå°±ä¼šæ•…æ„å‘å‡ºå·¨å¤§çš„çˆ†ç‚¸å£°ï¼Œåˆ©ç”¨è¿™ç§çªç„¶çš„åˆºæ¿€æ¥å”¤é†’è§‚ä¼—çš„æ³¨æ„ã€‚ \n![ç½—é©¬å¸‚æ¢µè’‚å†ˆçš„åœ£å½¼å¾—å¤§æ•™å ‚ï¼Œç”¨å·´æ´›å…‹è¡¨ç°åº„ä¸¥å¥¢åæ„Ÿ](notes/2022/2022.7/assets/Lazio_Roma_SIgnazio_tango7174.jpg)\nå·´æ´›å…‹è‰ºæœ¯ä»¥è¥¿ç­ç‰™å’Œæ³•å›½ä¸ºä¸­å¿ƒ, åœ¨é›•å¡‘ã€ç»˜ç”»ã€å»ºç­‘ç­‰è§†è§‰åŒ–çš„é¢†åŸŸé‡Œå¤§ä¸ºå‘å±•ï¼Œäº 17 ä¸–çºªæ™šæœŸåœ¨å…¨æ¬§æ´²å¼•å‘é£æ½®ï¼Œæ”¶è·äº†å·¨å¤§çš„åå“ã€‚å°¤å…¶æ˜¯å»ºç­‘é¢†åŸŸçš„å·´æ´›å…‹è‰ºæœ¯ï¼Œæœ€ç»ˆåè¶…äº†åŸå§‹çš„æˆå‰§é¢†åŸŸï¼Œæˆä¸ºç°ä»Šå·´æ´›å…‹çš„ä»£è¡¨ã€‚\n\nå·´æ´›å…‹çš„ä½œå“å¤§é‡ä½¿ç”¨é‡‘è‰²çš„ç‰¹å¾ï¼Œåœ¨è¾¹æ¡†ä¸Šå’Œå†…å®¹ä¸­æ‹©ä¸€ç•™ç™½ï¼Œåœ¨èƒ½æ”¾å…¥è£…é¥°çš„åœ°æ–¹å°½é‡æ”¾å…¥æ–¹å½¢ã€åœ†å½¢ã€ä¸‰è§’å½¢ç­‰å‡ ä½•å›¾å½¢çš„è§„åˆ™è£…é¥°ï¼Œç»™äººä¸€ç§å……æ»¡ä¸¥è‚ƒæ„Ÿå’Œå¯¹ç§°æ„Ÿï¼Œä»¥å‡¡å°”èµ›å®«ä¸ºå…¶è‰ºæœ¯å·…å³°ã€‚å·´æ´›å…‹ä¼ æ‰¿è‡ªæ–‡è‰ºå¤å…´é£æ ¼ï¼Œåœ¨ 18 ä¸–çºªå¼€å§‹è¿›å…¥æ´›å¯å¯å’Œæ–°å¤å…¸ä¸»ä¹‰çš„é¢†åŸŸã€‚ \n\nå’Œ byzantine ä¸€æ ·, baroque è¿™ä¸ªè¯ä¹Ÿè¢«ç”¨äºå½¢å®¹ç²¾ç¾ç¹å¤çš„é£æ ¼. Baroque things are complicated and elaborate. \n- He was a **baroque** figure dressed in theatrical, but elegant, clothes.\n- He is among the most **baroque** of contemporary poets.\n\n#### cholericâ˜¢\n`chol-,chole-,cholo-` \n= bile, è¡¨ç¤ºâ€œèƒ†ï¼Œèƒ†æ±â€ã€‚å¤å¸Œè…Šäººè®¤ä¸ºéœä¹±ä¸é»‘èƒ†æ±è¿‡å¤šæœ‰å…³ï¼Œæ‰€ä»¥ä¹Ÿè¡¨ç¤ºâ€œéœä¹±â€ã€‚æºè‡ªå¸Œè…Šè¯­ khole \"bile.\"\n\nè‹±è¯­å•è¯ choler æ¥è‡ªæ‹‰ä¸è¯­ choleraï¼Œæœ¬æ„æ˜¯èƒ†æ±ã€‚æ ¹æ®ä½“æ¶²å­¦ç†è®ºï¼Œ**èƒ†æ±å¤šçš„äººè„¾æ°”æš´èºæ˜“æ€’**ï¼Œå› æ­¤åŸæœ¬è¡¨ç¤ºèƒ†æ±çš„å•è¯ choler è¡ç”Ÿå‡ºâ€œæ„¤æ€’â€ä¹‹æ„ã€‚å¦ä¸€ä¸ªè¡¨ç¤ºâ€œèƒ†æ±â€çš„å•è¯ bile åœ¨å£è¯­ä¸­ä¹Ÿå¸¸å¸¸è¢«ç”¨æ¥è¡¨ç¤ºâ€œæ„¤æ€’â€ã€‚\n\n- cholerï¼š['kÉ’lÉ™] n. èƒ†æ±ï¼Œæ„¤æ€’\n- cholericï¼š['kÉ‘lÉ™rÉªk] adj. æ˜“æ€’çš„ï¼›æš´èºçš„ï¼›èƒ†æ±è´¨çš„\n- cholera éœä¹±\n- bileï¼š[baÉªl] n. èƒ†æ±ï¼Œæ„¤æ€’\n\n#### cleave\ncleaveæœ‰ä¸¤ä¸ªçœ‹ä¸Šå»å¾ˆçŸ›ç›¾çš„æ„æ€:\nCleave, a verb, has two very different meanings. It can describe **cutting or splitting something apart with a sharp instrument**, or â€” oddly enough â€” it can describe **sticking to something like glue**.\n\nTo cleave or not to cleave, that is the question. Cleave can refer to being in close contact, to staying really, really close to someone or something: \"If you are walking in the pitch-black woods without a flashlight, you want to cleave to the person in front of you.\" On the other hand, it can mean to split apart with a sharp tool â€” which is not the action you want to happen while walking in the woods. We've seen that movie.\n\ncleave to ... =\u003e be loyal to ...\n\n#### cossetâ˜¢\næ¥è‡ªå¤è‹±è¯­ cot-sit, å…¶ä¸­ cot æ˜¯å©´å„¿åºŠçš„æ„æ€, ååœ¨å©´å„¿åºŠé‡Œé¢çš„å°å­©æ˜¯è¢«å® çˆ±çš„, =\u003e å¼•ç”³ä¸º\"to give a lot of attention to making someone comfortable and to protecting them from anything unpleasant\", å¯ä»¥ç¿»è¯‘æˆ\"å® çˆ±\"ä¹Ÿå¯ä»¥ç¿»è¯‘æˆ\"æººçˆ±\", è¤’ä¹‰è´¬ä¹‰çš†å¯\n\n\n#### coward / cowardice / cower\nå‰ä¸¤ä¸ªæ˜¯ wArd, è€Œåé¢ä¸€ä¸ªæ˜¯ wEr, è™½ç„¶ä¸‰ä¸ªå•è¯çš„æ„æ€å¾ˆç›¸è¿‘, ä½†æ˜¯ cower çš„è¯æ ¹æ˜¯ä¸ä¸€æ ·çš„.\n\nè¿˜æœ‰ä¸€ä¸ªæ„æ€å·®ä¸å¤šçš„å•è¯æ˜¯ craven =\u003e extremely cowardly\n\n\n#### hermetic\nå¾ˆå¤šç‚¼é‡‘æœ¯å£«ã€ç¥ç§˜å­¦å­¦è€…å’Œæ–°æŸæ‹‰å›¾å­¦æ´¾å­¦è€…è®¤ä¸ºï¼ŒåŸƒåŠç¥è¯ä¸­çš„æ™ºæ…§ä¹‹ç¥æ‰˜ç‰¹ï¼ˆThothï¼Œåˆè¯‘é€ç‰¹æˆ–å›¾ç‰¹ï¼‰ç­‰åŒäºå¸Œè…Šç¥è¯ä¸­çš„èµ«å°”å¢¨æ–¯ï¼ˆHermesï¼‰ã€‚æ‰˜ç‰¹æ˜¯å¤åŸƒåŠç¥è¯çš„æ™ºæ…§ä¹‹ç¥ï¼Œç›¸ä¼ æ˜¯å¤åŸƒåŠæ–‡å­—çš„å‘æ˜è€…ã€‚äººä»¬å°†æ‰˜ç‰¹å°Šç§°ä¸ºâ€œä¸‰å€ä¼Ÿå¤§çš„èµ«å°”å¢¨æ–¯â€(Hermes Trismegistos, å³ Thrice-Great Hermes)ï¼Œå› ä¸ºä»–æ˜¯æœ€ä¼Ÿå¤§çš„å“²å­¦å®¶ã€æœ€ä¼Ÿå¤§çš„ç¥­å¸ã€æœ€ä¼Ÿå¤§çš„å›½ç‹ã€‚ä¸‰å€ä¼Ÿå¤§è¿˜æœ‰å¦ä¸€ç§è§£é‡Šï¼šé‚£å°±æ˜¯æ‰˜ç‰¹ï¼ˆæˆ–èµ«å°”å¢¨æ–¯ï¼‰çš„å­¦é—®è¢«åˆ†ä¸ºä¸‰å¤§åˆ†æ”¯ï¼šç‚¼é‡‘æœ¯ã€å æ˜Ÿæœ¯å’Œå·«æœ¯ï¼Œå®ƒä»¬è¢«è®¤ä¸ºæ˜¯å®‡å®™æ™ºæ…§çš„ä¸‰ä¸ªæ–¹é¢ã€‚æ‰˜ç‰¹åˆ›ç«‹äº†èµ«å°”å¢¨æ–¯ç¥æ™ºå­¦ï¼Œæ®è¯´å®Œå…¨å¯†å°ç»ç’ƒç“¶çš„æ–¹æ³•å°±æ˜¯ä»–å‘æ˜çš„ã€‚ä»èµ«å°”å¢¨æ–¯çš„åå­— Hermes è¡ç”Ÿå‡ºè‹±è¯­å•è¯ hermeticã€‚\n- hermeticï¼š[hÉœË'metÉªk] adj. å¯†å°çš„ï¼Œä¸é€æ°”çš„ï¼Œç‚¼é‡‘æœ¯çš„ n. ç‚¼é‡‘æœ¯å£«\n- hermeticalï¼š[hÉ'mÉ›tÉªkÉ™l] adj. ä¸é€æ°”çš„ï¼Œä¸å¤–ç•Œéš”ç»çš„\n- hermeticismï¼š[hÉ™:'metisizÉ™m] n. èµ«å°”å¢¨æ–¯ç¥æ™ºå­¦\n\n\n#### embroilâ˜¢\nto get deeply involved in a difficult situation\n - She had no desire to **embroil** herself in lengthy lawsuits with the tabloid newspapers. å¥¹ä¸æƒ³å·å…¥å’Œé‚£äº›å°æŠ¥çš„æ¼«é•¿çš„å®˜å¸çº çº·ä¸­ã€‚\n- The United Nations was reluctant to get its forces **embroiled** in civil war.\n\nè”ç³» embroider, åˆºç»£, åˆºç»£éƒ½æ˜¯å¤æ‚ç²¾å·§çš„, embroiled ä¸€ä¸ªå›°å¢ƒå°±åƒåˆºç»£é”™ç»¼å¤æ‚çš„çº¿ä¸€æ ·, éš¾ä»¥è§£å¼€\n\nimbroglio é”™ç»¼å¤æ‚çš„å±€é¢, a very confusing and complicated situation, å°±ç›¸å½“äº embroil çš„åè¯,\n\n- It brings Wayne's story to a suitably epic conclusion while at the same time offering the dramatic **imbroglios**, action set pieces, twists and surprises the form demands.\n- After a year of false starts and legal **imbroglios**, the contentious nightclub Brooklyn Mirage opened last Saturday as a huge, architecturally ambitious destination for deep house and techno parties.\n\n#### inclementâ˜¢\nclement æ˜¯\"æ¸©å’Œçš„\"æ„æ€, in + clement å°±æ˜¯\"ä¸æ¸©å’Œçš„\", è¿™ä¸¤ä¸ªè¯éƒ½ç‰¹æŒ‡å¤©æ°”, inclement é€šå¸¸ç”¨äºæŒ‡ cold, stormy çš„å¤©æ°”, \n\n#### industrious / industrial\nindustrious =\u003e äººå‹¤åŠ³çš„, å‹¤å¥‹çš„\nindustrial =\u003e å·¥ä¸šçš„\n\n#### indulge\n- indulge\n- indulgent\n- indulgence\n\n\n#### institute\nä½œä¸ºåŠ¨è¯, institute å¹¶ä¸ä¸€å®šæ˜¯è¦å»ºç«‹æŸä¸ª institution, åªè¦ start å°±å¯ä»¥äº†, å½“ç„¶è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒ formal'çš„ word\n- To institute something means to establish or advance it. You might institute the hiring of Spanish-speakers at your company, or, if workers complain about being overworked, you might institute a new policy on taking breaks.\n- The woman had had a child, and her boyfriend did not want to marry her; she was seeking to **institute** an action against him.\n\ninstitute è¿˜å¯ä»¥ä½œä¸ºåè¯, å¤§æ¦‚ç›¸å½“äºæ±‰è¯­é‡Œé¢çš„\"æœºæ„, ç ”ç©¶æ‰€, å­¦é™¢\", institution å’Œ institute çš„åŒºåˆ«å¹¶ä¸å¤§, ç½‘ä¸Šä¸€äº›è®ºå›çš„è®¨è®ºä¹Ÿæ²¡æœ‰å¾ˆæ˜ç¡®çš„ç»“è®º. ä¸è¿‡ä¼¼ä¹ institute æ›´åå‘äºæ•™è‚², ç§‘å­¦æœºæ„, æ¯”å¦‚ Massachusetts Institute of Technology.\n\n#### mettleâ˜¢\n**ability and determination** when competing or doing sth **difficult**, **ability to do sth well** under **difficult** circumstances.\nå›°å¢ƒä¸‹çš„åšæŒ, æ‰å¹²ä¸å‹‡æ°”, è¿™ä¸ªè¯æ„Ÿè§‰ç”¨ä¸­æ–‡é‡Œé¢çš„ä¸€ä¸ªè¯è¯´ä¸å…¨é¢.\n\n- The team showed/proved its **mettle** in the final round. \n- The real test of her political **mettle** came in the elections.\n\n**on your mettle**\nå¤§æ¦‚å°±æ˜¯å±•ç¤ºä½ çš„ mettle çš„æ„æ€, å°±æ˜¯åœ¨ä¸€ä¸ªå›°éš¾çš„å±€é¢ä¸‹å…¨åŠ›ä»¥èµ´çš„æ„æ€.\n- Both players were **on their mettle** in the final round. \n- Cooking for such important people really **puts you on your mettle**.\n\n#### posit / postulateâ˜¢\nposit = postulate\n- Starvation was **posited** as the most probable cause of death.\n- He **posited** three basic laws of nature\n- I started to think a lot about infinity, and what it was like there, and how all the **postulates** and theorems and principles were true across all the universe.\n- Others **postulate** that a mini black hole passed through the Earth in Siberia and out the other side.\n\n#### agape / agog\nè¿™ä¸¤ä¸ªè¯åªæœ‰ä¸€ä¸¢ä¸¢åƒ. \n- agog æ˜¯ååˆ†æ¿€åŠ¨, æœŸç›¼, å…´å¥‹\n- è€Œ agape æ˜¯æŠŠå˜´å·´å¼ å¼€, è™½ç„¶ agog çš„æ—¶å€™ä¹Ÿå¯èƒ½æŠŠå˜´å·´å¼ å¼€, ä½†æ˜¯å˜´å·´å¼ å¼€ä¹Ÿå¯ä»¥è¡¨ç¤ºæƒŠè®¶ç­‰ç­‰. \n\n##### agape\nagape åœ¨è¯å…¸é‡Œé¢æœ‰ä¸¤ä¸ªè¯»éŸ³, è¿™æ˜¯å› ä¸ºä¸¤ä¸ªè¯»éŸ³çš„æ„æ€ä¸ä¸€æ ·: \n\n\u003e agape is pronounced either â€œuh-gaypeâ€ or â€œuh-gah-payâ€, depending on which meaning youâ€™re referring to.\n\u003e \n\u003e The first pronounciation (a-gape) refers to a personâ€™s mouth being wide open in surprise, wonder or astonishment. Itâ€™s an adjective.\n\u003e \n\u003e The second pronounciation (a-ga-pe) has Greek origins and means the highest form of love - the love of God for man, under unconditional circumstances.\n\n\n#### baitâ˜¢\næ³¨æ„ bait ä½œä¸ºåŠ¨è¯å¹¶ä¸æ˜¯\"è¯±æƒ‘\"çš„æ„æ€, è€Œæ˜¯\"æ¿€æ€’\"çš„æ„æ€. \n- to intentionally make a person angry by saying or doing things to annoy them.\n\n- He delighted in baiting his mother.\n\nè€Œ\"è¯±æƒ‘\"å¯ä»¥å¯¹åº”å•è¯\"entrap\"\n\n\n#### demoralize\nè¿™é‡Œçš„ moral æ˜¯ morale çš„æ„æ€, æ‰€ä»¥ demoralize æ˜¯ dishearten, discourage çš„æ„æ€.\n- Losing several games in a row had completely demoralized the team. è¿ç»­è¾“æ‰æ•°åœºæ¯”èµ›ä½¿å…¨é˜Ÿä¸Šä¸‹å½»åº•æ³„äº†æ°”ã€‚ \n\n#### masquerade\nå¯ä»¥è®°å¿†ä¸º mask(q)uerade  =\u003e ç”¨maskä¼ªè£….\n\n-   He listed all the different things his mother would put in it, like cauliflower, peas, onions, and his least favorite, turnips that **masqueraded** as the much more palatable potato until he bit into them.\n-   A friend who was in the class said the teacher was just a wild-haired disorganized person **masquerading** as a wild-haired creative person.\n-   It was human history, **masquerading** as Godâ€™s Purpose, revealing herself to an under-age audience.\n-   It **masquerades** as a two-dollar word, but itâ€™s really worth only about twenty cents.\n\n\n#### applicable\nå°±æ˜¯ apply çš„ adj å½¢å¼\n\n\n#### gorge / disgorge\ngorge æœ¬æ„æ˜¯\"throat, å–‰å’™\", åæ¥å¼•ç”³ä¸º\"ç‹¼åè™å’½\"çš„æ„æ€\n\n- å³¡è°·ä¸¤è¾¹å¾ˆé™¡å³­, ä¸­é—´æœ‰ä¸€æ¡æ²³æµ, å’Œå–‰å’™æœ‰ç›¸ä¼¼ä¹‹å¤„, æ‰€ä»¥ gorge ä¹Ÿå¼•ç”³ä¸º\"å³¡è°·\"çš„æ„æ€\n\ndisgorge å°±æ˜¯ gorge çš„åä¹‰è¯, \n- å¤§é‡æ’æ”¾ï¼ˆæ¶²ä½“ã€æ°”ä½“ç­‰ç‰©è´¨ï¼‰\n\t- The pipe was found to be **disgorging** dangerous chemicals into the sea. \n- ï¼ˆåŒæ—¶ä»æŸåœ°ç‚¹æˆ–è½¦è¾†ä¸­ï¼‰æ¶Œå‡ºï¼ˆäººï¼‰\n\t- The delayed commuter train **disgorged** hundreds of angry passengers. \n- ï¼ˆä»èƒƒé‡Œï¼‰åå‡º\n\t- Flies **disgorge** digestive fluid onto their food to soften it up. \n- ä¸æƒ…æ„¿åœ°æä¾›ï¼ˆä¿¡æ¯ï¼‰ï¼›è¢«è¿«äº¤å‡ºï¼ˆé‡‘é’±ï¼‰\n\t- The judge has forced EXIP to **disgorge** $400,000 in illegal profits.\n\n\n#### bombast / bombardâ˜¢\nbombast =\u003e pomposity, ranting, bragging, æµ®å¤¸çš„ç©ºè¯\nbombard =\u003e è¿ç»­è½°ç‚¸\n\n- bombast =\u003e bombastic(adj.)\n- bombard =\u003e bombardment(n.)\n\n#### Bravado / Bravura\n\n**Bravado**: A swaggering show of courage\n- His tales of adventure are always told with **bravado**\n\n**Bravura**: Brilliant and showy technical skill\n- In a final **bravura** the ballerina(female ballet dancer) appeared to be floating in water\n\n\n#### ethereal / ephemeral\n##### ethereal\nSomething ethereal is **airy and insubstantial**, like a ghostly figure at the top of the stairs. This word can also describe something delicate and light, like a singerâ€™s ethereal voice.\n\nEthereal comes from the Greek word for ether, which means â€œairâ€ or more specifically â€œthe upper regions of space.â€ An ethereal substance or sound is one that carries the feeling of light and air â€” something you might see in a vision that strikes you as heavenly or supernatural.\n\n\n##### ephemeral\nSomething that is **fleeting or short-lived** is ephemeral, like a fly that lives for one day or text messages flitting from cellphone to cellphone.\n\nEphemeral (É™-FEM-É™r-É™l) was originally a medical term with the specific meaning \"lasting only one day,\" as a fever or sickness (Hemera means \"day\" in Greek.) The word became more general, coming to mean \"lasting a short time,\" covering the life spans of plants or insects and then eventually anything that is fleeting or transitory. A related word is the plural noun ephemera, meaning \"things that are meant to last for only a short time.\" Posters for a rock concert are often ephemera, unless the band is so famous that they get saved and sold on eBay.\n\nA thing can be ethereal but not ephemeral, like a nebula.\nA thing can also be ephemeral but not ethereal, like the Qin Empire.\n\n#### impetusâ˜¢\nAn **impetus** is **the force behind something**, whether it's a boulder rolling down a hill or a person making a decision.\n\nVery little would get done if there were no such thing as an impetus: an impetus is **some kind of force that gets something or somebody moving**. If you push a car that's out of gas, you're the impetus that's getting it moving. An impetus doesn't have to be physical. Advertisers hope their commercials will be an impetus to buy the product.\n\n- The recent publicity surrounding homelessness has given (a) fresh **impetus** to the cause.\n\n##### impetuous\nimpetus çš„å½¢å®¹è¯å½¢å¼å°±æ˜¯ impetuous, \"å……æ»¡ impetus çš„\", è¯ä¹‰è´¬ä¹‰åŒ–, å°±å˜æˆäº†å†²åŠ¨çš„, é²è½çš„, è‰ç‡çš„, è½»ç‡çš„ çš„æ„æ€äº†.\n\nHe was young and **impetuous**.\nHe tended to react in a heated and **impetuous** way.\n\n#### immemorialâ˜¢\nancient\n- a modern version of immemorial myth.\n\n**since/from time immemorial**\nfor a very long time =\u003e ç›¸å½“äº\"è‡ªå¤ä»¥æ¥\", æ˜¯ä¸€ç§å›ºå®šæ­é…\n- Her family had farmed that land since time immemorial.\n\n\n#### raveâ˜¢\nrave å¼ºè°ƒçš„æ˜¯è¯´è¯æ—¶ååˆ†æ¿€åŠ¨çš„çŠ¶æ€, è¯´çš„è¯å¯ä»¥æ˜¯å¥½çš„, ä¹Ÿå¯ä»¥æ˜¯åçš„\n- Grandpa is silent as I rant and **rave**.\n- â€œOh, Frightful,â€ I said, â€œyou are a **raving** beauty.â€\n- â€œThis child is going to wind up stark **raving** mad!â€\n- But tomorrow, I might be **raving** that my parents are trying to kill me, and Iâ€™ll believe it as completely as I believe the earth is round.\n- She **raved** about/over the clothes she had seen at the Paris fashion shows. å¥¹å¯¹å·´é»æ—¶è£…å±•ä¸Šå±•å‡ºçš„æœè£…èµä¸ç»å£ã€‚\n- The show has received **rave** reviews/notices in all the papers. è¿™åœºæ¼”å‡ºå—åˆ°æ‰€æœ‰æŠ¥çº¸çš„é«˜åº¦è¯„ä»·ï¼å¸å¼•äº†æ‰€æœ‰æŠ¥çº¸çš„æ³¨æ„å¹¶å¾—åˆ°çƒ­æƒ…æ´‹æº¢çš„æŠ¥é“ã€‚\n\n\n#### vitiate\nAs some sneaky five-year-olds know, crossing oneâ€™s fingers while making a promise is an effective way to **vitiate**, or destroy the validity of, an agreement.\n\nVitiate is often used when a legal agreement is made invalid, but it can also refer to the debasement or corruption of something or someone. If a malicious five-year-old on the playground teaches the other children to lie with their fingers crossed, she would be responsible for vitiating the playground community. The first syllable of this word is pronounced \"vish,\" like the first syllable in vicious.\n\n##### Why do we cross our fingers for luck and also cross them when we tell a lie?\n![](notes/2022/2022.7/assets/210px-Hands-Fingers-Crossed.jpg)\næœ‰è¶£çš„æ˜¯, Finger-crossing æ—¢å¯ä»¥ç”¨äºç¥ˆæ±‚å¥½è¿, ä¹Ÿå¯ä»¥åœ¨æ’’è°çš„æ—¶å€™ç”¨æ¥å…é™¤è‡ªå·±çš„\"ç½ªè´£\". \n\n\u003e It is speculated that Christians started making the cross symbol with their fingers when lying to protect themselves against Godâ€™s wrath for breaking one of the commandments. As to when this started, it has been speculated that it dates all the way back to the beginnings of Christianity. . . when Christians had to lie about being Christians since the religion was outlawed, often under penalty of death. However, as with the â€œluckâ€ finger crossing, direct evidence is hard to come by, so weâ€™re left with educated theories.\n\u003e \n\u003e These days we often use the evocative power of words to accomplish the same end, with phrases like â€˜I have my fingers crossed,â€™ when wishing for good luck, and the kidsâ€™ response: â€˜You canâ€™t get me: I had my fingers crossed!â€™ when theyâ€™re trying to catch one another in a lie.\n\n#### compress\ncompressæ—¢å¯ä»¥æŒ‡ç‰©ç†ä¸Šçš„\"æŒ‰å‹, å‹ç¼©\", ä¹Ÿå¯ä»¥æŒ‡æŠ½è±¡æ„ä¹‰ä¸Šçš„\"å‹ç¼© =\u003e ç¼©çŸ­, ç²¾ç‚¼\", è®¡ç®—æœºé‡Œé¢çš„æ–‡ä»¶å‹ç¼©ä¹Ÿå«\"compress\"\n\n- Firmly **compress** the soil in the pot so that the plant is secure. æŠŠç›†é‡Œçš„åœŸå‹å®ä½¿æ¤æ ªå›ºå®šã€‚\n- **compressed** air å‹ç¼©ç©ºæ°”\n- The course **compresses** two year's training into six intensive months. è¿™é¡¹è¯¾ç¨‹æŠŠä¸¤å¹´çš„åŸ¹è®­å†…å®¹å‹ç¼©æˆ 6 ä¸ªæœˆçš„å¼ºåŒ–è®­ç»ƒã€‚\n- I managed to **compress** ten pages of notes into four paragraphs. æˆ‘è®¾æ³•æŠŠ 10 é¡µçš„ç¬”è®°å‹ç¼©æˆäº† 4 ä¸ªæ®µè½ã€‚\n- to **compress** data/files å‹ç¼©æ•°æ®ï¼æ–‡ä»¶\n\n\n#### courteousâ˜¢\næœ‰ç¤¼è²Œçš„, ä¸æ˜¯ä¸€ä¸ªè´¬ä¹‰è¯!\n\n#### clarion\nclarion å‡ ä¹æ€»æ˜¯å‡ºç°åœ¨è¯ç»„\"clarion call\"é‡Œé¢, è¡¨ç¤º\"...çš„å·è§’, å·å¬\"çš„æ„æ€. \n- ... to issue/sound a clarion call for change\n\nå…³äº clarion çš„å†å²ç½‘ä¸Šè¯´æ³•ä¸ä¸€, æœ‰çš„äººè®¤ä¸ºè¿™æ˜¯ä¸€ç§éŸ³è°ƒå¾ˆé«˜çš„ trumpet, æœ‰çš„äººè®¤ä¸ºè¿™åªæ˜¯å°å·çš„é«˜éŸ³åŸŸ(high register), (æ²¡æœ‰æ‰¾åˆ°å…³äº clariond çš„æ–‡ç‰©å›¾ç‰‡), ä½†æ€»ä¹‹ clarion çš„å£°éŸ³ä¸€å®šæ˜¯å¾ˆå“äº®çš„, å¾ˆé«˜æ˜‚çš„.\n\n#### loath / loathe,  Is It 'Loath' or 'Loathe'?\n'**Loath**' is an **adjective**; '**loathe**' is a **verb**. \n![](notes/2022/2022.7/assets/loathe-2551-7f04a097ca502926e8fea6d11e80f09b@1x.jpg)\nFor example: \"No wonder my child **loathes** his food; I'm **loath** to try it myself.\"\n\n**Loathe** is a verb (â€œto dislike greatlyâ€). You loathe that guy at work who steals your food from the refrigerator (you probably loathe many more people than that, but the guy who steals your food is just the most convenient example).\n\n**Loath** is an adjective (â€œnot willingâ€). You are loath to confront the guy at work who keeps stealing your food from the refrigerator, because he often talks to himself and has a peculiar smell.\n\n#### stouthearted\nstout =\u003e ç»“å®çš„, é¡½å¼ºçš„\nheart\ned\n=\u003e å¿ƒè„å¼ºå¤§çš„ =\u003e brave and determined\n\n- Even the most stouthearted of hikers would have had to turn back in this weather.\n\n\n#### adumbrateâ˜¢\nad- =\u003e to\numbr =\u003e shadow, to cast in a shadow\nate\n=\u003e to cast a shadow over =\u003e to outline, sketch\nç”¨å½±å­æ¥è¡¨ç¤ºæŸä¸ªæ›´åŠ å¤æ‚çš„ä¸œè¥¿, ä¹Ÿå°±æ˜¯å¤§æ¦‚æè¿°çš„æ„æ€.\n![](notes/2022/2022.7/assets/ART_Light_and_shadows_ObjectShadowsInSand.jpg)\n\n#### umbrage\nè¿™é‡Œçš„è¯æ ¹å’Œ adumbrade ä¸€æ ·, umbrage å¯ä»¥ç†è§£ä¸ºè¢«é˜´å½±è¦†ç›–çš„çŠ¶æ€, ä¹Ÿå°±æ˜¯è¢«å†·è½äº†, è¢«å¿½è§†äº†, æ²¡æœ‰è¢«å°Šé‡, é€šå¸¸ç”¨åœ¨å›ºå®šè¯ç»„\"take umbrage\"é‡Œé¢.\n\n![400](notes/2022/2022.7/assets/big-businessman-overshadow-to-small-businessman-yellow-background-as-metaphor-73114032.jpg)\n\n\n#### ostensible / ostentatiousâ˜¢\n**ostensible**\nappearing or claiming to be one thing when it is really something else\nè¡¨é¢ä¸Šçš„ï¼›å‡ç§°çš„ï¼Œå‡æ‰˜çš„\n\n**ostentatious**\ntoo obviously showing your money, possessions, or power, in an attempt to make other people notice and admire you\né“ºå¼ çš„ï¼Œæ‘†é˜”çš„ï¼›ç‚«è€€çš„ï¼Œå–å¼„çš„ï¼›æ‹›æ‘‡çš„\n\n\n#### puissance / impuissanceâ˜¢\npuissance æ˜¯æƒåŠ›çš„æ„æ€, è€Œ impuissance æ‰æ˜¯è½¯å¼±æ— èƒ½çš„æ„æ€, imå‰ç¼€è¡¨ç¤ºç¼ºå°‘. å®¹æ˜“è¢«~~pussy~~è¿™ä¸ªå•è¯å½±å“è€Œææ··\n\n\n\n#### slipshod\nè¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„å•è¯, slip =\u003e slippers ä¹Ÿå°±æ˜¯æ‹–é‹, shod =\u003e\"wearing shoes\" , åˆèµ·æ¥å°±æ˜¯\"wearing slippers or loose shoes\", \"ç©¿æ‹–é‹çš„\"\nåœ¨å¤§è¡—ä¸Šçœ‹åˆ°ç©¿æ‹–é‹çš„, èµ°è·¯å¤§å¤§å’§å’§çš„äººæˆ‘ä»¬ä¼šè§‰å¾—ä»–ä»¬å¾ˆæ•£æ¼«, è€Œå¤äººä¹Ÿè¿™ä¹ˆè§‰å¾—, æ‰€ä»¥ slipshod ä¹Ÿå°±æœ‰äº†\"å·¥ä½œé©¬è™çš„, ä¸ä¸¥è°¨çš„\"æ„æ€\n\n- She complained that the carpenter's work had been slipshod.\n\n\n#### wholly or wholely ?â˜¢\nwholly æ‰æ˜¯å¯¹çš„!!!!!!!!!\n\n#### loll / lull\nlull =\u003e å®‰é™çš„é—´éš™, å®‰æŠš, ä½¿å®‰é™\nloll =\u003e æ‡’æ•£åœ°èººç€æˆ–è€…åç€\n\n#### waddle or wobble\n- **waddle** is a **swaying gait**, or **to walk with short steps, tilting the body from side to side** \n- **wobble** is an **unsteady motion**, or to move with an uneven or **rocking motion**, or unsteadily to and fro. \n\n**waddle**æ˜¯**æ‘‡æ™ƒç€å‘å‰èµ°**, **wobble**å°±åªæ˜¯**æ‘‡æ™ƒ**è€Œå·²\n\n\n#### bump\nä¸ºäº†åœ¨è®ºå›é‡Œé¢è®©è‡ªå·±çš„å¸–å­é‡æ–°å›åˆ°å¼€å¤´ï¼Œå°±å¯ä»¥å‘ä¸€ä¸ªbumpingï¼Œç±»ä¼¼äºæ±‰è¯­é‡Œé¢çš„â€œé¡¶â€ï¼Œâ€œä¸è¦æ²‰â€\n\n\n#### give you a leg up on...\nåŠ©ä½ ä¸€è‡‚ä¹‹åŠ›.\næœ‰è¶£çš„æ˜¯æ±‰è¯­é‡Œé¢æ˜¯æ‰‹è‡‚, è€Œè‹±è¯­é‡Œé¢æ˜¯è…¿, ä¸è¿‡è‹±è¯­é‡Œé¢çš„æ„æ€æ˜¯å°†åŒæ‰‹åˆæ‹¢ä½œä¸ºå…¶ä»–äººè¸©çš„åœ°æ–¹çš„æ„æ€.\n![](notes/2022/2022.7/assets/A-Leg-Up-black-300x300.png)\n- to hold one's hands together so that someone can step into them while climbing up onto something \n\u003e I don't think I can get on this horse without help. Can someone **_give me a leg up_**?\n\n\n#### to top it all off\nIf you have been describing bad things that happened, and then say that **to top it all off** something else happened, you mean that the final thing was even worse:\n- The washing machine started leaking, my car broke down, then **to top it all off** I locked myself out of the house.\n\n\n\n\n\n\n","lastmodified":"2023-11-19T19:19:34.52647389Z","tags":null},"/notes/2022/2022.9/That-being-so-With-that-said-vs-Having-said-this":{"title":"'That being so' \u0026 'With that said' vs 'Having said this'","content":"# å› è€Œ, å°½ç®¡å¦‚æ­¤, è¯è™½å¦‚æ­¤\n\n\u003cdiv align=\"right\"\u003e 2022-09-22\u003c/div\u003e\n\nTags: #English \n\n- 'That being so' ç±»ä¼¼äºæ±‰è¯­é‡Œé¢çš„'å› è€Œ', å‰åä¸¤ä¸ªå¥å­æ˜¯è¡”æ¥å…³ç³», æˆ–è€…å› æœå…³ç³»\n- 'With that said' ç±»ä¼¼äºæ±‰è¯­é‡Œé¢çš„'è¯è™½å¦‚æ­¤', è¡¨ç¤ºå¥å­ A å’Œå¥å­ B ä¹‹é—´å‡ºç°äº†ä¸€ä¸ª gap, ä½†æ˜¯å¦å®šæ„æ€æ²¡æœ‰'Having said that'é‚£ä¹ˆçš„å¼ºçƒˆ\n- 'Having said that' ç±»ä¼¼äº'å°½ç®¡å¦‚æ­¤, è¯è™½å¦‚æ­¤' è¡¨ç¤ºå‰åå¥å­å‡ºç°äº†ä¸€ä¸ªå†²çª.\n\nSource: è¿™ä¸ªå›ç­”è¯´çš„å¾ˆå¥½, æœ‰ä¸°å¯Œçš„ä¾‹å¥. [phrase usage - \"That being so\" \u0026 \"With that said\" vs \"Having said this\" - English Language Learners Stack Exchange](https://ell.stackexchange.com/a/182094)\n\n\n","lastmodified":"2023-11-19T19:19:34.52647389Z","tags":null},"/notes/2022/2022.9/Vision-Transformer-ViT":{"title":"Vision Transformer (ViT)","content":"# Vision Transformer\n\n\u003cdiv align=\"right\"\u003e 2022-09-22\u003c/div\u003e\n\nTags: #ViT\n\n## How the Vision Transformer works in a nutshell[^1]\n\nThe total architecture is called Vision Transformer (ViT in short). Letâ€™s examine it step by step.\n\n1.  **Split** an image into **patches**\n2.  **Flatten** the patches\n3.  Produce lower-dimensional **linear embeddings** from the flattened patches\n4.  Add **positional embeddings**\n5.  Feed the sequence as an input to a **standard transformer encoder**\n6.  **Pretrain** the model with image labels (fully supervised on a huge dataset)\n7.  **Finetune** on the downstream dataset for image classification\n\n![](notes/2022/2022.9/assets/img_2022-10-15.gif)\n\n\n\n\n\n\n[^1]: [How the Vision Transformer (ViT) works in 10 minutes: an image is worth 16x16 words | AI Summer](https://theaisummer.com/vision-transformer/)","lastmodified":"2023-11-19T19:19:34.52647389Z","tags":null},"/notes/2022/2022.9/indention-in-YAML":{"title":"indention in YAML","content":"# YAMLé‡Œé¢çš„ç¼©è¿›\n\n\u003cdiv align=\"right\"\u003e 2022-09-05\u003c/div\u003e\n\nTags: #YAML #Frontmatter\n\nYAML(YAML Ain't Markup Language)å¯ä»¥åœ¨ Markdown é‡Œé¢ç”¨äºå­˜å‚¨åŸå§‹æ•°æ®. ä½†æ˜¯ YAML é‡Œé¢çš„ç¼©è¿›å´éš¾ä½äº†æˆ‘.\n\nä¸€ä¸ª YAML çš„ä¾‹å­å¦‚ä¸‹:\n```YAML\n doe: \"a deer, a female deer\"\n ray: \"a drop of golden sun\"\n pi: 3.14159\n xmas: true\n french-hens: 3\n calling-birds:\n Â Â - huey\n Â Â - dewey\n Â Â - louie\n Â Â - fred\n xmas-fifth-day:\n Â Â calling-birds: four\n Â Â french-hens: 3\n Â Â golden-rings: 5\n Â Â partridges:\n Â Â Â Â count: 1\n Â Â Â Â location: \"a pear tree\"\n Â Â turtle-doves: two\n```\nå¯ä»¥çœ‹åˆ° YAML æ˜¯å…è®¸ç¼©è¿›çš„, ä½†æ˜¯å®¹æ˜“å¿½è§†çš„ä¸€ç‚¹æ˜¯: **YAML é‡Œé¢çš„ç¼©è¿›åªèƒ½æ˜¯ç©ºæ ¼(Space), ä¸å¯ä»¥æ˜¯åˆ¶è¡¨ç¬¦(Tab)**.\nè¿™æ˜¯å› ä¸º Tab åœ¨ä¸åŒçš„æ–‡å­—å¤„ç†è½¯ä»¶é‡Œé¢çš„å¤„ç†æ–¹å¼å„ä¸ç›¸åŒ, è€Œ YAML çš„è®¾è®¡åˆè¡·å°±æ˜¯ä¸ºäº†è®©å®ƒç®€å•é€šç”¨.\n\nSource: [YAML Tutorial: Everything You Need to Get Started in Minutes | Cloudbees Blog](https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started)\n","lastmodified":"2023-11-19T19:19:34.550474282Z","tags":null}}