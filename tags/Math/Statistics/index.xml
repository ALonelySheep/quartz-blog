<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Math/Statistics on</title><link>https://alonelysheep.github.io/quartz-blog/tags/Math/Statistics/</link><description>Recent content in Math/Statistics on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/Math/Statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>Likelihood_Function-似然函数</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/Likelihood_Function-%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0/</link><pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/Likelihood_Function-%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0/</guid><description>Likelihood Function - 似然函数 2022-02-11 Tags: #Math/Statistics #MachineLearning
对于某个(某组)随机变量 $X$, 我们通过采样获得了数据集 $x$ :
似然函数$\mathcal{L}(\theta \mid x)$就是在某个参数(parameter) $\theta$ 下, 现有数据 $x$ 出现的概率大小, 也就是说: $$\mathcal{L}(\theta \mid x) = P(X=x\mid\theta)$$ $P(X=x\mid\theta)$ 也常常写作 $p_{\theta}(x)=P_{\theta}(X=x)=P(X=x\space ;\theta)$</description></item><item><title>Dummy_Variables</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.1/Dummy_Variables/</link><pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.1/Dummy_Variables/</guid><description>Dummy Variable 2022-02-10 Tags: #Math/Statistics
Dummy variable (statistics) - Wikipedia
In statistics and econometrics, particularly in regression analysis, a dummy variable is one that takes only the value 0 or 1 to indicate the absence or presence of some categorical effect that may be expected to shift the outcome.</description></item><item><title>D2L-12-Predication_or_Inference-Difference</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-12-Predication_or_Inference-Difference/</link><pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-12-Predication_or_Inference-Difference/</guid><description>Prediction or Inference? The Difference 2022-02-08 Tags: #DeepLearning #Math/Statistics #Inference #Prediction
在深度学习里面, 给定特征估计目标的过程通常称为_预测_（prediction）或_推断_（inference）。 但是, 虽然 推断 这个词已经成为深度学习的标准术语，但其实 推断 这个词有些用词不当。 在统计学中，推断 更多地表示基于数据集估计参数。1 当深度学习从业者与统计学家交谈时，术语的误用经常导致一些误解。2 如Bayesian Inference: Bayesian_Estimation(Inference)贝叶斯估计&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Maximum_Likelihood_Estimation-极大似然估计</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Maximum_Likelihood_Estimation-%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</link><pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Maximum_Likelihood_Estimation-%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</guid><description>极大似然估计 MLE 2021-12-25 Tags: #MachineLearning #Math/Statistics
Links: Likelihood_Function-似然函数
假设样本 $X$ 服从已知的概率分布(比如正态分布)
极大似然估计就是要找一个参数 $\hat\theta$, 使似然函数 $\mathcal{L}(\theta \mid X)$ 取得最大值$$i.e.\quad \hat{\theta}=\operatorname{argmax}_{\theta \in \Theta} \mathcal{L}(\theta \mid X)$$ 极大似然估计认为: 最佳的参数 $\hat\theta$ 最可能使取样结果为现在的 $x$, 也就是说, 概率$P(X=x\mid \theta)$最大: $$\hat{\theta}=\operatorname{argmax}_{\theta \in \Theta} P(X=x\mid \theta)$$</description></item><item><title>参数估计-Parameter_Estimation</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1-Parameter_Estimation/</link><pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1-Parameter_Estimation/</guid><description>参数估计 2021-12-25 Tags: #MachineLearning #ParameterEstimation #Math/Statistics
在设计分类器或者进行回归预测的时候, 我们需要知道目标问题的概率分布情况. 但是通常我们能得到的数据只是一些特例(即训练样本). 为了对问题进行建模, 我们不仅需要确定合适的概率分布模型, 还需要根据训练样本确定模型里面的具体参数. 参数估计就是在模型已知的情况下得到最优参数的过程.
对于贝叶斯分类器, 估计先验概率$P(\omega_i)$通常不是很困难. 难点在于估计类条件概率密度$p(x|\omega_i)$, 这是因为:</description></item><item><title>Covariance-协方差</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Covariance-%E5%8D%8F%E6%96%B9%E5%B7%AE/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Covariance-%E5%8D%8F%E6%96%B9%E5%B7%AE/</guid><description>Covariance 2021-12-11 Tags: #Math/Statistics
期望值分别为 $E(X)=\mu$ 与 $E(Y)=\nu$ 的两个随机变量 X 与 Y 之间的协方差定义为: $$\begin{aligned} \operatorname{cov}(X,Y)&amp;amp;=\mathrm{E}((X-\mu)(Y-\nu))\ &amp;amp;=\mathrm{E}(X \cdot Y-\nu X-\mu Y +\mu\nu)\ &amp;amp;=\mathrm{E}(X \cdot Y)-\nu \mathrm{E}(X)-\mu \mathrm{E}(Y) +\mu\nu\ &amp;amp;=\mathrm{E}(X \cdot Y)-\mu\nu-\mu\nu +\mu\nu\ &amp;amp;=\mathrm{E}(X \cdot Y)-\mu \nu \end{aligned}$$</description></item><item><title>Chernoff Bounds</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Chernoff-Bounds/</link><pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Chernoff-Bounds/</guid><description>Chernoff Bounds 2021-12-04 Tags: #Math/Statistics
probabilitycourse.com - Chernoff Bounds
zotero:@ChernoffBounds(zotero://select/items/@ChernoffBounds)
The generic Chernoff bound for a random variable $X$ is attained by applying Markov&amp;rsquo;s inequality to $e^{tX}$.</description></item><item><title>Chi-Squared_Distribution-卡方分布</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Chi-Squared_Distribution-%E5%8D%A1%E6%96%B9%E5%88%86%E5%B8%83/</link><pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Chi-Squared_Distribution-%E5%8D%A1%E6%96%B9%E5%88%86%E5%B8%83/</guid><description>Chi-Squared Distribution 2021-12-04 Tags: #Math/Statistics
A very Good Website Chi-squared distribution - Wikipedia
重要结论 $Z_{1},Z_{2},\cdots,Z_{n}$ are independent standard normal random variables,</description></item><item><title>Markov's and Chebyshev's Inequalities</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Markovs-and-Chebyshevs-Inequalities/</link><pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Markovs-and-Chebyshevs-Inequalities/</guid><description>Markov and Chebyshev Inequalities 2021-12-04 Tags: #Math/Statistics
FileLink(zotero://select/items/@InequalitiesMarkov)
Markov&amp;rsquo;s Inequality $X$ 是一个非负的随机变量. 对于任意正实数 $a$ , 有 $$ P(X \geq a) \leq \frac{E(X)}{a} $$</description></item><item><title>Moment Generating Function-MGF</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Moment-Generating-Function-MGF/</link><pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Moment-Generating-Function-MGF/</guid><description>Moment Generating Function - MGF 2021-12-04 Tags: #Math/Statistics
This article covers it all. Moment Generating Function Explained | by Aerin Kim | Towards Data Science</description></item><item><title>Union_Bound-布尔不等式-Boole's_inequality</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Union_Bound-%E5%B8%83%E5%B0%94%E4%B8%8D%E7%AD%89%E5%BC%8F-Booles_inequality/</link><pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.12/Union_Bound-%E5%B8%83%E5%B0%94%E4%B8%8D%E7%AD%89%E5%BC%8F-Booles_inequality/</guid><description>Union Bound: 布尔不等式 2021-12-04 Tags: #Math/Statistics
This website explained it well: The Union Bound and Extension Intuition $$\begin{aligned} P(A \cup B) &amp;amp;=P(A)+P(B)-P(A \cap B) \ &amp;amp; \leq P(A)+P(B) .</description></item><item><title>为什么方差的分母常常是n-1</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.10/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%96%B9%E5%B7%AE%E7%9A%84%E5%88%86%E6%AF%8D%E5%B8%B8%E5%B8%B8%E6%98%AFn-1/</link><pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.10/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%96%B9%E5%B7%AE%E7%9A%84%E5%88%86%E6%AF%8D%E5%B8%B8%E5%B8%B8%E6%98%AFn-1/</guid><description>为什么方差的分母常常是$n-1$? 2021-10-29 Tags: #Math/Statistics #Variance
按照定义, 方差的分母的确应该是$n$
但是因为我们用样本的均值$\overline X$代替了数学期望$\mu$, 而这个$\overline X$是有误差的, $\frac 1 n \rightarrow \frac 1 {(n-1)}$是为了消除这个误差.</description></item><item><title>协方差矩阵_Covariance_Matrix</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.10/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5_Covariance_Matrix/</link><pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.10/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5_Covariance_Matrix/</guid><description>Covariance Matrix 2021-10-29 Tags: #Matrix #Math/Statistics
https://janakiev.com/blog/covariance-matrix/
Variance, Covariance Variance measures the variation of a single random variable (like height of a person in a population) $$\sigma_{x}^{2}=\mathbb E \left(\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\right)$$ Link: 为什么方差的分母常常是n-1</description></item><item><title>Part.26_Probabilistic_Interpretation_of_MSE(ML_Andrew.Ng.)</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.9/Part.26_Probabilistic_Interpretation_of_MSEML_Andrew.Ng./</link><pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.9/Part.26_Probabilistic_Interpretation_of_MSEML_Andrew.Ng./</guid><description>均方差的合理性 - 概率解释 2021-09-16 Tags: #MachineLearning #Math/Statistics #MeanSquareError #CostFunction
之前的一些讨论 Mean_Squared_Error-均方误差 Why_do_cost_functions_use_the_square_error CS229 - Probabilistic Interpretation 独立同分布-IID [[notes/2021/2021.</description></item><item><title>正态分布_高斯分布_Normal_Distribution-Gaussian_Distribution</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.9/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83_%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_Normal_Distribution-Gaussian_Distribution/</link><pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.9/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83_%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_Normal_Distribution-Gaussian_Distribution/</guid><description>正态分布 2021-09-16 Tags: #Math/Statistics
概率密度函数 正态分布, 概率密度函数: $$f(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{\Large -\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}}$$ or $$f(x)=\frac{1}{\sigma \sqrt{2 \pi}} \exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}\right)$$
重要性质 Mean $(\mu)$ and standard deviation $(\sigma)$ $$ \begin{aligned} &amp;amp;\mu=E(X)=\int_{-\infty}^{\infty} x p(x) d x \ &amp;amp;\sigma^{2}=E\left{(X-\mu)^{2}\right}=\int_{-\infty}^{\infty}(x-\mu)^{2} p(x) d x \end{aligned} $$</description></item><item><title>独立同分布-IID</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.9/%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83-IID/</link><pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.9/%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83-IID/</guid><description>独立同分布 Independent and identically distributed 2021-09-16 Tags: #Math/Statistics
定义 在概率论与统计学中，独立同分布（英语：Independent and identically distributed，或称独立同分配，缩写为iid、 i.i.d.、IID）是指一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立.</description></item><item><title>拉普拉斯分布与高斯分布的联系_Relation_of_Laplace_distribution _and_Gaussian_distribution</title><link>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.8/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83%E4%B8%8E%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%9A%84%E8%81%94%E7%B3%BB_Relation_of_Laplace_distribution-_and_Gaussian_distribution/</link><pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2021/2021.8/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83%E4%B8%8E%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%9A%84%E8%81%94%E7%B3%BB_Relation_of_Laplace_distribution-_and_Gaussian_distribution/</guid><description>Gaussian distribution, Laplace distribution: The Relation 2021-07-31 Tags: #Math/Statistics #GaussianDistribution #LaplaceDistribution
拉普拉斯分布, 概率密度函数: Look at the formula for the PDF in the infobox &amp;ndash; it&amp;rsquo;s just the Gaussian with $|\boldsymbol{x}-\boldsymbol{\mu}|$ instead of $(\boldsymbol{x}-\boldsymbol{\mu})^{2}$)1</description></item></channel></rss>