<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DenseNet on</title><link>https://alonelysheep.github.io/quartz-blog/tags/DenseNet/</link><description>Recent content in DenseNet on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 07 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/DenseNet/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-46-DenseNet</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.3/D2L-46-DenseNet/</link><pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.3/D2L-46-DenseNet/</guid><description>DenseNet 2022-03-07 Tags: #DenseNet #DeepLearning #CNN ResNet极大地改变了如何参数化深层网络中函数的观点。 稠密连接网络（DenseNet）在某种程度上是ResNet的逻辑扩展。
PDF(zotero://select/items/@huang2017densely)
数学直觉: 从ResNet到DenseNet 某个函数在 $x=0$ 处的泰勒展开为: $$f(x)=f(0)+f^{\prime}(0) x+\frac{f^{\prime \prime}(0)}{2 !</description></item></channel></rss>