<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LSTM on</title><link>https://alonelysheep.github.io/quartz-blog/tags/LSTM/</link><description>Recent content in LSTM on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 18 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/LSTM/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-57-LSTM-长短期记忆网络</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-57-LSTM-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/</link><pubDate>Mon, 18 Apr 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-57-LSTM-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/</guid><description>Long Short-Term Memory 2022-04-18 Tags: #LSTM #DeepLearning #RNN
LSTM是最早用于解决长期依赖问题的一种RNN. 它比GRU复杂, 但是设计思想是一样的. 有趣的是, LSTM(1997)比GRU(2014)早出现近20年.
LSTM和GRU一样, 使用了不同的门(Gate)来控制上一个隐状态在下一个隐状态里面的占比, 也就是有选择地来混合&amp;quot;长期记忆&amp;quot;和&amp;quot;短期记忆&amp;quot;, 这也是其名称的由来.</description></item></channel></rss>