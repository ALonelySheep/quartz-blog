<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>BatchNormalization on</title><link>https://alonelysheep.github.io/quartz-blog/tags/BatchNormalization/</link><description>Recent content in BatchNormalization on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 05 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/BatchNormalization/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-44-Batch_Normalization-批量归一化</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.3/D2L-44-Batch_Normalization-%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/</link><pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.3/D2L-44-Batch_Normalization-%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/</guid><description>Batch Normalization 2022-03-05 Tags: #BatchNormalization #Normalization #DeepLearning #Regularization
批量归一化是一种加速收敛的方法.
批量归一化作用于每一个mini-Batch, 先将这个Batch归一化, 然后再做一个统一的偏移与拉伸.
最后这个偏移和拉伸的量是一个可以学习的超参数 对于全连接层, BN作用于每一个特征</description></item></channel></rss>