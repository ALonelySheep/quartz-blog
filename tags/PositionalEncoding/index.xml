<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PositionalEncoding on</title><link>https://alonelysheep.github.io/quartz-blog/tags/PositionalEncoding/</link><description>Recent content in PositionalEncoding on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 27 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/PositionalEncoding/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-73-Positional_Encoding</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-73-Positional_Encoding/</link><pubDate>Wed, 27 Apr 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-73-Positional_Encoding/</guid><description>位置编码: 将位置信息加入数据 2022-04-27 Tags: #PositionalEncoding #Self-Attention #DeepLearning
为了使用序列的顺序信息，我们通过在输入表示中添加 位置编码（positional encoding）来注入绝对的或相对的位置信息。
我觉得D2L讲的很深入很好了: 10.6. Self-Attention and Positional Encoding</description></item></channel></rss>