<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Convolution on</title><link>https://alonelysheep.github.io/quartz-blog/tags/Convolution/</link><description>Recent content in Convolution on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 27 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/Convolution/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-36-1x1卷积层</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-36-1x1%E5%8D%B7%E7%A7%AF%E5%B1%82/</link><pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-36-1x1%E5%8D%B7%E7%A7%AF%E5%B1%82/</guid><description>$1×1$ 卷积层 2022-02-27 Tags: #CNN #DeepLearning #Convolution
$1×1$ 卷积，即 $k_h=k_w=1$，它虽然不能提取相关特征, 但是却能融合图像的不同通道, 也是一种很受欢迎的网络结构.
它相当于输入形状为 $n_{h} n_{w} \times c_{i}$ , 权重为 $c_{o} \times c_{i}$ 的全连接层</description></item><item><title>D2L-32-Convolution-卷积</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-32-Convolution-%E5%8D%B7%E7%A7%AF/</link><pubDate>Sat, 26 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-32-Convolution-%E5%8D%B7%E7%A7%AF/</guid><description>卷积 - Convolution 2022-02-26 Tags: #DeepLearning #Convolution
关键点:
Convolution Determines the Output of a System for any Input1</description></item><item><title>D2L-33-卷积神经网络CNN</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-33-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/</link><pubDate>Sat, 26 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-33-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/</guid><description>Convolutional Neural Network - 卷积神经网络 2022-02-26 Tags: #CNN #DeepLearning #Convolution
MLP的不足 随着图像分辨率的提高, MLP显露出以下不足:
假设我们的图像分辨率为 $1920\times 1080$, 那么一张图片就有 $2,073,600$ 个像素点, 假设和输入层相连的隐藏层有 $1000$ 个单元, 那么光是第一个全连接层就有大约 $2\times10^9$ ($20$ 亿) 个参数, 训练这样的网络是难以想象的, 况且这还只是网络的第一层.</description></item></channel></rss>