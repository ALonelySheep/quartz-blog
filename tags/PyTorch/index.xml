<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PyTorch on</title><link>https://alonelysheep.github.io/quartz-blog/tags/PyTorch/</link><description>Recent content in PyTorch on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 20 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/PyTorch/index.xml" rel="self" type="application/rss+xml"/><item><title>Indexing a tensor or ndarray with `None`</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/Indexing-a-tensor-or-ndarray-with-None/</link><pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/Indexing-a-tensor-or-ndarray-with-None/</guid><description>None as index 2022-04-20 Tags: #Numpy #PyTorch
None in index is equivalent to unsqueeze() Similar to NumPy you can insert a singleton dimension (&amp;ldquo;unsqueeze&amp;rdquo; a dimension) by indexing this dimension with None.</description></item><item><title>D2L-27-Computation-层和块</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-27-Computation-%E5%B1%82%E5%92%8C%E5%9D%97/</link><pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-27-Computation-%E5%B1%82%E5%92%8C%E5%9D%97/</guid><description>深度学习计算: 使用层 和块 2022-02-19 Tags: #DeepLearning #Computation #PyTorch
这一章主要介绍框架的使用细节, 最好的方法就是结合代码示例, 边运行边理解. 这里我们记录一些容易忽略的要点. 在线代码实例: 5.1. 层和块 层和块: 定义 &amp;ldquo;层&amp;quot;具有三个特征:</description></item><item><title>D2L-28-Computation-参数管理</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-28-Computation-%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86/</link><pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-28-Computation-%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86/</guid><description>深度学习计算: 参数管理 2022-02-19 Tags: #DeepLearning #Computation #Parameter #PyTorch
在线代码实例: 5.2. 参数管理 本节主要有以下内容：
访问参数，用于调试、诊断和可视化。 参数初始化。 在不同模型组件间共享参数。(保持某几个层的参数是同步的) 延后初始化 ¶ 深度学习框架无法判断网络的输入维度是什么。 这里的诀窍是框架的 延后初始化（defers initialization）， 即直到数据第一次通过模型传递时，框架才会动态地推断出每个层的大小。 这个在MXNET 和 Tensorflow 里面有, PyTorch还不太完善, 不过LazyLinear可以达到类似的功能</description></item><item><title>D2L-29-Computation-自定义层</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-29-Computation-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82/</link><pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-29-Computation-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82/</guid><description>深度学习计算: 自定义一个层 2022-02-19 Tags: #DeepLearning #Computation #PyTorch
在线代码实例: 5.4. 自定义层 我们可以通过基本层类设计自定义层。这允许我们定义灵活的新层。 在自定义层定义完成后，我们就可以在任意环境和网络架构中调用该自定义层。 层可以有局部参数，这些参数可以通过内置函数创建。</description></item><item><title>D2L-30-Computation-读写文件</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-30-Computation-%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6/</link><pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-30-Computation-%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6/</guid><description>深度学习计算: 读写文件 2022-02-19 Tags: #DeepLearning #Computation #PyTorch
在线代码实例: 5.5. 读写文件 我们可以保存一个张量, 或者张量的字典和列表 我们可以通过参数字典保存和加载网络的全部参数, 但是Pytorch中, 模型的定义需要用其他方法来保存.</description></item><item><title>D2L-31-Computation-购买与使用GPU</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-31-Computation-%E8%B4%AD%E4%B9%B0%E4%B8%8E%E4%BD%BF%E7%94%A8GPU/</link><pubDate>Sat, 19 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-31-Computation-%E8%B4%AD%E4%B9%B0%E4%B8%8E%E4%BD%BF%E7%94%A8GPU/</guid><description>深度学习计算: 购买与使用GPU 2022-02-19 Tags: #DeepLearning #Computation #PyTorch #GPU
购买与搭建计算平台: 16.4. 选择服务器和GPU
Pytorch使用GPU: 5.6. GPU — 动手学深度学习</description></item></channel></rss>