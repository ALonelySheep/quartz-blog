<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>BidirectionalRNN on</title><link>https://alonelysheep.github.io/quartz-blog/tags/BidirectionalRNN/</link><description>Recent content in BidirectionalRNN on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 18 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/BidirectionalRNN/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-59-双向循环神经网络</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-59-%E5%8F%8C%E5%90%91%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link><pubDate>Mon, 18 Apr 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-59-%E5%8F%8C%E5%90%91%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid><description>Bidirectional Recurrent Neural Networks 2022-04-18 Tags: #RNN #DeepLearning #BidirectionalRNN
双向神经网络增加了反向扫描的隐藏层, 使网络拥有了&amp;quot;前瞻能力&amp;quot; 正向层和反向层的输入是相同的, 是并行进行的, 最后正向和反向的结果一起生成输出. 在D2L教程里面将正向反向扫描的过程和隐马尔科夫模型动态规划的正向与反向传递1进行了类比: 这种转变集中体现了现代深度网络的设计原则： 首先使用经典统计模型的函数依赖类型，然后将其参数化为通用形式。</description></item></channel></rss>