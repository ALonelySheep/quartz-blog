<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ImageNet on</title><link>https://alonelysheep.github.io/quartz-blog/tags/ImageNet/</link><description>Recent content in ImageNet on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 02 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/ImageNet/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-40-AlexNet</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-40-AlexNet/</link><pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-40-AlexNet/</guid><description>AlexNet 2022-03-02 Tags: #DeepLearning #AlexNet #CNN #ImageNet
模型解析 对比LeNet 最重要的是, AlexNet导致了计算机视觉方法论的改变: 从核方法到深度神经网络, 开启了神经网络的第二次热潮 1 对比LeNet, AlexNet的主要特点有: 输入图片更 &amp;ldquo;大&amp;rdquo;, 网络结构更 &amp;ldquo;深&amp;rdquo;, 每层通道更 &amp;ldquo;多&amp;rdquo;, 滑动窗口更 &amp;ldquo;大&amp;rdquo;(核函数和池化层) 使用了ReLU作为激活函数 池化层采用了Max Pooling 使用了丢弃法(Dropout) 作为正则化方法2, 而 LeNet只采用了 权重衰减 AlexNet在训练前进行了数据增强 3</description></item></channel></rss>