<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Backpropagation on</title><link>https://alonelysheep.github.io/quartz-blog/tags/Backpropagation/</link><description>Recent content in Backpropagation on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 02 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/Backpropagation/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-55-在时间上反向传播</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-55-%E5%9C%A8%E6%97%B6%E9%97%B4%E4%B8%8A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</link><pubDate>Sat, 02 Apr 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.4/D2L-55-%E5%9C%A8%E6%97%B6%E9%97%B4%E4%B8%8A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</guid><description>Backpropagation Through Time 2022-04-02 Tags: #Backpropagation #RNN
和正向传播的时候一样, RNN在反向传播的时候需要在时间步上面进行迭代, 这可能导致梯度问题. 下面我们先大概分析在&amp;quot;时间上&amp;quot;反向传播的不同之处, 然后简要介绍一些缓解梯度问题的训练方法, 最后, 我们详细的分析一下在时间上反向传播的细节问题. 这篇笔记以 8.7. Backpropagation Through Time — Dive into Deep Learning 为基础.</description></item></channel></rss>