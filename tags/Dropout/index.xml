<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dropout on</title><link>https://alonelysheep.github.io/quartz-blog/tags/Dropout/</link><description>Recent content in Dropout on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 14 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://alonelysheep.github.io/quartz-blog/tags/Dropout/index.xml" rel="self" type="application/rss+xml"/><item><title>D2L-23-Dropout-丢弃法</title><link>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-23-Dropout-%E4%B8%A2%E5%BC%83%E6%B3%95/</link><pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate><guid>https://alonelysheep.github.io/quartz-blog/notes/2022/2022.2/D2L-23-Dropout-%E4%B8%A2%E5%BC%83%E6%B3%95/</guid><description>Dropout - 丢弃法(暂退法) 2022-02-14 Tags: #Dropout #Regularization #DeepLearning
1
Dropout就是在前向传播过程计算每一内部层的同时注入噪声, 从而提高模型的平滑性, 减少过拟合. 实现方式 实现的关键是要以一种无偏(不改变期望)的方式注入噪声.</description></item></channel></rss>