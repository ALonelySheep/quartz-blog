---
title: "D2L-51-语言的统计特征"
tags:
- all
- Zipf_Law
date: "2022-03-08"
---
# 语言的统计特征

<div align="right"> 2022-03-08</div>

Tags: #Zipf_Law 

## n元语法 n-gram
- 我们将涉及一个、两个和三个变量的概率公式的模型分别称为 “一元语法”（unigram）、“二元语法”（bigram）和“三元语法”（trigram）模型.
	$$\begin{aligned}
	&P\left(x_{1}, x_{2}, x_{3}, x_{4}\right)=P\left(x_{4}\right) P\left(x_{3}\right) P\left(x_{2}\right) P\left(x_{1}\right) \\
	&P\left(x_{1}, x_{2}, x_{3}, x_{4}\right)=P\left(x_{4} \mid x_{3}\right) P\left(x_{3} \mid x_{2}\right) P\left(x_{2} \mid x_{1}\right) P\left(x_{1}\right) \\
	&P\left(x_{1}, x_{2}, x_{3}, x_{4}\right)=P\left(x_{4} \mid x_{2}, x_{3}\right)P\left(x_{3} \mid x_{1}, x_{2}\right) P\left(x_{2} \mid x_{1}\right) P\left(x_{1}\right) \end{aligned}$$
	
	- 例如, 一阶马尔可夫模型的依赖关系为 $P\left(x_{t} \mid x_{t-1}\right)$, 对应二元语法.


## 齐普夫定律
- 在自然语言的语料库里，一个单词出现的频率与它在频率表里的排名成反比。[^1]
- 第 $i$ 个最常用单词的频率 $n_{i}$ 为：
$$n_{i} \propto \frac{1}{i^\alpha}$$ 等价于$$\log n_{i}=-\alpha \log i+c$$
- 在双对数曲线上可以表示为: 
	![](notes/2022/2022.3/assets/Zipf.svg)
- 有趣的是, 即使是多元语法的词序列也符合Zipf's Law: 
	![](notes/2022/2022.3/assets/ZipfALL.svg)
	- 这张图非常令人振奋！首先，除了一元语法词，**单词序列**似乎也遵循齐普夫定律， 并且公式中的指数 $α$ 更小 （指数的大小受序列长度的影响）。 
	- 其次，词表中 $n$ 元组的数量并没有那么大，**这说明语言中存在相当多的结构**， 这些结构给了我们应用模型的希望。 (要是语言中没有太多规律, 则n元组会更随机, 种类也会更多)

- 第三，很多n元组很少出现，这使得 [拉普拉斯平滑](notes/2022/2022.3/D2L-50-语言模型-传统模型的不足.md#拉普拉斯平滑) 非常不适合语言建模。 作为代替，我们将使用基于深度学习的模型。

[^1]: [齐普夫定律 Zipf's law - 集智百科 - 复杂系统|人工智能|复杂科学|复杂网络|自组织](https://wiki.swarma.org/index.php/%E9%BD%90%E6%99%AE%E5%A4%AB%E5%AE%9A%E5%BE%8B_Zipf%27s_law)