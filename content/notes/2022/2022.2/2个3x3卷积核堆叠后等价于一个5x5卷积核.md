---
title: "2个3x3卷积核堆叠后等价于一个5x5卷积核"
tags:
- all


---
- VGG16相比AlexNet的一个改进是**采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）**。
  - 对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。
  - **代价更小:**  [[notes/2022/2022.2/对于等价的网络, 小的卷积核参数更少]]

- 简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5x5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。

## 为什么使用2个3x3卷积核可以来代替5x5卷积核

- 5x5卷积看做一个小的全连接网络在5x5区域滑动，我们可以先用一个3x3的滤波器卷积，然后再用一个全连接层连接这个3x3卷积输出.  同时, 这个全连接层我们也可以看做一个3x3卷积层。这样我们就可以用两个3x3卷积级联（叠加）起来代替一个 5x5卷积。

- 具体如下图所示：
![](notes/2022/2022.2/assets/img_2022-10-15.jpg)

至于为什么使用3个3x3卷积核可以来代替 $7\times7$ 卷积核，推导过程与上述类似。

ref: [一文读懂VGG网络 - 知乎](https://zhuanlan.zhihu.com/p/41423739)
