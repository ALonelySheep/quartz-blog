---
title: "D2L-20-训练误差与泛化误差"
tags:
- all
- DeepLearning
date: "2022-02-12"
---
# 训练误差与泛化误差

<div align="right"> 2022-02-12</div>

Tags: #DeepLearning 

- 这一小节写的挺好的: [训练误差和泛化误差¶](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html#id2 "Permalink to this headline")

## 定义
- _训练误差_（training error）是指， 模型在训练数据集上计算得到的误差。 
- _泛化误差_（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。

- 因为我们不能得到无限多的样本, 所以我们只能估计泛化误差.

### 设置测试集的意义
- 如果我们将所有数据都用来训练, 我们就没法监控模型的泛化能力

	- 我们的目标是发现某些模式， 这些模式捕捉到了我们训练集潜在总体的规律。 如果成功做到了这点，即使是对以前从未遇到过的个体， 模型也可以成功地评估风险。 **如何发现可以泛化的模式是机器学习的根本问题**。


### 很多时候, 数据是不够用的
我们可以通过[Cross Validation](notes/2021/2021.12/Cross%20Validation.md), 来尽量增加验证集的大小